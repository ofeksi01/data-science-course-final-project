Job Title,Glassdoor Location,Employer Name,Location,Rating,Salary,Carrier Opportunities,Culure And Values,Senior Management,Comp And Benefits,Life Balance,Company Size,Found year,Description,Company Revenue,Industry,Company Type,Company Sector
Data Engineer,san-jose,"E&E Co. Ltd
3.2","Fremont, CA",3.2,Employer Provided Salary:$90K - $120K,3.0,2.8,2.9,3.1,3.1,501 to 1000 Employees,1994,"Summary
As a Data Engineer, you will be responsible for extracting, processing, and analyzing data from multiple sources to identify patterns and trends that can be used to automate marketing processes. You will design and implement automated systems to streamline marketing operations, such as data-driven decision-making, customer segmentation, and campaign targeting. You will collaborate with marketing, data analytics, and IT teams to integrate automation solutions into existing systems and workflows, ensuring data quality and accuracy throughout the process. Additionally, you will evaluate the performance of automated systems and make improvements based on feedback and data analysis. Staying up-to-date with industry trends and best practices in data engineering, marketing automation, and related technologies will be crucial to ensure the company remains competitive.
Essential responsibilities
Extract, process, and analyze data from multiple sources to identify patterns and trends that can be used to automate marketing processes.
Design and implement automated systems to streamline marketing operations, such as data-driven decision-making, customer segmentation, and campaign targeting.
Collaborate with marketing, data analytics, and IT team to integrate automation solutions into existing systems and workflows.
Evaluate the performance of automated systems and make improvements base on feedback and data analysis
Ensure data quality and accuracy throughout the automation process, including data cleaning, transformation, and validation.
Stay up-to-date with industry trends and best practices in data engineering, marketing automation, and related technologies.
Provide expertise and guidance on data engineering best practices, including data modeling, ETL processes, and data integration.
Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions.
Monitor and optimize data pipelines and automation processes for efficiency and effectiveness.
Troubleshoot and resolve data engineering and automation issues in a timely manner.
Develop and maintain documentations, including data flow diagrams, technical specifications, and use guidelines.
Stay informed about data privacy and security regulations and ensures compliance in data engineering and automation activities
Qualifications
Bachelor’s degree in computer science, data engineering, or a related field.
Strong experience in data engineering, including extracting, processing, and analyzing data from multiple sources using ETL tools, SQL, and scripting languages.
Knowledge of marketing automation tools, such as marketing automation platforms, CRM systems, and customer data Platforms (CDP).
Experience in designing and implementing automated systems for marketing operations, such as data-driven decision-making, customer segmentation, and campaign targeting.
Proficiency in data visualization tools, such as Tableau, Power BI, or similar tools.
Strong analytical skills with the ability to analyze complex data sets and identify patterns and trends.
Excellent communication skills, both verbal and written, with the ability to communicate effectively with cross-functional teams and stakeholders.
Ability to work independently and collaboratively in a fast paced, dynamic environment.
Knowledge of data privacy and security regulations, such as GDPR and CCPA, and their implications for data engineering and automation activities.
Proven track record of implementing successful data engineering and automation solutions that drive operational efficiency and effectiveness.
Ability to adapt to changing priorities and meet deadlines in a dynamic business environment
Continuous learning mindset to stay updated with the latest industry trends and best practices in data engineering, marketing automation, and related technologies.
Job Type: Full-time
Pay: $90,000.00 - $120,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Employee discount
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid time off
Referral program
Vision insurance
Experience level:
2 years
Schedule:
8 hour shift
Ability to commute/relocate:
Fremont, CA 94538: Reliably commute or planning to relocate before starting work (Required)
Experience:
ETL: 1 year (Preferred)
SQL: 1 year (Preferred)
Work Location: In person",$100 to $500 million (USD),Home Furniture & Housewares Stores,Company - Private,Retail & Wholesale
Data Analytics Engineer,san-jose,"Natron Energy
3.7","Santa Clara, CA",3.7,Employer Provided Salary:$102K,3.3,3.6,3.3,3.6,4.1,1 to 50 Employees,Company - Private,"The Data Team at Natron is responsible for the collection, management, analysis, and distribution of all the battery manufacturing and test data. The Data Team drives one of the core principles of Natron, rational decision making, by providing data for every critical decision. As a data analytics engineer on the Data Team, you will:
Be part of a small team that owns and maintains data pipelines and infrastructure for the entire company
Work closely with many positions and teams across Natron such as Data Engineers, Analysts, Test Engineers, Process Engineers, Reliability Team, R&D Team etc.
Own and develop robust and scalable analytics solutions
Contribute to the mission of building a company and a product to be proud of
Tech Stack: Python, SQL, DBT, Dagster, BigQuery, Tableau, JMP, MATLAB
Responsibilities:
Design, develop and own data analysis pipelines and models
Apply principles of electrochemical theory and statistical analysis to develop new algorithms to calculate initial and lifetime battery performance metrics
Craft compelling visualizations to depict process parameters and product performance metrics
Work with operations, product, technology, and R&D teams on their analytical needs, including identifying KPIs and supporting root cause analysis
Drive and own data quality and documentation for areas of ownership
Experience and Skills:
2+ years of industrial or academic experience developing data analysis and visualization tools
Working knowledge of electrical circuits and/or energy storage devices such batteries
Fluent in Python
Experience with SQL query writing
Familiar with version control software such as Git
Has a do-whatever-it-takes attitude, thrives in a fast-paced start up environment and can deliver project deliverables on time
A bachelor’s degree or higher in a science or engineering field, preferably Chemical Engineering, Materials Engineering, Physics or similar
Nice to have Skills:
Strong understanding of electrochemistry and battery performance testing
Experience with JMP or other statistical analysis tools
Experience with MATLAB
Familiar with dbt (data build tool)
Familiar with Dagster, AirFlow or other similar data orchestration tools
Familiar with BI tools such as Tableau, Looker, Power BI etc.
Logistics:
Compensation: competitive with other data analytics engineer positions at pre-revenue Bay Area startup companies
Hours and duration: permanent position, full time
Location: Hybrid (Santa Clara, CA)
Compensation/Pay Transparency:
Disclaimer: The actual salary of a successful applicant may vary from posted ranges based on the candidate’s experience, knowledge, skills, and abilities, internal equity and alignment with market data, and other legitimate business reasons, including, but not limited to, compliance with applicable immigration law prevailing wages.
In addition, Natron Energy has a strong benefits package including Medical, Dental, Vision, 401k Plan, Life Insurance, and Flexible Time Off and Personal Time Off for Exempt and Non-Exempt employees respectively.
The salary range for this position is a minimum of $102,000 and a maximum of $148,000.
About Us:
Natron Energy (natron.energy) is the future of energy storage. Natron Energy’s battery products solve operations performance and reliability problems for the world’s biggest electricity customers. Natron Energy’s initial products target markets exceeding $25B including data centers, oil & gas, EV fast charging, and commercial aviation. Natron Energy has additional products in development for >$50B markets including commercial and residential grid storage. Its products are based on sodium-ion cells containing Prussian blue electrodes that deliver unique power, cycle life, and safety: full discharge and recharge in just minutes and up to 50,000 deep discharge cycles from a nonflammable, fault tolerant system. Natron Energy’s current production is sold out for the next 12 months. The company has signed over $225M/year in master sales agreements and LOIs, and scale-up to mass production is now underway. Natron Energy has raised over $155M in venture capital investment to date, as well as $35M in non-dilutive funding to support its supply chain scale up. The company has a strong leadership team that includes world-class C and VP level strategy, sales, operations, and technology executives.
Quick Facts:
Founded in 2012 as a Stanford spin out
Now selling the world’s first UL certified Na-ion product in $9B data center market, with $700k shipped and $1.5M booked
First product (battery tray for in-rack power) is fully de-risked and sold out through Q1 2023
Second product (ultra high-power battery rack services) launched in 2022
What differentiates Natron Energy from other battery companies?
Natron Energy solves the problems created by lead acid and lithium-ion technology:
Higher power discharge and faster recharge
A smaller footprint for high power leaves more space to generate revenue
Fast recharge results in higher system uptime
Industry leading service life
Tens-of-thousands of charge-discharge cycles enables real-time peak saving of volatile electrical loads
Predictable degradation without surprise failures
Nonflammable
The only battery that cannot start a fire
Customers gain confidence and save on fire mitigation costs
Natron Energy is proud to be an equal opportunity employer. We value diversity. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.

If you need assistance or an accommodation due to a disability, you may contact us at: jobs@natron.energy",-1,-1,Less than $1 million (USD),-1
Data Engineer,san-jose,"Hermitage Infotech
3.5","Cupertino, CA",3.5,$99K - $139K (Glassdoor est.),3.7,3.8,3.8,3.7,3.9,1 to 50 Employees,Company - Private,"Hi,

Given below is the urgent req for my client.. If you are comfortable with it, available and looking for a project please send me your profile immediately in word document along with your expected hourly salary on CTC/1099 or yearly salary on W2. Please mention your work authorization and your availability to start the project.
Position: Data Engineer

Duration: Long Term

Location: CA

From Day 1 onsite

Main Skillsets:
Experience with Advance SQL, Snowflake, Tableau, Python is a must. ETL experience is also preferred. Should be able to work in a fast paced environment. Perform effectively under dynamic conditions such as directional changes, tight deadlines.

Years of experience - 3 - 7 years of experience.

Regards
Varma
732-338-7524",-1,Information Technology,Information Technology Support Services,$1 to $5 million (USD)
Data Center Facility Engineer IV (night shift),san-jose,"Equinix
4.2","San Jose, CA",4.2,-1,-1,-1,-1,-1,-1,10000+ Employees,1998,"Data Center Facility Engineer IV (night shift)
Equinix is the world’s digital infrastructure company, operating 245+ data centers across the globe and providing interconnections to all the key clouds and networks. Businesses need one place to simplify and bring together fragmented, complex infrastructure that spans private and public cloud environments. Our global platform allows customers to place infrastructure wherever they need it and connect it to everything they need to succeed.
We are a fast-growing global company with 20 years of continuous growth. Through our innovative portfolio of high-performance products and services, we have created the largest, most active global ecosystem of 10,000+ companies, including 2,100 networks and 3,000+ cloud and IT service providers in 32 countries spanning six continents.
Joining our operations team means that you will be at the forefront of all we do, maintaining critical facilities infrastructure as part of a close-knit team delivering best-in-class service to our data center customers. We embrace diversity in thought and contribution and are committed to providing an equitable work environment. that is foundational to our core values as a company and is vital to our success.
Do you want to be at the forefront of maintaining critical facilities infrastructure? Would you enjoy being part of a close-knit team delivering outstanding service to our data center customers? Then read on about the role and requirements for an Equinix Critical Facilities Engineer!
Data Centers are considered Critical Facilities. This means that we support hospitals, laboratories, public safety centers. Simply put - We cannot go dark. In this crucial role, a Critical Facilities Engineer:
Maintains datacenter infrastructure systems in a mission-critical, high-risk and high-reliability environment.
Operates, maintains, and repairs multiple critical and non-critical facility components, including: HVAC (heating, cooling, and ventilation) systems, plumbing, fire control and suppression, roofing systems and exterior grounds.
Has proficient understanding of critical facility components that may be impacted by failures or malfunctions of infrastructure systems.
Evaluates facility standards and practices to ensure efficient operations for maintaining and monitoring facilities systems.
Responds to emergency situations and ensures corrective measures are rapid and detailed.
Participates in the planning and installing of new facility systems.
Responsibilities in facility and infrastructure maintenance include performing preventative and corrective maintenance checks on-site to facility components, repairs, maintenance, installations and on-site inspections to facility systems. Support energy efficiency measures. Monitor and resolve Building Monitoring System (BMS) alarm issues. Operate and maintain plumbing, fire suppression, and safety systems.
Supports the work approval process for vendors/service providers on maintenance work, by briefing at the start of work, supervising work during the day workday/shift and final review of the work carried out. Ensures vendor maintenance activities are carried out as per Equinix's standard operating procedures. Cooperate with vendors in modifying technical files for plants and equipment ensuring files and builds are up-to-date.
Site administration and incident support responsibilities include performing site logs for permits, such as Maintenance Operation Protocol (MOPs) and scripts. Identify Single Points of Failure (SPOFs) and make recommendations. Respond to all on-site incidents, including failures, problems and delays. Display substantial understanding in following operating procedures to support on-site administration.
Completes routine work requests and circuit installations, troubleshoots and maintains office equipment (if needed); supports auxiliary equipment and machines with problem solving and repairs to avoid/minimize downtime. Makes minor changes to mechanical, electrical and specialized systems, as directed. Carries out infrastructure projects.
Collaborates with others to resolve moderately difficult facility incidents. Optimally collaborates within the department; may mentor team members on general maintenance activities. Notifies team members of inventory needs in order to maintain optimal stock levels of critical parts and equipment. May recommend infrastructure projects.
This is a 12 hour night shift. Beginning Week shift is Sunday through every other Wednesday. End Week shift is every other Wednesday through Saturday.
Qualifications
Demonstrated commercial MEP (mechanical/HVAC and/or electrician) experience
Experience working in a critical facility
High School Diploma
A natural curiosity and strong troubleshooting skills
Currently reside in the United States
You perform all essential job functions, including walking, standing, bending, stooping, climbing, lifting and manual dexterity, with or without reasonable accommodation
You are available to work days/nights/weekends/holidays, if needed and/or required as part of our 365/24/7 operation
You can lift heavy equipment/items up to 50 pounds
The targeted pay range for this position in the following location is / locations are:
San Francisco, CA / Bay Area: $69,000 to $107,000
Our pay ranges reflect the minimum and maximum target for new hire pay for the full-time position determined by role, level, and location. Individual pay is based on additional factors including job-related skills, experience, and relevant education and/or training.
This position may be offered in other locations. Your recruiter can share more about the specific pay range for your preferred location during the hiring process.
The targeted pay range listed reflects the base pay only and does not include bonus, equity, or benefits. Employees are eligible for bonus, and equity may be offered depending on the position.
More details about our company benefits can be found at the following link:
https://equinixbenefits.us.newsweaver.com/icfiles/201/1002910/1057118/1171391/921bc962bf0e0352cb2d6c93/equinix%202023%20oe%20ebook_rev122022%20-%20final.pdf
Equinix is committed to ensuring that our employment process is open to all individuals, including those with a disability. If you need assistance in applying for an open position, you may send an email to Staffing@equinix.com. Please provide your contact information and let us know how we can assist you.
Equinix is an Equal Employment Opportunity and, in the U.S., an Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to unlawful consideration of race, color, religion, creed, national or ethnic origin, ancestry, place of birth, citizenship, sex, pregnancy / childbirth or related medical conditions, sexual orientation, gender identity or expression, marital or domestic partnership status, age, veteran or military status, physical or mental disability, medical condition, genetic information, political / organizational affiliation, status as a victim or family member of a victim of crime or abuse, or any other status protected by applicable law.",$1 to $5 billion (USD),Enterprise Software & Network Solutions,Company - Public,Information Technology
Data Engineer III,san-jose,"Intelliswift Software, Inc.
4.2","Menlo Park, CA",4.2,Employer Provided Salary:$80.00 - $90.00 Per Hour,4.1,4.1,4.0,3.9,4.1,1001 to 5000 Employees,2001,"Job Title: Data Engineer III
Duration: Longterm Contract
Location: Menlo Park, CA
Pay Range: $80-$90/hr
Intelliswift Software Inc. conceptualizes, builds, and supports the world's most amazing technology products and solutions. Our team of rich experts from diverse backgrounds contributes to making Intelliswift one of the most reliable partners in IT and Talent solutions. We specialize in delivering world-class Digital Product Engineering, Data Management and Analytics, and Staffing Solutions services to Fortune companies, SMBs, ISVs, and fast-growing startups.

Job Description: Onsite at Menlo Park location only.
Summary:
The main function of the Data Engineer is to develop, evaluate, test and maintain architectures and data solutions within our organization. The typical Data Engineer executes plans, policies, and practices that control, protect, deliver, and enhance the value of the organization’s data assets.

Job Responsibilities:
Design, construct, install, test and maintain highly scalable data management systems.
Ensure systems meet business requirements and industry practices.
Design, implement, automate and maintain large scale enterprise data ETL processes.
Build high-performance algorithms, prototypes, predictive models and proof of concepts.

Skills:
Ability to work as part of a team, as well as work independently or with minimal direction.
Excellent written, presentation, and verbal communication skills.
Collaborate with data architects, modelers and IT team members on project goals.
Strong PC skills including knowledge of Microsoft SharePoint.

Education/Experience:
Bachelor's degree in a technical field such as computer science, computer engineering or related field required.

Process certification, such as, Six Sigma, CBPP, BPM, ISO 20000, ITIL, CMMI.",$100 to $500 million (USD),Software Development,Company - Private,Information Technology
"Engineer, Data",san-jose,"Ayar Labs
4.6","San Jose, CA",4.6,Employer Provided Salary:$115K - $142K,4.3,4.0,3.8,4.3,3.8,51 to 200 Employees,Company - Private,"Job Title: Data Engineer:

We are seeking a Data Engineer to design, build, and maintain the infrastructure necessary for the automated storage, processing, and analysis of measurement data and design information. As a Data Engineer, you will be responsible for the entire lifecycle of data pipeline development. This includes working with small, manually generated input datasets with a wide variety of formats, and later developing highly automated and rigorously defined pipelines. In addition, you will drive the adoption of data format specifications from manufacturing suppliers, as well as adhere to data format specifications from customers.

The Test Team is responsible for systems that collect measurements for the Design Teams (R&D, product development), Manufacturing and Operations (quality control screens), and Reliability Teams (product qualification, ongoing reliability testing). You will collaborate with Test Engineers to automate raw-to-parametric data processing in hands-off pipelines and provide Python tools and frameworks for data producers and consumers. This opening is our second Data Engineer on the team. Code for extracting and storing parameters from raw data has been written by many different stakeholders in many different styles, but within Ayar Labs Engineering you will find a collaborative atmosphere with people eager to help our new data engineering development efforts succeed in owning and developing this code into uniform, scalable, professionally maintained systems.

Responsibilities:
Developing, maintaining, and scaling data pipelines: Designing, developing, and maintaining ETL pipelines to extract data from various sources, transform it, and load it into a data warehouse or other data storage systems.
Building and maintaining data infrastructure: Designing and maintaining data storage and processing systems such as databases, data lakes, and data warehouses.
Ensuring data quality and integrity: Ensuring the accuracy, consistency, and reliability of the data by developing and implementing data validation and testing strategies.
Collaborating with data scientists and analysts: Working closely with data scientists and analysts to understand their data needs and help them to access and analyze data effectively.
Automating data processing tasks: Developing automation scripts to perform routine data processing tasks, such as data cleaning, data transformation, and data loading.
Implementing data security and access controls: Ensuring the security and privacy of data by implementing data access controls, data encryption, and data masking.
Staying up-to-date with the latest technologies: Keeping up-to-date with the latest technologies, trends, and best practices in data engineering and applying them to improve the efficiency and effectiveness of data processing and analysis.
Requirements:
Bachelor’s Degree in Computer Science, Software Engineering, or similar with emphasis on Data Engineering; OR Bachelor’s degree in Applied Physics, Engineering, or similar with 3 years of experience in a Data Engineering role
Experience processing test and measurement data from electronic engineering, photonics, or similar; and meeting requirements of internal data customers in R&D, product engineering, or manufacturing
Proficiency in Python, NumPy, Pandas, git.
Experience with Extract, Transform, Load and/or Extract, Load, Transform paradigms.
Baseline proficiency with statistical analysis.
Experience with data modeling, data warehousing, and ETL tools.
Excellent communication and collaboration skills - must be able to present plans, gather feedback, and proactively seek information relevant to assigned projects.
Preferences:
Familiarity with Dagster or other data orchestration tools
Proficiency with SQL and relational database systems
Domain-specific knowledge in electronics or photonics test and measurement, or background in electronic or photonic experiments.
Experience with MongoDB.
Familiarity with cloud computing platforms such as AWS, Azure, or Google Cloud Platform.
If you are a Data Engineer with a passion for building and maintaining data infrastructures, we encourage you to apply for this exciting opportunity.
Salary Range: $115K to $142K
NOTE TO RECRUITERS:
Principals only. We are not accepting resumes from recruiters for this position. Remuneration for recruiting activities is only applicable subject to a signed and executed agreement between the parties. Please don’t send candidates to Ayar Labs, and do not contact our managers.
About Ayar Labs:
At Ayar Labs we’re about to revolutionize computing by moving data with light. We’re unleashing processing power for artificial intelligence, high performance computing, cloud and telecommunications by removing the bottlenecks created by today’s electrical I/O - making it possible to continue scaling computing system performance. Ayar Labs is the first to deliver an optical I/O solution that combines in-package optical I/O chiplets and multi-wavelength remote light sources to replace traditional electrical I/O. This silicon photonics-based I/O solution enables chips to communicate with each other from millimeters to kilometers, to deliver orders of magnitude improvements in latency, bandwidth density, and power consumption.

With our strong collaborations with industry leaders and government, our deep ties to MIT and UC Berkeley, and our commitment to hiring the best engineers in photonics and electronics, joining our team gives you the opportunity to collaborate with renowned experts on challenging, paradigm-shifting work.

We are passionate about delivering in-package optical I/O at scale, leveraging the strength of our patent portfolio and our team of leading interdisciplinary experts. We believe that deep cross-collaboration between teams facilitated by honest, open debate is the best way to drive innovation and achieve big wins. Join our team and experience the possibilities.

Resources:
Executives from Intel and GLOBALFOUNDRIES share their thoughts on Ayar Labs and the promise of in-package optical I/O (video)
Ayar Labs in the News and Recent announcements
LinkedIn and Twitter

Ayar Labs is an Affirmative Action/Equal Opportunity Employer and is strongly committed to all policies which will afford equal opportunity employment to all qualified persons without regard to age, national origin, race, ethnicity, creed, gender, disability, veteran status, or any other characteristic protected by law.",-1,-1,Unknown / Non-Applicable,-1
"Data Engineer (Python, SQL)",san-jose,"Iron Service Global Inc
3.4","Menlo Park, CA",3.4,Employer Provided Salary:$110K - $135K,3.2,3.2,3.3,3.5,3.4,201 to 500 Employees,1987,"Data Analytics & Engineering - Data Engineer III
Job Description: Onsite at Menlo Park location only.
Summary:
The main function of the Data Engineer is to develop, evaluate, test, and maintain architectures and data solutions within our organization. The typical Data Engineer executes plans, policies, and practices that control, protect, deliver, and enhance the value of the organization’s data assets.
Job Responsibilities:
Design, construct, install, test, and maintain highly scalable data management systems.
Ensure systems meet business requirements and industry practices.
Design, implement, automate and maintain large scale enterprise data ETL processes.
Build high-performance algorithms, prototypes, predictive models and proof of concepts.Skills:
Ability to work as part of a team, as well as work independently or with minimal direction.
Excellent written, presentation, and verbal communication skills.
Collaborate with data architects, modelers and IT team members on project goals.
Strong PC skills including knowledge of Microsoft SharePoint
Strong Python/SQL experience
Education/Experience:
Bachelor's degree in a technical field such as computer science, computer engineering or related field required.
Process certification, such as, Six Sigma, CBPP, BPM, ISO 20000, ITIL, CMMI.
Job Types: Full-time, Contract
Salary: $110,000.00 - $135,000.00 per year
Benefits:
Dental insurance
Health insurance
Life insurance
Paid time off
Vision insurance
Schedule:
8 hour shift
Day shift
Monday to Friday
Ability to commute/relocate:
Menlo Park, CA: Reliably commute or planning to relocate before starting work (Required)
Experience:
ETL: 5 years (Preferred)
Data management: 5 years (Preferred)
Enterprise data ETL processes: 5 years (Preferred)
Business process modeling: 5 years (Preferred)
License/Certification:
Six Sigma (Preferred)
ISO 20000 (Preferred)
ITIL (Preferred)
Work Location: One location",$25 to $100 million (USD),Information Technology Support Services,Company - Private,Information Technology
"Data Engineer, Product Analytics - Monetization",san-jose,"Meta
3.9","Menlo Park, CA",3.9,Employer Provided Salary:$109K - $166K,4.0,3.7,3.3,4.6,3.6,10000+ Employees,2004,"From making valuable connections between people and businesses to building premium services that deliver high-value experiences, the monetization organization at Meta empowers people and businesses to succeed in the global economy. As Meta focuses on building the next evolution of social experiences, the monetization team plays a crucial role in shaping the communication pathways and financial tools that all sized businesses, especially small to medium ones, need to thrive in the new digital economic environment. And we achieve that from end-to-end product and technology innovation.As a data engineer on the monetization team at Meta, you can help build cutting-edge full-stack technologies that will transform the way people and businesses connect and communicate. You’ll help develop industry-leading solutions that power next-generation, large-scale platforms and AI services to help connect billions of people around the world.


Data Engineer, Product Analytics - Monetization Responsibilities:
Manage and execute data warehouse plans for a product or a group of products to solve well-scoped problems
Identify the data needed for a business problem and implement logging required to ensure availability of data, while working with data infrastructure to triage issues and resolve
Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights in a meaningful way
Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership
Design, build and launch new data models and visualizations in production, leveraging common development toolkits
Independently design, build and launch new data extraction, transformation and loading processes in production, mentoring others around efficient queries
Support existing processes running in production and implement optimized solutions with limited guidance
Define and manage SLA for data sets in allocated areas of ownership



Minimum Qualifications:
Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
2+ years of work experience in data engineering
Experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.)



Preferred Qualifications:
Experience with one or more of the following: data processing automation, data quality, data warehousing, data governance, business intelligence, data visualization, data privacy
Experience working with terabyte to petabyte scale data





Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics. You may view our Equal Employment Opportunity notice here. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. We may use your information to maintain the safety and security of Meta, its employees, and others as required or permitted by law. You may view Meta's Pay Transparency Policy, Equal Employment Opportunity is the Law notice, and Notice to Applicants for Employment and Employees by clicking on their corresponding links. Additionally, Meta participates in the E-Verify program in certain locations, as required by law",$10+ billion (USD),Internet & Web Services,Company - Public,Information Technology
Data Engineer,san-jose,Strivernet RPO Services Ltd,"Santa Clara, CA",-1,Employer Provided Salary:$90.00 - $95.00 Per Hour,-1,-1,-1,-1,-1,Unknown,Company - Public,"(W2 CANDIDATES ONLY) (SANTA CLARA, CA)
PLEASE SHARE UPDATED RESUMES AS PER THE JD
Following skills sets is must
1. 5 years of hands-on experience working on data using SQL on multiple platforms (SQL server, my SQL, NoSQL, Snowflake, Mongo) (required)
2. 4 years of hands-on experience with Python and C# programming (required)
3. 4 years of hands-on AWS Stack (S3, CLI, Lamdba, SNS,SQS)
4. 3-4 years of hands-on experience with Application Development Skills - web based or service based (required)
5. 3 years of hands-on experience with ETL tools and automation (required)
6. 2 years experience of using statistics for data modeling and predictions
BS degree: 7-9 years of hands-on experience MS degree- 4-5 years of hands-on experience In order to perform the responsibilities of this position, the individual must have:
M.S. in Computer Science, Software/Computer Engineering, or Applied Math with minimum of 4 years industry experience or B.S. degree with minimum (7) years industry experience
Demonstrated excellent communication skills both written and verbal
Ability to independently work with services team to gather product requirements and manage development life cycle
Demonstrated ability to work on large data sets
Interested in early pipeline research and development/prototype efforts
Proficient with relational SQL ( Microsoft SQL , MySQL, Snowflake Postgres, Mongo, NoSQL etc.)
Proficient in two of Python, C#
Solid knowledge of statistics
Proficient in AWS (S3,CLI, Lambda, SNS, SQS)
Good understanding of Event driven workflows and patterns
Proficient in Dockers/Containers
Any experience in the following would be ideal
o EKS or Kubernetes o Elastic Search - ELK
o Database design and management
o CI/CD pipeline and Build tools such as Jenkins, CircleCI, GitLab etc.
Job Type: Contract
Salary: $90.00 - $95.00 per hour
Experience level:
8 years
9 years
Schedule:
8 hour shift
Experience:
Python and C# programming: 3 years (Required)
SQL server, my SQL, NoSQL, Snowflake, Mongo: 3 years (Required)
Data modeling: 6 years (Required)
ETL tools: 5 years (Required)
Application development: 5 years (Required)
AWS Stack (S3, CLI, Lamdba, SNS,SQS: 4 years (Required)
Work Location: On the road",-1,-1,Unknown / Non-Applicable,-1
Data Engineer Leader,san-jose,"Synopsys
4.1","Mountain View, CA",4.1,Employer Provided Salary:$117K - $204K,3.9,4.1,3.8,3.8,4.0,10000+ Employees,Company - Public,"44867BR
USA - California - Mountain View/Sunnyvale
Job Description and Requirements
The Synopsys Central Engineering team is tasked to digitize Synopsys product development activities. We will achieve it by identifying areas of improvement and correlating various aspects of the product development, and providing all levels of management visibility for action. The domain areas we are focused on relate to Quality, Productivity, and Operational Efficiency,

We are looking for an experienced Data Engineer who will contribute to building the next-generation Data Platform. As a Data Engineer, you will be working on modern, large-scale big data technologies to build data platforms on Snowflake and toolset. The goal is to create an effective and efficient data pipeline to facilitate data exchange between various applications.

In this role, you will be partnering with data providers to enable them to make available volumes of data and integrate in a common data platform. You will also interact with Data analysts to transform data into information and insights driving data-based strategic outcomes. This is a hands-on role, and you are joining the team near the beginning of our journey where you can help shape our way to manage big data.

Responsibilities:
Drive strategic goal of data consolidation for the whole of engineering to enable cross-domain analytics.
Own and establish Center of Excellence for Data Engineering practices by defining architecture, rules, and setting guardrails for data processing capabilities. This includes data Ingestion, quality control, transformation, and high availability.
Incorporate state-of-the-art practices in Data Engineering to scale the value we deliver in transforming data into insights.
Identify, design and implement internal process improvements, including data infrastructure, for scalability, optimizing data delivery, and automating manual processes.
Leverage your experience and proficiency in all aspects of data management, data cataloging, analytics solution architecture & design, and implementation roadmap.
Build data cataloging infrastructure and metadata platform to enable data discovery, data observability, and federated governance.
Drive cross-team projects to integrate data from numerous separate sources into a unified data environment.

Expertise & Skills:
Must be proficient in ELT (Extract-Load-Transform) process with hands-on experience.
Must be detailed-oriented with a passion for data accuracy and reliable solution development.
Subject Matter Resource in designing and building high performance data pipelines to move and process data using modern tools.
Experience in Data Engineering Architecture and Design.
Subject Matter Resource in SQL (advanced).
Experience in at least one prominent programming language, such as Python (preferred), or Java.
The ability to work with other team members, drive projects to completion, and work autonomously.
Excellent written and verbal communication, work autonomously, and have proven organizational and planning skills.
We also value:
Prior experience in leading Data or Analytics teams.
Experience in database design and management, such as MS SQL Server, Oracle Database, MySQL Database, Cassandra, MongoDB, etc
Familiarity and experience in Snowflake toolset is a proven asset for this position.
Experience with Power BI and/or Tableau or other visualization tools.
Experience with HVR and Fivetran a plus.
Experience with dbt Cloud a plus.

Requirements:
Bachelor's or master's Degree in a quantitative field
> 5-10 years of relevant experience
5+ years’ experience engineering and operationalizing data pipelines with large and complex datasets
3+ years’ experience working with Cloud technologies such as Snowflake

At Synopsys, we’re at the heart of the innovations that change the way we work and play. Self-driving cars. Artificial Intelligence. The cloud. 5G. The Internet of Things. These breakthroughs are ushering in the Era of Smart Everything. And we’re powering it all with the world’s most advanced technologies for chip design and software security. If you share our passion for innovation, we want to meet you.

Stay Connected: Join our Talent Community

The hourly range across the U.S. for this role is between $117,000 - $204,000. In addition, this role may be eligible for an annual bonus, equity, and other discretionary bonuses. Synopsys offers comprehensive health, wellness, and financial benefits as part of a comparative total rewards package. The actual compensation offered will be based on a number of job-related factors, including location, skills, experience, and education. Your recruiter can provide more specific details on the total rewards package upon request.

Inclusion and Diversity are important to us. Synopsys considers all applicants for employment without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, military veteran status, or disability.

Job Category
Engineering
Country
United States
Job Subcategory
R&D Engineering
Hire Type
Employee
Base Salary Range
$117,000 - $204,000",-1,Information Technology,Computer Hardware Development,$1 to $5 billion (USD)
"Technical Support Engineer (L5) - Data Platform, Online Data Stores",san-jose,"Netflix
4.3","Los Gatos, CA",4.3,$56K - $85K (Glassdoor est.),3.9,4.2,3.8,4.6,3.9,5001 to 10000 Employees,1997,"Los Gatos, California
Core Engineering
Netflix is the world’s leading streaming entertainment service with 220 million paid memberships in over 190 countries, enjoying TV series, documentaries, and feature films across a wide variety of genres and languages. Members can watch as much as they want, anytime, anywhere, on any internet-connected screen.

About the Engineering Support Organization
The aim of the Engineering Support Organization is to enable Platform Engineering to effectively and sustainably scale the support they provide to their customers. The team is the frontline resource for the engineering support needs of our customers (i.e., our workforce) - handling, troubleshooting, and resolving customer requests and issues. In addition, the team will focus on ways of working, customer advocacy, support tooling, platform product offerings, documentation, and developer education.

Our Mission
Deliver an excellent support experience to Netflix’s developer community. To advocate for our customers, follow through on issues and resolve them in a reasonable time. If blockers prevent immediate resolution, we communicate status and ensure there is visibility into why there is a delay.

Provide insights, feedback and champion customer sentiment about the tools we support to our partners across Productivity and Data Platform Engineering. Partner with Product Management, Developer Education and Engineering to track and maintain visibility into ongoing issues and communicate customer needs to ensure improving in these areas is prioritized.

Drive collaboration efforts to reduce product friction and increase usability so that Platform Engineering can build, deploy and deliver highly functional solutions for the Developer Community.

The Role
We are looking for a Technical Support Engineer with a passion for data platform infrastructure and tooling, customer service, and automation. You will be responsible for monitoring and handling our customers’ requests, troubleshooting, solving issues, automating support needs, developing support documentation and runbooks, improving and maintaining support tools and automation, understanding our product offerings, and continuously looking for ways to improve the engineering support experience.

Our ideal team member has previous experience supporting or working in a data platform engineering environment with specific experience working in customer-facing, engineering support roles and has knowledge of infrastructure, internal tooling, platforms, and cloud computing. You are excellent at understanding and solving complex and ambiguous problems and constantly seek improvement. As an Engineer in this role, we need a candidate who can understand our complex offerings on a technical level, be hands-on in the development of our support automation tooling, and recommend product and operational improvements based on customer interactions.
Location
Our offices are located in Los Gatos.
What you’ll need to be successful:
You are skilled in providing superior customer support across a complex organization, ideally as part of a central team
You are passionate about customer experience
You are a data-driven decision-maker
You have excellent communications skills and appreciate the importance of comprehensive documentation
You have experience operating and using one (or more) of the following: Relational databases (e.g. MySQL), NoSQL databases (e.g. Cassandra) or Caching systems like Redis and Memcached
You have experience with scripting/automation, APIs, development, automation tools, and are comfortable with at least one programming language
You excel in developing tooling and automation to improve process and reduce toil
You are able to develop metrics and dashboards and have the skills to build them using industry standard tooling
You have worked with high RPS distributed systems
You understand importance of observability and have used monitoring systems (e.g. Atlas, Prometheus)
Looking at logs doesn’t scare you and you are familiar with distributed tracing systems like Zipkin
Nice to have
You have previous AWS administration experience
Our culture is unique, and we tend to live by our values, allowing you to do your best work and grow. To learn more about Platform Engineering, feel free to listen to this podcast.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity of thought and background builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

At Netflix, we carefully consider a wide range of compensation factors to determine your personal top of market. We rely on market indicators to determine compensation and consider your specific job family, background, skills, and experience to get it right. These considerations can cause your compensation to vary and will also be dependent on your location.

The overall market range for roles in this area of Netflix is typically $100,000 - $700,000

This market range is based on total compensation (vs. only base salary), which is in line with our compensation philosophy. Netflix is a unique culture and environment. Learn more here.",$5 to $10 billion (USD),Internet & Web Services,Company - Public,Information Technology
Data Engineer,san-jose,"Fresh Consulting
3.9","Menlo Park, CA",3.9,Employer Provided Salary:$70.00 - $80.00 Per Hour,3.7,3.8,3.5,3.6,4.2,201 to 500 Employees,2007,"Fresh Consulting is a design-led, software development and hardware engineering company, offering end-to-end digital services to help companies innovate. We bring together amazing UX designers, sophisticated developers, digital strategists, and top-notch engineers to help companies create fresh experiences that connect humans, systems, and machines. We’ve been growing fast and need someone to help us continue to manage the delivery of high-quality work in a fast-paced environment.
See more at freshconsulting.com Visit freshconsulting.com/portfolio to see our project work across several industries.
View and apply to all jobs - https://freshconsulting.applytojob.com/apply/ or visit freshconsulting.com/careers
Title: Data Engineer
Duration: 6 months with possible extension
Location: Onsite Menlo Park, CA
Benefits: Employee benefits at 100% including Medical, PTO, Holiday Pay, 401K Plan, and much more!
Hours: Minimum 40 Hours/Week
Role:
Design, construct, install, test, and maintain highly scalable data management systems.
Ensure systems meet business requirements and industry practices.
Design, implement, automate, and maintain large-scale enterprise data ETL processes.
Build high-performance algorithms, prototypes, predictive models, and proof of concepts.
Skills:
5+ years of work experience as a Data Engineer.
Ability to work as part of a team, as well as work independently or with minimal direction.
Excellent written, presentation, and verbal communication skills.
Collaborate with data architects, modelers, and IT team members on project goals.
Strong PC skills including knowledge of Microsoft SharePoint.
Process certification, such as Six Sigma, CBPP, BPM, ISO 20000, ITIL, and CMMI.
Education: BSCSE or related.
FRESH-
Work on engineering and research assignments with F500 companies and startups.
The relationships that we have created with our clients are one of a kind.
We help solve problems in many technologies focusing on R&D, product development, and manufacturing.
We work with the most cutting-edge and latest technologies from AR/VR to Autonomous technologies.
Closely working with our clients, we believe that long-term investments are extremely important to maintain the culture we together have created.
We’re a handpicked team of Engineers, digital strategists, designers, and developers united together in creating a fresh experience. Whether we are strategizing, designing, developing, or analyzing, our integrated team works as an extension of yours to improve your impact, your usability, and your customer conversion. In the process, we collaborate with you to get to know your business, understand your industry, and incorporate your big ideas into memorable experiences that keep your customers coming back for more.
Equal employment opportunity: All qualified persons will be considered for employment without regard to race, color, religion, sex, national origin, age, marital status, familial status, gender identity, sexual orientation, disability for which a reasonable accommodation can be made or any other status protected by law. Assistance will be gladly provided upon request for any applicant with sensory or non-sensory disabilities.
Fresh Consulting is a participating E-Verify company.
freshconsulting.com
Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Range $70/hr - $80/hr.
ylM5WIC1Wr",$25 to $100 million (USD),Business Consulting,Company - Private,Management & Consulting
Senior Data Science Engineer,san-jose,"Adobe
4.4","San Jose, CA",4.4,Employer Provided Salary:$140K - $261K,4.0,4.4,3.9,4.4,4.3,10000+ Employees,1982,"Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

Our Company
Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to craft and deliver exceptional digital experiences! We’re passionate about empowering people to create appealing and powerful images, videos, and apps, and transform how companies work well with customers across every screen. cur
We’re on a mission to hire the very best and are committed to crafting exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new insights can come from everywhere in the organization, and we know the next big idea could be yours!

Responsibilities:
Design, architect and build data insight dashboards and visualizations.
Provide reports related to large-scale data metrics related but not limited to data coverage, freshness, quality.
Work closely with data platform engineers and architects to identify requirements in order to improve the flawless operation of the data platform for machine learning and data science needs.
Lead and operate large-scale ETL pipelines in collaboration with other teams such as data platform engineering etc.
Write high quality, product level code that is easy to maintain and test following standard methodologies. Key skill requirements:
7+yrs of proficiency in Python and SQL
Expert in one or more data science tools such as Pandas, Numpy, Octave, R
Experience building data processing machine learning models in a product environment (5+ yrs)
Experience with machine learning (ML) frameworks such as Scikit Learn, TensorFlow, Pytorch
Strong fundamentals in statistics as well as shown skills in data visualizations.
Hands on experience with high-dimensional, large datasets
Understanding of concepts in machine learning for data processing (e.g. Anomaly detection, etc.)
Experience with A/B testing and sampling methods
B.S., M.S, or Ph.D. in Computer Science, Computer Engineering, Statistics, Mathematics, Physics or a related area
At Adobe, you will be immersed in an exceptional work environment that is recognized around the world. You will also be surrounded by colleagues who are committed to helping each other grow through our outstanding Check-In approach where ongoing feedback flows freely. If you’re looking to make an impact, Adobe's the place for you. Discover what our employees are saying about their career experiences on the Adobe Life blog and explore the significant benefits we offer. M
Adobe is an equal opportunity and affirmative action employer. We welcome and encourage diversity in the workplace regardless of gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other characteristics protected by law.
If you have a disability or special need that requires accommodation to navigate our internal careers site or to complete the application process, please contact accomodations@adobe.com
Our compensation reflects the cost of labor across several U.S. geographic markets, and we pay differently based on those defined markets. The U.S. pay range for this position is $140,200 -- $261,400 annually. Pay within this range varies by work location and may also depend on job-related knowledge, skills, and experience. Your recruiter can share more about the specific salary range for the job location during the hiring process.

At Adobe, for sales roles starting salaries are expressed as total target compensation (TTC = base + commission), and short-term incentives are in the form of sales commission plans. Non-sales roles starting salaries are expressed as base salary and short-term incentives are in the form of the Annual Incentive Plan (AIP).

In addition, certain roles may be eligible for long-term incentives in the form of a new hire equity award.

Adobe is proud to be an Equal Employment Opportunity and affirmative action employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.

Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.

Adobe values a free and open marketplace for all employees and has policies in place to ensure that we do not enter into illegal agreements with other companies to not recruit or hire each other’s employees.",$5 to $10 billion (USD),Computer Hardware Development,Company - Public,Information Technology
Biomedical Data Engineer - Health Technologies,san-jose,"Apple
4.2","Cupertino, CA",4.2,-1,-1,-1,-1,-1,-1,10000+ Employees,1976,"Summary
Posted: Aug 8, 2022
Weekly Hours: 40
Role Number:200402289
The Health Technologies Team conceives and proves out innovative technology for Apple’s future products and features in health. We are seeking a highly capable Biomedical Data Engineer to join a multi-disciplinary team. Successful candidates will be able to integrate with our research study leads, data scientists and engineers to develop and support effective data analysis and machine learning workflows.
Key Qualifications
Experience with software engineering frameworks
Excellent coding skills in Python (e.g.,Pandas, Spark, Jupyter)
Workflow orchestrations (e.g., Airflow, Luigi)
Designing and maintaining (non-)relational databases (e.g. Postgres, Cassandra, MongoDB) and file systems (e.g. Parquet, CSV, JSON)
Great understanding of infrastructure designs
Linux, MacOS based development frameworks
iOS/ watchOS development (e.g., Swift, Objective-C)
Web Service APIs (e.g., AWS, REDCap, XNAT)
Version control frameworks (Git, virtualenv)
Familiarity with best practices for information security, including safe harbor privacy principles for sensitive data
Experience with biomedical sensors/platforms for measuring physiological signals in the health, wellness and/or fitness realms
Description
- Work closely with team members and study staff to design, build, launch and maintain systems for storing, aggregating and analyzing large amounts of data - Process, troubleshoot, and clean incoming data from human studies - Automate and monitor data ingestion and transformation pipelines, with hooks for QA, auditing, redaction and compliance checks per data management specifications - Create and maintain databases with existing and incoming clinical data - Architect data models and create tools to harmonize disparate data sources - Incorporate and comply with regulations as they pertain to electronic and clinical data and databases
Education & Experience
BS/MS in Computer Science, Engineering, Informatics, or equivalent with relevant 4+ years industry experience with biomedical, health or sensitive data.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $104,000 and $190,000 annualized, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",$10+ billion (USD),Computer Hardware Development,Company - Public,Information Technology
"Engineer III, Data Engineering",san-jose,"Samsung Electronics
3.5","Mountain View, CA",3.5,Employer Provided Salary:$219K - $239K,3.3,3.0,3.0,3.9,2.9,1001 to 5000 Employees,1938,"Position Summary
Design and develop scalable data stores and frameworks with sub-second query latency on highly multidimensional data.
Role and Responsibilities
Design and develop scalable data stores and frameworks with sub-second query latency on highly multidimensional data. Provide engineering solutions to aggregate and automate large scale data flows from varying sources. Build real time streaming pipelines that deliver data with measurable quality under the SLA. Deliver products with top notch quality in a fast-paced environment. Contribute towards building a system with a test-driven development/agile approach. Collaborate with other team members in breaking down tasks and implementation of the initiatives all the way to release.
Skills and Qualifications
Master’s degree in Business Analytics, Mathematics, Statistics, Data Science, Computer Applications, Computer Information Systems, a related field, or a foreign equivalent plus 2 years of post-baccalaureate experience in job offered or related role. In Lieu of a Master’s degree and 2 years of experience, Employer is willing to accept a Bachelor’s degree in Business Analytics, Mathematics, Statistics, Data Science, Computer Applications, Computer Information Systems, a related field, or a foreign equivalent plus 5 years of progressively responsible post-baccalaureate experience in job offered or related role. Applicants must have 2 years of experience (5 years in possession of a relevant Bachelor’s degree) in the following: (1) utilizing Apache Spark (EMR) for distributed data processing at a large scale (PySpark); (2) running interactive SQL queries(Spark SQL); (3) Extracting and analyzing data from databases using SQL queries to find relevant insights and customer-specific aggregated results; (4) building ETL pipelines to collect, process, and integrate structured and semi-structured data from various data producers into Snowflake; (5) AWS Glue/Lambad to populate Data Catalog with metatable definitions and run scalable serverless data processing jobs as a part of ETL operations; (6) creating data and dimensional models, design Entity Relationships, and building scalable data pipelines to build Enterprise Data Warehouse; (7) utilizing AWS as an infrastructure service (IAAS) to build frameworks for data ingestion, transformation, and orchestration of data pipelines; and (8) building data pipelines DAG’s, schedules, operators, connections, and hooks for data orchestration and optimize data workflows using Apache Airflow.
Compensation for this role between $218,608 – $238,608/Year
Regular full-time employees (salaried or hourly) have access to benefits including Medical, Dental, Vision, Life Insurance, 401(k), Employee Purchase Program, Tuition Assistance (after 6 months), Paid Time Off, Student Loan Program (after 6 months), Wellness Incentives, and many more.
Life @ Samsung -
https://www.samsung.com/us/careers/life-at-samsung/
Benefits @ Samsung -
https://www.samsung.com/us/careers/benefits/
#LI-DNP

At Samsung, we believe that innovation and growth are driven by an inclusive culture and a diverse workforce. We aim to create a global team where everyone belongs and has equal opportunities, inspiring our talent to be their true selves. Together, we are building a better tomorrow for our customers, partners, and communities.
Samsung Electronics America, Inc. and its subsidiaries are committed to employing a diverse workforce, and provide Equal Employment Opportunity for all individuals regardless of race, color, religion, gender, age, national origin, marital status, sexual orientation, gender identity, status as a protected veteran, genetic information, status as a qualified individual with a disability, or any other characteristic protected by law.
Reasonable Accommodations for Qualified Individuals with Disabilities During the Application Process
Samsung Electronics America is committed to providing reasonable accommodations for qualified individuals with disabilities in our job application process. If you have a disability and require a reasonable accommodation in order to participate in the application process, please contact our Reasonable Accommodation Team (855-557-3247) or SEA_Accommodations_Ext@sea.samsung.com for assistance. This number is for accommodation requests only and is not intended for general employment inquiries.",$10+ billion (USD),Computer Hardware Development,Subsidiary or Business Segment,Information Technology
Data Engineer III,san-jose,"Iron Systems
3.4","Menlo Park, CA",3.4,Employer Provided Salary:$68.00 Per Hour,3.2,3.2,3.3,3.5,3.4,201 to 500 Employees,1987,"Date Posted:
6/1/2023

Job Function:
Software Development

Location:
Menlo Park CA - USA

Offered Salary:
USD 68 Hourly


Iron Systems is an innovative, customer-focused provider of custom-built computing infrastructure platforms such as network servers, storage, OEM/ODM appliances & embedded systems. For more than 15 years, customers have trusted us for our innovative problem-solving combined with holistic design, engineering, manufacturing, logistic, and global support services.

Job Title: Data Engineer III
Location: US - CA - Menlo Park

Summary:
The main function of the Data Engineer is to develop, evaluate, test, and maintain architectures and data solutions within our organization.
The typical Data Engineer executes plans, policies, and practices that control, protect, deliver, and enhance the value of the organization’s data assets.
Job Responsibilities:
Design, construct, install, test, and maintain highly scalable data management systems.
Ensure systems meet business requirements and industry practices.
Design, implement, automate, and maintain large-scale enterprise data ETL processes.
Build high-performance algorithms, prototypes, predictive models, and proof of concepts.
Skills:
Ability to work as part of a team, as well as work independently or with minimal direction.
Excellent written, presentation, and verbal communication skills.
Collaborate with data architects, modelers, and IT team members on project goals.
Strong PC skills including knowledge of Microsoft SharePoint.
Education/Experience:
Bachelor's degree in a technical field such as computer science, computer engineering, or related field required.
Process certification, such as Six Sigma, CBPP, BPM, ISO 20000, ITIL, and CMMI.",$25 to $100 million (USD),Information Technology Support Services,Company - Private,Information Technology
Data Engineer,san-jose,"Kodeva
5.0","San Jose, CA",5.0,$108K - $155K (Glassdoor est.),-1,-1,-1,-1,-1,51 to 200 Employees,Company - Private,"Location: San Jose CA
Duration: 12 Months
Job Description :
Profile should have more than 8years of experience
Hands on experience in designing and executing projects on Google Cloud Platform features like App Engine, Compute, storage, Big Query, Data Proc, Data Flow.
Strong Programming Skills in R, Python or Spark.
Strong Knowledge on Data Engineering, Simulation and Modelling concepts
Proficiency in handling the billions of structured or unstructured transactional data.
Proficiency in modeling techniques such linear regression, logistic regression, GLM
Knowledge on machine learning techniques such as Decision Trees, xgboost, random forest, PCA etc.
Knowledge on unsupervised Machine learning techniques such as Clustering, Segmentation
Strong knowledge on Data Manipulation and transformation
Knowledge on data loading to GCP services like big query, cloud storage.
Knowledge in Hadoop, HIVE and Pig languages.
Good communication skills.",-1,-1,Unknown / Non-Applicable,-1
Data Engineer,san-jose,"Aptos
3.9","Palo Alto, CA",3.9,$93K - $131K (Glassdoor est.),3.7,3.7,3.6,3.8,3.9,1001 to 5000 Employees,2015,"Aptos is a people-first blockchain on a mission to help billions of people achieve universal and fair access to decentralized assets in a safe and scalable way.
Founded by some of the original creators and maintainers that researched, designed, and built the Diem blockchain to serve this purpose, we have dedicated several years toward this mission. We believe the open-source Diem technology we have developed is an important foundation of a safe and scalable web3 world where everyone has more equitable opportunities to grow and access financial assets with lower fees and fewer intermediaries.
Aptos (Ohlone for ""The People"") encompasses our mission and ethos for why we build.
About The Role
We are seeking an experienced Data Engineer to join our growing Analytics team. You will be responsible for expanding and optimizing our data infra and data pipeline architecture, as well as optimizing data flow, collection, and management of on-chain, off-chain, and cross-chain data. As one of the first data engineers, you will be in charge of the entire data warehouse, from ingestion to insight. You will work closely with Data Scientists to derive data-driven insights that drive our product vision forward and work with Data Platform engineers to structure raw data. We are looking for a bold thinker who has the ability to execute well; in return, you will receive a lot of autonomy and ownership over the projects you tackle.'
What you'll be doing:
Define, build, and deliver data pipelining architecture. This includes ingesting data from different data sources and creating aggregate views.
Work with stakeholders to assemble large, complex data sets for ready business consumption.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Ensure that Aptos Data Warehouse has high-quality, high-trust data the company can drive decisions from. Build a core data model that serves as the foundation of all of the use cases.
Manage data scalability, partitioning, growth, and availability utilizing cloud data warehousing technologies like Bigquery.
Assist analytics and data scientist team members in building and optimizing our product into an innovative industry leader.
What we're looking for:
3+ years of relevant experience
A degree in a technical field such as Finance, Data Science, Statistics, Computer Science, or similar field
Strong data wrangling and SQL skills. You have a track record of optimizing large pipelines to run very efficiently
Experience in at least one programming language (e.g. Python)
Experience manipulating large amounts of structured and unstructured data through pipeline development tools like Airflow
Be able to proactively manage prioritization of work and deliver work with great quality and influence the broader team in creating leverage
Hands-on experience building dashboards with a data visualization tool such as Tableau, Looker, Data Studio, etc.

The base salary range for this full-time position is $160k - $260k. The range displayed on each job posting reflects the minimum and typical maximum target for new hire salaries for the position of a candidate based in the Bay Area at any level. We do hire exceptionally talented professionals with decades of experience in their field. As such, our range may be higher than what is displayed. Our base salary ranges are determined by experience and location, and we hire at all levels for multiple roles. Within the range, individual pay is determined by work location, job-related skills demonstrated during the interviews, working experience, and relevant education or training. Please note that the compensation details listed in role postings reflect the base salary only and do not include equity, tokens, or benefits.
Our Benefits
100% insurance premium coverage for medical, dental, and vision for you and your dependents
Equipment of your choice
Flexible vacation time, 11 holidays, and floating company days off
Competitive Salary
Equity (RSUs)
Protocol Token Grants
401k matching
Fun and inclusive in-person and digital events
Aptos is committed to diversity in the workplace, and we're proud to be an Equal Opportunity Employer. We do not hire on the basis of race, color, religion, creed, gender, national origin, citizenship, age, disability, veteran status, marital status, pregnancy, parental status, sex, gender expression or identity, sexual orientation, or any other basis protected by local, state or federal law. All employment is decided based on qualifications, merit, and business need.",$100 to $500 million (USD),Enterprise Software & Network Solutions,Company - Private,Information Technology
Big Data Platform Engineer,san-jose,"Apple
4.2","Cupertino, CA",4.2,-1,-1,-1,-1,-1,-1,10000+ Employees,1976,"Summary
Posted: Nov 20, 2022
Weekly Hours: 40
Role Number:200444140
The SWE (Software) Data Analytics team at Apple collects, processes, and analyzes diagnostics and usage data from Apple devices across the world. We leverage streaming and batch analytics solutions to generate data that advises and drives product strategies across all of Apple software and hardware development. We discuss, analyze, and implement ground breaking solutions to problems of scale and distributed computing and are looking to expand our team with an engineer passionate about the big data workspace! Kafka, Flume, Hadoop, Spark, and other innovative technologies are core to our large scale infrastructure. You will be collaborating with data analysts, device engineers, and diverse engineering teams and drive the development of data pipelines and services with a high degree of ownership.
Key Qualifications
Experience developing large scale distributed computing systems.
In-depth knowledge and experience in one or more large scale distributed technologies including but not limited to: Hadoop ecosystem, Kafka, Samza, Flink, Storm, Flume, HBase, Cassandra, Redshift, Vertica, Spark.
Passion for and understanding of key algorithms and tools for developing high efficiency data processing systems.
Proficient in working with Linux or other POSIX operating systems, shell scripting, and networking technologies.
Problem-solving and debugging skills with experience in one or more of the following languages: Java, Python, Scala, Go, or Ruby.
There is a lot of communication involved! Excellent interpersonal skills are highly valued.
Description
As part of a team of highly skilled data engineers you will own significant responsibility in crafting, developing and maintaining our large-scale ETL pipelines, storage, and processing services. You will build self-service analytics tools to help engineering teams derive concrete metrics out of large volumes of raw data. You will partner with data science and engineering teams and develop algorithms to answer sophisticated questions on usage of Apple products. You will work closely with the DevOps team and develop monitoring and alerting scripts on various data pipelines and jobs. You will have the opportunity to learn and work on the latest Big Data technologies, lead PoCs to exercise new insights and, influence the strategic direction of our technology stack.
Education & Experience
Bachelors in Computer Science or equivalent experience
Additional Requirements
Experience using data storage technologies such as Apache Parquet or Avro Experience in machine learning algorithms is a plus.
Testing tools and methodologies to test large scale distributed computing systems.
Experience in data modeling and developing SQL database solutions is a plus.
Validated software engineering experience and field in design, test, source code management, and CI/CD practices.
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $130,000 and $242,000, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",$10+ billion (USD),Computer Hardware Development,Company - Public,Information Technology
Data Engineer,san-jose,Radiant System,"Pleasanton, CA",-1,-1,-1,-1,-1,-1,-1,-1,-1,"First Priority: Pleasanton, CA –
Second Priority for a superstar: Plano, TX
Experience in developing and deploying data pipelines, preferably in the Cloud
Experience working with Spark, Databricks, and other relevant technologies in Microsoft Azure cloud
Experience in productionizing and deploying Big Data platforms and applications
Expert in writing SQL statements
Job Type: Contract
Application Question(s):
Are you willing to work on W2?
Work Location: In person",-1,-1,-1,-1
Data Engineer,san-jose,"Sutter Health
3.7","Palo Alto, CA",3.7,Employer Provided Salary:$55.42 - $83.13 Per Hour,3.5,3.7,3.1,3.8,3.5,10000+ Employees,1981,"Organization:
PAMF-Palo Alto Medical Foundation PAD
Position Overview:
Responsible for developing Sutter Health’s Research analytic data infrastructure. This includes all aspects of how data is ingested, stored, collected, governed, cleansed, accessed, and used. It includes making sure that the data used by the organization is of the highest quality and is made available as soon as possible in a format that allows the business to make critical decisions based on the data. Utilizes tools and infrastructure such as scalable data pipelines to manage high volume and high-speed data storage and retrieval, as well as automated testing and tools for improving data quality. Works with all types of data including batch and streaming data, structured, semi-structured and unstructured data, files, web downloads, and other sources of data. Creates and improves processes required by other data-dependent function including analytics, strategic business intelligence, and data science. Uses state-of-the-art methods to capture, route and store data, combining information from different sources, transforming it to improve the data’s reliability, quality and usability. Develops and tests new architectures that enable data extraction, automation, and modeling for predictive or prescriptive analytic purposes. Sets the standard for high value high quality datasets that are accurate, timely, secure and well-suited to strategic analytic purposes.
Job Description:
EDUCATION:
Bachelor’s degree in Computer Science, Engineering, Information Management, or Healthcare Administration.
TYPICAL EXPERIENCE:
8 years recent relevant experience.
SKILLS AND KNOWLEDGE:
Experience creating data pipelines on big data platforms and data integrations in databases and data lakes, working with various cloud and on-premises technologies.
Experience leveraging scalable data platforms to build secure infrastructure; experience building batch or streaming data ingestion pipelines.
Ability to assess and profile raw data and reassemble raw data from multiple sources into a single, enterprise model.
Hands on experience with data management tools (Cloudera, Spark, Python, Databricks, etc.); fluency with SQL programming, scripting, and data architecture.
Extensive familiarity with relational database concepts / technologies (SQL, Oracle, etc.) including data design, table design, partitioning, as well as determining the technology to use in any given scenario.
Experience ensuring data quality and implementing tools and frameworks for automating identification of data quality issues.
Strong understanding of data engineering and data traceability best practices and framework
Ability to work in a consulting role, building technology and communicating with end-users and customers of varying levels of technical capability.
Ability to produce high-quality, professional documentation and communication materials.
Strong knowledge in the development of Business Intelligence and Reporting solutions.
Ability to translate data into Management reports and presentations.
Strong problem solving, organization, and prioritization skills.
Detail-oriented, producing timely results and ability to work both independently with minimal supervision and as a member of a scrum/product team.
Track-record of successful project delivery, building collaborative cross-functional relationships, and an ability to find creative ways to solve business problems.
Ability to balance the competing needs of multiple priorities and work in a dynamic environment; ability to perform under pressure and in stressful situations.
Demonstrable capacity for learning technical concepts and adapting to new technologies quickly; ability to stay current with evolving best practices in data management.
Familiar with healthcare provider data structures and sources; experienced with HIPAA regulations and methods for safeguarding PHI and PII through mitigation of data exposure risk.
Knowledge of health care operations and structure, general requirements in an integrated delivery.

The role requires significant technical skills, including multiple programming languages and extensive knowledge of Sequel (SQL), as well as experience with modern, distributed, scalable data platform.
Build fact tables and analytical data sets for the research team by partnering with the Principal Investigator and Statistician on IRB approved Studies.
Propose, develop, and implement algorithms for investigating and cleaning data collected from health care systems.
Work with Research Privacy and Security staff as necessary.
Write clear and logical documentation on the sources and methodologies used to extract and transform the information for researchers, other analysts, and programming staff.
Pay Range: $55.42 - $83.13 / hour
The salary range for this role may vary above or below the posted range as determined by location. This range has not been adjusted for any specific geographic differential applicable by area where the position may be filled. Compensation takes into account several factors including but not limited to a candidate’s experience, education, skills, licensure and certifications, department equity, training and organizational needs. Base pay is just one piece of the total rewards program offered by Sutter Health. Eligible roles also qualify for a comprehensive benefits package.
Job Shift:
Days
Schedule:
Full Time
Shift Hours:
8
Days of the Week:
Friday, Monday, Thursday, Tuesday, Wednesday
Weekend Requirements:
None
Benefits:
Yes
Unions:
No
This position is work from home eligible.
Position Status:
Exempt
Weekly Hours:
40
Employee Status:
Regular
Number of Openings:
1
Sutter Health is an equal opportunity employer EOE/M/F/Disability/Veterans.",$5 to $10 billion (USD),Health Care Services & Hospitals,Nonprofit Organization,Healthcare
"Senior Developer Technology Engineer, Data Analytics",san-jose,"NVIDIA
4.6","Santa Clara, CA",4.6,Employer Provided Salary:$144K - $270K,4.4,4.6,4.4,4.5,4.2,10000+ Employees,1993,"We are now looking for a Senior Developer Technology Engineer, Data Analytics:
Data Analytics is one of the rapidly growing fields in GPU accelerated computing. Data preprocessing and data engineering are traditionally CPU based and are becoming the bottleneck for Machine Learning (ML) and Deep Learning (DL) applications, as performance of the frameworks and core ML/DL libraries has been highly optimized leveraging GPUs. Many of today’s applications have complex data analytics pipelines that can benefit from optimizations in memory management, compression, parallel algorithms like sort, search, join, aggregation, groupby, scaling up to multi GPU systems, and scaling out to many nodes. Take a look at some of the open-source projects that our Devtech team have worked on:
NVIDIA nvcomp
,
NVIDIA Distributed join
,
NVIDIA cuCollections
What you will be doing:
In this role, you will research and develop techniques to GPU-accelerate applications across data analytics domains, e.g., ETL, ML, graphs, etc., and intersecting with DL.
Work directly with key customers to perform in-depth analysis and optimization of complex data intensive workloads to ensure the best possible performance on current and next-generation GPU architectures.
Collaborate with libraries, tools, system software architecture, hardware, and research teams at NVIDIA to influence the design of next-generation programming models, software, and architectures.
What we need to see:
A Bachelors, Masters or PhD in Computer Science, Computer Engineering, or related computationally focused science degree (or equivalent experience)
At least 3+ years of relevant work or research experience.
Programming fluency in C/C++ with a deep understanding of algorithms and software design.
Experience with parallel programming, e.g., CUDA, OpenACC, OpenMP, MPI, pthreads, TBB, etc.
In-depth expertise with computer architecture fundamentals, especially memory subsystem.
Good communication and organization skills, with a logical approach to problem solving, and prioritization skills.
Ways to stand out from the crowd:
Domain expertise in data analytics, e.g., ETL, ML, graph applications .
Experience optimizing the performance of distributed systems and frameworks, Spark highly desired.
Background with compression, storage systems, networking, and distributed systems.
Experience with linear algebra and machine learning applications.
Graduate degree in Computer Engineering, Computer Science, or related engineering discipline.
The Developer Technology Engineer (DevTech) plays a crucial role in the success of NVIDIA and our customers. DevTechs work with external technologists to investigate performance of their applications, design parallel algorithms and implement optimizations in a GPU accelerated computing environment. As recognized experts in the field we publish our findings in developer blogs or at relevant conferences and workshops. With visibility to our customers, the industry, and academia we are important representatives of NVIDIA as a technology leader. Within NVIDIA we contribute valuable application expertise that influences next generation hardware and software products. As critical problem solvers, we deepen our expertise, expand our knowledge, and work across domains and organizations. Whether you are a leading industry luminary or early in your career, the Developer Technology Team provides ample opportunity for growth in the exciting field of GPU accelerated computing!
NVIDIA is widely considered to be one of technology’s most desirable employers. We have some of the most forward-thinking and hardworking people on the planet working for us. Does contributing to and pushing the boundaries of state-of-the-art in GPU Accelerated Computing, HPC and Artificial Intelligence excite you? If so, we want to hear from you!
The base salary range is $144,000 - $270,250. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
You will also be eligible for equity and
benefits
.
NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",$5 to $10 billion (USD),Computer Hardware Development,Company - Public,Information Technology
Network Engineer/Data Center,san-jose,"Geopaq Logic
4.7","San Jose, CA",4.7,$84K - $125K (Glassdoor est.),4.9,5.0,5.0,4.8,4.9,1 to 50 Employees,2014,"Job Title: IP Telephony Engineer
Work location: San Jose, CA (on-site)
Duration: 10+Months
Korean/English Bilingual Required
IP Telephony Engineer
This position is responsible for technical support for Communication Practice-related business products and services supported by Business Operations.
This operational position requires the Engineer to speak directly to internal and external customers about a wide variety of technical issues/requests.
Responsibilities
Responsibilities will include providing the necessary support in order to resolve the customer's issues and/or fulfill requests in a manner that meets or exceeds agreed upon Service Level Agreements (OLAs/SLAs) with internal/external customers.
Provide technical support to internal/external customers for VoIP-related incidents, requests, and inquiries relating to a variety of business products and services
Document work updates in a company-provided ticketing system until a resolution is complete and the ticket is closed with the customer
Collaborate with other analysts to determine resolutions for customer incidents and requests
Western IPT Network & System management (hardware/software)
Other duties as assigned
Knowledge/Skills
Excellent written and oral communication skills
Excellent customer service and conflict resolution skills
Working understanding of Information Technology and computing systems
Working understanding of IP networking fundamentals
Familiar with Microsoft applications such as Windows operating system, Office applications, Outlook, and SharePoint
Familiar with common ticketing systems
Demonstrated desire for self-directed education regarding IP networking and VoIP technologies
Job Types: Full-time, Contract
Ability to commute/relocate:
San Jose, CA 95110: Reliably commute or planning to relocate before starting work (Required)
Experience:
Computer networking: 1 year (Preferred)
LAN: 1 year (Preferred)
Language:
Korean (Required)
Work Location: In person",$1 to $5 million (USD),Computer Hardware Development,Company - Private,Information Technology
"Data Engineer, Data Analytics",san-jose,"Tesla
3.6","Fremont, CA",3.6,$113K - $163K (Glassdoor est.),3.7,3.3,3.1,3.7,2.9,10000+ Employees,2003,"What to Expect
The Data and Analytics, Applications Engineering team drives business critical decision making, and ensures cross functional alignment of goals and execution for all of Tesla. We stay focused on aligning the highest-level company priorities with strong day-to-day operations and build capabilities to power hyper-growth.
As the Data Analyst, you will partner with members of the Data and Analytics team and its leadership in Applications Engineering to provide critical analysis operations to support our demanding and fast-paced environment where you will work on critical subsystems of an incredibly exciting product.

What You’ll Do
Assist with implementation, maintenance and documentation of the internal Data and Analytics and reporting processes.
Research and keep abreast of rapidly evolving data requirements, ensuring necessary system and process changes are implemented to meet these requirements.
Identify potential process improvements and recommend implementation strategies.
Educate business team on procedures when rolling out new initiatives.
Develop and demonstrate expertise in communicating data related topics, including reporting.
Work cross functionally across business teams including HR, Service, Supply Chain, Logistics, Financials, and Sales.
Analyze the need for new applications or enhancements to the existing application to suit business needs and make decisions if they are needed or not.
Recommend solutions that adhere to industry standards, keeping in mind the impact on upstream and downstream system and stakeholders.
Closely monitor the project from inception to completion and assist in User Acceptance Testing.
Work on special projects related to data as assigned.
Continuously improve SQL and python skills, helping you automate repetitive work and multiply yourself
On-call support, where needed.

What You’ll Bring
2+ years of prior experience as Systems/Data/Product/Program Analyst.
Must be proficient in SQL.
Expertise in key deliverables such as Project Plans, Business Requirement Documents, Functional requirements, Use Cases, System Sequence Diagrams.
Ability to support multiple on-going projects in a fast-paced environment.
Strong analytical and problem-solving ability to design an effective solution.
Ability to explain financial/technical concepts and analysis implications clearly to a wide audience and be able to translate business objectives into actionable analyses.
Strong communicational skills, organizational skills, negotiation skills, and flexibility to address competing demands.
Working knowledge of data management software like Airflow, or other ETL tools a plus.
Experience with bug/enhancement tracking system like JIRA a plus.
2+ years in cross-functional project management experience.
Superior business judgement – ability to flex between big picture thinking, understand and distill complex ideas, and analyze data to drive strategic objectives.
Problem solver that is action-oriented with the ability to look at problems in new ways.
Trustworthy and discreet with extremely sensitive non-public information.
Passion for Tesla’s products and belief in Tesla’s mission to accelerate the transition to sustainable energy

Nice to have:
Experience in project management, Jira
Experience with Tableau, Data Warehousing, Data Modeling
Capable of leading a technical team

EEO statement
Tesla believes in equal treatment and affirmative action and is committed to diversity in the workplace. All qualified applicants will be considered for employment regardless of race, color, religion, gender, sexual orientation, age, nationality, disability, protected veteran status, gender identity, or any other factor protected by applicable federal, state, or local laws.
Tesla is also committed to employing people with disabilities and making reasonable accommodations for them. Let your recruiter know if you need an adjustment at any point during the application process.
For quick access to screen reading technology compatible with this website, click here to download a free compatible screen reader(a free step-by-step how-to video is available here).
Benefits
Along with competitive pay, as a full-time Tesla employee, you are eligible for the following benefits at day 1 of hire:
Aetna PPO and HSA plans > 2 medical plan options with $0 payroll deduction
Family-building, fertility, adoption and surrogacy benefits
Dental (including orthodontic coverage) and vision plans, both have options with a $0 paycheck contribution
Company Paid (Health Savings Account) HSA Contribution when enrolled in the High Deductible Aetna medical plan with HSA
Healthcare and Dependent Care Flexible Spending Accounts (FSA)
LGBTQ+ care concierge services
401(k) with employer match, Employee Stock Purchase Plans, and other financial benefits
Company paid Basic Life, AD&D, short-term and long-term disability insurance
Employee Assistance Program
Sick and Vacation time (Flex time for salary positions), and Paid Holidays
Back-up childcare and parenting support resources
Voluntary benefits to include: critical illness, hospital indemnity, accident insurance, theft & legal services, and pet insurance
Weight Loss and Tobacco Cessation Programs
Tesla Babies program
Commuter benefits
Employee discounts and perks program",$1 to $5 billion (USD),Transportation Equipment Manufacturing,Company - Public,Manufacturing
AWS Data Engineer,san-jose,"Plaxonic
4.6","San Jose, CA",4.6,Employer Provided Salary:$125K,4.4,4.7,4.4,4.2,4.4,51 to 200 Employees,2013,"Design, build and maintain data platform infrastructure on AWS environment
Oversee design, build, and maintain data platform infrastructure on AWS environment
Develop data pipelines to collect the metrics that is required to monitor data refreshes, reports deliveries and track SLAs.
Work with the DWH development team and business users in establishing SLAs for data refreshes and reports
Build continuous integration/deployment (CI/CD) pipelines to accelerate development and improve team agility
Oversee project
Monitor all aspects of data platform system security, performance, storage, incidents, and usage for databases, data pipelines, applications, and infrastructure on AWS. Escalate to respective teams for fixes.
Ensure data pipelines meet intraday and daily SLAs, as per documented SLA definitions and escalate accordingly.
develop appropriate instrumentation to collect metrics on system performance, cost, data ingress/egress /storage processes
Have a clear understanding of the reports/analyses/insights to be driven by data and build data driven solutions to optimally support the operational analytics needs
Documents user stories, epics, and reports
Coordinate infrastructure enhancements and maintenance with the system/network engineering teams
Work with DWH development team and analytics team to do manual releases where required.
Onboard users to data analytics systems with appropriate approvals
Conduct system performance tests and collect metrics. Tune/add capacity
Complete knowledge management processes
Own strategy and communicate potential major shifts in expected workload based on business, market, or operational changes.
Operate ongoing business relationship management sessions to review operational metrics, understand pain points, identify upcoming projects and engagement efforts
Job Type: Full-time
Salary: Up to $125,000.00 per year
Schedule:
Monday to Friday
Experience:
AWS: 7 years (Preferred)
Data Engineer: 7 years (Preferred)
Work Location: On the road
Speak with the employer
+91 727-758-5913",$1 to $5 million (USD),Information Technology Support Services,Company - Private,Information Technology
"Data Engineer, E-Commerce",san-jose,"TikTok
3.6","San Jose, CA",3.6,Employer Provided Salary:$136K - $280K,3.4,3.4,3.1,3.6,3.0,1001 to 5000 Employees,2016,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

The Global E-Commerce team focuses on building data infrastructure and data product areas to support business engineering teams working directly on TikTok's E-Commerce platform.

As a data engineer in the Global E-Commerce team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. You'll have the opportunity to gain hands-on experience on all kinds of systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.

Responsibilities - What You'll Do
Design and build data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, multi-dimensional analysis);
Design and implement reliable, scalable, robust and extensible big data systems that support core products and business;
Establish solid design and best engineering practice for engineers as well as non-technical people.
Qualifications
BS or MS degree in Computer Science or related technical field or equivalent practical experience;
Experience in the Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.);
Experience with performing data analysis, data ingestion and data integration;
Experience with ETL(Extraction, Transformation & Loading) and architecting data systems;
Experience with schema design, data modeling and SQL queries;
Passionate and self-motivated about technologies in the Big Data area.
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or an accommodation, please reach out to us at Dennis.Chau@tiktok.com
Job Information
The base salary range for this position in the selected city is $136000 - $280000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",Unknown / Non-Applicable,Internet & Web Services,Company - Private,Information Technology
Distributed Systems Engineer (L4) - Data Platform,san-jose,"Netflix
4.3","Los Gatos, CA",4.3,$111K - $184K (Glassdoor est.),3.9,4.2,3.8,4.6,3.9,5001 to 10000 Employees,1997,"Los Gatos, California
Data Platform
At Netflix, we want to entertain the world and are constantly innovating on how entertainment is imagined, created and delivered to a global audience. We currently stream content in more than 30 languages in 190 countries, topping over 220 million paid subscribers and are expanding into new forms of entertainment such as gaming.

The data infrastructure teams at Netflix enable us to leverage data to bring joy to our members in many different ways. We provide centralized data platforms and tools for various business functions at Netflix, so they can utilize our data to make critical data-driven decisions. We do all the heavy lifting to make it easy for our business partners to work with data efficiently, securely, and responsibly. We aspire to lead the industry standard in building a world-class data infrastructure, as Netflix leads the way to be the most popular and pervasive destination for global internet entertainment.

We are looking for distributed systems engineers to help evolve and innovate our infrastructure as we work towards our ambitious goal of 500 million members worldwide. We are committed to building a diverse and inclusive team to bring new perspectives as we solve the next set of challenges. In addition, we are open to remote candidates. We value what you can do, from anywhere in the U.S.

Spotlight on Data Infrastructure Teams:

Data Movement and Processing Platform | Learn More
Offers an abstracted self-service paved-paved path product to enable varied user persona across Netflix meet their low-latency Data Movement and Processing requirements; enables abstraction over complex Real-Time frameworks such as Kafka and Flink; offers a Schema driven processing experience; invests in operational automation, reliability and tools for predictable data quality.

Storage and Insights | Learn More
Offers storage and insights products. Those products provide storage services to platforms, applications and users around the globe which are performant, secure and centrally managed; enabling platforms to move, store and efficiently archive data in the cloud. We offer a consistent mechanism to create & manage S3 resources, integrate Netflix ecosystem for access control and provide observability into the cost & resource lifecycle of these resources, by taking ownership of existing tools and shaping a more cohesive strategy.

Big Data Orchestration | Learn More
Offers the platform for scheduling, orchestrating and executing big data jobs and workflows in a self serve manner. These platforms include foundational services that host all ETL and ML workloads running on Big Data Systems at Netflix. These fully distributed systems are constantly evolving for Netflix scale with state of the art technology. We are moving towards event driven and intelligent orchestration which would need minimal user input/intervention.

Data Access Platform | Learn More
The Database Access Platform team builds and operates a flexible query gateway that facilitates data abstractions to operate at sub-millisecond latencies while allowing Netflix microservices to more easily store, consume, and manage their data. This team holds a substantial responsibility in enabling Netflix microservices to satisfy their ever-growing and evolving data needs.
This team is passionate about distributed data systems technology. We are active in the open source community and believe in operating what we own. We are a small team responsible for business critical systems and are committed to a culture of feedback and engineering

Data Platform Infrastructure | Learn More
The Data Platform Infrastructure team acts as a platform for our own data platforms. Our shared infrastructure and tooling enable Netflix to quickly innovate on providing state-of-the-art data and analytics systems to the rest of the company without building bespoke scaffolding for each new system. To do this, we create high-leverage infrastructure, control, and deployment systems that are fine-tuned for the needs of running our data systems at scale; uniquely, many of our tools and systems are written in Python, so this is a great team to consider if you enjoy working in a variety of languages.

This would be your dream job if you enjoy:
Solving real business needs at large scale by applying your software engineering and analytical problem-solving skills.
Architecting and building a robust, scalable, and highly available distributed infrastructure.
Leading cross-functional initiatives and collaborating with engineers, product managers, and TPM across teams.
Sharing our experiences with the open source communities and contributing to Netflix OSS.
About you:
You have 2+ years of experience in building large-scale distributed systems features or applications.
You are proficient in the design and development of RESTful web services.
Experienced in building and operating scalable, fault-tolerant, distributed systems
You are experienced in Java or other object-oriented programming languages.
Multi-threading is a challenge that you are comfortable tackling.
You have a BS in Computer Science or a related field.

A few more things about us:

As a team, we come from many different countries and our fields of education range from the humanities to engineering to computer science. Our team includes product managers, program managers, designers, full-stack developers, distributed systems engineers, and data scientists. Folks have the opportunity to wear different hats, should they choose to. We strongly believe this diversity has helped us build an inclusive and empathetic environment and look forward to adding your perspective to the mix!

At Netflix, we carefully consider a wide range of compensation factors to determine your personal top of market. We rely on market indicators to determine compensation and consider your specific job family, background, skills, and experience to get it right. These considerations can cause your compensation to vary and will also be dependent on your location.

The overall market range for roles in this area of Netflix is typically $100,000 - $700,000

This market range is based on total compensation (vs. only base salary), which is in line with our compensation philosophy. Our culture is unique, and we tend to live by our values, so it’s worth learning more about Netflix here.",$5 to $10 billion (USD),Internet & Web Services,Company - Public,Information Technology
Software Engineer - Data Platform,san-jose,"Eightfold.AI
3.5","Santa Clara, CA",3.5,Employer Provided Salary:$99K - $149K,3.5,3.4,3.2,3.8,3.5,501 to 1000 Employees,2016,"Eightfold.ai was founded with a vision to solve for employment in our society. For decades, the connection between individuals and opportunities has been based on who the individuals are and the strength of their network, vs. their potential. Eightfold leverages artificial intelligence to transform how to think about skills and capabilities for individuals as well as how jobs and career decisions are made. Eightfold offers the industry’s first AI-powered Talent Intelligence Platform to transform how organizations plan, hire, develop and retain a diverse workforce, enabling individuals to transform their career.
About Data Platform Team
The data platform team at Eightfold builds and innovates at all levels of our stack. You will own a global data platform stack that powers all Eightfold products. The platform manages hundreds of terabytes of data across Eightfold. We power the entire AI platform with the data.
Responsibilities
Build out large-scale software platforms that are used by millions of users.
Scale, Optimize and Innovate to extend Data Platform capabilities..
Contribute to the design and development of Eightfold's data platform.
Build out micro services using frameworks such as Docker and Kubernetes to power all our products.
Deliver high-performance, reliable, and scalable product leveraging best-of-breed technology.
Diagnose problems which can arise in a complex distributed environment.
Support the deployment and operation of our product across multiple environments.
Collaborate with Engineering, Operations, Analytics, Marketing, and Business teams throughout the organization
Qualifications
Experience with backend development.
0-3+ years of experience building high-quality software
Experience in building distributed systems or high performance systems.
Interest in large-scale distributed system design, problem-solving, and data analysis skills.
Bachelors or Masters degree or equivalent years of experience

Pay Transparency
The information below is provided for candidates hired in California location.
In California, the standard base pay range for this role is USD $99,000 - $149,000 annually.

In addition to a competitive base salary, this position is also eligible for equity awards, benefits and discretionary bonuses. A candidate’s salary is determined by various factors including, but not limited to, experience, skills, and geographic location within the state.

We offer competitive compensation and benefits, including family medical, vision, and dental coverage. We also offer a 401k plan, stock options, and unlimited paid time off for all eligible employees.
Eightfold.ai provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, or disability.",Unknown / Non-Applicable,Enterprise Software & Network Solutions,Company - Private,Information Technology
"Software Engineer III, Performance, Google Cloud Data Management",san-jose,"Google
4.4","Sunnyvale, CA",4.4,-1,-1,-1,-1,-1,-1,10000+ Employees,1998,"Minimum qualifications:
Bachelor’s degree or equivalent practical experience.
2 years of experience with software development in one or more programming languages, or 1 year of experience with an advanced degree.
2 years of experience with data structures or algorithms.


Preferred qualifications:
Master's degree or PhD in Computer Science or related technical fields.
2 years of experience with performance, large scale systems data analysis, visualization tools, and/or debugging.
Experience developing accessible technologies.
About the job
Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward.
With your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance software solutions.
Google Cloud accelerates organizations’ ability to digitally transform their business with the best infrastructure, platform, industry solutions and expertise. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology – all on the cleanest cloud in the industry. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems.
The US base salary range for this full-time position is $133,000-$194,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.

Responsibilities
Write product or system development code.
Participate in, or lead design reviews with peers and stakeholders to decide amongst available technologies.
Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency).
Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback.
Triage product or system issues and debug/track/resolve by analyzing the sources of issues and the impact on hardware, network, or service operations and quality.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.",$10+ billion (USD),Internet & Web Services,Company - Public,Information Technology
Data Infrastructure Engineer,san-jose,Tasktoday,"Newark, CA",-1,$93K - $139K (Glassdoor est.),-1,-1,-1,-1,-1,Unknown,Company - Public,"At Tasktoday we are building a shared task list for teams in an effort to re-imagine the way people work together. As knowledge workers, we and our loved ones spend most of our time living in programs (email, calendar, document editors, etc.) that help us move and manage data, and get things done. This is an opportunity to improve that part of our lives.
The Metrics Infrastructure Engineer is a critical role for Tasktoday’s growth. As a key member of the engineering team, you will work closely with the product teams to build out and refine the infrastructure we use to gain insights from our data and evaluate our success. As our user base rapidly grows, you will architect and develop improvements to our data infrastructure, and design and implement data analysis tools that increase the scalability, accuracy and accessibility of our data to support ongoing product decisions.
With this data infrastructure, you will be in the unique position to help shape the company roadmap by identifying opportunities in our data and enabling us to rapidly test our assumptions.
Requirements
Strong background in computer science, math or other technical field
Fluent in SQL and at least one modern scripting language
Capable of supporting live production infrastructure, can put out fires under pressure when things go wrong
Distributed computing experience
Passion for deriving insights from data and transforming it into actionable facts
Desirable
Extensive experience with data infrastructure and reporting tools
Strong analytical skills including the ability to identify problems and draw conclusions that are supported by a principled analysis of data
Capable of explaining results in a clear and effective manner
Knowledge of modern web technologies",-1,-1,Unknown / Non-Applicable,-1
Data Engineer,san-jose,"Luminar
3.8","Palo Alto, CA",3.8,$105K - $155K (Glassdoor est.),4.0,3.4,3.1,4.2,3.4,201 to 500 Employees,2012,"Luminar is a global automotive technology company ushering in a new era of vehicle safety and autonomy. For the past decade, Luminar has built an advanced hardware and software platform to enable its more than 50 industry partners, including the majority of global automotive OEMs. From Volvo Cars and Mercedes-Benz for consumer vehicles and Daimler Trucks for commercial trucks, to tech partners NVIDIA and Intel's Mobileye, Luminar is poised to be the first automotive technology company to enable next-generation safety and autonomous capabilities for production vehicles. For more information please visit www.luminartech.com.
Team Overview
The Data Engineering team builds the apps and infrastructure to leverage data from our vehicles and operations. We are building the next generation data lake and pipelines as we scale our offerings. You will develop and implement the systems that power Luminar's data-driven improvement and growth.
Responsibilities
Designing, building, and maintaining the infrastructure that transforms data at scale into insights:
Ingestion of real-world vehicle data.
Automated labeling and data enrichment.
Generation of ground truth information.
Analysis of data quality.
Partnering with engineering and ML teams to define data consumption patterns and establish best practices.
Establishing robust data integrity and systems monitoring.
Minimum Qualifications
4+ years of relevant industry experience:
Building backend / data services at scale.
Hands-on Big Data software and infrastructure development skills.
Experience with NoSQL databases and/or Relational databases.
Accomplished in at least one backend language, preferably Python.
Strong communication skills, being able to collaborate with the wider software organization.
Bachelor's Degree (or higher) in Computer Science.
Preferred Qualifications
Proficiency in Python.
Experience with MongoDB.
Experience with pipeline / workflow frameworks: Argo Workflows or Airflow.
Hands-on experience with cloud computing: AWS / GCP / Azure / Alibaba Cloud.
Experience with automation of data infrastructure: Docker / Kubernetes / Terraform / Linux.
Experience with SRE practices - running services reliably in production environments:
Incident management and root cause analysis.
Performance Engineering.
Previous experience in the Automotive / Robotics industry.
Nice To Have
Proficiency in front-end development, preferably using React.
Experience with processing frameworks like Spark / Hadoop.
Experience with big data / data warehouse tools like Redshift, Presto/Athena, BigQuery and Snowflake.
Experience with streaming and message queueing technologies: Kafka / Kinesis / RabbitMQ.
Hands-on experience with data storage and transfer schemes like Avro, Parquet and Protobuf.
Experience with rosbags.
Benefits and Perks
Competitive Pay, 401k Matching and meaningful Equity from a publicly traded company
Great Medical Benefits
Tuition Assistance, Meals served in the office
No limit on PTO
Flexible Work Schedule with some Work From Home flexibility as well

Industry: Autonomous vehicles, automotive, product demonstration
Employment Type: Full-time
Job Functions: Engineering

Luminar is an equal opportunity employer. All applicants will be considered for employment without regard to race, color, ancestry, national origin, sex, gender, sexual orientation, marital status, religion, age, disability, gender identity, results of genetic testing, service in the military, or any other characteristic protected by applicable federal, state or local laws. We will make a reasonable accommodation for any qualified applicant with a disability, provided that the individual is otherwise qualified to safely perform the essential functions of the job with or without accommodation and that the accommodation would not impose an undue hardship on the operation of our business. Please let us know if you believe you require reasonable accommodation, or if you would like assistance to complete an application or to participate in an interview at the company.

At Luminar, your base pay is one part of your total compensation package. This role pays a base between $142,000 and $199,000* per year. Within this range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. You will also be eligible to receive other benefits including: equity in the form of restricted stock unit awards, comprehensive medical and dental coverage, 401k plan, life and disability benefits, flexible time off, paid parental leave, and tuition reimbursement for formal education related to advancing your career at Luminar. The specific programs and options available to an employee may vary depending on date of hire and schedule type.
Note that the pay range listed for this position is a good faith and reasonable estimate of the range of possible base compensation at the time of posting.",Unknown / Non-Applicable,Computer Hardware Development,Company - Public,Information Technology
Data Engineer,san-jose,"Purple Drive Technologies
4.2","Cupertino, CA",4.2,Employer Provided Salary:$116K - $208K,3.9,4.0,4.0,3.7,4.2,1 to 50 Employees,Company - Private,"Terraform along with synapse Azure cloud
Deep expertise in Data Engineering and Data Warehousing (minimum 4+ years)
Azure synapse , Azure Data Factory , Spark Pool , SQL , SQL Pool (minimum 4+ yrs)
CI/CD and Python/Java programming experience (minimum 3+ years)
Ideal to have a 24 x 7 development i.e offshore presence or different time zones
Job Type: Full-time
Salary: $115,871.32 - $207,675.38 per year
Ability to commute/relocate:
Cupertino, CA: Reliably commute or planning to relocate before starting work (Required)
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: One location",-1,-1,Unknown / Non-Applicable,-1
Data engineer,san-jose,"Stacklogy
4.8","Fremont, CA",4.8,$105K - $151K (Glassdoor est.),4.8,4.5,4.8,4.8,4.5,1 to 50 Employees,Company - Public,"Qualification:
Master's Degree in Statistical Analytics, Data Science, or Bachelor's Degree in computer science engineering will be considered with at least three - five years of applicable work experience
Preferred Proficiency:

Web development experience (AngularJS, D3).
Experience in a statistical programming language like R or Python; applied machine learning techniques including dimensionality reduction strategies, supervised/unsupervised classification and natural language processing frameworks.
Experience in at least one data visualization tools (e.g. Tableau, QlikView) and data warehousing tools (e.g. Informatica) is preferred
Huge Advantage:
Building and scaling Machine Learning frameworks
Hadoop (Hive, Spark, UDF's)
Definite Plus:

Web development experience (AngularJS, D3).
Experience:

5+ years of relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analytics.
5+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.
2+ years of experience in scripting languages like Python etc.",-1,-1,Unknown / Non-Applicable,-1
Data Integrations Engineer,san-jose,"ShareThis, Inc
4.0","Palo Alto, CA",4.0,Employer Provided Salary:$90K - $130K,3.9,3.9,3.8,4.1,4.3,51 to 200 Employees,2007,"About the Role:
ShareThis is seeking a skilled Data Integration Engineer for a client-facing role to ensure the smooth and efficient delivery of accurate data. The ideal candidate will work closely with the Data Engineering team to optimize and automate data integrations with data customers and data suppliers. The successful candidate will have a strong understanding of data integration processes, experience in optimizing data integrations, and excellent technical skills. This role will act as a liaison between clients, sales, operations, and engineering and will report to the VP of Product and Integrations.

About ShareThis:
ShareThis uncovers the topography of human behavior, unlocking the power of digital behavioral data while providing stewardship and respect for global consumers who share their data. From our free sharing service installed on 3 million websites around the world, ShareThis assembles data from billions of user page visits every month, under agreements with site owners and with the permission of site visitors. Using this data, ShareThis builds products to help marketers understand and connect to groups of consumers most likely to be interested in that marketer’s products and messages. Our products are used by companies, agencies, and analytics providers, and are widely available through leading technology platforms. Our clients and partners choose ShareThis data for its unparalleled scale and breadth in delivering insight into consumer interest and intent.

Responsibilities:

As a member of the Product Integrations team, you will

Directly and independently work with clients and suppliers to ensure that accurate data
is delivered smoothly and efficiently
Work with the Data Engineering team to understand the current data integrations with
data customers and data suppliers
Optimize and automate custom integrations to provide a seamless experience for clients
Implement a QA process to continually improve the success rate and customer
satisfaction
Identify and troubleshoot data integration issues in a timely manner, e.g. client access
(AWS/GCP buckets, Snowflake and more), internal data creation (Airflow DAGs, Scala
code) etc.
Develop and implement best practices for data integration
Collaborate with business partners and data engineers to understand business context,
technical needs, and review implementations to improve data integration process
efficiency
Maintain and update internal technical documents related to integrations to ensure that
processes are sustainable and repeatable

Requirements:

Bachelor’s degree in Computer Science, Computer Engineering, or a related field
5 or more years of experience in cloud-based data integration
Strong communication and interpersonal skills, with a client-facing mentality
Experience with cloud-based data integration tools for data management, ETL processes,
and database technologies (preferably AWS)
Hands-on expertise with access and security on Cloud
Expert level with SQL and scripting languages such as Python and Scala
Experience with Airflow DAGs and GitHub
Excellent analytical and problem-solving skills with a focus on data quality
Ability to work independently and collaboratively as part of a multifunctional team

This is a remote position.",$25 to $100 million (USD),Internet & Web Services,Company - Private,Information Technology
Data Engineer,san-jose,"FutureSoft IT
5.0","Sunnyvale, CA",5.0,$95K - $140K (Glassdoor est.),-1,-1,-1,-1,-1,51 to 200 Employees,Company - Public,"**Please Read**


Local candidates only. This opportunity does not provide Visa sponsorship. No corp to corp applicants please. Candidate must be available to work on our W2.


Data Engineer


Data applications are critical to our success, powering many aspects of our marketplace and supporting products. We are looking for data engineers who will build, migrate and maintain data pipelines. In this role, you’ll expand and refactor the data sets that generate and transform data into applications, insights, and experiences for our users.


The work includes:
? Refactoring existing and build new data pipelines
? Migrating existing data sets into next-gen reporting frameworks and tools
? Using existing data tools and frameworks to configure reports and metrics
? Developing and automating large scale, high-performance data processing systems to drive our business growth and improve the product experience
? Building and refactoring scalable data pipelines on top of Hive and Spark leveraging Airflow scheduler/executor framework


We are looking for engineers with:
? Demonstrated ability to analyze large data sets to identify gaps and inconsistencies, provide data insights, and drive effective product solutions
? Experience designing and deploying high performance systems with robust monitoring and logging practices
? Experience building high performance data pipelines
? Nice to have: proven ability to think critically about team direction and use analysis to inform that
? Experience using machine learning is a plus, but not required.
? Excellent communication skills, both written and verbal",-1,-1,Unknown / Non-Applicable,-1
Data Engineer,san-jose,"Pinnacle Technical Resources
3.2","Cupertino, CA",3.2,Employer Provided Salary:$80.00 - $90.00 Per Hour,2.3,3.7,3.7,3.0,4.3,1 to 50 Employees,Company - Public,"The Data Infrastructure group within the AI/ML organization powers the analytics, experimentation and ML feature engineering that powers the Machine Learning technologies we all love in our devices. Our mission is to provide cutting edge, reliable and easy to use infrastructure for ingesting, storing, processing and interacting with data while keeping users’ data private and secure. The Core Infra team sits within the AI/ML Data Infrastructure group and is looking for an engineer to bring their passion for scalability and efficiency to help build world class data infrastructure enabling data engineers and scientists to produce world-class ML data products.

Key Qualifications:
3+ years of experience scaling and operating distributed systems like big data processing engines (e.g., Apache Hadoop, Apache Spark), distributed file systems (e.g. HDFS, CEPH, S3, etc.), streaming systems (e.g., Apache Flink, Apache Kafka), resource management systems (e.g., Apache Mesos, Kubernetes), or Identity and Access Management (e.g. Apache Ranger, Sentry, OPA)
3+ years experience with infrastructure as code and systems automation
Fluency in Java or a similar language
Ability to debug complex issues in large scale distributed systems
Passion for building infrastructure that is reliable, easy to use and easy to maintain
Excellent communication and collaboration skills
Experience with Spark and ETL processing pipelines is helpful, but not required
Experience with systems security, identity protocols and encryption is helpful, but not required

Description
The ideal candidate will have outstanding communication skills, proven data infrastructure design and implementation capabilities, strong business acumen, and an innate drive to deliver results. They will be a self-starter, comfortable with ambiguity and will enjoy working in a fast-paced dynamic environment.

Responsibilities:
Improving the efficiency of the large compute fleet in AIML. This compute infrastructure supports various data processing and analytics workloads across AIML on Cloud, including widely used compute engines like Spark, Flink, Kafka, and more.
Collaborate with partner teams to design, develop, and maintain scalable and efficient data infrastructure. This includes deploying Kubernetes clusters, setup network, storage, monitoring and observability tools.
Optimize compute resources with smart autoscaling strategies.
Streamline and fine-tune the allocation and utilization of compute resources within the fleet, ensuring maximum efficiency for all workloads.
Identify opportunities to improve the overall performance of the compute fleet, minimizing latency, enhancing throughput, and reducing bottlenecks.
Implement robust monitoring and reporting mechanisms to track the performance, resource utilization, and cost continuously. Utilize this data to identify areas for further optimization and proactively address any issues or inefficiencies.
Ensure data infrastructure offers reliable high-quality data with consistent SLAs with good monitoring, alerting and incident response and continual investment to reduce tech-debt
Write code, documentation, participate in code reviews and design sessions

Pay Range: $80 - $90 per hour
The specific compensation for this position will be determined by a number of factors, including the scope, complexity and location of the role as well as the cost of labor in the market; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. Our full-time consultants have access to benefits including medical, dental, vision as well as 401K contributions.

#LI-ZA1",-1,-1,$1 to $5 million (USD),-1
Data Engineer,san-jose,BXGI,"Palo Alto, CA",-1,$98K - $148K (Glassdoor est.),-1,-1,-1,-1,-1,1 to 50 Employees,Company - Public,"Overview
We are conducting a search for a Data Engineer to join our client’s engineering team in Palo Alto, CA or remotely anywhere in the United States.
Interested in shaping the future of pediatrics behavioral health? Our client is looking for a skilled Data Engineer to join their Engineering team who has in-depth experience with a variety of databases and maintaining data repositories from multiple data sources using different schemas.
Come join a world-class company delivering AI-powered diagnostics and therapeutics to dramatically improve the outlook of young children with cognitive and behavioral conditions.
Ability to work remotely is possible, with quarterly visits to Palo Alto.

Responsibilities
Create and maintain a data repository for analytics by combining multiple data sources using different schemas.
Work with various groups in Engineering to source the necessary data.
Implement industry best practices including quality assurance and compliance standards related to Protected Health Information (HIPAA).
Develop and maintain ETL processes to populate the data warehouse.
Deploy utility applications to Amazon AWS EC2, Fargate or Kubernetes.
Qualifications
BS in Computer Science, Engineering or related discipline.
4+ years experience with two of MySQL, Oracle SQL, Postgres.
Deep understanding of relational database structure and performance.
Past experience maintaining data repositories with disparate data sources.
Past experience building visualizations of underlying data.
Experience with Linux, Python, REST API.
Excellent verbal and written communication skills.
Excellent organizational skills and attention to detail.
Nice to Have
Experience with Amazon Web Services (RDS)
Experience building/supporting HIPAA-compliant software.
Understanding of underlying technologies of Tableau (Hyper databases, Hyper API, server extracts, prep flows, Python libraries.
Deep understanding of dimensional data warehouses
Experience with design star and snowflake schemas
Ability to come into the office every so often (once we actually can).


If interested, please send your resume to lana@bxgi.com.",-1,-1,Unknown / Non-Applicable,-1
Data Warehouse Engineer,san-jose,Horizon Corp,"Cupertino, CA",-1,Employer Provided Salary:$110K - $150K,-1,-1,-1,-1,-1,-1,-1,"Job Title: Data Warehouse Engineer
Location: Cupertino, CA
Duration: Full Time
Skills Required:
Terraform along with synapse Azure cloud.
Deep expertise in Data Engineering and Data Warehousing (minimum 4+ years)
Azure synapse, Azure Data Factory, Spark Pool, SQL, SQL Pool (minimum 4+ yrs.)
CI/CD and Python/Java programming experience (minimum 3+ years)
Ideal to have a 24 x 7 development i.e., offshore presence or different time zones
Job Type: Full-time
Salary: $110,000.00 - $150,000.00 per year
Work Location: One location",-1,-1,-1,-1
Data Engineer,san-jose,"Cequence Security
4.8","Sunnyvale, CA",4.8,Employer Provided Salary:$120K - $200K,4.4,4.6,4.6,4.7,4.6,51 to 200 Employees,2014,"About Cequence Security
Cequence Security, the pioneer of Unified API Protection, provides the only solution that unifies API discovery, inventory tracking, risk analysis and native mitigation with proven, real-time threat protection against ever-evolving API attacks. Cequence Security protects more than 2 billion user accounts across our Fortune 500 customers.
Learn more

Data Engineer Position Overview
As a Data Engineer at Cequence Security, you will be responsible for developing and enhancing the various Real Time Data flow pipelines as well as enabling sophisticated Data Analysis from the data at rest in multiple data lakes, while also maintaining strict high performance and throughput requirements. You will also work closely with other Data Engineers, Data Scientists and Security experts to bring new ideas in Data Exploration, Analytics and Machine Learning to fruition as product features that will enable new ways of catching malicious actors and help protect our customers from various forms of exploits and abuse.
There are multiple openings for the Data Engineer in both our Sunnyvale, CA headquarters and our Cincinnati, OH development center.
Responsibilities
Build and enhance an optimal real time data pipeline architecture using technologies such as Spark Streaming, Kafka Streams, Kafka Messaging, Elasticsearch and other Big Data technologies.
Identify, design, and implement improvements in the data pipelines to achieve ever higher throughput and scalability.
Work with data scientists and security experts to strive for greater functionality in our core products.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work within an Agile workflow to organize tasks and collaborate with other team members (Jira).
Work in a Test-Driven Development environment focused on producing reliable, well-documented production code.
Requirements
Bachelor’s degree or equivalent experience in Computer Science, or another relevant field.
Expert level experience with programming languages Java/Scala/Kotlin etc.
Minimum 4 years of experience in building and optimizing ‘Big Data’ data pipelines, architectures and data sets.
Experience with message queuing, stream processing, and highly scalable ‘big data’ data stores.
Experience with big data tools: Spark, Kafka, Elasticsearch, Hadoop etc.
Experience with stream-processing systems: Flink, Spark-Streaming, Kafka Streams etc.
Experience with Cloud services such as AWS EC2, EMR, EKS etc is a plus.
Experience with working in Docker and Kubernetes is a plus.
Salary Range 120-200k USD
Salary Disclaimer
The salary range represents the low and high end of the base salary range for this position. Actual salaries will vary depending on factors including but not limited to location, experience, and performance. The range listed is just one component of the total compensation package for Cequence Security employees. Other rewards may include quarterly bonuses, commissions, stock options, unlimited Paid Time Off, and other benefits not listed.
Come talk with us if you’re looking to make a difference and work at a fast-paced, fun, and rewarding environment. It’s the best career decision that you can make!",Unknown / Non-Applicable,Enterprise Software & Network Solutions,Company - Private,Information Technology
Geospatial Data Engineer,san-jose,"Wing
4.5","Palo Alto, CA",4.5,Employer Provided Salary:$133K - $177K,3.9,5.0,3.9,5.0,5.0,Unknown,Subsidiary or Business Segment,"About Wing:
Wing offers drone delivery as a safe, fast, and sustainable solution for last mile logistics. Consumer appetites for on-demand services are increasing, but current delivery methods are inefficient, costly, and contribute to road accidents and air pollution. Wing's fleet of autonomous delivery drones can transport small packages directly from businesses to homes on-demand, in minutes. We design, build, and operate our aircraft, and offer drone delivery services on three continents. Our technology is designed to be easy to integrate into existing delivery and logistics networks, offering a scalable drone delivery solution for a broad range of businesses. Wing is a part of Google's parent company, Alphabet, and our mission is to create the preferred means of delivery for the planet. To do this, we must build a workforce that's representative of the global communities that we serve. If you're ready to do the greatest work of your life, come join us.
About the Role:
Wing is looking for a Geospatial Data Engineer to join our Flight Operations team. This position is based in the United States and is remote. The ideal candidate has a passion for developing and implementing custom geospatial processes, demonstrated knowledge of software engineering expertise, familiarity with geospatial data management, and the ability to deliver results as part of a dynamic, cross-functional team.
What You'll Do:
Develop and implement custom geospatial data processing solutions
Provide expertise to help drive Wing's geospatial data processes and specifications
Create large-scale innovative geospatial data automation systems and tools for unique aviation applications
Collaborate within the geospatial team on processes, procedures, and required data for new flight operations areas
Design and develop automated systems to import geospatial data into Wing's geospatial data management system
What You'll Need:
BA/BS degree in Computer Science, Information Systems, Software Engineering, Geographic Information Systems, a related field or equivalent professional experience
5+ years of professional experience as a geospatial software engineer
Experience developing large scale Information storage and retrieval, mapping technologies, and/or GIS data processing / visualization tools
Experience developing and maintaining production systems deployed to the cloud
Programming languages in SQL, C++, Java, or Python
Experience with industry GIS tools such as ArcGIS, QGIS, gdal/ogr, or FME
Excellent written and verbal communication skills
Bonus:
Crewed or uncrewed aviation licenses or certifications
Experience working in the uncrewed aviation systems industry
Experience in highly regulated environments, such as aerospace or healthcare
Experience working with raw data sources such as LiDAR point clouds, digital terrain models, aerial imagery, global geospatial data sources

The US base salary range for this full-time position is the salary range below + bonus + equity + benefits. Your recruiter will share more about the specific salary range for your targeted location during the hiring process.
Salary Range
$133,000—$177,000 USD",-1,Information Technology,Information Technology Support Services,Unknown / Non-Applicable
Data Engineer,san-jose,DUOPEAK,"Menlo Park, CA",-1,$103K - $150K (Glassdoor est.),-1,-1,-1,-1,-1,51 to 200 Employees,Company - Private,"At DuoPeak we’re a team of passionate and hard-working individuals with a real love for mobile games. We found ourselves enamored with understanding the process of what makes a game successful. Through our combined understanding, we found that the real essence of a successful game comes down to three things: Product, Marketing and Operations.

What we’re looking for is the Data Engineer, who will thrive in an environment that is hands on and is always looking for ways to improve and further our business through big data and AI. We are offering a large opportunity for growth.

Job Type: Full-time
Key Responsibilities:

Create and maintain optimal data pipeline architecture.
Identify, design, and implement internal data process improvements for security, accuracy, stability and scalability purposes.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, GCS and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipelines to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Create data tools and deploy ML models for the analytics/data scientist team members, which will assist them in building and optimizing our product into an innovative industry leader.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.

What We're Looking For:

Highly analytical, data-driven individuals
Detail-oriented and organized people
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience with data processing software (such as Hadoop, Spark, Pig, Hive) , data processing algorithms (MapReduce, Flume) and data pipeline & workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience building processes supporting data transformation, data structures, metadata, dependency and workload management.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
A Plus For:

Strong project management and organizational skills is a plus
Experience supporting and working with cross-functional teams in a dynamic environment.
A Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:
Experience with Google or AWS cloud services
Experience with stream-processing systems: Storm, Kafka, Spark-Streaming, etc.

Benefits:

Fully Covered Health insurance
Unlimited DTO
401K
Snacks (Food/Drinks)
Cell Phone Reimbursement
‍
Apply",-1,-1,Unknown / Non-Applicable,-1
Data Warehouse Engineer,san-jose,"Purple Drive Technologies
4.2","Cupertino, CA",4.2,Employer Provided Salary:$98K - $191K,3.9,4.0,4.0,3.7,4.2,1 to 50 Employees,Company - Private,"Terraform along with synapse Azure cloud
Deep expertise in Data Engineering and Data Warehousing (minimum 4+ years)
Azure synapse , Azure Data Factory , Spark Pool , SQL , SQL Pool (minimum 4+ yrs)
CI/CD and Python/Java programming experience (minimum 3+ years)
Ideal to have a 24 x 7 development i.e offshore presence or different time zones
Job Type: Full-time
Salary: $97,654.83 - $190,994.11 per year
Ability to commute/relocate:
Cupertino, CA: Reliably commute or planning to relocate before starting work (Required)
Experience:
Data modeling: 1 year (Preferred)
Work Location: One location",-1,-1,Unknown / Non-Applicable,-1
Data Center Infrastructure Engineer,san-jose,"Direct Line
3.7","Santa Clara, CA",3.7,Employer Provided Salary:$45.00 - $50.00 Per Hour,3.4,3.5,3.6,3.8,3.8,501 to 1000 Employees,1997,"SUMMARY:
Direct Line (“DL”) is a high growth global technology services company with primary focus in providing design, integration, installation, maintenance and managed services to well-known data center operators and technology companies. Direct Line deploys decades of experience and knowledge through key partnerships with hyperscale technology companies and multi-tenant data center operators that give its clients a competitive marketplace advantage. Direct Line is committed to continually improving our industry through certified training of cutting-edge technicians that deliver superior results with a passion for detail. Direct Line is headquartered in Fremont, California with additional locations in Virginia, Tennessee, North Carolina, New Mexico, the Pacific Northwest, Asia-Pacific, and Europe.
POSITION: Data Center Infrastructure Engineer
LOCATION: MUST BE LOCATED WITHIN A COMMUTABLE DISTANCE TO SANTA CLARA, CA OR ASHBURN, VA / MUST BE WILLING TO TRAVEL (75-80% travel)
Job description
We are now looking for a Data Center Infrastructure Engineer!
We are looking to grow our company and grow with the hardest working people in the world. Academic and commercial groups around the world are powering a revolution in artificial intelligence using deep learning techniques running on GPUs, enabling breakthroughs in the most complex problems from autonomous driving to medial image processing to natural language processing. Come work on an innovative company's AI technologies!
What You’ll Be Doing:
You will lead all aspects of and personally implement complex architectures in one of several data centers.
Solutions will include network, storage, and compute resources to meet customer requirements, SLAs and high levels of uptime. As a key member of the engineering team you will develop, implement, and lead rack-level elevation designs to ensure velocity and scale while efficiently utilizing space, power, and cooling.
Review, evaluate and improve the design and implementation of structured cable solutions to support network topologies
Establish continuous improvements in the design, implementation, deployment and operation of large-scale cloud-based solutions in power-dense air- and water-cooled environments
Develop and maintain processes and procedures associated with the management and deployment of data center infrastructure including asset management and RMAs
Support and expand data center monitoring applications, with a strong focus on CI/CD automation
You will ensure standards supporting operating procedures and engineering issues for problem incident management are followed, including all safety requirements
Handle network, electrical and mechanical operations at data centers focusing on availability, service delivery, and internal customer relationship management
Analyze and resolve critical engineering issues, often under tight timeframe pressures; Off hours and on-call hours are to be encouraged
What We Need to See:
You love solving hard problems and can work independently or as part of a team under tight timelines
You are passionate about providing outstanding support to customers
Bachelor’s degree in Math, Computer Science, or Engineering subject area. Equivalent background in Military Technical School also acceptable or equivalent experience in datacenter engineering operations.
6+ years’ experience as datacenter operations engineers with critical systems and telecommunications Infrastructure Standards, network certification is very desirable
Deep knowledge of data center operations including network, power, rack layouts, cabling, Raised Floor Systems, HOT/COLD aisle containment. Operational experience with compute, storage and GPU servers in both air- and water-cooled environments
Install, config, and maintain all NW and 3rd party HW
Experience with ERMA, Break-fix, etc.
Reading and understanding P2P cabling, labeling and cable mgt/dressing etc.
Ways to stand out of the crowd:
An obvious passion for getting things done in a fast-paced technology environment
Deep understanding of data center power and cooling infrastructure, of network and cabling infrastructure.
Experience with NetBox, CMMS, SNOW and Inventory Management tools.
You're a self-starter with an attitude for growth, continuous learning, and constantly looking to improve the team.
Attention to detail with superb interpersonal skills and the ability to effectively manage multiple priorities.
A positive attitude with a strategic outlook.
Constantly look to improve the team and build strong business relationships
Direct Line is a proud equal opportunity employer. We are a drug free, EEO employer committed to a diverse workforce. We will consider all qualified candidates regardless of race, color, national origin, sex, age, marital status, personal appearance, sexual orientation, gender identity, family responsibilities, disability, political affiliation, or veteran status.
Job Type: Full-time
Pay: $45.00 - $50.00 per hour
Benefits:
401(k)
401(k) matching
Dental insurance
Employee assistance program
Flexible spending account
Health insurance
Life insurance
Paid time off
Referral program
Vision insurance
Schedule:
Monday to Friday
Experience:
CI/CD: 3 years (Required)
Linux: 3 years (Preferred)
Server Support: 3 years (Required)
Break/Fix / ERMA: 3 years (Preferred)
Data center Engineering: 3 years (Required)
Work Location: On the road",Unknown / Non-Applicable,Enterprise Software & Network Solutions,Company - Private,Information Technology
ML and Data Infrastructure Engineer - SPG,san-jose,"Apple
4.2","Cupertino, CA",4.2,-1,-1,-1,-1,-1,-1,10000+ Employees,1976,"Summary
Posted: Dec 13, 2022
Role Number:200425055
As an engineer in the Special Projects Group, you will be part of a team building infrastructure and tools for exciting new technologies that will shape the future. You will work in a startup-like environment where products are still being defined and developed, giving you the chance to influence some of the core tools used by the project. You will be part of every stage of development from concept to deployment. We are looking for an senior engineer to architect, build and scale a robust ecosystem for data processing and distributed computation. Specifically you will develop solutions that will orchestrate and support the seamless transitioning of petabytes of data through various stages like ingestion, indexing/mining, transformation, machine learning and algorithm validation.
Key Qualifications
You have hands-on experience in building distributed systems, including real-time streaming and batch data processing
You are proficient in multiple programming languages relevant for such systems (e.g. Python, C++, Go, Java)
You know what it takes to deploy and operate high availability production systems in the cloud
You have experience designing service-oriented architectures and leveraging various data stores technologies (blob, NoSQL, and relational)
You have experience with cloud computing platform like AWS, GCP and Azure
Description
• Develop and scale a data processing platform using the latest open-source technologies • Develop platforms that enable researchers and developers to run machine learning jobs in the cloud easily • Define a consistent continuous integration/deployment model that will encourage cross-functional development teams to self-service application unit testing, deployment and operations • Influence and lead cross-functional initiatives that will align the team towards commonly used technologies and methodologies
Education & Experience
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $130,000 and $242,000, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",$10+ billion (USD),Computer Hardware Development,Company - Public,Information Technology
"Data Engineer, WW CSO",san-jose,"Apple
4.2","Cupertino, CA",4.2,-1,-1,-1,-1,-1,-1,10000+ Employees,1976,"Summary
Posted: May 31, 2023
Weekly Hours: 40
Role Number:200481124
Imagine what you could do here! The people here at Apple don’t just create products — they create the kind of wonder that’s revolutionized entire industries. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple, and help us leave the world better than we found it. Apple's Worldwide Channel Strategy & Operations (WW CSO) organization focuses on developing and deploying worldwide sales programs and best practices to deliver an extraordinary customer experience in the channel and drive Apple Channel sales. With deep functional expertise in digital, physical, and people enablement spaces, our WW CSO team closely collaborates with many cross-functional groups at global and regional levels. We are seeking an experienced Senior Data Engineer to drive data ingestion, aggregation and visualization efforts for our channel sales platforms. This role will be critical in scaling how we ingest and transform data, from digital and in-store platforms to build a comprehensive view of the business. In this position, you will closely collaborate with multi-functional teams including, regional sales teams, engineering teams, as well as external partners, to build data pipelines using advanced ETL capabilities and Cloud Data Infrastructure.
Key Qualifications
8+ years experience building highly scalable, compliant, and secure, enterprise-grade data and analytics platforms with robust data quality, data governance, data discovery, catalog and visualization capabilities
4+ years of experience working with large-scale e-commerce data and analytics platform, including building pipelines for Digital performance KPIs, Performance Marketing, and Testing & Optimization
Strong coding knowledge/abilities in handling large data sets through SQL, data manipulation and ETL tools such as Alteryx; and experience with using cloud data platforms such as Snowflake and Amazon S3
Experience building data pipelines in production and ability to work across structured, semi-structured and unstructured data
Proven understanding of the enterprise data concepts (Master Data, Operational Data, Reference Data, Transactional Data)
Hands on experience with the latest OSS, cloud, container, query languages and database technologies
Solid understanding of security and risk principles around data, including governance and architecture considerations
Strong expertise in implementing effective and successful Cloud based Data Migration and Data Integration strategies across ERP systems
Good understanding of data warehousing, data lake concepts and Tableau dashboards (including Tableau Prep), visualizations, etc.
Proven track record in enterprise-wide API management, micro-services, event-driven architectures and complex integrations
Entrepreneurial attitude with an ability to navigate ambiguity while being able to “focus on what matters most”
Strong influencing skills that drive alignment with a wide range of partners in a non-hierarchical environment, including business, operational and technical teams
Programming skills in R or Python, a plus
Commercial experience in a data-driven role, a huge plus
Relevant certifications in AWS or other cloud data platforms preferred
Experience with Marketing Analytics Platform such as Salesforce Datorama, a plus
Description
In this role, you will focus on the following key areas: Data Pipelines: Build sustainable data pipelines and curated data sets needed to for business use-cases across multiple sources (operational, analytical and reporting) Data Quality: Conduct data assessment, perform data quality checks and transform and load raw data into Cloud Data Hub using SQL and ETL tools such as Dataiku Data Definition: Manage data lifecycle including definition, usage and quality using architecture repositories like data dictionaries, data models, metadata and data quality logs KPIs: Responsible for assembling and maintaining the data sets enabling the suite of Digital and Physical Performance metrics Governance: Partner closely with technology partners and internal engineering teams on data architecture, standardization, and curation for prioritized use-cases Teamwork: Collaborate with GEO business and technical partners and teams to analyze needs and develop data integration solutions Roadmap: Contribute to overall Data and Analytics strategy and roadmap
Education & Experience
Ph.D. in Computer Science, Machine Learning, Statistics, Operations Research or related field; or Ph.D. in Math, Engineering, Economics, or hard science with data science fellowship; or M.S. in related field with 3+ years experience applying machine learning engineering to real business problems
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $161,000 and $242,000, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",$10+ billion (USD),Computer Hardware Development,Company - Public,Information Technology
Data Engineer,san-jose,"American Century Investments
3.9","Santa Clara, CA",3.9,Employer Provided Salary:$104K - $135K,3.4,3.9,3.4,3.5,3.7,1001 to 5000 Employees,1958,"Our Firm
American Century Investments® is a leading global asset manager with over 60 years of experience helping investors achieve their financial goals. Serving a broad client base including financial advisors, institutions, and individual investors, we offer a wide range of investment strategies across a variety of investment disciplines.
Privately controlled and independent, we focus solely on investment management. This empowers us to align our decisions with client expectations and concentrate on their long-term money management needs.
We are committed to providing institutional-quality, actively managed solutions with a performance-centered mindset. Our expertise spans global growth equity, global value equity, disciplined equity, multi-asset strategies, global fixed income, alternatives, and ETFs.
Our culture of winning behaviors exemplifies our dedication to clients every single day. Delivering investment results enables us to distribute over 40% of our dividends—or more than $1.5 billion since 2000—to the Stowers Institute for Medical Research, a 550-person, non-profit biomedical research organization with a controlling interest in American Century Investments. Our dividend payments provide ongoing financial support for the Institute’s work of uncovering the causes, treatments, and prevention of life-threatening diseases, like cancer.
Headquartered in Kansas City, MO, we also have offices located in New York; London; Hong Kong; Sydney; El Segundo, CA (Los Angeles area); and Mountain View, CA (Silicon Valley).
For more information, please visit americancentury.com.
The American Century Investments Technology Group is looking for a dedicated Data Engineer with confirmed analysis and design skills to support our Portfolio Management team. You will provide leadership and guidance in the design, development, implementation, configuration, integration, and support of the various technology tools used by Portfolio Management team. This includes working closely with a diverse group of veteran portfolio teams and research analysts to understand their needs and then translating those into solutions.
Are you passionate about an opportunity to drive continuous improvements? Do you enjoy working in a fast-paced environment? We are seeking individuals with a real passion for problem solving and a drive for continuous improvement. Distinguishing characteristics will include curiosity, innovation, and the ability to adapt quickly in a dynamic environment.
Responsibilities:
The Data Engineer will be essential in designing and developing data systems and pipelines to enable investment management teams to use the financial data and build alpha generating models. Your responsibilities include, but are not limited to:
Analyze, organize, transform, and store data while implementing data validation and data quality checks
Develop and maintain data pipelines for data extraction, transformation, and ingesting data from various sources
Build data consumption options for business partners to consume data in various ways (APIs, query like tools from various platforms like database, data warehouse, and/or EDL)
Work with data governance, data management and infrastructure teams to develop the solutions required
Automate manual processes for productivity improvements and data consistency
Build tools to deliver practical insights and operational efficiency
Empower portfolio management and research teams, so they can build data driven solutions
Establish relationships with internal business partners and vendors
You, as part of a team, will provide on call support and occasional overtime may be required
Required:
Bachelor’s degree in computer science or similar technical field, or an equivalent combination of education and work experience
3+ years of experience developing data extraction, transformation, and data analysis solutions
Experience working with AWS technologies, lambdas, Athena, ETL, structured and un-structured datasets
Solid understanding of SQL and experience with relational and non-relational databases
Experience working with business intelligence and data visualization tools (like Tableau)
Proficiency in the clear expression of ideas both verbally and in writing with business and technical teams
Models the American Century Investments Winning Behaviors: Client Focused, Courageous and Accountable, Collaborative, Curious and Adaptable, Competitively Driven, Adheres to the highest ethical standards and business practices, and Supports a culture of compliance
Preferred:
Experience working with programming languages, preferably Python
Experience with data models, data mining, and data segmentation techniques is a plus
Knowledge of investment instruments such as stocks, bonds, futures, and FX
Knowledge of the financial services industry, including financial securities, mutual funds, and ETFs
Understanding of or experience implementing artificial intelligence, predictive modeling, NLP, and machine learning
This position will work in a hybrid work environment. Position may be filled in New York, Kansas City, MO, Santa Clara, CA or DFW/Southlake, Texas. For those hired outside of KCMO, there will be some travel, at least once per quarter, to ACI Headquarters (KCMO)
The salary range for this position is $103,500 - $135,450 depending on qualifications and work location. This position is eligible for cash incentive providing the potential to earn more.
Additional Requirements:
As a global firm with offices in several cities, we will uphold any local regulations regarding COVID-19 precautions and/or vaccination requirements for the workplace. Based on work location, you may be required to submit proof of having received the final dose of an approved COVID-19 vaccine prior to the position start date unless you have obtained a reasonable accommodation.
American Century Investments is committed to complying with the Americans with Disabilities Act and all other applicable Equal Employment Opportunity laws and regulations. As such, American Century strives to provide a reasonable accommodation to any qualified individual under the ADA to perform essential job functions.
American Century Investments believes all individuals are entitled to equal employment opportunity and advancement opportunities without regard to race, religious creed, color, sex, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, gender, gender identity, gender expression, age for individuals forty years of age and older, military and veteran status, sexual orientation, and any other basis protected by applicable federal, state and local laws. ACI does not discriminate or adopt any policy that discriminates against an individual or any group of individuals on any of these bases.
EOE Policy Statement: American Century Investments believes all individuals are entitled to equal employment opportunity and advancement opportunities without regard to race, religious creed, color, sex, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, gender, gender identity, gender expression, age for individuals forty years of age and older, military and veteran status, sexual orientation, and any other basis protected by applicable federal, state and local laws. ACI does not discriminate or adopt any policy that discriminates against an individual or any group of individuals on any of these bases.
©2019 American Century Proprietary Holdings, Inc. All rights reserved.",Unknown / Non-Applicable,Investment & Asset Management,Company - Private,Financial Services
Data Engineer – R01524613,san-jose,"Brillio
3.8","Santa Clara, CA",3.8,$97K - $145K (Glassdoor est.),3.7,3.7,3.5,3.7,3.6,1001 to 5000 Employees,2014,"Data Engineer - R01524613
About Brillio:
Brillio is the partner of choice for many Fortune 1000 companies seeking to turn disruption into a competitive advantage through innovative digital adoption. Backed by Bain Capital, Brillio is one of the fastest growing digital technology service providers. We help clients harness the transformative potential of the four superpowers of technology - cloud computing, internet of things (IoT), artificial intelligence (AI), and mobility. Born digital in 2014, we apply Customer Experience Solutions, Data Analytics and AI, Digital Infrastructure and Security, and Platform and Product Engineering expertise to help clients quickly innovate for growth, create digital products, build service platforms, and drive smarter, data-driven performance. With delivery locations across United States, Romania, Canada, Mexico, and India, our growing global workforce of over 6,000 Brillians blends the latest technology and design thinking with digital fluency to solve complex business problems and drive competitive differentiation for our clients. Brillio was awarded ‘Great Place to Work’ in 2021 and 2022

Data Engineer
Primary Skills
Amazon API Gateway, AWS CodeBuild, AWS CodeDeploy, AWS CodePipeline, AWS Lambda, AWS Step Function, CloudFormation
Secondary Skills
AWS QuickSight, Python, Tableau, Snowflake
Specialization
AWS DevOps Specialization: Engineer, Automation Solutions
Job requirements
• Provide recommendations to business stakeholders to solve complex business issues. • Develop business justifications and ROI on projects with a projected return on investment or cost savings. • Design, develop, and operate highly scalable, high-performance and low-cost data pipelines in distributed data processing platforms with AWS/cloud technologies. • Collaborate with Engineers, Analysts and Data Scientists in the organization to construct complex data sources for algorithms and machine learning models • Own and Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and AWS big data technologies. • Creation and support of Batch and real-time data pipelines built on AWS technologies including Glue, Kinesis, EMR, Lambda and Athena. • Extensive experience in Snowflake - data loading/unloading and data sharing. SnowSQL( JSON/XMLdata) as well as Snowflake Internals and integrations, S3 Internal data copy/movement. • Develop tools, plug-ins and solutions for CI/CD workflow using tools such as Jenkins, Cloud Formation, Docker, Github and other microservices. • Continual research of the latest big data and visualization technologies to provide new capabilities and increase efficiency. • Drive and participate in architecture discussions, influence product roadmap, and take ownership and responsibility over new projects. • Maintain and support existing platforms and evolve to newer technology stacks and architectures. • Collaborate with the Enterprise System team, product owners, Business stakeholders, Scrum-master to refine and estimate stories/epics. • Be an integral part of the scrum team to deliver commitments on time and with good quality. • Review and ensure all code documentation is complete and updated periodically. Review work of Junior associates in the team. • Analyze the business Problems and deliver Optimal solutions using AWS Technologies. #LI-AT2
Know what it’s like to work and grow at Brillio: Click here",$100 to $500 million (USD),Information Technology Support Services,Company - Private,Information Technology
"R&D Data Engineer, Supira Medical",san-jose,"Shifamed
4.0","Campbell, CA",4.0,$109K - $182K (Glassdoor est.),4.0,4.7,4.0,4.2,4.0,1 to 50 Employees,Company - Private,"Supira Medical, a clinical-stage Shifamed Portfolio Company, is developing a low-profile, high continuous flow percutaneous ventricular assist device (pVAD) to provide temporary mechanical circulatory support in high risk percutaneous coronary interventional (HRPCI) procedures as well as patients suffering from cardiogenic shock. To learn more about Supira Medical, please visit www.supiramedical.com.
ABOUT SHIFAMED
Founded in 2009 by serial entrepreneur Amr Salahieh, Shifamed LLC is a privately held medical device innovation hub focused on the development of novel medical products to address clinical needs in the rapidly evolving fields of cardiology and ophthalmology.
Description
We are currently looking for a hands-on R&D Data Engineer with strong analytical skills and is a collaborative team player. This position represents an exciting opportunity to join the Supira team as we expand the clinical usage of the Supira mechanical circulatory support system.
As the R&D Data Engineer on the Supira team, you will play a key role working with product development engineers to analyze system performance and patient hemodynamic data. You will develop and test innovative new algorithms to drive better patient outcomes through predictive models.
Responsibilities, Skills & Hands-On Experience
Time domain and frequency domain analysis of system performance and patient hemodynamic data.
Develop and test algorithms for improved system performance.
Automate data processing workflows (extracting, cleaning, collating, storage, analysis, etc.).
Assist in the development and maintenance of the database system used to store all system performance and patient hemodynamic data.
Perform benchtop and pre-clinical system performance testing as needed.
Expand the capabilities of catheter test systems and physiological simulators as needed.
Introduce new technology for data collection and automated test reporting.
Manage tasks related to multiple projects.
Contribute to the intellectual property position of the company via lab notebook documentation, invention disclosures, and prototypes to demonstrate reduction to practice.
Participate in technical ""brainstorming"" sessions to generate new intellectual property.
Education & Work Experience
Degree in bioengineering, biomedical engineering, mechanical engineering, electrical engineering, or related technical field.
Experience with time and frequency domain signal analysis and algorithm development in the context of biological or electro-mechanical signals.
Strong Python coding skills and related data analysis & plotting stack (i.e., Pandas, NumPy, SciPy, Scikit-learn, Matplotlib, Seaborn, etc.).
Experience with relational databases (e.g., Postgres) and writing SQL queries.
Familiarity with basic statistical analysis, machine learning, and artificial intelligence methods.
Self-motivated, execute tasks with attention to detail in a timely manner.
Ability to formulate hypotheses, create research plans, and form conclusions based on available data.
Ability to work collaboratively with a cross-functional technical team of electro-mechanical and software engineers.
Independent worker able to both find technical answers on their own and recognize when other team members have useful solutions.
Strong written and verbal communication skills including the ability to write reports and present highly technical information to a diverse audience with varied backgrounds (e.g., operations, marketing, regulatory, clinical, etc.).
Familiarity with anatomy and physiology, particularly of the cardiovascular system is a plus.
Prior experience developing algorithms for medical device or biological signal applications is a plus.
Prior electro-mechanical CAD experience (e.g., SolidWorks, KiCAD) is a plus.
Contributes to opensource projects or has a personal project portfolio is a plus.
Our salary ranges are calculated by role and level. Your position within that range will be determined by your job-related knowledge, skills, experience, relevant education, and training/certifications. In addition to those factors, we also examine internal equity as well as consider current market rate, and title may be assessed one level lower or higher accordingly. After you join the company your performance, contributions, and results along with business and organizational needs will affect your base salary. The base salary range for this full-time position is between $90,000 to $180,000 + equity + benefits.
NOTICE TO CANDIDATES: Please be aware that Shifamed and its portfolio companies do not conduct interviews or extend offers through mobile web chat applications. Please report any such occurrences to hr@shifamed.com.",-1,Manufacturing,Consumer Product Manufacturing,$1 to $5 million (USD)
"Data Center Mechanical Engineer, Advanced Technology and Innovation",san-jose,"Google
4.4","Sunnyvale, CA",4.4,-1,-1,-1,-1,-1,-1,10000+ Employees,1998,"Minimum qualifications:
Bachelor's degree in Mechanical Engineering, Industrial Design, a related technical field, or equivalent practical experience.
3 years of experience in mechanical design and analysis for medium-scale production, structural beams/elements, and international building codes.
2 years of experience with 3D CAD systems, structural and thermal analysis techniques (e.g., Ansys, RISA-3D, etc.).

Preferred qualifications:
Experience in designing complex modular building scale assemblies with an understanding of mechanical tolerances and tolerance analysis.
Ability to architect solutions backed by business case analysis.
About the job
Our thirst for technology is a part of everything we do. The Data Center Engineering team takes the physical design of our data centers into the future. Our lab mirrors a research and development department - cutting-edge strategies are born, tested and tested again. Along with a team of great minds, you take on complex topics like how we use power or how to run state-of-the-art, environmentally-friendly facilities. You're a visionary who optimizes for efficiencies and never stops seeking improvements - even small changes that can make a huge impact. You generate ideas, communicate recommendations to senior-level executives and drive implementation alongside facilities technicians.
As a Data Center Mechanical Engineer, you will own and design to the entire product design life cycle, including requirements gathering, concept generation, detailed design with analysis, verification testing, cross-functional reviews, and manufacturing release. You will develop and execute designs for complex systems backed by thorough engineering analysis.
Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible.
The US base salary range for this full-time position is $96,000-$139,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.
Responsibilities
Create test plans, perform testing, and validate designs to meet engineering requirements.
Troubleshoot, root cause, and resolve potential technical challenges. Influence and shape future products by providing mechanical and structural engineering expertise into the technology roadmap with data-driven decisions.
Identify and scope projects around innovation opportunities as well as technology risks.
Provide technical mentorship and coaching and foster professional growth within the team.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.",$10+ billion (USD),Internet & Web Services,Company - Public,Information Technology
Data Engineer,san-jose,"LatentView
4.1","San Jose, CA",4.1,$110K - $152K (Glassdoor est.),4.1,4.2,3.8,3.7,3.9,1001 to 5000 Employees,2006,"Job Description:
About LatentView:
LatentView Analytics is a leading global analytics and decision sciences provider, delivering solutions that help companies drive digital transformation and use data to gain a competitive advantage. With analytics solutions that provide 360-degree view of the digital consumer, fuel machine learning capabilities and support artificial intelligence initiatives., LatentView Analytics enables leading global brands to predict new revenue streams, anticipate product trends and popularity, improve customer retention rates, optimize investment decisions and turn unstructured data into a valuable business asset.
We specialize in Predictive Modelling, Marketing Analytics, Big Data Analytics, Advanced Analytics, Web Analytics, Data Science, Data Engineering, Artificial Intelligence and Machine Learning Applications.
LatentView Analytics is a trusted partner to enterprises worldwide, including more than two dozen Fortune 500 companies in the retail, CPG, financial, technology and healthcare sectors.

Key Skills for all given roles: Advanced SQL, Python, Spark

Position Type: Fulltime
Location: Multiple Locations across US
No of Roles: Multiple
Job Responsibilities:
Help make improvements to current data pipeline
Reduce failures
Automate some of the existing pipelines
Manage customer escalations including cases such as missing data
Address performance issues
Develop processes to help monitor database queries
Overall, the Engineer is expected to be proactive and take a leading role in data platform maintenance, including suggesting improvements to the client.
Mandatory Skills:

5+ years of experience working with big data and related technologies
Experience using Big Data technologies (Spark, Hive, etc.)
Working experience and a good understanding of public cloud environments (AWS, Azure, and/or Google Cloud) is a plus.
Oozie, Apache airflow is preferred or any other related workflow management system.
Passion for producing high-quality work and continuously improving the ways we deliver data services.
Good knowledge of security policies and vulnerabilities.
Experience with policies and role management is a plus.
You excel at taking vague requirements and crystallizing them into scalable solutions.
You have exceptional communication skills.",$25 to $100 million (USD),Business Consulting,Company - Public,Management & Consulting
"Platform Data Engineer, Financial Services",san-jose,"Recruiting From Scratch
3.9","Saratoga, CA",3.9,Employer Provided Salary:$140K - $250K,4.0,3.6,3.5,3.9,3.9,1 to 50 Employees,2019,"Who is Recruiting from Scratch:
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
Data Engineer - Platform
A Career with our Market Intelligence Team:
Our Market Intelligence team is responsible for developing proprietary research products and providing data and research management services for investment teams to support their pursuit of superior, risk-adjusted returns. We leverage innovative alternative data sources, advanced data analytics and technologies, and deep fundamental research to create high-quality compliant and differentiated research. Backed by the full resources of our company, our sector aligned teams of fundamental researchers, data scientists, data strategists, relationship managers, and data engineers collaborate to solve important research problems in partnership with the Firm’s investment and compliance professionals.

What you’ll do
Platform Engineers build solutions for processing big and unstructured data sets. Our team works closely with portfolio managers and data scientists to understand the potential business value of data sets and ultimately build data processing pipelines around those data sources. In this role, you will:
Develop big data processing pipelines for new data sources containing structured and unstructured data
Build platform infrastructure using Hadoop technologies
Build and support visualization and exploration capabilities around our big data sets
Maintain knowledge of new technology developments and conduct proof of concepts to evaluate new technologies

What’s required
We want you to join us if you have extensive experience or demonstrated interest in big data technologies. Other requirements include:
2+ years of experience in Data Engineering or related field
Commitment to the highest ethical standards
Strong experience in Python Development
Experience with Spark or Scala
Ability to devise novel and innovative solutions to challenges
Knowledge of/experience with graph databases is a plus

We take care of our people
We invest in our people, their careers, their health, and their well-being. We want you to concentrate on success and leave the rest to us. When you work here, we provide:
Fully-paid health care benefits
Generous parental and family leave policies
Mental and physical wellness programs
Tuition assistance
A 401(k) savings program with an employer match and more
Salary Range: $140,000-$250,000 base.",$1 to $5 million (USD),Staffing & Subcontracting,Company - Private,Human Resources & Staffing
"Network Engineer, Data Center",san-jose,"Tesla
3.6","Fremont, CA",3.6,$94K - $138K (Glassdoor est.),3.7,3.3,3.1,3.7,2.9,10000+ Employees,2003,"What to Expect
Tesla is currently seeking a Network Engineer to join our Data Center team. This role will provide network design, implementation, and operational support for Tesla's Data Centers.
What You’ll Do

Help design, build and maintain new and existing Data Centers
Work closely with other team members on design and initiatives; maintain and grow existing data center networks.
Work with Tesla’s key application teams to support their growth, including Tesla Autopilot team.
Provide high availability & reliability to network
Requirements gathering, analyze, and propose solution to networking needs.
Monitor, analyze, and report metrics of network services.
Develop automation methods to rapidly deploy, configure, and update network equipment.
Assist with network troubleshooting.
Conduct product POC evaluation.
Document network knowledge base and operational “Run-Book.”
Must be able to work occasional weekends, after hours, and holidays.
Participate in on call rotation.
May require unscheduled after-hours work. 10-20% travel required as necessary.
What You’ll Bring
2+ years’ experience mid-large global enterprise networking infrastructure
Experience with mid/large-scale networks in a global environment
Juniper, Arista and Palo Alto Networks hardware
Experience in IP networking, L2/L3 network protocols (spanning-tree, OSPF, BGP), TCP/IP, DHCP, DNS, end to end QOS, VLAN, VRRP, LACP, MC-LAG, EVPN with VXLAN, ACL and infrastructure cabling.
Basic knowledge of AWS, Azure or GCP.
Experience with various tools such as Protocol Analyzer, SNMP, flow, IPAM, RADIUS, Splunk, network taps, and load/stress testing",$1 to $5 billion (USD),Transportation Equipment Manufacturing,Company - Public,Manufacturing
Computer Vision Data Capture Engineer for Body Technologies,san-jose,"Apple
4.2","Cupertino, CA",4.2,-1,-1,-1,-1,-1,-1,10000+ Employees,1976,"Summary
Posted: Nov 11, 2022
Role Number:200405526
Do you love to solve challenging computer vision problems, have worked with complex multi camera setups, and have experience with large scale data collections? Do you thrive on collaboration with cross functional teams? Are you ready to bring your expertise to Apple to build the foundation of future Apple products that excite millions of people around the world? We are looking for a Computer Vision Engineer who can design complex capture setups, coordinate cross functional teams, and understands data needs of deep learning-based algorithms. This is a unique opportunity to shape future Apple products by working at the intersections of software and hardware, data and algorithm.
Key Qualifications
Strong knowledge and experience with computer vision algorithms
Experience with computer vision cameras and synchronization and calibration of complex systems
Experience with data collections and dataset design
Exposure to deep learning algorithms and datasets
Strong mathematical foundation in computer vision and optimization approaches
Experience working with 2D / 3D data
Strong experience in Python and C/C++
Excellent understanding of data structures and algorithms
Excellent problem solving skills
Excellent verbal and written communication
Description
We are the “Body Technology” team that is responsible for many of the key algorithms for videos and photos on Apple products (e.g iPhone, iPad and more), provide backbone algorithms for ARKit, and conduct research and development in the space of Virtual and Augmented Reality. We build people understanding algorithms that drive features such as ARKit Motion Capture. We are looking for smart engineers who are passionate about building products for millions of customers around the world. You will be working on ground breaking technology and develop algorithms that enable a high-quality user experience across a range of applications. As a part of our team, you will collaborate with both software teams (computer vision, deep learning, camera capture software, image signal processing (ISP), data collection software, data generation/annotation, system integration) and hardware engineers (data collection systems, cameras, silicon, electrical engineering, product design). Join us for the rare opportunity to work on novel algorithms software that go beyond the state of the art and eventually will touch the lives of millions of people around the world!
Education & Experience
PhD or Masters in computer science, computer vision, machine learning, or equivalent. Alternatively, a comparable industry career with a proven track record. If this is you, we'd love to hear from you!
Additional Requirements
Additionally beneficial is experience with processing large-scale datasets, motion capture systems, capture protocol design, interactive visualization of complex 2d/3d data, high-framerate dense 3D reconstruction, photogrammetry, animation, 3D computer graphics, algorithm optimization on CPU/GPU, HW-accelerated image or geometry processing, parallel compute architectures, asynchronous processing or embedded systems.
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $130,000 and $242,000, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",$10+ billion (USD),Computer Hardware Development,Company - Public,Information Technology
"Data Scientist / Data Engineer, Quant Modeling - USDS",san-jose,"TikTok
3.6","Mountain View, CA",3.6,Employer Provided Salary:$124K - $270K,3.4,3.4,3.1,3.6,3.0,1001 to 5000 Employees,2016,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity, celebrate individuality and bring people together. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About USDS
At TikTok, we're committed to a process of continuous innovation and improvement in our user experience and safety controls. We're proud to be able to serve a global community of more than a billion people who use TikTok to creatively express themselves and be entertained, and we're dedicated to giving them a platform that builds opportunity and fosters connection. We also take our responsibility to safeguard our community seriously, both in how we address potentially harmful content and how we protect against unauthorized access to user data.

U.S. Data Security (“USDS”) is a standalone department of TikTok in the U.S. This new security-first division was created to bring heightened focus and governance to our data protection policies and content assurance protocols to keep U.S. users safe. Our focus is on providing oversight and protection of the TikTok platform and user data in the U.S., so millions of Americans can continue turning to TikTok to learn something new, earn a living, express themselves creatively, or be entertained. The teams within USDS that deliver on this commitment daily span Trust & Safety, Security & Privacy, Engineering, User & Product Ops, Corporate Functions and more.

About Team & Role
The Data Science team of the US Tech Service department at TikTok USDS is responsible for providing high-quality and timely data solutions for the business and for building easy-to-use and scalable data products to support business growth.

For the quant modeling role, we are seeking a data scientist with strong data engineering and modeling background. You will be working on designing and monitoring core metrics, identifying the root causes for metric movements, and building models to inform optimal business decisions. You will also have the opportunity to build, optimize, and grow one of the largest data platforms in the world.
Qualifications
Qualifications
BS/MS in Computer Science, Math, Economics, Statistics, or other science and engineering fields
2+ years of experience in statistical modeling (Regression, Classification, Clustering, etc.)
2+ years of experience in data engineering (data ingestion, data integration, data analysis, data modeling, ETL)
Proficiency in SQL, Python / R
Hand-on experience in Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.)
Self-motivated, detail-oriented, learn autonomously, and highly organized
Ability to conduct rigorous analysis and communicate conclusions to both technical and non-technical audiences
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to us at debjani.sarkar@tiktok.com
Job Information
The base salary range for this position in the selected city is $123911 - $269689 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",Unknown / Non-Applicable,Internet & Web Services,Company - Private,Information Technology
Senior Data Engineer,san-jose,"Humu
3.8","Mountain View, CA",3.8,Employer Provided Salary:$160K - $220K,3.7,3.7,3.5,3.7,3.9,51 to 200 Employees,2017,"What you'll get to work on
Humu's Nudge Engine® deploys thousands of customized nudges—small, personal steps—throughout organizations to empower every employee, manager, team, and leader as a change agent. Over time, our nudges grow increasingly aware of the timing, messaging, and motivational techniques that inspire individual employees towards action.
As a member of Humu's Data Engineering team, you will be responsible for building and maintaining systems focused on expanding and optimizing data pipelines to compute insights and analyses at scale. Some of the team's major ownership areas include:
A data pipeline tool for helping transform ingested HR data into a consistent and clean format.
The automated processes for deciding which nudges to send to users, scheduling them for delivery, and delivering them through a multitude of formats (email, text messages, etc).
The logic and systems to make data available to a variety of cross functional teams at Humu.

Where you fit in
We are committed to change the working world for the better by bringing greater meaning and happiness into everyone's working lives, everywhere. We are passionate about our mission, and excited to grow our school of fish with people who want to do the same - and people who will bring in their different perspectives to help us continue to shape our team and product. If this is you, we encourage you swim into our candidate pool!

The details
Role and responsibilities:
As a member of our Product Team, you will ensure optimal data delivery architecture is consistent throughout ongoing projects.
Create and optimize our data pipeline architecture
Build data access platform for our data science and tech teams
Manage and optimize customer ingestions for the Humu product
Add and improve logging and monitoring
Willingness to occasionally implement UI for internal data tools.
Qualifications:
4 - 99 years of experience managing data pipelines
Driven engineer that is motivated to build a great product and great codebase in a fast-paced environment
Strong communication skills with a growth and learning mindset
Understanding of object-oriented languages (Java, Python, etc.)
Familiarity with cloud based platforms - GCP (Preferred), AWS, Azure
Experience with large-scale databases (preference towards non-relational unstructured databases).
Usage or understanding of complex data pipelines.
Working knowledge of message queuing, stream processing, and highly scalable 'big data' data stores.

Salary range: $160,000 - $220,000
Only open to candidates in Seattle, WA or SF Bay Area, CA",Unknown / Non-Applicable,Enterprise Software & Network Solutions,Company - Private,Information Technology
Senior CV deep learning engineer (Synthetic data),san-jose,"Apple
4.2","Cupertino, CA",4.2,-1,-1,-1,-1,-1,-1,10000+ Employees,1976,"Summary
Posted: Mar 22, 2023
Role Number:200470811
We are seeking an experienced computer vision deep learning engineer with a strong background in synthetic data generation and domain adaptation between real and synthetic data. The ideal candidate will have a proven track record of delivering successful computer vision applications, with experience in developing and deploying deep learning models in production environments.
Key Qualifications
Develop and deploy deep learning models to solve computer vision problems using synthetic data and domain adaptation between real and synthetic data (hands, body, face preferred)
Build and maintain high-quality datasets, including synthetic data, for use in training and testing machine learning models.
Analyze and interpret data, develop insights, and communicate findings to collaborators.
Work collaboratively with computer vision researchers, software engineers, and other collaborators to design and develop scalable and reliable computer vision applications.
Conduct research on developing novel deep learning algorithms and architectures that can be used to reduce domain gap between real and synthesized datasets.
Stay up-to-date with the latest developments in deep learning/computer vision and related fields, and evaluate new tools and technologies for potential integration into our computer vision applications.
Description
At least 3 years of experience in developing and deploying deep learning models for computer vision applications, with a focus on synthetic data generation and domain adaptation between real and synthetic data. A strong understanding of deep learning frameworks such as TensorFlow or PyTorch, JAX. Experience with data preprocessing, feature engineering, and data visualization. Strong programming skills in Python or similar languages. Strong communication and collaboration skills, with the ability to work effectively in a team environment. Consistent track record of researching, inventing and/or shipping advanced machine learning algorithms Solid mathematical foundation of machine learning and deep learning techniques (linear algebra, optimization theory, ...) Optional : Familiarity with real time / path tracing renderers (VRay, Arnold, Unreal Engine, ...) Optional : Familiarity with cloud-based machine learning platforms, such as AWS or GCP Optional : Familiarity with content creation tools (Maya, Houdini, ... )
Education & Experience
A Bachelor's degree in Computer Science, Mathematics, or a related field. A Master's degree or PhD is preferred.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $130,000 and $242,000, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",$10+ billion (USD),Computer Hardware Development,Company - Public,Information Technology
Data Engineer,san-jose,"Stanford Health Care
3.9","Palo Alto, CA",3.9,Employer Provided Salary:$51.11 - $67.71 Per Hour,3.6,3.5,3.1,3.9,3.4,10000+ Employees,1957,"If you're ready to be part of our legacy of hope and innovation, we encourage you to take the first step and explore our current job openings. Your best is waiting to be discovered.

Day - 08 Hour (United States of America)
The Stanford Medicine Technology and Digital Solutions team was formed to provide the Stanford Medicine community with the most innovative technology services as efficiently as possible. Led by Michael Pfeffer, CIO and Michael Halaas, Chief Operating Officer and Associate Dean in the School of Medicine, the unified organization brings together the best of the School of Medicine and Stanford Health Care IT to enable new opportunities for groundbreaking work and compassionate care. Together, the Technology and Digital Solutions team will work to break down historic organizational barriers to enable even greater collaboration across Stanford Medicine hospital and clinics, and the entire University.
This is a Stanford Health Care job.

A Brief Overview
The Data Architect II is responsible for providing analytics supporting improvement efforts, generally within a defined value stream or strategic domain. This includes developing data architecture and solutions to sustain improvement efforts and provide ongoing support for existing applications.

Locations
Stanford Health Care

What you will do
Builds effective working relationships with cross discipline team members, including hospital staff, new users, line management, on/offshore team members, etc.
Guides user leadership in formulation of project plan, regular status reporting to IT and user management, issue management and escalation
Develops business cases for new technology solutions. Confidently and professionally presents and defends recommended solution, approach, timeline, etc. to IT and user leadership and manages expectations accordingly
Organizes and conducts regular project status meetings and design reviews sessions leveraging appropriate project artifacts
With little supervision, performs analysis of the scope and requirements for projects
Prepares specifications, designs, data models and diagrams from which databases can be developed
Develops, tests, and deploys data structures using Entity Relationship Diagramming, SQL Server tools, and data modeling tools.
Troubleshoots incidents surrounding supported databases and solutions.
Tunes performance of databases, ETL processes and queries

Education Qualifications
BS/BA DEGREE IN INFORMATION TECHNOLOGY, INFORMATION SYSTEMS, BUSINESS MANAGEMENT, BUSINESS ANALYTICS, BUSINESS ADMINISTRATION OR A DIRECTLY-RELATED FIELD FROM AN ACCREDITED COLLEGE OR UNIVERSITY

Experience Qualifications
Two (2) years of experience in analytics, business intelligence or healthcare technology.

Required Knowledge, Skills and Abilities
Delivers high quality Reporting & Analytics solutions that meet user requirements with minimal on-going maintenance and a low volume of production incidents (production failures, help desk calls, etc.).
Proficient with best practices and common processes for developing solutions with SHC tools (i.e., SSIS, Crystal Reports, WebI, Qlikview, etc.) utilized in role.
Troubleshoots incidents and enhancement requests surrounding supported applications. Recommends improvements to supported applications.
1+ years experience with SQL in an Oracle and/or SQL Server enviroment. Very proficient with SQL (joins, multpile joins, subqueries, unions) including DDL for creation of tables, views, materialized views, etc.
Ability to perform basic performance tuning to optimize queries to meet user needs.
Demonstrated proficiency with Data Warehousing and ETL concepts, including: source to target mapping, transformations, error handling, job control, logging, alerting, and scheduling.
Demonstrated proficiency in Data Definition Language (DDL) , Data Manipulation Language (DML), and Extraction, Transformation and Loading (ETL) design and development using SQL Server tools (SQL Management Studio, T-SQL, SSIS, Team Foundation, etc.) and/or Epic Clarity Compass.
Complex Report writing & some metadata (universe) creation with SHC standard tools.
Operates with minimal supervision.
Accountable interaction up to Tier 4 levels of the organization
Demonstrated ability for completing moderately complex projects and/or multiple assigned projects.
Highly capable individual with expanded skill sets
Understands SHC's vision and communicates it to others. Appropriately questions how their assigned work relates and supports this vision.
Mastered one domain and learning others.
Ability to anticipate design or technical problems and suggest viable alternatives.
Partner with multidisciplinary teams with limited supervision.
Track record of consistently good work with only occasional problems or defects.
Utilizes strategic A3s and is proficient with Lean methods
Makes reliable operational internal decisions with limited supervision.
Can present ideas to peers and peer-group end-users. Effective verbal, written, and interpersonal communication skills.

Licenses and Certifications
None

These principles apply to ALL employees:

SHC Commitment to Providing an Exceptional Patient & Family Experience

Stanford Health Care sets a high standard for delivering value and an exceptional experience for our patients and families. Candidates for employment and existing employees must adopt and execute C-I-CARE standards for all of patients, families and towards each other. C-I-CARE is the foundation of Stanford’s patient-experience and represents a framework for patient-centered interactions. Simply put, we do what it takes to enable and empower patients and families to focus on health, healing and recovery.

You will do this by executing against our three experience pillars, from the patient and family’s perspective:
Know Me: Anticipate my needs and status to deliver effective care
Show Me the Way: Guide and prompt my actions to arrive at better outcomes and better health
Coordinate for Me: Own the complexity of my care through coordination
Equal Opportunity Employer Stanford Health Care (SHC) strongly values diversity and is committed to equal opportunity and non-discrimination in all of its policies and practices, including the area of employment. Accordingly, SHC does not discriminate against any person on the basis of race, color, sex, sexual orientation or gender identity and/or expression, religion, age, national or ethnic origin, political beliefs, marital status, medical condition, genetic information, veteran status, or disability, or the perception of any of the above. People of all genders, members of all racial and ethnic groups, people with disabilities, and veterans are encouraged to apply. Qualified applicants with criminal convictions will be considered after an individualized assessment of the conviction and the job requirements.
Base Pay Scale: Generally starting at $51.11 - $67.71 per hour
The salary of the finalist selected for this role will be set based on a variety of factors, including but not limited to, internal equity, experience, education, specialty and training. This pay scale is not a promise of a particular wage.",$1 to $5 billion (USD),Health Care Services & Hospitals,Hospital,Healthcare
"AIML - Sr Machine Learning Engineer, Data & ML Innovation",san-jose,"Apple
4.2","Cupertino, CA",4.2,-1,-1,-1,-1,-1,-1,10000+ Employees,1976,"Summary
Posted: May 17, 2023
Role Number:200464615
Do you want to innovate at the intersection of Machine Learning and Data to make Apple products smarter for our users? The Data and Machine Learning Innovation team is looking deeply into the end-to-end lifecycle of ML product development, and finding innovative ways to make it scalable and efficient. We are a R&D team with strong expertise in Applied Machine Learning, Data Engineering and Distributed Infrastructure. The team works broadly with Machine Learning teams across the company to advance capabilities in the data centric machine learning world. As part of our team, you will work together with similar minds in a unique development team where your skills and expertise will be put into the Apple products. This role is highly multi-functional, and you will collaborate very closely with various highly skilled machine learning and software development teams developing groundbreaking solutions!
Key Qualifications
10+ years of technical leadership experience.
Excellent knowledge and experienced practical skills in major machine learning algorithms.
Extensive knowledge in design and development of large scale distributed and big data processing systems.
Mastery of one of following languages: Python, Java or C++, demonstrating strong background in algorithms and data structures.
Excellent interpersonal skills, ability to work independently as well as in a team.
Creativity and curiosity for solving highly complex problems.
Excellent data analytical skills.
Description
As a member of our fast-paced group you’ll have the unique and rewarding opportunity to shape upcoming products from Apple. Our team includes a diversity of background engineers focusing on making ML development lifecycle scalable and efficient. As such we are looking for candidates with both strong applied machine learning experiences and engineering skills.
Education & Experience
MS or Ph.D in Computer Science, Machine Learning or related field. Apple is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics. Learn more about your EEO rights as an applicant.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $229,000 and $343,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",$10+ billion (USD),Computer Hardware Development,Company - Public,Information Technology
Biomedical Data Engineer II,san-jose,"Exact Sciences Corporation
3.5","Redwood City, CA",3.5,Employer Provided Salary:$75K - $120K,3.3,3.4,3.0,3.9,3.6,1001 to 5000 Employees,1995,"Position Overview
The Biomedical Data Engineer II will ensure accurate, complete, and timely collection, delivery, and tracking of data from research, commercial, and manufacturing laboratories for analysis, reports, and presentations. This role will support a collaborative environment that promotes positive teamwork with all members of Exact Sciences.
Essential Duties
Include, but are not limited to, the following:
Use Python, R, and SAS languages to provide custom data engineering solutions, as needed.
Assist with the front-end and back-end development for web applications by the group, as needed.
Develop and manage Tableau dashboards for data visualization.
Develop programs independently for collection, extraction, analysis, presentation, and tracking data.
Write and debug the Python programs of medium to high complexity.
Write and optimize the SQL queries against various database systems (MSSQL, Snowflake, PostgreSQL, Databricks).
Work within Databricks and AWS environments to develop and run programs.
Run and monitor Bioinformatics pipelines.
Able to quickly learn new skills as needed to adapt to changing requirements
Maintain accurate documentation for all programs and procedures.
Ability to gather information from verbal and various written forms of communication to present materials and email other teams within the organization.
Ability to maintain strong open communication with internal employees, managers, and customers.
Ability to integrate and apply feedback in a professional manner.
Ability to prioritize and drive to results with a high emphasis on quality.
Ability to work as part of a team.
Ability to act with an inclusion mindset and model these behaviors for the organization.
Apply excellent problem-solving abilities.
Apply strong organizational skills.
Uphold company mission and values through accountability, innovation, integrity, quality, and teamwork.
Support and comply with the company’s Quality Management System policies and procedures.
Maintain regular and reliable attendance.
Ability to act with an inclusion mindset and model these behaviors for the organization.
Ability to work on a mobile device, tablet, or in front of a computer screen and/or perform typing for approximately 90% of a typical working day.
Ability to spend considerable periods of time to concentrate and analyze data.
Minimum Qualifications
Bachelor’s Degree in Life Science, Computer Science, Science, or field as outlined in the essential duties.
3+ years of experience working in data engineering, computer programming, or database management.
2+ years of experience with SQL/MSSQL data management.
2+ years of experience with statistical/scientific programming languages, such as Python, R, and SAS.
Demonstrated ability to provide outstanding analytical thinking, collaboration, and communication.
Proficient in Microsoft Office programs, such as Word, Excel, PowerPoint, and Outlook.
Demonstrated ability to perform the Essential Duties of the position with or without accommodation.
Authorization to work in the United States without sponsorship.
Preferred Qualifications
Master’s Degree in Computer Science, Life Sciences, or field as outlined in the essential duties.
Experience with source control in global information technology and team foundation servers to include GIT and TFS.
Experience with AWS cloud computing.
Experience with molecular biology and bioinformatics.
Experience working with commercial LIMS system backends.
Familiarity with web application development to include Django and JQuery.
Salary Range:
$75,000.00 - $120,000.00
The annual base salary shown is for this position located in US - CA - Redwood City on a full-time basis. In addition, this position is bonus eligible, and is eligible to receive company stock upon hire as well as annually. Benefits offered include a retirement savings plan, paid vacation, holiday and personal days, paid caregiver/parental leave, and health benefits to include medical, prescription drug, dental and vision coverage in accordance with the terms, conditions, and eligibility requirements of the applicable plans.
If you need any assistance seeking a job opportunity at Exact Sciences, or if you may require a reasonable accommodation with the application process, please email
hr@exactsciences.com
.
We are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to age, color, creed, disability, gender identity, national origin, protected veteran status, race, religion, sex, sexual orientation, and any other status protected by applicable local, state or federal law. Applicable portions of the Company’s affirmative action program are available to any applicant or employee for inspection upon request.
To view the Right to Work, E-Verify Employer, and Pay Transparency notices and Federal, Federal Contractor, and State employment law posters, refer to
this link
. These documents summarize important details of the law and provide key points that you have a right know.",$100 to $500 million (USD),Biotech & Pharmaceuticals,Company - Public,Pharmaceutical & Biotechnology
Data Science Engineer,san-jose,"Apple
4.2","Cupertino, CA",4.2,-1,-1,-1,-1,-1,-1,10000+ Employees,1976,"Summary
Posted: Apr 18, 2023
Role Number:200475573
Apple’s Technology Development Group is looking for a highly motivated Data Science Engineer to help extract insights from sophisticated data sets to maintain high quality software builds. You will provide a key function in shaping the success of Apple’s current and future products, and help deliver exciting new software features while maintaining Apple’s world class quality.
Key Qualifications
Strong analytical skills
Excellent written and verbal communication skills
Proficiency with databases and SQL
Proficiency in scripting languages, including Python, Javascript, Ruby or Bash
Knowledge of data mining, statistical modeling, and machine learning methodologies
Experience articulating and translating business questions and using statistical techniques to arrive at an answer using available data
Experience with data visualization and presentation, familiar with data analysis tools such as Tableau
Expertise working with engineering and project management teams, demonstrating strong communication and coordination skills
Familiarity with distributed systems and microservices preferred
Description
TDG Engineering Operations supports the complex build and integration process for exciting new software critical to Apple’s current and future products. As a data science engineer, your role will be to collect, analyze, and visualize data generated by this process to help the organization move quickly in producing high quality products. You will be a part of a fast-paced environment with rapidly changing priorities, collaborating with software engineers and project managers to extract insights from data and help prioritize development focus for the organization. Responsibilities of the job include: Developing tools to extract and analyze data from multiple build system services. Creating dashboards and reports to keep teams and organizational leadership informed on trends in software quality. Developing comprehensive analysis of Apple’s software build process to identify bottlenecks and using data to advocate for changes where needed. Driving cross-functional initiatives that will steer the team’s direction with data-driven decision making.
Education & Experience
3+ years of industry experience in a Data Science or similar role Bachelor’s degree in an engineering related field, or equivalent experience
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $121,000 and $230,000, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",$10+ billion (USD),Computer Hardware Development,Company - Public,Information Technology
"Network Engineer, Data Center",san-jose,"Tesla
3.6","Fremont, CA",3.6,$94K - $138K (Glassdoor est.),3.7,3.3,3.1,3.7,2.9,10000+ Employees,2003,"What to Expect
Tesla is currently seeking a Network Engineer to join our Data Center team. This role will provide network design, implementation, and operational support for Tesla's Data Centers.
What You’ll Do

Help design, build and maintain new and existing Data Centers
Work closely with other team members on design and initiatives; maintain and grow existing data center networks.
Work with Tesla’s key application teams to support their growth, including Tesla Autopilot team.
Provide high availability & reliability to network
Requirements gathering, analyze, and propose solution to networking needs.
Monitor, analyze, and report metrics of network services.
Develop automation methods to rapidly deploy, configure, and update network equipment.
Assist with network troubleshooting.
Conduct product POC evaluation.
Document network knowledge base and operational “Run-Book.”
Must be able to work occasional weekends, after hours, and holidays.
Participate in on call rotation.
May require unscheduled after-hours work. 10-20% travel required as necessary.
What You’ll Bring
2+ years’ experience mid-large global enterprise networking infrastructure
Experience with mid/large-scale networks in a global environment
Juniper, Arista and Palo Alto Networks hardware
Experience in IP networking, L2/L3 network protocols (spanning-tree, OSPF, BGP), TCP/IP, DHCP, DNS, end to end QOS, VLAN, VRRP, LACP, MC-LAG, EVPN with VXLAN, ACL and infrastructure cabling.
Basic knowledge of AWS, Azure or GCP.
Experience with various tools such as Protocol Analyzer, SNMP, flow, IPAM, RADIUS, Splunk, network taps, and load/stress testing",$1 to $5 billion (USD),Transportation Equipment Manufacturing,Company - Public,Manufacturing
ML Data and Search Engineer - SPG,san-jose,"Apple
4.2","Cupertino, CA",4.2,-1,-1,-1,-1,-1,-1,10000+ Employees,1976,"Summary
Posted: Oct 26, 2022
Role Number:200439674
Play a role in bringing autonomous technologies to the real world. As an engineer in the Special Projects Group, you will be part of a team building infrastructure, models, and tools for new technologies that will shape the future. We are looking for an experienced and highly motivated engineer to help build the next generation of data processing, modeling, and search systems. In this team, you will have the opportunity to explore and prototype solutions using the latest technologies, and engineer software products that help accelerate the development of cutting-edge autonomous systems.
Key Qualifications
Experience working with large/distributed datasets and non-/relational databases
Strong software engineering skills in complex, multi-language systems; fluency in Python
Experience working with cloud data processing technologies (AWS, Spark, Elasticsearch, SQL, Presto, etc)
Experience working with non-standard data types (e.g. camera imagery, serialized formats, bonus: ROS bags or similar)
Knowledge of data mining, statistical modeling, and machine learning methodologies
Ability to thrive in a fast-paced work environment
Clear and concise written and verbal communication skills
Description
You will be building and integrating end-to-end data processing pipelines. You will contribute to developing a compelling and intuitive platform for introspecting and analyzing large datasets. You will work cross-functionally with specialists across robotics, high-performance computing, and machine learning to build data-driven solutions. • Develop and scale data processing pipelines using the latest open-source technologies • Develop novel analytical strategies to evaluate the data that an autonomous system both consumes and produces • Work on applied ML solutions in the areas of data mining, modeling, and forecasting • Be self-motivated in seeking solutions when the correct path isn’t always known • Mentor fellow engineers in your areas of expertise; contribute to a team culture that values effective collaboration, direct communication, technical perfection, and innovation • Influence and lead cross-functional initiatives that will align the project toward data-driven decision making
Education & Experience
• MS/PhD or equivalent experience in physical sciences, computer science, data science/machine learning, or other engineering background • 3+ years industry experience
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $130,000 and $242,000, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",$10+ billion (USD),Computer Hardware Development,Company - Public,Information Technology
Geospatial Data Engineer,san-jose,"Wing
4.5","Palo Alto, CA",4.5,Employer Provided Salary:$133K - $177K,3.9,5.0,3.9,5.0,5.0,Unknown,Subsidiary or Business Segment,"About Wing:
Wing offers drone delivery as a safe, fast, and sustainable solution for last mile logistics. Consumer appetites for on-demand services are increasing, but current delivery methods are inefficient, costly, and contribute to road accidents and air pollution. Wing's fleet of autonomous delivery drones can transport small packages directly from businesses to homes on-demand, in minutes. We design, build, and operate our aircraft, and offer drone delivery services on three continents. Our technology is designed to be easy to integrate into existing delivery and logistics networks, offering a scalable drone delivery solution for a broad range of businesses. Wing is a part of Google's parent company, Alphabet, and our mission is to create the preferred means of delivery for the planet. To do this, we must build a workforce that's representative of the global communities that we serve. If you're ready to do the greatest work of your life, come join us.
About the Role:
Wing is looking for a Geospatial Data Engineer to join our Flight Operations team. This position is based in the United States and is remote. The ideal candidate has a passion for developing and implementing custom geospatial processes, demonstrated knowledge of software engineering expertise, familiarity with geospatial data management, and the ability to deliver results as part of a dynamic, cross-functional team.
What You'll Do:
Develop and implement custom geospatial data processing solutions
Provide expertise to help drive Wing's geospatial data processes and specifications
Create large-scale innovative geospatial data automation systems and tools for unique aviation applications
Collaborate within the geospatial team on processes, procedures, and required data for new flight operations areas
Design and develop automated systems to import geospatial data into Wing's geospatial data management system
What You'll Need:
BA/BS degree in Computer Science, Information Systems, Software Engineering, Geographic Information Systems, a related field or equivalent professional experience
5+ years of professional experience as a geospatial software engineer
Experience developing large scale Information storage and retrieval, mapping technologies, and/or GIS data processing / visualization tools
Experience developing and maintaining production systems deployed to the cloud
Programming languages in SQL, C++, Java, or Python
Experience with industry GIS tools such as ArcGIS, QGIS, gdal/ogr, or FME
Excellent written and verbal communication skills
Bonus:
Crewed or uncrewed aviation licenses or certifications
Experience working in the uncrewed aviation systems industry
Experience in highly regulated environments, such as aerospace or healthcare
Experience working with raw data sources such as LiDAR point clouds, digital terrain models, aerial imagery, global geospatial data sources

The US base salary range for this full-time position is the salary range below + bonus + equity + benefits. Your recruiter will share more about the specific salary range for your targeted location during the hiring process.
Salary Range
$133,000—$177,000 USD",-1,Information Technology,Information Technology Support Services,Unknown / Non-Applicable
Data Engineer,san-jose,"LatentView
4.1","San Jose, CA",4.1,$110K - $152K (Glassdoor est.),4.1,4.2,3.8,3.7,3.9,1001 to 5000 Employees,2006,"Job Description:
About LatentView:
LatentView Analytics is a leading global analytics and decision sciences provider, delivering solutions that help companies drive digital transformation and use data to gain a competitive advantage. With analytics solutions that provide 360-degree view of the digital consumer, fuel machine learning capabilities and support artificial intelligence initiatives., LatentView Analytics enables leading global brands to predict new revenue streams, anticipate product trends and popularity, improve customer retention rates, optimize investment decisions and turn unstructured data into a valuable business asset.
We specialize in Predictive Modelling, Marketing Analytics, Big Data Analytics, Advanced Analytics, Web Analytics, Data Science, Data Engineering, Artificial Intelligence and Machine Learning Applications.
LatentView Analytics is a trusted partner to enterprises worldwide, including more than two dozen Fortune 500 companies in the retail, CPG, financial, technology and healthcare sectors.

Key Skills for all given roles: Advanced SQL, Python, Spark

Position Type: Fulltime
Location: Multiple Locations across US
No of Roles: Multiple
Job Responsibilities:
Help make improvements to current data pipeline
Reduce failures
Automate some of the existing pipelines
Manage customer escalations including cases such as missing data
Address performance issues
Develop processes to help monitor database queries
Overall, the Engineer is expected to be proactive and take a leading role in data platform maintenance, including suggesting improvements to the client.
Mandatory Skills:

5+ years of experience working with big data and related technologies
Experience using Big Data technologies (Spark, Hive, etc.)
Working experience and a good understanding of public cloud environments (AWS, Azure, and/or Google Cloud) is a plus.
Oozie, Apache airflow is preferred or any other related workflow management system.
Passion for producing high-quality work and continuously improving the ways we deliver data services.
Good knowledge of security policies and vulnerabilities.
Experience with policies and role management is a plus.
You excel at taking vague requirements and crystallizing them into scalable solutions.
You have exceptional communication skills.",$25 to $100 million (USD),Business Consulting,Company - Public,Management & Consulting
Data Engineer,san-jose,"Cequence Security
4.8","Sunnyvale, CA",4.8,Employer Provided Salary:$120K - $200K,4.4,4.6,4.6,4.7,4.6,51 to 200 Employees,2014,"About Cequence Security
Cequence Security, the pioneer of Unified API Protection, provides the only solution that unifies API discovery, inventory tracking, risk analysis and native mitigation with proven, real-time threat protection against ever-evolving API attacks. Cequence Security protects more than 2 billion user accounts across our Fortune 500 customers.
Learn more

Data Engineer Position Overview
As a Data Engineer at Cequence Security, you will be responsible for developing and enhancing the various Real Time Data flow pipelines as well as enabling sophisticated Data Analysis from the data at rest in multiple data lakes, while also maintaining strict high performance and throughput requirements. You will also work closely with other Data Engineers, Data Scientists and Security experts to bring new ideas in Data Exploration, Analytics and Machine Learning to fruition as product features that will enable new ways of catching malicious actors and help protect our customers from various forms of exploits and abuse.
There are multiple openings for the Data Engineer in both our Sunnyvale, CA headquarters and our Cincinnati, OH development center.
Responsibilities
Build and enhance an optimal real time data pipeline architecture using technologies such as Spark Streaming, Kafka Streams, Kafka Messaging, Elasticsearch and other Big Data technologies.
Identify, design, and implement improvements in the data pipelines to achieve ever higher throughput and scalability.
Work with data scientists and security experts to strive for greater functionality in our core products.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work within an Agile workflow to organize tasks and collaborate with other team members (Jira).
Work in a Test-Driven Development environment focused on producing reliable, well-documented production code.
Requirements
Bachelor’s degree or equivalent experience in Computer Science, or another relevant field.
Expert level experience with programming languages Java/Scala/Kotlin etc.
Minimum 4 years of experience in building and optimizing ‘Big Data’ data pipelines, architectures and data sets.
Experience with message queuing, stream processing, and highly scalable ‘big data’ data stores.
Experience with big data tools: Spark, Kafka, Elasticsearch, Hadoop etc.
Experience with stream-processing systems: Flink, Spark-Streaming, Kafka Streams etc.
Experience with Cloud services such as AWS EC2, EMR, EKS etc is a plus.
Experience with working in Docker and Kubernetes is a plus.
Salary Range 120-200k USD
Salary Disclaimer
The salary range represents the low and high end of the base salary range for this position. Actual salaries will vary depending on factors including but not limited to location, experience, and performance. The range listed is just one component of the total compensation package for Cequence Security employees. Other rewards may include quarterly bonuses, commissions, stock options, unlimited Paid Time Off, and other benefits not listed.
Come talk with us if you’re looking to make a difference and work at a fast-paced, fun, and rewarding environment. It’s the best career decision that you can make!",Unknown / Non-Applicable,Enterprise Software & Network Solutions,Company - Private,Information Technology
"Platform Data Engineer, Financial Services",san-jose,"Recruiting From Scratch
3.9","Saratoga, CA",3.9,Employer Provided Salary:$140K - $250K,4.0,3.6,3.5,3.9,3.9,1 to 50 Employees,2019,"Who is Recruiting from Scratch:
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
Data Engineer - Platform
A Career with our Market Intelligence Team:
Our Market Intelligence team is responsible for developing proprietary research products and providing data and research management services for investment teams to support their pursuit of superior, risk-adjusted returns. We leverage innovative alternative data sources, advanced data analytics and technologies, and deep fundamental research to create high-quality compliant and differentiated research. Backed by the full resources of our company, our sector aligned teams of fundamental researchers, data scientists, data strategists, relationship managers, and data engineers collaborate to solve important research problems in partnership with the Firm’s investment and compliance professionals.

What you’ll do
Platform Engineers build solutions for processing big and unstructured data sets. Our team works closely with portfolio managers and data scientists to understand the potential business value of data sets and ultimately build data processing pipelines around those data sources. In this role, you will:
Develop big data processing pipelines for new data sources containing structured and unstructured data
Build platform infrastructure using Hadoop technologies
Build and support visualization and exploration capabilities around our big data sets
Maintain knowledge of new technology developments and conduct proof of concepts to evaluate new technologies

What’s required
We want you to join us if you have extensive experience or demonstrated interest in big data technologies. Other requirements include:
2+ years of experience in Data Engineering or related field
Commitment to the highest ethical standards
Strong experience in Python Development
Experience with Spark or Scala
Ability to devise novel and innovative solutions to challenges
Knowledge of/experience with graph databases is a plus

We take care of our people
We invest in our people, their careers, their health, and their well-being. We want you to concentrate on success and leave the rest to us. When you work here, we provide:
Fully-paid health care benefits
Generous parental and family leave policies
Mental and physical wellness programs
Tuition assistance
A 401(k) savings program with an employer match and more
Salary Range: $140,000-$250,000 base.",$1 to $5 million (USD),Staffing & Subcontracting,Company - Private,Human Resources & Staffing
Senior CV deep learning engineer (Synthetic data),san-jose,"Apple
4.2","Cupertino, CA",4.2,-1,-1,-1,-1,-1,-1,10000+ Employees,1976,"Summary
Posted: Mar 22, 2023
Role Number:200470811
We are seeking an experienced computer vision deep learning engineer with a strong background in synthetic data generation and domain adaptation between real and synthetic data. The ideal candidate will have a proven track record of delivering successful computer vision applications, with experience in developing and deploying deep learning models in production environments.
Key Qualifications
Develop and deploy deep learning models to solve computer vision problems using synthetic data and domain adaptation between real and synthetic data (hands, body, face preferred)
Build and maintain high-quality datasets, including synthetic data, for use in training and testing machine learning models.
Analyze and interpret data, develop insights, and communicate findings to collaborators.
Work collaboratively with computer vision researchers, software engineers, and other collaborators to design and develop scalable and reliable computer vision applications.
Conduct research on developing novel deep learning algorithms and architectures that can be used to reduce domain gap between real and synthesized datasets.
Stay up-to-date with the latest developments in deep learning/computer vision and related fields, and evaluate new tools and technologies for potential integration into our computer vision applications.
Description
At least 3 years of experience in developing and deploying deep learning models for computer vision applications, with a focus on synthetic data generation and domain adaptation between real and synthetic data. A strong understanding of deep learning frameworks such as TensorFlow or PyTorch, JAX. Experience with data preprocessing, feature engineering, and data visualization. Strong programming skills in Python or similar languages. Strong communication and collaboration skills, with the ability to work effectively in a team environment. Consistent track record of researching, inventing and/or shipping advanced machine learning algorithms Solid mathematical foundation of machine learning and deep learning techniques (linear algebra, optimization theory, ...) Optional : Familiarity with real time / path tracing renderers (VRay, Arnold, Unreal Engine, ...) Optional : Familiarity with cloud-based machine learning platforms, such as AWS or GCP Optional : Familiarity with content creation tools (Maya, Houdini, ... )
Education & Experience
A Bachelor's degree in Computer Science, Mathematics, or a related field. A Master's degree or PhD is preferred.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $130,000 and $242,000, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",$10+ billion (USD),Computer Hardware Development,Company - Public,Information Technology
Senior Data Engineer,san-jose,"Humu
3.8","Mountain View, CA",3.8,Employer Provided Salary:$160K - $220K,3.7,3.7,3.5,3.7,3.9,51 to 200 Employees,2017,"What you'll get to work on
Humu's Nudge Engine® deploys thousands of customized nudges—small, personal steps—throughout organizations to empower every employee, manager, team, and leader as a change agent. Over time, our nudges grow increasingly aware of the timing, messaging, and motivational techniques that inspire individual employees towards action.
As a member of Humu's Data Engineering team, you will be responsible for building and maintaining systems focused on expanding and optimizing data pipelines to compute insights and analyses at scale. Some of the team's major ownership areas include:
A data pipeline tool for helping transform ingested HR data into a consistent and clean format.
The automated processes for deciding which nudges to send to users, scheduling them for delivery, and delivering them through a multitude of formats (email, text messages, etc).
The logic and systems to make data available to a variety of cross functional teams at Humu.

Where you fit in
We are committed to change the working world for the better by bringing greater meaning and happiness into everyone's working lives, everywhere. We are passionate about our mission, and excited to grow our school of fish with people who want to do the same - and people who will bring in their different perspectives to help us continue to shape our team and product. If this is you, we encourage you swim into our candidate pool!

The details
Role and responsibilities:
As a member of our Product Team, you will ensure optimal data delivery architecture is consistent throughout ongoing projects.
Create and optimize our data pipeline architecture
Build data access platform for our data science and tech teams
Manage and optimize customer ingestions for the Humu product
Add and improve logging and monitoring
Willingness to occasionally implement UI for internal data tools.
Qualifications:
4 - 99 years of experience managing data pipelines
Driven engineer that is motivated to build a great product and great codebase in a fast-paced environment
Strong communication skills with a growth and learning mindset
Understanding of object-oriented languages (Java, Python, etc.)
Familiarity with cloud based platforms - GCP (Preferred), AWS, Azure
Experience with large-scale databases (preference towards non-relational unstructured databases).
Usage or understanding of complex data pipelines.
Working knowledge of message queuing, stream processing, and highly scalable 'big data' data stores.

Salary range: $160,000 - $220,000
Only open to candidates in Seattle, WA or SF Bay Area, CA",Unknown / Non-Applicable,Enterprise Software & Network Solutions,Company - Private,Information Technology
Principal Data Engineer,san-jose,"Safeway
3.2","Pleasanton, CA",3.2,Employer Provided Salary:$147K - $206K,3.0,2.9,2.8,3.0,2.9,10000+ Employees,1915,"About the company
Albertsons is one of the largest retail employers, providing approximately 300,000 jobs across 2,200 stores, 22 distribution centers, 20 food and beverage plants and various support offices. We operate in 34 states and the District of Columbia under the Albertsons banner, as well as Safeway, Tom Thumb, Jewel Osco, Shaw’s, and many more recognizable names. We hold a #1 or #2 position by market share in 68% of the 121 metropolitan statistical areas in which we operate.
What you will be doing
This role is within Inventory management team under Supply chain technology group. Our team strives to achieve adaptive, resilient, and efficient inventory flow with the help of modern technologies and data. Many thousands of items (SKUs) move through Albertsons’s vast supply chain network on daily basis, which makes this position both important and fascinating.
In this role, you are empowered to build large scale, high-performance data pipelines in a cloud environment that will be a game changer for the entire enterprise. You will have an opportunity to become proficient in supply chain data models at Albertsons and use that knowledge to make a direct and significant impact on business for many years to come. Your following traits will set you apart for this role.
You grasp the power of data to solve critical business problems
You effortlessly navigate through complexity and ambiguity of data and technical designs
You enthusiastically learn and weave the aspects of data engineering, data science, analytics, and visualization in your implementation
Key Responsibilities
Enable novel and transformative supply chain management capabilities that require processing of big data and integration from disparate sources
Help with project roadmap planning, provide realistic estimates, and identify risks
Technically lead engineering team to stay on project delivery milestones and assure quality output. Remove technical roadblocks, perform code reviews
Design and implement real time as well as batch (ETL, ELT) data pipelines using cloud-based services (Currently on GCP)
Design and develop large-scale data schemas and structures to optimally balance the usage, performance, and cost
Champion the understanding of Albertson’s supply chain data; support data science and application developers with data analysis and insights
Mentor and guide new or junior members of the team to ramp up and become productive
Help customer support team by troubleshooting and fixing issues post-deployment
Be the custodian of engineering backlog and promote the continuous improvement and maintenance of the current solution
*The salary range is $147,000 to $206,000 annually. Starting salary will vary based on criteria such as location, experience, and qualifications. There may be flexibility for exceptional candidates.*
Qualifications
BS in Computer Science or related field
6+ years of experience in the data engineering space, building, and deploying data pipelines.
Proficient in at least one programming language between Java and Python
Hands-on experience of GCP (Google Cloud Platform) or willingness to get GCP Certifications
Experience utilizing and integrating variety of data – structured, unstructured, or semi structured
Some experience with data warehousing tools (SnowFlake, BigQuery etc.) and the BI Visualization Tools (PowerBI, Looker, Tableau etc.)
Working knowledge of AI/ML and related tools/technologies is preferred
Hands on experience with data toolset like Apache Beam, Airflow, Kafka and Spark is ideal
Designing and developing Supply Chain and Inventory Management applications is a huge plus
Some experience developing RESTful APIs will come very handy
What it is like at Albertsons?
Albertsons Culture Principles
Compassion: We always treat each other with kindness and respect
Team: We always support and recognize each other
Inclusive: We always value everyone’s perspective
Learning: We always strive to grow and develop ourselves and others
Competitive: We always act with integrity to win over the customer
Ownership: We always take actions to drive our success",$10+ billion (USD),Grocery Stores,Company - Private,Retail & Wholesale
Vehicle & Energy Scheduling – Machine Learning Engineer/Data Scientist,san-jose,"Tesla
3.6","Fremont, CA",3.6,$92K - $145K (Glassdoor est.),3.7,3.3,3.1,3.7,2.9,10000+ Employees,2003,"What to Expect
You will be part of a team of data scientists and developers aiming to build a smart scheduling system for service and fulfillment operations that includes vehicle routing, demand prediction, and resource assignment optimization.

What You’ll Do
Enhance customer experience of Tesla product deliveries and service globally with data-driven scheduling solutions.

Participate in the entire data solution process including data gathering and analysis, literature reviews, modeling and training, creating simulations, developing and maintaining production data applications
Collaborate with team members and stakeholders to understand business contexts and create data-driven solutions
What You’ll Bring
Bachelor’s degree in Data Science, Computer Science, Industrial Engineering, Mathematics , or related field

Understanding of statistics, probability, and machine learning concepts
Experience training and maintaining models for real world applications
Strong experience with Python and data manipulation tools including SQL, pandas, numpy, scipy, matplotlib, scikit-learn, jupyter notebooks.
Familiar with software engineering best practices including api design and version control.
Ability to thrive in a fast-moving and constantly evolving high growth environment
Comfortable in an environment with unstructured, incomplete, and ambiguous data
Curious, open-minded, and driven to solve complex problems
(Bonus) experience working with geospatial data and vehicle routing algorithms",$1 to $5 billion (USD),Transportation Equipment Manufacturing,Company - Public,Manufacturing
Data Engineer,san-jose,"Stanford Health Care
3.9","Palo Alto, CA",3.9,Employer Provided Salary:$51.11 - $67.71 Per Hour,3.6,3.5,3.1,3.9,3.4,10000+ Employees,1957,"If you're ready to be part of our legacy of hope and innovation, we encourage you to take the first step and explore our current job openings. Your best is waiting to be discovered.

Day - 08 Hour (United States of America)
The Stanford Medicine Technology and Digital Solutions team was formed to provide the Stanford Medicine community with the most innovative technology services as efficiently as possible. Led by Michael Pfeffer, CIO and Michael Halaas, Chief Operating Officer and Associate Dean in the School of Medicine, the unified organization brings together the best of the School of Medicine and Stanford Health Care IT to enable new opportunities for groundbreaking work and compassionate care. Together, the Technology and Digital Solutions team will work to break down historic organizational barriers to enable even greater collaboration across Stanford Medicine hospital and clinics, and the entire University.
This is a Stanford Health Care job.

A Brief Overview
The Data Architect II is responsible for providing analytics supporting improvement efforts, generally within a defined value stream or strategic domain. This includes developing data architecture and solutions to sustain improvement efforts and provide ongoing support for existing applications.

Locations
Stanford Health Care

What you will do
Builds effective working relationships with cross discipline team members, including hospital staff, new users, line management, on/offshore team members, etc.
Guides user leadership in formulation of project plan, regular status reporting to IT and user management, issue management and escalation
Develops business cases for new technology solutions. Confidently and professionally presents and defends recommended solution, approach, timeline, etc. to IT and user leadership and manages expectations accordingly
Organizes and conducts regular project status meetings and design reviews sessions leveraging appropriate project artifacts
With little supervision, performs analysis of the scope and requirements for projects
Prepares specifications, designs, data models and diagrams from which databases can be developed
Develops, tests, and deploys data structures using Entity Relationship Diagramming, SQL Server tools, and data modeling tools.
Troubleshoots incidents surrounding supported databases and solutions.
Tunes performance of databases, ETL processes and queries

Education Qualifications
BS/BA DEGREE IN INFORMATION TECHNOLOGY, INFORMATION SYSTEMS, BUSINESS MANAGEMENT, BUSINESS ANALYTICS, BUSINESS ADMINISTRATION OR A DIRECTLY-RELATED FIELD FROM AN ACCREDITED COLLEGE OR UNIVERSITY

Experience Qualifications
Two (2) years of experience in analytics, business intelligence or healthcare technology.

Required Knowledge, Skills and Abilities
Delivers high quality Reporting & Analytics solutions that meet user requirements with minimal on-going maintenance and a low volume of production incidents (production failures, help desk calls, etc.).
Proficient with best practices and common processes for developing solutions with SHC tools (i.e., SSIS, Crystal Reports, WebI, Qlikview, etc.) utilized in role.
Troubleshoots incidents and enhancement requests surrounding supported applications. Recommends improvements to supported applications.
1+ years experience with SQL in an Oracle and/or SQL Server enviroment. Very proficient with SQL (joins, multpile joins, subqueries, unions) including DDL for creation of tables, views, materialized views, etc.
Ability to perform basic performance tuning to optimize queries to meet user needs.
Demonstrated proficiency with Data Warehousing and ETL concepts, including: source to target mapping, transformations, error handling, job control, logging, alerting, and scheduling.
Demonstrated proficiency in Data Definition Language (DDL) , Data Manipulation Language (DML), and Extraction, Transformation and Loading (ETL) design and development using SQL Server tools (SQL Management Studio, T-SQL, SSIS, Team Foundation, etc.) and/or Epic Clarity Compass.
Complex Report writing & some metadata (universe) creation with SHC standard tools.
Operates with minimal supervision.
Accountable interaction up to Tier 4 levels of the organization
Demonstrated ability for completing moderately complex projects and/or multiple assigned projects.
Highly capable individual with expanded skill sets
Understands SHC's vision and communicates it to others. Appropriately questions how their assigned work relates and supports this vision.
Mastered one domain and learning others.
Ability to anticipate design or technical problems and suggest viable alternatives.
Partner with multidisciplinary teams with limited supervision.
Track record of consistently good work with only occasional problems or defects.
Utilizes strategic A3s and is proficient with Lean methods
Makes reliable operational internal decisions with limited supervision.
Can present ideas to peers and peer-group end-users. Effective verbal, written, and interpersonal communication skills.

Licenses and Certifications
None

These principles apply to ALL employees:

SHC Commitment to Providing an Exceptional Patient & Family Experience

Stanford Health Care sets a high standard for delivering value and an exceptional experience for our patients and families. Candidates for employment and existing employees must adopt and execute C-I-CARE standards for all of patients, families and towards each other. C-I-CARE is the foundation of Stanford’s patient-experience and represents a framework for patient-centered interactions. Simply put, we do what it takes to enable and empower patients and families to focus on health, healing and recovery.

You will do this by executing against our three experience pillars, from the patient and family’s perspective:
Know Me: Anticipate my needs and status to deliver effective care
Show Me the Way: Guide and prompt my actions to arrive at better outcomes and better health
Coordinate for Me: Own the complexity of my care through coordination
Equal Opportunity Employer Stanford Health Care (SHC) strongly values diversity and is committed to equal opportunity and non-discrimination in all of its policies and practices, including the area of employment. Accordingly, SHC does not discriminate against any person on the basis of race, color, sex, sexual orientation or gender identity and/or expression, religion, age, national or ethnic origin, political beliefs, marital status, medical condition, genetic information, veteran status, or disability, or the perception of any of the above. People of all genders, members of all racial and ethnic groups, people with disabilities, and veterans are encouraged to apply. Qualified applicants with criminal convictions will be considered after an individualized assessment of the conviction and the job requirements.
Base Pay Scale: Generally starting at $51.11 - $67.71 per hour
The salary of the finalist selected for this role will be set based on a variety of factors, including but not limited to, internal equity, experience, education, specialty and training. This pay scale is not a promise of a particular wage.",$1 to $5 billion (USD),Health Care Services & Hospitals,Hospital,Healthcare
Data Engineer - Professional Services,san-jose,"Treasure Data, Inc.
4.1","Mountain View, CA",4.1,-1,-1,-1,-1,-1,-1,501 to 1000 Employees,2011,"Treasure Data:
At Treasure Data, we’re on a mission to radically simplify how companies use data to create connected customer experiences. Our sophisticated cloud-based customer data platform drives operational efficiency across the enterprise to deliver powerful business outcomes in a way that’s safe, flexible, and secure. We’re proud to be InfoWorld’s 2022 “Technology of the Year” Award winner and trusted by leading companies around the world, spanning the Fortune 500 and Global 2000 enterprises.

Treasure Data employees are enthusiastic, data-driven, and customer-obsessed. We are a team of drivers—self-starters who take initiative, anticipate needs, and proactively jump in to solve problems. Our actions reflect our values of honesty, reliability, openness, and humility. We offer a competitive salary and benefits and were named one of the “50 Best Workplaces of the Year 2022” as well as the national ranking as one of the “Best and Brightest Companies to work For. ”

About the Role:
Our Professional Services team is front and center when it comes to working with marquee customers and solving tough problems. Our team consists of data driven professionals with an analytical mindset and obsessed with delivering ROI for our customers. We pride ourselves in accelerating time to value for our customers and designing unique solutions that scale for our global customers. Whether it is a strategic conversation that needs to be had with customers or a technical discussion with architects and machine learning engineers, we have a wide variety of roles in the team that gives our employees the ability to expand their skills and grow horizontally as well as vertically within the organization.

Responsibilities & Duties:
Help customers extract maximum value from their data by building data orchestration pipelines and solving complex problems.
Be the domain expert in all things Treasure Data!
Develop sophisticated solutions that will scale for large datasets and withstand the test of time.
Ensure that your solutions are efficient, well-documented and easily customizable to different types of data and business use cases.
Participate in blueprinting, scoping, prioritizing technical requirements and assist our customers in their digital transformation journey.
Guide customers in best-practices for CDP implementation and ensure they are self-sufficient.
Visit customers on-site and participate in in-person meetings. Approximately 10-25 % travel may be required as part of this job.

Required Qualifications:
University degree in Engineering or Computer Science or a quantitative field such as Math or Statistics.
Background in data & technology and a track record (at least 2 years) of working with data and building scalable solutions.
Working knowledge and 2+ years of experience in SQL and have successfully deployed data-oriented solutions (DW, BI, ETL, etc).
2+ years of experience coding with a scripting language such as Python.
Comfortable working on team projects and collaborating via version control tools such as GitHub and GitLab.
Experience handling issues, customer concerns, engaging with developers, business teams and working towards resolution.

We would be thrilled if you

Have experience with Cloud-based or SaaS products and a good understanding of Digital Marketing and Marketing Technologies.
Have experience working with Big Data technologies (such as Hadoop, MapReduce, Hive/Pig, Cassandra, MongoDB, etc)
An understanding of web technologies such as Javascript, node.js and html.
Some level of understanding or experience in AI/ML.

Perks and Benefits (US):
Our benefit package showcases our culture of care and empathy with

Comprehensive medical, dental, vision plans and Employee Assistance Program (EAP)
Competitive compensation packages
Company paid life insurance 3x salary
Company paid short- and long-term disability coverage
Retirement planning (401K) with company match
Restricted Stock Units (RSU)
Paid vacation and sick time
Paid volunteer and mental health days
Up to 26 weeks paid parental leave
16 Company holidays (includes 2 floating holidays)

Our Dedication to You:
We value and promote diversity, equity, inclusion, and belonging in all aspects of our business and at all levels. Success comes from acknowledging, welcoming, and incorporating diverse perspectives.

Diverse representation alone is not the desired outcome. We also strive to create an inclusive culture that encourages growth, ownership of your role, and achieving innovation in new and unique ways. Your voice will be heard, and we will help amplify it.

Agencies and Recruiters:
We cannot consider your candidate(s) without a contract in place. Any resumes received without having an active agreement will be considered gratis referrals to us. Thank you for your understanding and cooperation!",Unknown / Non-Applicable,Enterprise Software & Network Solutions,Company - Private,Information Technology
Software Engineer - Data Integration Platform,san-jose,"TikTok
3.6","San Jose, CA",3.6,Employer Provided Salary:$126K - $339K,3.4,3.4,3.1,3.6,3.0,1001 to 5000 Employees,2016,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

Team Introduction
The Data Management Suite team is building products that cover the whole lifecycle of data pipeline, including data ingestion and Integration, data development, data catalog, data security and data governance. These Products support various businesses so data engineers and data scientists could great boost their productivity.

As software engineers in Data Management Suite team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. The team operates several large scale distributed systems powering the whole company: 1) ingesting and processing in real-time trillions of events per day and 2) a platform to efficiently transfer petabytes of data daily between storage systems.

You'll have the opportunity to gain hands-on experience on all kinds of systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.

Responsibilities - What You'll Do
Design and build the next generation data integration platform efficiently and reliably for different purposes
Tackle design and architectural challenges such as performance, scalability, reusability and flexibility
Establish solid design and best engineering practice for engineers as well as non-technical people
Qualifications
BS or MS degree in Computer Science or related technical field with 3+ relevant working experience
Experience in Big Data technologies(Flink, Hadoop, Hive, Spark, Metastore, Kafka etc.)
Experience with performing data analysis, data ingestion and data integration
Solid communication and collaboration skills
Preferred Qualifications
Working industry experience with Big Data systems and projects, and proficient in Java development
Experience in building large scale distributed systems in a product environment
Experience with data ingestion and data integration
Experience in data privacy and security related projects
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at marriah.yambao@tiktok.com.
Job Information
The base salary range for this position in the selected city is $126000 - $338560 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",Unknown / Non-Applicable,Internet & Web Services,Company - Private,Information Technology
SENIOR STAFF DATA ENGINEER,san-jose,"Karius
3.5","Redwood City, CA",3.5,Employer Provided Salary:$180K - $240K,3.6,3.7,3.3,4.0,4.0,51 to 200 Employees,2014,"About Karius
Karius is a venture-backed life science startup that is transforming the way pathogens
and other microbes are observed throughout the body. By unlocking the information
present in microbial cell-free DNA, helping doctors quickly solve their most
challenging cases, providing industry partners with access to 1000’s of biomarkers to
accelerate clinical trials, discover new microbes, and reduce patient suffering worldwide.
Karius aims to conquer infectious diseases through innovations around genomic
sequencing and machine learning. The company’s platform is already delivering
unprecedented insights into the microbial landscape, providing clinicians with a
a comprehensive test capable of identifying more than a thousand pathogens directly
from blood, and helping the industry accelerate the development of therapeutic
solutions. The Karius test we provide today is one of the most advanced solutions
available to physicians who aim to deliver better care to many otherwise ineffectively
treated patients.

Position Summary
Karius is building AI-driven data analytics pipelines to deliver life-saving results in the
highly complex infectious disease landscape. We are seeking a seasoned Senior Staff
Data Engineer in Redwood City, CA to lead the design and development of a scalable
data platform to meet our rapid business growth. Senior Staff Data Engineer will be
responsible for defining the technology roadmap, and developing and optimizing the
data platform to enable us to extract values from large amounts of genomic, clinical,
operation and clinical data to provide actionable insights to serve the patients and
develop innovative products. In this regard, the Senior Staff Data Engineer will work
with key stakeholders within the company to understand our data landscape and the
core needs for data governance and usage.

Primary Responsibilities
Design, develop, and operate a scalable data platform that ingests, stores, and
aggregates various datasets to meet the defined requirements;
As the primary subject matter expert in the data engineering domain, evaluate
technology trends in the data industry, identify those technologies relevant to
the company’s business objectives, and develop a roadmap to update the
company’s data platform;
Provide Machine Learning (“ML”) data platform capabilities for R&D and
Analytics teams to perform data preparation, model training and management,
and run experiments against clinical and genomic datasets;
Train the R&D and Analytics teams on using Karius data toolsets and mentor
and support them throughout their research and development efforts;
Build and maintain data ETL/ELT pipelines to source and aggregate the
required internal data to calculate operational and commercial Key Performance
Indicators (“KPIs”) and various data analysis and reporting needs;
Develop integrations with Karius and 3rd party systems to source, qualify and
ingest various datasets; work closely with cross-functional groups and
stakeholders, such as the product, engineering, medical, and scientiﬁc teams,
for data modeling and general life cycle management;
Provide data analytics and visualization tools to extract valuable insights from
the data and enable data-driven decisions; and
Work closely with the Security and Compliance teams, and deploy necessary
data governance to meet the regulatory and legal requirements.

Position Minimum Requirements
At least a Bachelor’s degree in Computer Science, Data Science, or Software
Engineering, Electrical Engineering, or Bio-Engineering (or its foreign equivalent);
plus
At least 10 years of experience as a Software or Data Engineer or similar
position, including at least 5 years in a senior or higher-level position;

AND (or experience must include):

4+ years of hands-on design, development and operation of data solutions using
the following data technologies: Spark and Spark Streaming, Presto, Parquet,
MLﬂow, Kafka, and ETL tools such as Stitch or FiveTran;
4+ years of hands-on experience with design, development and maintenance of
structured, semi and non-structured (NoSQL) data stores, such as MySQL,
PostgreSQL, AWS Redshift, Teradata, Graph databases like Neo4j, and
Databricks Lakehouse;
4+ years of hands-on development and operation of workflows and jobs using
task orchestration engines such as Airﬂow, Argo, NextFlow, Dollar U and Tidal;
4+ years of hands-on experience building and operating data solutions on
operating systems such as Linux and Unix hosted in Amazon Web Services
(AWS) cloud;
5+ years of hands-on building and operation of scalable infrastructure to support
batch, micro-batch, and stream data processing for large volumes of data;
5+ years of hands-on experience designing and implementing enterprise data
warehouse/Lakehouse solutions to house business and technical datasets and
derive KPI dimensions for consumption;
Demonstrated experience with enterprise data modeling in healthcare and/or life
science sectors;
Demonstrated experience with the development and operation of visualization
and dashboards for business KPI reporting using tools such as Tableau or
Looker;
Proficiency in Python and PySpark;
Automation of Data Testing using scripting;
Experience developing and managing technical and administrative controls for
data governance and regulatory compliance in the healthcare and/or life sciences
sectors;
Experience mentoring and coaching junior data engineers; and
Cross-functional project management experience.

Travel: No travel is required.

Reports to: VP, Engineering
$180,000 - $240,000 a year",Unknown / Non-Applicable,Biotech & Pharmaceuticals,Company - Private,Pharmaceutical & Biotechnology
"AIML - Sr Machine Learning Engineer, Data & ML Innovation",san-jose,"Apple
4.2","Cupertino, CA",4.2,-1,-1,-1,-1,-1,-1,10000+ Employees,1976,"Summary
Posted: May 17, 2023
Role Number:200464615
Do you want to innovate at the intersection of Machine Learning and Data to make Apple products smarter for our users? The Data and Machine Learning Innovation team is looking deeply into the end-to-end lifecycle of ML product development, and finding innovative ways to make it scalable and efficient. We are a R&D team with strong expertise in Applied Machine Learning, Data Engineering and Distributed Infrastructure. The team works broadly with Machine Learning teams across the company to advance capabilities in the data centric machine learning world. As part of our team, you will work together with similar minds in a unique development team where your skills and expertise will be put into the Apple products. This role is highly multi-functional, and you will collaborate very closely with various highly skilled machine learning and software development teams developing groundbreaking solutions!
Key Qualifications
10+ years of technical leadership experience.
Excellent knowledge and experienced practical skills in major machine learning algorithms.
Extensive knowledge in design and development of large scale distributed and big data processing systems.
Mastery of one of following languages: Python, Java or C++, demonstrating strong background in algorithms and data structures.
Excellent interpersonal skills, ability to work independently as well as in a team.
Creativity and curiosity for solving highly complex problems.
Excellent data analytical skills.
Description
As a member of our fast-paced group you’ll have the unique and rewarding opportunity to shape upcoming products from Apple. Our team includes a diversity of background engineers focusing on making ML development lifecycle scalable and efficient. As such we are looking for candidates with both strong applied machine learning experiences and engineering skills.
Education & Experience
MS or Ph.D in Computer Science, Machine Learning or related field. Apple is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics. Learn more about your EEO rights as an applicant.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $229,000 and $343,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",$10+ billion (USD),Computer Hardware Development,Company - Public,Information Technology
Software Engineer - Data and Evaluation,san-jose,"pony.ai
3.3","Fremont, CA",3.3,Employer Provided Salary:$120K - $160K,3.3,3.0,3.0,3.6,3.0,501 to 1000 Employees,2016,"Pony.ai, Inc. (“Pony.ai”) is a startup co-located in Silicon Valley and China that is pursuing an ambitious vision for autonomous mobility. We aim to bring safe, sustainable, and accessible mobility to the entire world. We believe that autonomous technology can make our roads exponentially safer for travelers. Founded in late 2016, Pony.ai has been a pioneer in autonomous mobility technologies and services across the U.S. and China, spearheading public-facing Robotaxi pilots in both markets. The company is currently valued at $8.5B and some of its major investors include Toyota, Ontario Teachers’ Pension Plan, Sequoia Capital China, and IDG Capital. Pony.ai has formed partnerships with leading OEMs including Toyota, GAC Group, FAW Group, etc. We believe our work has the potential to transform lives and industries for the better. You will have every opportunity to grow and develop as our company scales globally.

Responsibility

Design and implement tools and pipeline to handle data from autonomous vehicles including data labeling, batch processing, simulation, system and module evaluation
Setup and maintain monitoring for system metrics, latency and alerts.
Work closely with different autonomous driving components and dive deep into each component and design corresponding evaluation metrics and tools
Requirements
Strong programming skills in C/C++, Python, and software design
BS/MS or Ph.D. in Computer Science or a related field
Experience in large data set processing and familiarity with real time systems
Solid experience in a fast-paced and structured engineering environment
Full stack experience including both front end and back end is preferred
Statistics analysis experience is preferred
Start before June 2023


Compensation and Benefits
Base Salary Range: $120,000 - $160,000 Annually
Compensation may vary outside of this range depending on many factors, including the candidate’s qualifications, skills, competencies, experience, and location. Base pay is one part of the Total Compensation and this role may be eligible for bonuses/incentives and restricted stock units.
Also, we provide the following benefits to the eligible employees:
Health Care Plan (Medical, Dental & Vision)
Retirement Plan (Traditional and Roth 401k)
Life Insurance (Basic, Voluntary & AD&D)
Paid Time Off (Vacation & Public Holidays)
Family Leave (Maternity, Paternity)
Short Term & Long Term Disability
Free Food & Snacks",Unknown / Non-Applicable,Computer Hardware Development,Company - Private,Information Technology
Research Data Center Engineer,san-jose,"Stanford University
4.3","Stanford, CA",4.3,Employer Provided Salary:$130K - $135K,4.1,4.1,3.8,3.6,3.8,10000+ Employees,1891,"Research Data Center Engineer:

Facilities Engineer 3, 4353/K in terms of Stanford job classification

The expected pay range for this position is $130,000 to $135,000 per annum. Stanford University provides pay ranges representing its good faith estimate of what the university reasonably expects to pay for a position. The pay offered to a selected candidate will be determined based on factors such as (but not limited to) the scope and responsibilities of the position, the qualifications of the selected candidate, departmental budget availability, internal equity, geographic location and external market pay for comparable jobs.

This position will serve as a technical expert in the performance of facilities engineering responsibilities involving the operation and maintenance of a major campus facility, the Stanford Research Computing Facility Module 2 (SRCF2).

The position, reporting to the Research Computing (RC) Data Center Manager, will be to provide facilities support for data centers under the management of the Stanford Research Computing Center (Research Computing). Research Computing offers High Performance Computing (HPC) hosting services, computational and data systems, services, and support for researchers from a variety of Stanford and SLAC organizations. The data center facility that hosts the HPC systems themselves is the Stanford Research Computing Facility (SRCF1). The SRCF2 is a state of the art expansion of the original facility (SRCF1) and it is designed to accommodate high density computational infrastructure. The Facilities Engineer will assist in the operation of the SRCF2, monitoring temperatures, facilitating deliveries, racking servers, and storage devices, troubleshooting and repairing servers, install network wiring, installing, and securing racks. This position will also provide backup to the Facilities Engineer for SRCF1 and also for the Research Computing data center in Forsythe Hall on the Stanford campus. This position may also occasionally be responsible for interfacing with vendors, for installations, equipment repairs, and maintenance.

Core Duties
Ensure ongoing production facility operation to maximize the reliability, dependability and availability of it and systems hosted therein.
Serve as an expert, providing design and technical recommendations in areas of specialization. This includes interfacing and coordination with and across specialties and disciplines.
Work with groups or individual researchers from Stanford, Stanford Medicine, and SLAC who have equipment hosted at SRCF2 to ensure safe facility operation and standards are met.
Identify and resolve complex technical systems issues which may have high risk/consequences of failure.
Review and analyze projects’ technical plans and specifications for conformance with design guidelines and other related criteria, and pertinent codes and standards
Serve as a technical lead on projects in areas of expertise across multiple contractor activities, through all project phases.
Conduct risk assessments and develop contingency plans

Minimum Requirements

Education and Experience
Bachelor’s degree in relevant discipline. Ten years of relevant work experience or a combination of those attributes.

Knowledge, Skills and Abilities
Strong interpersonal skills
Demonstrated breadth of understanding of electrical and mechanical systems found in a data center environment such as: Power distribution systems, UPS, Variable Frequency Drives, Generators, Air Handlers, Chillers, PLC’s, Etc.
Knowledge and proficiency with engineering software related to assignment, specifically Building Control and Monitoring Systems
Deep technical knowledge in area of expertise
Understanding of the basics of high performance computing and associated networking features and functions.
Strong customer service focus
Excellent project management skills
Excellent written and oral communication skills
Working knowledge of computer systems and typical office productivity software
Ability to identify and mitigate potential project risk components

Certifications and Licenses:
Data center operation certification is highly desired.

Physical Requirements
Occasionally sitting, perform desk-based computer tasks, lift/carry/push/pull objects that weigh up to 10 pounds.
Occasionally stand/walk, twist/bend/stoop/squat, grasp lightly/fine manipulation, use a telephone, lift/carry/push/pull objects that weigh from 11 to 40 pounds,
Frequently kneel/crawl, climb (ladders, scaffolds, or other), reach/work above shoulders, grasp forcefully, writing by hand, sort/file paperwork or parts, lift/carry/push/pull objects that weigh >40 pounds.

- Consistent with its obligations under the law, the University will provide reasonable accommodation to any employee with a disability who requires accommodation to perform the essential functions of his or her job

Working Conditions
Requires 24-hour response availability seven days per week for emergency situations.
Requires after hours and weekend work on occasion for maintenance and/or project related activities.
May be exposed to noise > 80dB TWA.
May work at heights 4 - 10 ft.

Work Standards
Interpersonal Skills: Demonstrates the ability to work well with Stanford colleagues, clients and with external organizations.
Promote Culture of Safety: Demonstrates commitment to personal responsibility and value for safety; communicates safety concerns; uses and promotes safe behaviors based on training and lessons learned.
Subject to and expected to comply with all applicable University policies and procedures, including but not limited to the personnel policies and other policies found in the University’s Administrative Guide, https://adminguide.stanford.edu/.

The job duties listed are typical examples of work performed by positions in this job classification and are not designed to contain or be interpreted as a comprehensive inventory of all duties, tasks, and responsibilities. Specific duties and responsibilities may vary depending on department or program needs without changing the general nature and scope of the job or level of responsibility. Employees may also perform other duties as assigned.

Stanford is an equal employment opportunity and affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other characteristic protected by law.",$10+ billion (USD),Colleges & Universities,College / University,Education
Data Center Facility Engineer,san-jose,"Asiacom Americas Inc
2.9","Santa Clara, CA",2.9,$69K - $98K (Glassdoor est.),2.8,2.4,2.5,2.9,3.0,Unknown,2018,"Data Center Facility Engineer
We are seeking an energetic Data Center Facility Engineer to serve as a technical resource in data centers. The position will help ensure overall availability and reliability to meet or exceed defined service levels of data center operations. The Data Center Facility Engineer is responsible for the overall operation and maintenance of all electrical, mechanical, and HVAC equipment within the data center.
This role acts as front line when it comes to hands-on electrical and mechanical equipment troubleshooting. They will maintain, operate, and troubleshoot mission-critical data center facility equipment including electrical support equipment such as stand-by diesel generators and related fuel systems, 3 phase electrical systems that include but not limited to switchgear, UPS units, PDUs, and wet cell batteries and associated systems. Additional support equipment is included in the scope of the role which includes fire suppression systems, building automation systems, and general facilities equipment.

Responsibilities
Oversee all aspects of the data center's critical physical infrastructure. Ensure that all work performed within the space is done to high quality and without impact to internal/external customers.
Engage in improvement projects, often requiring reaching out to a variety of support teams and drive them from conception to completion.
Coordinates daily with a multitude of third-party vendors ensuring adherence to contracted SLAs
Routinely operate as the afterhours on-call Data Center Facility Manager for the data centers in the region. This will include responding to any issues within the data centers and managing the investigation, mitigation, and recovery of the issue(s).

Basic Qualifications
Bachelor's degree in an engineering, electrical or mechanical discipline or equivalent work experience.
Preferred Qualifications.
Data Center experience.
2+ years of experience working in data centers with an emphasis on building and equipment operation.
Understanding of the electrical and mechanical systems involved in critical data center operations such as: feeders, transformers, generators, switchgear, UPS systems, ATS units, PDU units。
Must be fluent in English and Chinese Mandarin.",Unknown / Non-Applicable,Information Technology Support Services,Company - Public,Information Technology
Senior Data Engineer,san-jose,"Atlassian
4.5","Mountain View, CA",4.5,$127K - $183K (Glassdoor est.),4.3,4.6,4.2,4.6,4.6,5001 to 10000 Employees,2002,"Working at Atlassian

Atlassian can hire people in any country where we have a legal entity. Assuming you have eligible working rights and a sufficient time zone overlap with your team, you can choose to work remotely or from an office (unless it’s necessary for your role to be performed in the office). Interviews and onboarding are conducted virtually, a part of being a distributed-first company.

Your future team
Data engineering team at Atlassian is a group of professionals responsible for developing databases, data pipelines, and data marts, and ensuring that data is structured and formatted for use by downstream applications. Members of the data engineering team typically have a background in computer science, software engineering, and database design. These teams typically work with data scientists, business analysts, and other partners to ensure that data is available, accurate, and usable for decision-making purposes. In this role as a Senior Data Engineer, you will report into the Engineering Manager - Product Data Engineering.
Role
A successful Senior Data Engineer has technical skills in data modeling, database design, and programming languages such as Python, Java, or Scala. You should also have experience working with Big Data technologies such as Hadoop, and Spark. You will need to work with other teams to understand their data needs and develop solutions. Additionally, experience with streaming data sources and sinks, such as Apache Kafka or AWS Kinesis, would be valuable.
What you'll do
Design and implement data pipelines to ETL data from multiple sources into a central data warehouse.
Design and implement real-time data processing pipelines using Apache Spark Streaming.
Maintain data processing infrastructure, including databases, data lakes, and data warehouses.
Ensure data quality and consistency across all data systems.
Develop and implement data governance procedures to ensure data security, privacy, and compliance.
Collaborate with other teams, such as software engineers, product managers, and business analysts, to understand data needs and develop solutions to meet those needs.
Implement new technologies to improve data processing and analysis.
Coach junior data engineers to improve their skills.
Compensation
At Atlassian, we tie our base pay ranges to role and level. In the United States, that means your base pay ranges will fall into one of three geographic pay zones depending on your location. Our current base pay ranges for new hires in each zone are:
(Zone A: $151,100 - $231,800)
(Zone B: $136,000 - $208,700)
(Zone C: $125,400 - $192,400)
Within each range, base pay is ultimately determined based on your skills, expertise, and experience. This role may also be eligible for benefits, bonuses, commissions, and/or equity.
Please visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter.

Our perks & benefits

To support you at work and play, our perks and benefits include ample time off, an annual education budget, paid volunteer days, and so much more.

About Atlassian

The world’s best teams work better together with Atlassian. From medicine and space travel, to disaster response and pizza deliveries, Atlassian software products help teams all over the planet. At Atlassian, we're motivated by a common goal: to unleash the potential of every team.

We believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines.

To learn more about our culture and hiring process, explore our Candidate Resource Hub.",Unknown / Non-Applicable,Software Development,Company - Public,Information Technology
"AIML - Senior Software Engineer, Data & ML Innovations",san-jose,"Apple
4.2","Cupertino, CA",4.2,-1,-1,-1,-1,-1,-1,10000+ Employees,1976,"Summary
Posted: Mar 20, 2023
Weekly Hours: 40
Role Number:200467259
We are seeking a highly skilled and experienced software engineer to join our team at Apple AIML in building an on-device machine learning platform. As a key member of the team, you will help design and develop the infrastructure and work on various machine learning solutions and models. You will also have the chance to collaborate with product teams and utilize your expertise to solve technical challenges for upcoming products. Your responsibilities will include building the on-device machine learning infrastructure, working with product teams, and contributing to the development of machine learning solutions and platforms.
Key Qualifications
Strong background in distributed systems and machine learning
Experience with on-device machine learning and system development
Experience building and maintaining machine learning infrastructure
Ability to work effectively across multiple codebases, teams, and organizations
5+ years of professional experience as a software engineer, preferably in machine learning or a related field
Proactive and determined problem-solving skills
Excellent communication skills
Description
Our team is seeking a highly skilled and experienced software engineer to join us in building on-device Machine Learning platform that enables product teams across Apple to develop ML solutions that power intelligent user experiences. In this role, you will play a crucial role in the design and development on-device ML infrastructure and work closely with multiple ML-based solutions and experiences. You will also have the opportunity to engage with product teams across Apple and use your expertise to solve challenging technical problems in our next-generation products that will delight millions of people. Your responsibilities will include: * Designing and building on-device Machine Learning infrastructure to enable efficient and effective model training, evaluation, deployment, and performance monitoring. * Collaborating with product teams to identify and prioritize machine learning needs and opportunities. * Working with data scientists and machine learning researchers to design and conduct experiments to optimize model performance. * Participating in the development of machine learning infrastructure and tools, including model life-cycle management, experimentation tracking, and data management. To succeed in this role, you should have a strong background in distributed systems, Machine Learning and a proven track record of building and maintaining machine learning infrastructure. You should also be a proactive and determined problem solver with excellent communication skills and the ability to work effectively across multiple codebases, teams, and organizations. Experience with on-device Machine Learning and a passion for crafting compelling user experiences are highly desirable.
Education & Experience
Bachelor's or Master's degree in Computer Science or a related field
Additional Requirements
Preferred qualifications
Development experience at the systems level with Objective-C, Swift
Understanding of iOS, macOS fundamentals and frameworks
Proficiency in Python and ML frameworks such as Pytorch and Tensorflow
Experience with Core ML framework and tools
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $161,000 and $278,000, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",$10+ billion (USD),Computer Hardware Development,Company - Public,Information Technology
"Data Engineer, Experimentation & Evaluation-TikTok Data Platform",san-jose,"TikTok
3.6","San Jose, CA",3.6,Employer Provided Salary:$136K - $280K,3.4,3.4,3.1,3.6,3.0,1001 to 5000 Employees,2016,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

Team Introduction
Our mission in experimentation and evaluation team is to build the next-gen A/B testing platform, that empowers the company to make data-driven decision for the products. The supported scenarios include recommendation, push, ads, search, mobile app, UI interaction and service upgrades etc. Our platform's capabilities cover the entire experiment life cycle, from experiment design, experiment creation, metrics calculation, statistical analysis to final evaluation and launch. In the process of rapid iteration, we provide reliable services for businesses to make bold hypotheses and cautious verification.

As a data engineer in experimentation and evaluation team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. You'll have the opportunity to gain hands-on experience on all kinds of systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.

Design and build data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, multi-dimensional analysis)
Design and implement reliable, scalable, robust and extensible big data systems that support core products and business
Establish solid design and best engineering practice for engineers as well as non-technical people
Qualifications
BS or MS degree in Computer Science or related technical field or equivalent practical experience
Experience in the Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.)
Experience with performing data analysis, data ingestion and data integration
Solid communication and collaboration skills
Preferred Qualifications
Working industry experience with Big Data systems and projects
Experience in building large scale distributed systems in a product environment
Experience with ETL(Extraction, Transformation & Loading), architecting data systems, schema design, and data modeling
Experience in writing, analyzing and debugging SQL queries
Experience in data privacy and security related projects
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or an accommodation, please reach out to us at dennis.chau@tiktok.com.
Job Information
The base salary range for this position in the selected city is $136000 - $280000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",Unknown / Non-Applicable,Internet & Web Services,Company - Private,Information Technology
Sr. Data Engineer,san-jose,LOVEFOODIES INC,"Menlo Park, CA",-1,Employer Provided Salary:$30.00 Per Hour,-1,-1,-1,-1,-1,Unknown,Company - Public,"Role: Data Engineer
Essential Skills:
SQL. SQL, or Structured Query Language, is the ubiquitous industry-standard database language
Data pipelines in python is required
Python–Statistical Programming
Data Visualization
Strong Python programming.
Strong SQL programming.
Strong Data Modeling.
Excellent communication and presentation skills.
Basic knowledge of Tableau.
Should have interest in creating BI reports.
Job Types: Full-time, Contract
Pay: From $30.00 per hour
Benefits:
Dental insurance
Health insurance
Paid time off
Vision insurance
Schedule:
8 hour shift
Ability to commute/relocate:
Menlo Park, CA: Reliably commute or planning to relocate before starting work (Required)
Experience:
SQL: 3 years (Required)
Work Location: In person",-1,-1,Unknown / Non-Applicable,-1
Senior Data Center Engineer,san-jose,"Sirius XM
3.6","San Jose, CA",3.6,$90K - $132K (Glassdoor est.),3.2,3.7,3.2,3.4,3.7,1001 to 5000 Employees,1990,"Responsibilities:
Who We Are:
SiriusXM and its brands (Pandora, Stitcher, SXM Media, AdsWizz, Simplecast, and SiriusXM Connected Vehicle Services) are leading a new era of audio entertainment and services by delivering the most compelling subscription and ad-supported audio entertainment experience for listeners - in the car, at home, and anywhere on the go with connected devices. Our vision is to shape the future of audio, where everyone can be effortlessly connected to the voices, stories and music they love wherever they are.
This is the place where a diverse group of emerging talent and legends alike come to share authentic and purposeful songs, stories, sounds and insights through some of the best programming and technology in the world. Our critically-acclaimed, industry-leading audio entertainment encompasses music, sports, comedy, news, talk, live events, and podcasting. No matter their individual role, each of our employees plays a vital part in bringing SiriusXM’s vision to life every day.
SiriusXM is the leading audio entertainment company in North America, and the premier programmer and platform for subscription and digital advertising-supported audio products. SiriusXM’s platforms collectively reach approximately 150 million listeners, the largest digital audio audience across paid and free tiers in North America, and deliver music, sports, talk, news, comedy, entertainment and podcasts. Pandora, a subsidiary of SiriusXM, is the largest ad-supported audio entertainment streaming service in the U.S. SiriusXM's subsidiaries Stitcher, Simplecast and AdsWizz make it a leader in podcast hosting, production, distribution, analytics and monetization. The Company’s advertising sales organization, which operates as SXM Media, leverages its scale, cross-platform sales organization and ad tech capabilities to deliver results for audio creators and advertisers. SiriusXM, through Sirius XM Canada Holdings, Inc., also offers satellite radio and audio entertainment in Canada. In addition to its audio entertainment businesses, SiriusXM offers connected vehicle services to automakers.
How you’ll make an impact:
We have a terrific opportunity in our Technical Operations team for an intelligent and motivated Senior Data Center Operations Engineer who is enthusiastic about data center deployment and site reliability for large-scale consumer online services. As a member of our Site Operations team, you will be responsible for the day-to-day operations of our co-location data centers and assume a critical role in maintaining the overall uptime, performance, and capacity of the Pandora service. You will be able to bring your solid experience to bear in supporting the various services we manage and take on interesting and mission-critical projects as part of a fast-paced, highly collaborative team. We hold ourselves to high standards, and take pride in our work. You should be dedicated to excellence and have a strong sense of personal responsibility. This position is primarily on-site at our data center facilities in San Jose and Santa Clara, CA, with occasional travel to our various data center locations, around the country.
What you’ll do:
100% hands-on with data center infrastructure provisioning and server/network equipment deployments.
Rack/Cable/Provision a large inventory of servers, switches, PDUs and consoles.
Perform initial configuration of systems as defined by our standard operating procedures. (BIOS configuration, PXE OS installs, DNS updates etc.)
Diagnose complex technical problems, provide detailed remediation/mitigation recommendations.
Plan and assist with hardware life-cycle management from provisioning to retiring and decommission.
Manage RMA processes with various vendors.
Maintain an up-to-date inventory list of all hardware equipment across our data centers.
Implement best-practice methodology for maintaining a data center environment.
Create automated provisioning processes for streamlining hardware deployments.
Plan, schedule and perform upgrades/maintenance on infrastructure hardware.
Document and track all assigned tasks via our internal ticketing system in a timely fashion.
What you’ll need:
BA/BS Information Technology, Computer Science or a related field. (or equivalent experience)
IT Certifications such as Server+, RHCSA/RHCE, CCNA or similar a plus.
Minimum 6 years of data center related experience with at least 3 years of day-to-day hands-on experience in an enterprise scale data center environment.
Demonstrated proficiency in monitoring stacks such as Prometheus, Alertmanager, and Grafana.
Hands-on experience with PXE boot, UEFI, AMI BIOS distributions, BMC/iDRAC implementation.
Experience creating and executing Ansible playbooks.
Practical professional knowledge of Linux and full network stack from NIC firmware to TCP/IP.
Expertise with SAN and NAS arrays such as Netapp, Isilon, Pure Storage, and Brocade.
Familiarity with version control systems such as Bitbucket and Git.
Familiarity with performance testing and reporting tools, such as Phoronix, FIO, Stream and others.
Experience with ISC DHCP and BIND DNS operations.
Basic scripting skills in Python and familiarity with Bash.
Significant knowledge of Linux kernel drivers, kernel tuning, and debugging hardware compatibility issues.
Basic understanding of subnetting, DHCP Relays, load balancing, and ARP.
Working knowledge of package management tools such as APT, RPM.
Self-motivated, continuous learner, appreciates challenge, comfortable and effective working in new areas that require experimentation and rapid problem solving.
Excellent time management skills, with the ability to prioritize and multitask, and work under shifting deadlines in a fast-paced environment.
Strong understanding of x86 server hardware architecture and subsystems as it relates to configuration, triage, and certification in a large-scale server environment.
Knowledgeable in data center best practices including but not limited to cabling, power balancing, cooling and airflow optimization, inventory tracking, capacity planning and host/service diversity.
Troubleshoot and remedy hardware issues, document findings and provide detailed RCA reports.
Assist with data center capacity and growth planning as well as power and cooling aspects.
Work alongside a group of data center operations engineers in accomplishing the various day-to-day data center related tasks and facilitating new build-outs.
Strong interpersonal skills with the ability to lead as well as work in a team environment.
Meticulous attention to detail and strong organization skills.
Maintain an up-to-date inventory of hardware equipment across all our data center co-locations.
Take pride in keeping a clean and tidy work environment within each data center co-locations.
Ability to lift and carry equipment up to 75 pounds safely and reliably on a regular basis.
Excellent written and verbal communication skills.
Participate in a 24x7x365 on-call rotation.
Up to 15% travel
Ability to travel to our other data center co-locations sites within the U.S.
Must have legal right to work in the U.S.
At SiriusXM, we carefully consider a wide range of factors when determining compensation, including your background and experience. These considerations can cause your compensation to vary. We expect the base salary for this position to be in the range of $98,900 to $200,156 and will depend on your skills, qualifications, and experience. Additionally, this role might be eligible for discretionary short-term and long-term incentives. We encourage all interested candidates to apply.
Our goal at SiriusXM is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.
The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",$1 to $5 billion (USD),Broadcast Media,Company - Public,Media & Communication
Energy Engineering - Software Engineer/Data Scientist (Fall 2023),san-jose,"Tesla
3.6","Fremont, CA",3.6,$103K - $160K (Glassdoor est.),3.7,3.3,3.1,3.7,2.9,10000+ Employees,2003,"What to Expect
Disclaimer: This position is expected to start around August or September 2023 and continue through the entire Fall term (i.e. through December) or into Winter/Spring 2024 if available. We ask for a minimum of 12 weeks, full-time, in-person. Please consider before submitting an application.

International Students: If your work authorization is through CPT, please consult your school on your ability to work 40 hours per week before applying. Again, please do not apply until you know you can work 40 hours per week. Many students will be limited to part-time during the academic year.

Internship Program at Tesla
The Internship Recruiting Team is driven by the passion to recognize and develop emerging talent. Our year-round program places the best students in positions where they will grow technically, professionally, and personally through their experience working closely with their Manager, Mentor, and team. We are dedicated to providing an experience that allows the intern to experience life at Tesla by including them in projects that are critical to their team’s success.

Locations
Fremont, CA
Palo Alto, CA
What You’ll Do
The Energy and Supercharging reliability engineering team is in charge of helping Tesla optimize product design and validate the most compelling and reliable for our customers. For this purpose, the team is responsible for both designing/building automated test equipment to validate current and future products and collecting data to enable the reliability physics analyses.

Responsibilities
The Intern will utilize large-scale data and help Tesla engineers design and validate the most compelling and reliable products for our customers. The reliability data team collects real-time life data from test and fleet (energy, charging, and vehicle products) and is responsible for retrieving, analyzing and summarizing results to cross-functional teams. The team provides support through the whole design cycle by building software and statistical tools that orchestrate all the reliability physics analyses.
Answer complex questions on fleet usage and behavior to enable proactive monitoring, grow reliability, and minimize field failures
Build scalable data pipelines to deploy fleet health monitoring models
Apply modern statistical frameworks to support Design for Reliability and associated corrective actions
Work closely with cross-functional teams to create/interpret/validate numeric models of fielded and in-test products
Build visualizations to effectively communicate results
What You’ll Bring
Excellent SW skills (proficiency in Python - Data Science stack)
Strong MLOps and DevOps skills
Solid understanding of statistics (Statistical Learning, Bayesian Models,…)
Strong knowledge of data structures and architectures and languages such as SQL
Strong verbal and written communication skills
Experience with scalable Machine Learning & time-series modeling
PySpark and Big Data frameworks
Familiarity with CI/CD
Ability to code robust-apps (potentially interfacing with data streams, etc.)",$1 to $5 billion (USD),Transportation Equipment Manufacturing,Company - Public,Manufacturing
Senior Software Engineer - Data,san-jose,"Uber
3.9","Sunnyvale, CA",3.9,Employer Provided Salary:$174K,3.5,3.7,3.3,3.6,3.8,10000+ Employees,2009,"Senior Software Engineer - Data
About the role:
Partners with stakeholders to translate complex business or technical problems into end-to-end data tools and solutions (e.g., pipelines, models, tables). This role also leads team efforts to design and develop large-scale data systems (e.g., databases, data warehouses, big data systems), platforms, and infrastructure for various analytics and business applications.

About the Team:
The Marketplace Driver Pricing team is responsible for Uber’s growth and profitability story. Driver Pricing team focuses on how to price the trip intelligently for Uber drivers to improve driver trust in Uber platform, improve marketplace reliability and fulfill long-term objectives oriented around growth & profitability. The team is critical in fostering a healthy ride-sharing ecosystem and in providing an upfront pricing experience for Uber drivers, so they can maximize their earnings on Uber. We seek the best opportunities to grow Uber's business with the state-of-the-art machine learning technology and distributed platform to achieve industry leading ROI.

We keep innovating in this crucial space with breakneck speed (causal ML, constrained optimization, high throughput systems, etc.), and all subteams work very closely with each other but with different focuses. Collectively we are responsible to shape up a healthy marketplace in all markets Uber operates and affect millions of drivers directly on a daily basis.

We have a lot of opportunities to work with product managers and data scientists from other teams. We participate in the whole development cycle of a software product from product scoping, architecture design, software implementation, and productionization, and learn how to iterate a product for greater success. We work with many popular open source software and Uber systems built in-house. We own a few products that directly impact Uber's top line and bottom line.
Minimum qualifications:
PhD or equivalent in Computer Science, Engineering, Mathematics or related field OR 3-years full-time Software Engineering work experience, WHICH INCLUDES 2-years total technical software engineering experience in one or more of the following areas:
Programming and scripting language (e.g. Python, SQL, Java/Scala)
Big data frameworks (e.g. Spark, Flink, Presto), data modeling, and writing ETLs
Designing end-to-end data solutions and architecture

Note the 2-years total of specialized software engineering experience may have been gained through education and full-time work experience, additional training, coursework, research, or similar (OR some combination of these). The years of specialized experience are not necessarily in addition to the years of Education & full-time work experience indicated.
Technical skills:

Data Analytics
Data Modeling
Big Data Processing
Data Storage Systems
Distributed Systems
SQL, ETLs, Complex Data Pipelines
Spark, Hive, Hadoop

At Uber, we ignite opportunity by setting the world in motion. We take on big problems to help drivers, riders, delivery partners, and eaters get moving in more than 600 cities around the world!
We welcome people from all backgrounds who seek the opportunity to help build a future where everyone and everything can move independently. If you have a curiosity, passion and collaborative spirit, work with us, and let’s move the world forward, together!
Uber is proud to be an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.
If you have a disability or special need that requires accommodation, please let us know by completing this form.

For San Francisco, CA-based roles: The base salary range for this role is $174,000 per year - $193,500 per year.

For Sunnyvale, CA-based roles: The base salary range for this role is $174,000 per year - $193,500 per year.

For all US locations, you will be eligible to participate in Uber's bonus program, and may be offered an equity award & other types of comp. You will also be eligible for various benefits. More details can be found at the following link https://www.uber.com/careers/benefits.",$10+ billion (USD),Internet & Web Services,Company - Public,Information Technology
"Data Engineer, 5+ Years of Experience",san-jose,"Snapchat
3.9","Palo Alto, CA",3.9,Employer Provided Salary:$174K - $251K,3.6,4.0,3.1,4.3,3.7,5001 to 10000 Employees,2011,"Snap Inc
is a technology company. We believe the camera presents the greatest opportunity to improve the way people live and communicate. Snap contributes to human progress by empowering people to express themselves, live in the moment, learn about the world, and have fun together. The Company’s three core products are
Snapchat
, a visual messaging app that enhances your relationships with friends, family, and the world;
Lens Studio
, an augmented reality platform that powers AR across Snapchat and other services; and its AR glasses,
Spectacles
.
Snapchat
is a camera and messaging app that connects people to their friends and the world. Every day around the globe, millions of people use Snapchat to communicate with friends, build relationships, play, and learn. No matter where you are or how you express yourself, it’s always the fastest way to share a moment!
We’re looking for a Data Engineer on our Data Insights and Governance team!
What you’ll do:
Work closely with stakeholders in engineering, finance, sales, marketing, strategy, and governance to make high quality datasets available to consumers in a timely manner
Develop data pipelines adhering with privacy and governance principles
Become familiar with our data consumption portals and their capabilities
Build expertise and ownership of data quality for supported domains
Build tooling and implement systems to overcome limitations of the data consumption portals when appropriate
Drive adoption of the data sets you’ve produced
Knowledge, Skills & Abilities:
Experience in building data pipelines to serve reporting needs
Experience owning all or part of a team roadmap
Ability to prioritize requests from multiple stakeholders in disparate domains
Ability to effectively communicate complex projects to non-technical stakeholders

Minimum Qualifications:
BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
5+ year experience in SQL or similar languages
5+ years development experience in at least one object-oriented or scripting language (Python, Java, Scala, etc)
Preferred Qualifications:
Hands on experience with Google BigQuery
Experience in version control systems such as Git
Data architecture and warehousing experience
Experience leading a small team of data or software engineers
Experience with Airflow
Experience in ETL / Data application development
Compensation
In the United States, work locations are assigned a pay zone which determines the salary range for the position. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These pay zones may be modified in the future.
Zone A (CA, WA, NYC)
: The base salary range for this position is $205,000 - 295,000 annually
Zone B
: The base salary range for this position is $195,000 - 280,000 annually
Zone C
: The base salary range for this position is $174,000 - $251,000 annually
This position is eligible for equity in the form of RSUs
""Default Together"" Policy at Snap. At Snap Inc. we believe that being together in person helps us build our culture faster, reinforce our values, and serve our community, customers and partners better through dynamic collaboration. To reflect this, we practice a “default together” approach and expect our team members to work in an office at least 80% of the time (an average of 4 days per week).
If you are not based in the same location(s) listed for this role and are open to relocation, we encourage you to apply to take advantage of our generous relocation policy.

At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets. If you have a disability or special need that requires accommodation, please don’t be shy and contact us at
accommodations-ext@snap.com
.
Our Benefits
: Snap Inc. is its own community, so we’ve got your back! We do our best to make sure you and your loved ones have everything you need to be happy and healthy, on your own terms. Our benefits are built around your needs and include paid parental leave, comprehensive medical coverage, emotional and mental health support programs, and compensation packages that let you share in Snap’s long-term success!",Unknown / Non-Applicable,Computer Hardware Development,Company - Public,Information Technology
3D Vision Engineer - Dynamic Perception Data (TDG),san-jose,"Apple
4.2","Cupertino, CA",4.2,-1,-1,-1,-1,-1,-1,10000+ Employees,1976,"Summary
Posted: May 16, 2022
Role Number:200380142
Do you want to push the limits of the best Augmented Reality platform in the world? Apple's Technology Development Group (TDG) delivers algorithms that drive revolutionary Apple products, including the augmented reality (AR) platform ARKit to create ground-breaking new products. In this position, you will have the opportunity to be part of our extraordinary team of computer vision and deep learning researchers and engineers to discover and build solutions to previously-unsolved challenges and push the state of the art in AR algorithms that will change the way people experience the world! We are looking for a driven computer vision software engineer, optimally with experience in motion capture, sensor fusion, and interactive 3D UI tool creation to invent and develop hardware and software solutions for dynamic 3D data collection and annotation. As a member of a fast-paced team, you have the rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day. To succeed within this role, you should have shown experience in several of the following areas:
Key Qualifications
Strong C++ experience, including modern C++
Strong experience in Python. Including popular science libraries like Numpy, Pandas, … etc.
Solid understanding of 3D computer vision and multi-camera systems.
Experience in sensor fusion and calibration.
Experience in interactive 3D graphics programming/UI tool development.
Excellent communication and collaboration skills
Excellent problem solving and analytical thinking skills
Track record of successfully building and shipping products or open source projects
Creativity and curiosity for solving highly complex problems
Bonus for iOS development experience
Bonus for experience in Swift or Objective-C
Description
You’ll be working in a team of computer vision and deep learning researchers and engineers to implement world class algorithms that pushes the state of the art. Your goal is to design and drive building a novel infrastructure for collecting and annotating 3D data in dynamic environments that enables the team to measure their progress accurately across all target scenarios. Your job responsibilities will include: -Working with cameras, IMUs, motion capture systems and robots to define and build multi-sensor data capture setups. -Developing 3D computer vision and sensor fusion algorithms. -Building UI tools for visualizing and interacting with multi-modal 3D data. -Improving and extending existing tools and frameworks. -Collaborating with CVML engineers and researchers in order to define quality metrics and regression tests. -Cooperating with your team members to prepare presentations, papers, and talks to explain your inventions.
Education & Experience
M.S., or Ph.D. or 5+ years of industry experience in computer vision, machine learning or robotics or related fields
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $130,000 and $242,000, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",$10+ billion (USD),Computer Hardware Development,Company - Public,Information Technology
"Staff Software Engineer, Infrastructure, Google Cloud Data Management",san-jose,"Google
4.4","Sunnyvale, CA",4.4,-1,-1,-1,-1,-1,-1,10000+ Employees,1998,"Note: Google’s hybrid workplace includes remote and in-office roles. By applying to this position you will have an opportunity to share your preferred working location from the following:

In-office locations: Kirkland, WA, USA; Sunnyvale, CA, USA.
Remote location(s): United States.
Minimum qualifications:
Bachelor's degree or equivalent practical experience.
8 years of experience in software development, and with data structures/algorithms.
5 years of experience testing, and launching software products, and 3 years of experience with software design and architecture.
5 years of experience building and developing large-scale infrastructure, distributed systems or networks, and/or experience with compute technologies, storage, and/or hardware architecture.


Preferred qualifications:
Master’s degree or PhD in Engineering, Computer Science, or a related technical field.
3 years of experience in a technical leadership role leading project teams and setting technical direction.
3 years of experience working in a complex, matrixed organization involving cross-functional, and/or cross-business projects.
About the job
Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward.
With your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance software solutions.

Google Cloud accelerates organizations’ ability to digitally transform their business with the best infrastructure, platform, industry solutions and expertise. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology – all on the cleanest cloud in the industry. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems.
Salary Range Info:
The US base salary range for this full-time position is $185,000-$283,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.
Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.

Responsibilities
Provide technical leadership on high-impact projects.
Influence and coach a distributed team of engineers.
Facilitate alignment and clarity across teams on goals, outcomes, and timelines.
Manage project priorities, deadlines, and deliverables.
Design, develop, test, deploy, maintain, and enhance large scale software solutions.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.",$10+ billion (USD),Internet & Web Services,Company - Public,Information Technology
Data Warehouse Engineer,san-jose,"Purple Drive Technologies
4.2","Cupertino, CA",4.2,Employer Provided Salary:$98K - $191K,3.9,4.0,4.0,3.7,4.2,1 to 50 Employees,Company - Private,"Terraform along with synapse Azure cloud
Deep expertise in Data Engineering and Data Warehousing (minimum 4+ years)
Azure synapse , Azure Data Factory , Spark Pool , SQL , SQL Pool (minimum 4+ yrs)
CI/CD and Python/Java programming experience (minimum 3+ years)
Ideal to have a 24 x 7 development i.e offshore presence or different time zones
Job Type: Full-time
Salary: $97,654.83 - $190,994.11 per year
Ability to commute/relocate:
Cupertino, CA: Reliably commute or planning to relocate before starting work (Required)
Experience:
Data modeling: 1 year (Preferred)
Work Location: One location",-1,-1,Unknown / Non-Applicable,-1
Software Engineer - Data Platform,san-jose,"Lacework
4.3","Mountain View, CA",4.3,Employer Provided Salary:$119K - $300K,4.1,4.1,3.9,4.6,3.7,1001 to 5000 Employees,2015,"At Lacework, we strive to provide a supportive, collaborative environment where people are empowered to do the best work of their careers.
Our team members enjoy solving complex problems, big sky thinking, and obsess over getting the details right. We love what we do and are proud of our work to secure clouds and container environments for thousands of users worldwide.
At Lacework, we strive to provide a supportive, collaborative environment where people are empowered to do the best work of their careers.
Our team members enjoy solving complex problems, big sky thinking, and obsess over getting the details right—all while building bonds of teamwork and friendships that last a lifetime. We love what we do and are proud of our work to secure clouds and container environments for thousands of users worldwide.
Cloud computing is revolutionizing IT and forcing organizations to rethink their approach to cloud security. Lacework is at the forefront of this transformation. We enable security teams to effectively secure public and private clouds – AWS, Azure or collocations – by eliminating repetitive, manual and labor-intensive security tasks. Using Lacework, security teams operate security at the same pace as DevOps, which relies on automated tools to publish daily updates to the cloud.
We are looking for a Senior Software Developer, Data Platform

What You Will Accomplish
Architect, design, and implement highly scalable distributed systems that provide availability, scalability and latency guarantees.
Develop infrastructure as required to monitor and scale.
Own one or more services in its entirety within Data Platform from design, coding to delivery and monitoring post deployment.
Participate in functional scoping and work distribution (be a tech lead)
Peer Code reviews and technical design reviews
Mentor and guide junior team members.
What You Will Bring
Minimum 5 years of experience building highly available, scalable, distributed services.
Bachelors in CS or similar
Proven ability and an understanding of design for scalability, performance, and reliability
Deep understanding of relational databases such as MySQL, Postgres, Oracle, and SQL development are required. Experience with Snowflake is plus
Must have experience developing microservices with Java, using frameworks such as Spring, Drop wizard.
Experience developing Kubernetes based services on AWS Stack is highly desired.
Excellence in technical communication with peers and non-technical cohorts
Detail oriented, have a proven ability to be a technical lead for a small team / project.
Preferred Qualifications and Nice-To-Have
10 years of industry experience.
Advance degree (M.S. preferred)
Hands-on experience in developing Data Integration applications for large scale (petabyte scale) environments with experience in both batch and online systems.
Experience with Unix/Linux development/production environments
Powerful sense of ownership, customer obsession, and drive
Sharp analytical abilities, Quick learner; self-starter, detailed and thorough.
Strong skills on mentoring/growing junior people.
Demonstrated technical leadership abilities & a team player.
Demonstrated ability to achieve stretch goals in a highly innovative and fast paced environment.
Salary Range: $119k - $300k USD Annually + Benefits + Bonus + Equity
Actual compensation may vary based on factors such as geographic location, work experience, education/training and skill level.
Location: Mountain View, CA | Seattle, WA | Ireland | United Kingdom
Lacework is an Equal Opportunity Employer. It is the policy of Lacework to provide equal employment opportunity to all persons, regardless of age, race, religion, color, national origin, sex, political affiliations, marital status, non-disqualifying physical or mental disability, age, sexual orientation, membership, or non-membership in an employee organization, or on the basis of personal favoritism or other non-merit factors, except where otherwise provided by law",$100 to $500 million (USD),Enterprise Software & Network Solutions,Company - Private,Information Technology
"Data Engineer, Product Analytics",san-jose,"Meta
3.9","Fremont, CA",3.9,Employer Provided Salary:$165K - $232K,4.0,3.7,3.3,4.6,3.6,10000+ Employees,2004,"As a highly collaborative organization, our data engineers work cross-functionally with software engineering, data science, and product management to optimize growth, strategy, and experience for our 3 billion plus users, as well as our internal employee community. In this role, you will see a direct correlation between your work, company growth, and user satisfaction. Beyond this, you will work with some of the brightest minds in the industry, and you'll have a unique opportunity to solve some of the most interesting data challenges with efficiency and integrity, at a scale few companies can match.


Data Engineer, Product Analytics Responsibilities:
Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems.
Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve.
Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights visually in a meaningful way.
Define and manage SLA for all data sets in allocated areas of ownership.
Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership.
Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains.
Solve our most challenging data integration problems, utilizing optimal ETL patterns, frameworks, query techniques, sourcing from structured and unstructured data sources.
Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts.
Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts.
Influence product and cross-functional teams to identify data opportunities to drive impact.
Mentor team members by giving/receiving actionable feedback.



Minimum Qualifications:
Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
5+ years experience in the data warehouse space.
5+ years experience in custom ETL design, implementation and maintenance.
5+ years experience with object-oriented programming languages.
7+ years experience with schema design and dimensional data modeling.
7+ years experience in writing SQL statements.
Experience analyzing data to identify gaps and inconsistencies.
Experience managing and communicating data warehouse plans to internal clients.



Preferred Qualifications:
Master's or Ph.D degree in a STEM field
Experience with one or more of the following: data processing automation, data quality, data warehousing, data governance, business intelligence, data visualization, data privacy
Experience working with terabyte to petabyte scale data
Experience influencing product decisions with data.





Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics. You may view our Equal Employment Opportunity notice here. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. We may use your information to maintain the safety and security of Meta, its employees, and others as required or permitted by law. You may view Meta's Pay Transparency Policy, Equal Employment Opportunity is the Law notice, and Notice to Applicants for Employment and Employees by clicking on their corresponding links. Additionally, Meta participates in the E-Verify program in certain locations, as required by law",$10+ billion (USD),Internet & Web Services,Company - Public,Information Technology
3D Vision Engineer - Dynamic Perception Data (TDG),san-jose,"Apple
4.2","Cupertino, CA",4.2,-1,-1,-1,-1,-1,-1,10000+ Employees,1976,"Summary
Posted: May 16, 2022
Role Number:200380142
Do you want to push the limits of the best Augmented Reality platform in the world? Apple's Technology Development Group (TDG) delivers algorithms that drive revolutionary Apple products, including the augmented reality (AR) platform ARKit to create ground-breaking new products. In this position, you will have the opportunity to be part of our extraordinary team of computer vision and deep learning researchers and engineers to discover and build solutions to previously-unsolved challenges and push the state of the art in AR algorithms that will change the way people experience the world! We are looking for a driven computer vision software engineer, optimally with experience in motion capture, sensor fusion, and interactive 3D UI tool creation to invent and develop hardware and software solutions for dynamic 3D data collection and annotation. As a member of a fast-paced team, you have the rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day. To succeed within this role, you should have shown experience in several of the following areas:
Key Qualifications
Strong C++ experience, including modern C++
Strong experience in Python. Including popular science libraries like Numpy, Pandas, … etc.
Solid understanding of 3D computer vision and multi-camera systems.
Experience in sensor fusion and calibration.
Experience in interactive 3D graphics programming/UI tool development.
Excellent communication and collaboration skills
Excellent problem solving and analytical thinking skills
Track record of successfully building and shipping products or open source projects
Creativity and curiosity for solving highly complex problems
Bonus for iOS development experience
Bonus for experience in Swift or Objective-C
Description
You’ll be working in a team of computer vision and deep learning researchers and engineers to implement world class algorithms that pushes the state of the art. Your goal is to design and drive building a novel infrastructure for collecting and annotating 3D data in dynamic environments that enables the team to measure their progress accurately across all target scenarios. Your job responsibilities will include: -Working with cameras, IMUs, motion capture systems and robots to define and build multi-sensor data capture setups. -Developing 3D computer vision and sensor fusion algorithms. -Building UI tools for visualizing and interacting with multi-modal 3D data. -Improving and extending existing tools and frameworks. -Collaborating with CVML engineers and researchers in order to define quality metrics and regression tests. -Cooperating with your team members to prepare presentations, papers, and talks to explain your inventions.
Education & Experience
M.S., or Ph.D. or 5+ years of industry experience in computer vision, machine learning or robotics or related fields
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $130,000 and $242,000, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",$10+ billion (USD),Computer Hardware Development,Company - Public,Information Technology
"Platform Data Engineer, Financial Services",san-jose,"Recruiting From Scratch
3.9","Saratoga, CA",3.9,Employer Provided Salary:$140K - $250K,4.0,3.6,3.5,3.9,3.9,1 to 50 Employees,2019,"Who is Recruiting from Scratch:
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
Data Engineer - Platform
A Career with our Market Intelligence Team:
Our Market Intelligence team is responsible for developing proprietary research products and providing data and research management services for investment teams to support their pursuit of superior, risk-adjusted returns. We leverage innovative alternative data sources, advanced data analytics and technologies, and deep fundamental research to create high-quality compliant and differentiated research. Backed by the full resources of our company, our sector aligned teams of fundamental researchers, data scientists, data strategists, relationship managers, and data engineers collaborate to solve important research problems in partnership with the Firm’s investment and compliance professionals.

What you’ll do
Platform Engineers build solutions for processing big and unstructured data sets. Our team works closely with portfolio managers and data scientists to understand the potential business value of data sets and ultimately build data processing pipelines around those data sources. In this role, you will:
Develop big data processing pipelines for new data sources containing structured and unstructured data
Build platform infrastructure using Hadoop technologies
Build and support visualization and exploration capabilities around our big data sets
Maintain knowledge of new technology developments and conduct proof of concepts to evaluate new technologies

What’s required
We want you to join us if you have extensive experience or demonstrated interest in big data technologies. Other requirements include:
2+ years of experience in Data Engineering or related field
Commitment to the highest ethical standards
Strong experience in Python Development
Experience with Spark or Scala
Ability to devise novel and innovative solutions to challenges
Knowledge of/experience with graph databases is a plus

We take care of our people
We invest in our people, their careers, their health, and their well-being. We want you to concentrate on success and leave the rest to us. When you work here, we provide:
Fully-paid health care benefits
Generous parental and family leave policies
Mental and physical wellness programs
Tuition assistance
A 401(k) savings program with an employer match and more
Salary Range: $140,000-$250,000 base.",$1 to $5 million (USD),Staffing & Subcontracting,Company - Private,Human Resources & Staffing
Data Scientist and AI Engineer,san-jose,SKT Lab,"Santa Clara, CA",-1,$109K - $164K (Glassdoor est.),-1,-1,-1,-1,-1,1 to 50 Employees,Company - Public,"We are always looking for smart, enthusiastic, creative people to join our team! If you are interested in working with us, please email us at job@sktlab.com.

Qualifications:
We are looking for a candidate with 5+ years of experience in a Data Scientist role, who has Bachelor's or Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
Experience with big data tools
Experience with relational SQL and NoSQL databases
Developing in R and Python
Experience working with Hadoop /Spark
Have Knowledge of Machine learning (supervised/unsupervised) & common ML frameworks",-1,Information Technology,Computer Hardware Development,Unknown / Non-Applicable
SENIOR STAFF DATA ENGINEER,san-jose,"Karius
3.5","Redwood City, CA",3.5,Employer Provided Salary:$180K - $240K,3.6,3.7,3.3,4.0,4.0,51 to 200 Employees,2014,"About Karius
Karius is a venture-backed life science startup that is transforming the way pathogens
and other microbes are observed throughout the body. By unlocking the information
present in microbial cell-free DNA, helping doctors quickly solve their most
challenging cases, providing industry partners with access to 1000’s of biomarkers to
accelerate clinical trials, discover new microbes, and reduce patient suffering worldwide.
Karius aims to conquer infectious diseases through innovations around genomic
sequencing and machine learning. The company’s platform is already delivering
unprecedented insights into the microbial landscape, providing clinicians with a
a comprehensive test capable of identifying more than a thousand pathogens directly
from blood, and helping the industry accelerate the development of therapeutic
solutions. The Karius test we provide today is one of the most advanced solutions
available to physicians who aim to deliver better care to many otherwise ineffectively
treated patients.

Position Summary
Karius is building AI-driven data analytics pipelines to deliver life-saving results in the
highly complex infectious disease landscape. We are seeking a seasoned Senior Staff
Data Engineer in Redwood City, CA to lead the design and development of a scalable
data platform to meet our rapid business growth. Senior Staff Data Engineer will be
responsible for defining the technology roadmap, and developing and optimizing the
data platform to enable us to extract values from large amounts of genomic, clinical,
operation and clinical data to provide actionable insights to serve the patients and
develop innovative products. In this regard, the Senior Staff Data Engineer will work
with key stakeholders within the company to understand our data landscape and the
core needs for data governance and usage.

Primary Responsibilities
Design, develop, and operate a scalable data platform that ingests, stores, and
aggregates various datasets to meet the defined requirements;
As the primary subject matter expert in the data engineering domain, evaluate
technology trends in the data industry, identify those technologies relevant to
the company’s business objectives, and develop a roadmap to update the
company’s data platform;
Provide Machine Learning (“ML”) data platform capabilities for R&D and
Analytics teams to perform data preparation, model training and management,
and run experiments against clinical and genomic datasets;
Train the R&D and Analytics teams on using Karius data toolsets and mentor
and support them throughout their research and development efforts;
Build and maintain data ETL/ELT pipelines to source and aggregate the
required internal data to calculate operational and commercial Key Performance
Indicators (“KPIs”) and various data analysis and reporting needs;
Develop integrations with Karius and 3rd party systems to source, qualify and
ingest various datasets; work closely with cross-functional groups and
stakeholders, such as the product, engineering, medical, and scientiﬁc teams,
for data modeling and general life cycle management;
Provide data analytics and visualization tools to extract valuable insights from
the data and enable data-driven decisions; and
Work closely with the Security and Compliance teams, and deploy necessary
data governance to meet the regulatory and legal requirements.

Position Minimum Requirements
At least a Bachelor’s degree in Computer Science, Data Science, or Software
Engineering, Electrical Engineering, or Bio-Engineering (or its foreign equivalent);
plus
At least 10 years of experience as a Software or Data Engineer or similar
position, including at least 5 years in a senior or higher-level position;

AND (or experience must include):

4+ years of hands-on design, development and operation of data solutions using
the following data technologies: Spark and Spark Streaming, Presto, Parquet,
MLﬂow, Kafka, and ETL tools such as Stitch or FiveTran;
4+ years of hands-on experience with design, development and maintenance of
structured, semi and non-structured (NoSQL) data stores, such as MySQL,
PostgreSQL, AWS Redshift, Teradata, Graph databases like Neo4j, and
Databricks Lakehouse;
4+ years of hands-on development and operation of workflows and jobs using
task orchestration engines such as Airﬂow, Argo, NextFlow, Dollar U and Tidal;
4+ years of hands-on experience building and operating data solutions on
operating systems such as Linux and Unix hosted in Amazon Web Services
(AWS) cloud;
5+ years of hands-on building and operation of scalable infrastructure to support
batch, micro-batch, and stream data processing for large volumes of data;
5+ years of hands-on experience designing and implementing enterprise data
warehouse/Lakehouse solutions to house business and technical datasets and
derive KPI dimensions for consumption;
Demonstrated experience with enterprise data modeling in healthcare and/or life
science sectors;
Demonstrated experience with the development and operation of visualization
and dashboards for business KPI reporting using tools such as Tableau or
Looker;
Proficiency in Python and PySpark;
Automation of Data Testing using scripting;
Experience developing and managing technical and administrative controls for
data governance and regulatory compliance in the healthcare and/or life sciences
sectors;
Experience mentoring and coaching junior data engineers; and
Cross-functional project management experience.

Travel: No travel is required.

Reports to: VP, Engineering
$180,000 - $240,000 a year",Unknown / Non-Applicable,Biotech & Pharmaceuticals,Company - Private,Pharmaceutical & Biotechnology
Principal Data Engineer,san-jose,"Safeway
3.2","Pleasanton, CA",3.2,Employer Provided Salary:$147K - $206K,3.0,2.9,2.8,3.0,2.9,10000+ Employees,1915,"About the company
Albertsons is one of the largest retail employers, providing approximately 300,000 jobs across 2,200 stores, 22 distribution centers, 20 food and beverage plants and various support offices. We operate in 34 states and the District of Columbia under the Albertsons banner, as well as Safeway, Tom Thumb, Jewel Osco, Shaw’s, and many more recognizable names. We hold a #1 or #2 position by market share in 68% of the 121 metropolitan statistical areas in which we operate.
What you will be doing
This role is within Inventory management team under Supply chain technology group. Our team strives to achieve adaptive, resilient, and efficient inventory flow with the help of modern technologies and data. Many thousands of items (SKUs) move through Albertsons’s vast supply chain network on daily basis, which makes this position both important and fascinating.
In this role, you are empowered to build large scale, high-performance data pipelines in a cloud environment that will be a game changer for the entire enterprise. You will have an opportunity to become proficient in supply chain data models at Albertsons and use that knowledge to make a direct and significant impact on business for many years to come. Your following traits will set you apart for this role.
You grasp the power of data to solve critical business problems
You effortlessly navigate through complexity and ambiguity of data and technical designs
You enthusiastically learn and weave the aspects of data engineering, data science, analytics, and visualization in your implementation
Key Responsibilities
Enable novel and transformative supply chain management capabilities that require processing of big data and integration from disparate sources
Help with project roadmap planning, provide realistic estimates, and identify risks
Technically lead engineering team to stay on project delivery milestones and assure quality output. Remove technical roadblocks, perform code reviews
Design and implement real time as well as batch (ETL, ELT) data pipelines using cloud-based services (Currently on GCP)
Design and develop large-scale data schemas and structures to optimally balance the usage, performance, and cost
Champion the understanding of Albertson’s supply chain data; support data science and application developers with data analysis and insights
Mentor and guide new or junior members of the team to ramp up and become productive
Help customer support team by troubleshooting and fixing issues post-deployment
Be the custodian of engineering backlog and promote the continuous improvement and maintenance of the current solution
*The salary range is $147,000 to $206,000 annually. Starting salary will vary based on criteria such as location, experience, and qualifications. There may be flexibility for exceptional candidates.*
Qualifications
BS in Computer Science or related field
6+ years of experience in the data engineering space, building, and deploying data pipelines.
Proficient in at least one programming language between Java and Python
Hands-on experience of GCP (Google Cloud Platform) or willingness to get GCP Certifications
Experience utilizing and integrating variety of data – structured, unstructured, or semi structured
Some experience with data warehousing tools (SnowFlake, BigQuery etc.) and the BI Visualization Tools (PowerBI, Looker, Tableau etc.)
Working knowledge of AI/ML and related tools/technologies is preferred
Hands on experience with data toolset like Apache Beam, Airflow, Kafka and Spark is ideal
Designing and developing Supply Chain and Inventory Management applications is a huge plus
Some experience developing RESTful APIs will come very handy
What it is like at Albertsons?
Albertsons Culture Principles
Compassion: We always treat each other with kindness and respect
Team: We always support and recognize each other
Inclusive: We always value everyone’s perspective
Learning: We always strive to grow and develop ourselves and others
Competitive: We always act with integrity to win over the customer
Ownership: We always take actions to drive our success",$10+ billion (USD),Grocery Stores,Company - Private,Retail & Wholesale
Staff Data Engineer,san-jose,"Safeway
3.2","Pleasanton, CA",3.2,Employer Provided Salary:$131K - $190K,3.0,2.9,2.8,3.0,2.9,10000+ Employees,1915,"About the company
Albertsons Companies is one of the largest food and drug retailers in the United States, with over 2,200 stores in 34 states and the District of Columbia. Our well-known banners include Albertsons, Safeway, Vons, Jewel-Osco, Shaw's, Acme, Tom Thumb, Randalls, United Supermarkets, Pavilions, Star Market, Haggen, Carrs, Kings Food Markets, and Balducci's Food Lovers Market. We support our stores with 22 distribution centers and 19 manufacturing plants.
Our 290,000 associates have a passion for great service and building lasting relationships with our customers. Through a companywide focus on innovation, we are continually enhancing our digital and product offerings, making it easy for customers to get what they need, wherever they are.
Main responsibilities
The Data and Analytics team at Albertsons inspires to build best in class customer experiences and revolutionize the food and drug retail industry. We are looking for people who are excited in re-imagining the grocery experience by harnessing the power of Data and AI. The team uses a decoupled and near real time data integration paradigm to make data available to improve store operations, digital ecommerce, merchandizing, supply chain, finance, etc. to proactively improve product lifecycle.
Design and develop secure, scalable, high-performance, reliable, and cost-effective data pipelines and platform in a multi-cloud environment.
Lead and mentor junior Data and Analytics engineers
Provide technical leadership in Data Engineering practices. Partner with architecture, Infosec, and engineering teams across the entire enterprise in delivering projects on time and with a high degree of quality.
Establish patterns for re-use, standards, and best practices for Data Engineering & Analytics such that data timeliness and quality are maximized.
Partner with the Audit, Compliance and Governance leaders to ensure data is secured and conforms to the guidelines laid out by the organization and the industry.
Partner with cross-functional teams to deliver large scale strategic projects as well as ongoing operational activities related to Big Data Platform. Interface with cross functional leaders and represent point of views to drive measurable success.
**The salary range is $131,100 to 190,400 annually. Starting salary will vary based on criteria such as location, experience, and qualifications. There may be flexibility for exceptional candidates.**
Required Qualifications
7+ years proven experience in developing and deploying data pipelines in Azure and/or GCP
5+ years of Snowflake, BigQuery and/or Databricks experience
5+ years proven experience in building frameworks for data ingestion, processing, and consumption.
4+ years of strong experience with SQL, Python, Java, API development
2+ years of proven expertise in creating real-time pipelines.
Building high quality data pipelines with monitoring and observability
2+ years of experience building dashboards and reports with PowerBI and/or Thoughtspot
Preferred Qualifications
Extensive experience in data transformations for Retail and e-commerce business use cases will be a plus
Bachelor’s or Master’s in computer engineering, computer science or related area.
Knowledge of Github Actions for CICD
Knowledge of building machine learning models
Albertson’s Culture
Compassion: We always treat each other with kindness and respect
Team: We always support and recognize each other
Inclusive: We always value everyone’s perspective
Learning: We always strive to grow and develop ourselves and others
Competitive: We always act with integrity to win over the customer
Ownership: We always take actions to drive our success",$10+ billion (USD),Grocery Stores,Company - Private,Retail & Wholesale
Software Engineer - Data and Evaluation,san-jose,"pony.ai
3.3","Fremont, CA",3.3,Employer Provided Salary:$120K - $160K,3.3,3.0,3.0,3.6,3.0,501 to 1000 Employees,2016,"Pony.ai, Inc. (“Pony.ai”) is a startup co-located in Silicon Valley and China that is pursuing an ambitious vision for autonomous mobility. We aim to bring safe, sustainable, and accessible mobility to the entire world. We believe that autonomous technology can make our roads exponentially safer for travelers. Founded in late 2016, Pony.ai has been a pioneer in autonomous mobility technologies and services across the U.S. and China, spearheading public-facing Robotaxi pilots in both markets. The company is currently valued at $8.5B and some of its major investors include Toyota, Ontario Teachers’ Pension Plan, Sequoia Capital China, and IDG Capital. Pony.ai has formed partnerships with leading OEMs including Toyota, GAC Group, FAW Group, etc. We believe our work has the potential to transform lives and industries for the better. You will have every opportunity to grow and develop as our company scales globally.

Responsibility

Design and implement tools and pipeline to handle data from autonomous vehicles including data labeling, batch processing, simulation, system and module evaluation
Setup and maintain monitoring for system metrics, latency and alerts.
Work closely with different autonomous driving components and dive deep into each component and design corresponding evaluation metrics and tools
Requirements
Strong programming skills in C/C++, Python, and software design
BS/MS or Ph.D. in Computer Science or a related field
Experience in large data set processing and familiarity with real time systems
Solid experience in a fast-paced and structured engineering environment
Full stack experience including both front end and back end is preferred
Statistics analysis experience is preferred
Start before June 2023


Compensation and Benefits
Base Salary Range: $120,000 - $160,000 Annually
Compensation may vary outside of this range depending on many factors, including the candidate’s qualifications, skills, competencies, experience, and location. Base pay is one part of the Total Compensation and this role may be eligible for bonuses/incentives and restricted stock units.
Also, we provide the following benefits to the eligible employees:
Health Care Plan (Medical, Dental & Vision)
Retirement Plan (Traditional and Roth 401k)
Life Insurance (Basic, Voluntary & AD&D)
Paid Time Off (Vacation & Public Holidays)
Family Leave (Maternity, Paternity)
Short Term & Long Term Disability
Free Food & Snacks",Unknown / Non-Applicable,Computer Hardware Development,Company - Private,Information Technology
Data Warehouse Engineer,san-jose,"Purple Drive Technologies
4.2","Cupertino, CA",4.2,Employer Provided Salary:$98K - $191K,3.9,4.0,4.0,3.7,4.2,1 to 50 Employees,Company - Private,"Terraform along with synapse Azure cloud
Deep expertise in Data Engineering and Data Warehousing (minimum 4+ years)
Azure synapse , Azure Data Factory , Spark Pool , SQL , SQL Pool (minimum 4+ yrs)
CI/CD and Python/Java programming experience (minimum 3+ years)
Ideal to have a 24 x 7 development i.e offshore presence or different time zones
Job Type: Full-time
Salary: $97,654.83 - $190,994.11 per year
Ability to commute/relocate:
Cupertino, CA: Reliably commute or planning to relocate before starting work (Required)
Experience:
Data modeling: 1 year (Preferred)
Work Location: One location",-1,-1,Unknown / Non-Applicable,-1
"Staff Software Engineer, Infrastructure, Google Cloud Data Management",san-jose,"Google
4.4","Sunnyvale, CA",4.4,-1,-1,-1,-1,-1,-1,10000+ Employees,1998,"Note: Google’s hybrid workplace includes remote and in-office roles. By applying to this position you will have an opportunity to share your preferred working location from the following:

In-office locations: Kirkland, WA, USA; Sunnyvale, CA, USA.
Remote location(s): United States.
Minimum qualifications:
Bachelor's degree or equivalent practical experience.
8 years of experience in software development, and with data structures/algorithms.
5 years of experience testing, and launching software products, and 3 years of experience with software design and architecture.
5 years of experience building and developing large-scale infrastructure, distributed systems or networks, and/or experience with compute technologies, storage, and/or hardware architecture.


Preferred qualifications:
Master’s degree or PhD in Engineering, Computer Science, or a related technical field.
3 years of experience in a technical leadership role leading project teams and setting technical direction.
3 years of experience working in a complex, matrixed organization involving cross-functional, and/or cross-business projects.
About the job
Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward.
With your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance software solutions.

Google Cloud accelerates organizations’ ability to digitally transform their business with the best infrastructure, platform, industry solutions and expertise. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology – all on the cleanest cloud in the industry. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems.
Salary Range Info:
The US base salary range for this full-time position is $185,000-$283,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.
Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.

Responsibilities
Provide technical leadership on high-impact projects.
Influence and coach a distributed team of engineers.
Facilitate alignment and clarity across teams on goals, outcomes, and timelines.
Manage project priorities, deadlines, and deliverables.
Design, develop, test, deploy, maintain, and enhance large scale software solutions.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.",$10+ billion (USD),Internet & Web Services,Company - Public,Information Technology
Data Center Controls Systems Engineer,san-jose,"Google
4.4","Sunnyvale, CA",4.4,-1,-1,-1,-1,-1,-1,10000+ Employees,1998,"Minimum qualifications:
Master's degree in Engineering, Science, a related field or equivalent practical experience.
5 years of experience designing and implementing controls systems and dynamic modeling.
5 years of experience with Machine Learning and construction of algorithms.
Experience with programming in C, Python, MATLAB, or Shell.

Preferred qualifications:
PhD in Engineering, Science or a related field.
Experience with modeling/statistical software such as TensorFlow, Simulink, R, or Matlab Machine Learning Toolbox.
Experience with dynamic system analysis, feedback control systems (PID Control) and optical control.
Experience with digital signal processing and time-series analysis.
Experience with optimization, Linear Programming and Convex Optimization.
About the job
Our thirst for technology is a part of everything we do. The Data Center Engineering team takes the physical design of our data centers into the future. Our lab mirrors a research and development department - cutting-edge strategies are born, tested and tested again. Along with a team of great minds, you take on complex topics like how we use power or how to run state-of-the-art, environmentally-friendly facilities. You're a visionary who optimizes for efficiencies and never stops seeking improvements - even small changes that can make a huge impact. You generate ideas, communicate recommendations to senior-level executives and drive implementation alongside facilities technicians.
Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible.
The US base salary range for this full-time position is $114,000-$167,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.
Responsibilities
Research and develop new algorithms and methods for optimizing data center efficiency and performance.
Design, validate, and implement controls algorithms to handle electrical and mechanical stability.
Analyze and recommend approaches to handle dynamics of the electromechanical systems and their interactions within a data center.
Conduct empirical statistical analysis/modeling on relevant data for use in data center controls.
Collaborate with the Engineering team to implement proposed strategies and algorithms in our technology system. Develop Machine Learning algorithms for pattern recognition and Bayesian and non-linear systems.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.",$10+ billion (USD),Internet & Web Services,Company - Public,Information Technology
"Senior Data and Software Engineer, Generative AI Foundation Models",san-jose,"NVIDIA
4.6","Santa Clara, CA",4.6,Employer Provided Salary:$144K - $270K,4.4,4.6,4.4,4.5,4.2,10000+ Employees,1993,"We are now seeking a Senior Data/Software Engineer for Generative AI Foundation Model Research Productization:
Foundation models are changing how digital content is produced for various commercial applications, ranging from digital advertisement to visual art creation. NVIDIA Picasso is a foundry to help NVIDIA’s partners build cutting-edge generative foundation model products in the visual space to capture the business opportunity. To better help our partners, the NVIDIA Picasso product team is seeking multiple experienced engineers to help with data curation and processing for text2image, text2video, and text23d productization as well as building the demo apps.
What you'll be doing:
Working on data curation and processing for training generative foundation models.
Monitoring large-scale training jobs that use several hundred to thousand GPUs.
Building prototype demo apps to demonstrate the capabilities of the foundation models.
Designing, improving, and maintaining the generative ai production and research codebase.
Designing and implementing generative algorithms and tools to support production.
Aspiring the group members to maintain high software quality, test coverage, and documentation.
Coordinating and managing software development using standard software dev-ops patterns and tools.
Working closely with generative ai researchers in building visual foundation models.
Documenting the product design and specs.
What we need to see:
MS or Ph.D. degree in computer vision/computer graphics fields (or equivalent experience).
3+ years of work-related experience in software development.
Strong Python and C++ programming skills.
Expert in PyTorch
Time management and organization skills for coordinating multiple initiatives, priorities, and implementations of new algorithms into very complex projects.
Great communication skills
Ways to stand out from the crowd:
Experience in developing or using deep learning frameworks.
Experience in data curation and processing for building foundation models.
CUDA programming experience.
Experience implementing computer vision algorithms using deep neural networks, such as object detection, scene parsing, image segmentation, and image captioning.
Experience in computer graphics products.
Background in core computer science areas, e.g., algorithms, software design, UI design, computer graphics, and machine learning.
Experience developing a larger software project, preferably with a collaborative component.
NVIDIA is widely considered to be one of the technology world’s most desirable employers. We have some of the most forward-thinking and hardworking people in the world working for us. Are you a creative and autonomous engineer with a genuine passion for advancing the state of AI? If so, we want to hear from you!
The base salary range is $144,000 - $270,250. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
You will also be eligible for equity and
benefits
.
NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",$5 to $10 billion (USD),Computer Hardware Development,Company - Public,Information Technology
"Machine Learning Engineer, Risk Data Mining - USDS",san-jose,"TikTok
3.6","Mountain View, CA",3.6,Employer Provided Salary:$126K - $305K,3.4,3.4,3.1,3.6,3.0,1001 to 5000 Employees,2016,"Responsibilities
About TikTok
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About USDS
At TikTok, we're committed to a process of continuous innovation and improvement in our user experience and safety controls. We're proud to be able to serve a global community of more than a billion people who use TikTok to creatively express themselves and be entertained, and we're dedicated to giving them a platform that builds opportunity and fosters connection. We also take our responsibility to safeguard our community seriously, both in how we address potentially harmful content and how we protect against unauthorized access to user data.

U.S. Data Security (“USDS”) is a standalone department of TikTok in the U.S. This new security-first division was created to bring heightened focus and governance to our data protection policies and content assurance protocols to keep U.S. users safe. Our focus is on providing oversight and protection of the TikTok platform and user data in the U.S., so millions of Americans can continue turning to TikTok to learn something new, earn a living, express themselves creatively, or be entertained. The teams within USDS that deliver on this commitment daily span Trust & Safety, Security & Privacy, Engineering, User & Product Ops, Corporate Functions and more.

Responsibilities:
Build machine learning solutions to respond to and mitigate business risks in TikTok products/platforms. Such risks include and are not limited to abusive accounts, fake engagements, spammy redirection, scraping, fraud, etc.
Improve modeling infrastructures, labels, features and algorithms towards robustness, automation and generalization, reduce modeling and operational load on risk adversaries and new product/risk ramping-ups.
Uplevel risk machine learning excellence on privacy/compliance, interpretability, risk perception and analysis.
Qualifications
Master or above degree in computer science, statistics, or other relevant, machine-learning-heavy majors.
Solid engineering skills. Proficiency in at least two of: Linux, Hadoop, Hive, Spark, Storm.
Strong machine learning background. Proficiency or publications in modern machine learning theories and applications such as deep neural nets, transfer/multi-task learning, reinforcement learning, time series or graph unsupervised learning.
Ability to think critically, objectively, rationally. Reason and communicate in result-oriented, data-driven manner. High autonomy.
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or an accommodation, please reach out to us at usrc@tiktok.com.
Job Information
The base salary range for this position in the selected city is $126000 - $304704 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",Unknown / Non-Applicable,Internet & Web Services,Company - Private,Information Technology
Energy Fleet Data Engineer,san-jose,"Tesla
3.6","Palo Alto, CA",3.6,$97K - $151K (Glassdoor est.),3.7,3.3,3.1,3.7,2.9,10000+ Employees,2003,"What to Expect
The Tesla Energy Service Infrastructure and Analytics team is looking for a passionate and collaborative Analyst to join the team and leverage cutting-edge data and analytics to ensure the best customer experience and fleet availability across the Tesla Energy portfolio; Industrial, Residential, Supercharger, and Solar. In the Energy Service Engineering Fleet Analyst role, you will identify and help resolve fleet-wide performance, operation, and maintenance challenges across the growing fleet of energy products. This role is an integral part of the measurement and improvement of fleet health, and you will be responsible for building and sustaining information-dense dashboards that provide insight to drive action and the supporting infrastructure for these dashboards. The Senior Engineering Fleet Analyst’s primary role is to leverage incredible real-world performance and maintenance data to drive fleet-wide improvements by identifying trends and determining effective strategies to improve key fleet health metrics. This position is well suited for curious, inventive, and adventurous analysts who want to solve problems with data and aren’t afraid to venture into the unknown and untested when required. As part of the team, you will be enabled to work across the organization to solve problems and ensure the success of our products working alongside Industrial Energy, Residential Energy, and Solar Product and Service Engineering. Our world-class teams operate with a non-conventional philosophy of inter-disciplinary collaboration. Each member of the team is expected to challenge and to be challenged, to create, and to innovate. We’re tackling the world’s most difficult and important problems—and we wouldn’t succeed without our shared passion for making the world a better place.
What You’ll Do
Build and sustain various dashboards used to identify and quantify various issues and metrics across the Tesla Energy fleet of products. Work across the organization to restore underperforming sites and drive action.
Collect and analyze large sets of data using SQL, Python, Tableau, and other tools
Create visualizations and tools to provide insight, drive action, and support engineering work throughout the business
Define and validate software tools and initiatives to improve proactive monitoring tools and analysis tools provided to energy analysts and the network operations center
Conducts ad-hoc analysis to determine the impact of defined issues or initiatives using existing tools or prototype new tools that are scaled with the help of data analysts
Collaborates with other team members to build and maintain the automation for hardware and site health diagnostics, build and maintain databases, dashboards, and tools required for other team members to simplify or automate analysis, and build and maintain required automation infrastructure for customer-facing reports
What You’ll Bring
Bachelor’s degree in Engineering - Computer Science or Data Engineering with experience working with hardware, Electrical or Mechanical Engineering with experience working with Data. Related degrees with relevant and applicable experience are also considered.
Experience in creating information-dense dashboards that facilitate insight discovery and drive action.
Experience with Tableau or dashboarding tools, preferably with certifications
Experience using Python to interact with databases. The use of pandas is a strong plus.
Excellent written and verbal communication and presentation skills
Possess strong planning, scheduling, and project management skills with the ability to plan and work independently Preferred Qualifications
Experience working with renewable energy, batteries, power electronics, solar cells, and relevant performance tracking/monitoring analytics.
Experience working in a data analytics role monitoring a large fleet of products
Experience using Jira, Git, and other work management tools
Experience with SQL and distributed system optimization (Spark, Presto, Hive)
Preferred experience with an ETL framework (Airflow)",$1 to $5 billion (USD),Transportation Equipment Manufacturing,Company - Public,Manufacturing
"Senior Frontend Software Engineer, Global E-Commerce Data Intelligence",san-jose,"TikTok
3.6","Mountain View, CA",3.6,Employer Provided Salary:$187K - $280K,3.4,3.4,3.1,3.6,3.0,1001 to 5000 Employees,2016,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Mountain View, Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul, and Tokyo.

Why Join Us

At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

Global e-commerce is content e-commerce business with international short video product as the carrier. It is committed to becoming the first choice for users to discover and purchase good products at affordable prices. Global e-commerce business team hopes to provide users with more tailored, active and efficient consumption experience, enabling merchants to receive stable and reliable platform services in different scenarios such as live e-commerce, short video content e-commerce, so as to make more affordable and high-quality products sell easily and a better life within reach.

The data insights team is responsible for development of data analytics & data-empowered platform capabilities across global e-commerce. Our mission is to empower our users to leverage and extract actionable insights from data to maximize their potential and efficiency on the global e-commerce platform. In essence, we want to extract facts, attribute causes and predict the future from oceans of data; and our fundamental goals are to reflect business impact, leverage data to support key decisions by lowering decision making complexity and optimising decision making efficacy and efficiency.

Responsibilities:
Architect and develop efficient and highly reusable front-end systems that drive complex web applications for e-commerce products.
Code optimisation to improve scalability, reliability, security and performance of web applications.
Collaborate with product design, product management and software engineering teams to deliver best in class user experience.
Qualifications
B. Sc or higher degree in Computer Science or related fields from accredited and reputable institutions.
5+ years experience in frontend engineering, with demonstrable experience with JavaScript/HTML/CSS, React/Vue/Angular and packaging frameworks like Webpack/Rollup/BaBel/AST/Gulp. Qualified fresh graduates would also be considered.
Familiar with key concepts like functional and asynchronous programming, closures and types, layouts, specificity, animation, cross browser compatibility, data security and accessibility.
Good understanding of multi-tier application architecture and protocols, familiarity with product and software development lifecycle process.
Demonstrable experience in developing data visualisation or data insights web/mobile applications is advantageous
Even Better if:
Agile, quick self-learner, highly self-motivated with a strong sense of product ownership, and creative problem solver.
Deeply passionate about software coding/development and building great mobile/web applications.
Ability to lead independent research to solve complex technical problems.
Good collaborator and team player, comfortable working in a fast-moving, culturally diverse, and globally distributed team environment.
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to us at allen.chen@bytedance.com.
Job Information
The base salary range for this position in the selected city is $187040 - $280000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",Unknown / Non-Applicable,Internet & Web Services,Company - Private,Information Technology
Big Data Engineers,san-jose,"Sigma Data Systems
4.6","Sunnyvale, CA",4.6,$96K - $148K (Glassdoor est.),3.0,4.0,4.0,4.0,4.0,201 to 500 Employees,Company - Private,"Company Culture
Sigma is looking for talent, which believes in creating a difference. Sigma is always open to candidates passionate for playing with data and can understand the science behind it. It welcomes dynamic people who can break conventional methods.

Sigma believes in work-life balance. It provides time flexibility with 5 days working pattern to give our employees space and showcase their creativity.

Our Core Values
Innovation & Experience
We believe experience is necessary to deliver quality work, but along with the experience we believe in young new minds who can be innovative. We have a blend of all like-minded people.
Infrastructure
We provide our employees with a comfortable working space with a relaxing indoor games facility. We believe in a stress-free environment. Our employees enjoy their time being in office.
Integrity & Transparent culture
We have a very transparent and honest culture. Everyone has an equal opportunity to put their thoughts and ideas on the table. We have 360-degree reviews and appraisal processes.
Career Roadmap
We have a clear roadmap for each of our employees. By reviewing it, they can know their current status, and they can know what & how to plan for their next milestone. We believe in providing equal opportunity to every employee.

Are you up for the challenge?
If you believe Sigma is the right place for you, tell us about yourself and email your CV to career@sigmadatasys.com

We’re looking for strong Big Data Software Engineer having a passion for data, programming and visualization. The ideal candidate must have extensive experience in a fast-paced and innovative development environment.
Responsibilities:
Strong working experience in architecting data structures, writing scalable and efficient code.
Design and architect technical solutions for the business problems of large-scale projects.
You will be responsible for working with the cross-functional team, prioritize project requirements, manage development.
Follow coding standards and able to perform unit-testing.
Prior work experience in AWS and 3rd Party integration.
Ability to adapt latest technologies and implement the same on projects.
Skills And Qualifications:
Strong understanding of REST API development, ETL ( Extract Transform Load ), Data Logging and Warehousing.
Strong experience in client-side scripting, JavaScript frameworks like D3.js / React.js / Node.js / Vue.js / Angular.js and server-side framework like Java Spring Boot, Python etc.
Strong experience in Elastic Search ( ELK Stack ), Hadoop, Cassandra, Spark, Redis, MongoDB, DynamoDB etc will be an add-on.
Experience with various messaging systems, such as Kafka or RabbitMQ
Knowledge of code versioning tools, such as Git.
Strong Computer Science fundamentals in object-oriented design, data structures, algorithm design, problem solving and complexity analysis.
Qualifications / *Eligibility Criteria:
BE/B.Tech/MS in Computers / IT / EC.
HSC percentages : 65% +
No backlogs in engineering and academics
Mandatory Documents:
Passport size Photo
Resume
Photo ID Proof: Driving License, Aadhar Card & PAN Card
Mark-sheets of Engineering & HSC
Salary slips and bank statement with salary credit amount ( with company name )
Notes: Please carry photo copy of all documents.
Interview Process:
Document verification + HR interview — 30 minutes
Aptitude — 30 minutes
Technical interview — 40 minutes
Practical Task — 3-4 hours
Final Round — 30 minutes
Offer & documentation on selection — 1 hour",-1,-1,Unknown / Non-Applicable,-1
Big Data/Machine Learning Software Engineer,san-jose,"Nova Ltd.
4.5","Fremont, CA",4.5,$112K - $172K (Glassdoor est.),4.2,4.6,4.2,4.1,4.3,501 to 1000 Employees,1993,"The Data Analytics team at Nova is looking for a Big Data/Machine Learning Software Engineer to work with Data Scientists and other Software Engineers to gather requirements and implement solutions. For you, it is exciting to see your code interacting with algorithms and data to produce results via complex interactions in Big Data systems. In this role, you will work with Data Scientists to adapt new and existing Machine Learning algorithms to Big Data microservices and build functionality to access those via web-based user interfaces.
Nova Ltd. is a leading innovator and key provider of metrology solutions for advanced process control used in semiconductor manufacturing. Our products are used in-line by leading chip foundries as well as original equipment manufacturers. Nova’s technology serves critical sectors of patterning, thin film deposition, CMP and diffusion in leading logic and memory fabs worldwide. market.

About us:
Nova provides insights into process control in the world’s most technologically advanced industry. We employ physics, mathematics, algorithms, software and hardware expertise to redefine the limits of what is possible in semiconductor manufacturing.
We invite you to join our dreamers and winners and brilliant high- aimers who see impossible as the starting point to exciting challenges, and work together in multidisciplinary global teams to find answers.
We dive deep to extract unique insights and provide our customers and partners with crucial decision-making data. Each and every one of us helps redefine what people can achieve through technology.
Why Nova:
Fortune magazine chose Nova as one of the fastest growing companies in the world in 2019 and 2020
Great Place to Work-Certified™ 2022 & 2023
Opportunity to collaborate with the best in this field, our 1000+ employees love coming to work every day in our 12 offices across the globe and share their passion for technology and innovation

Requirements:
Self-starter and quick learner of new technologies and processes – we are using some technologies not easily found in current skill portfolios, so this is the most important requirement! If you are under-skilled in some of the other requirements below, evidence of your ability to learn quickly will be seriously considered. Example of technology needed to learn quickly is customization/extension of ElasticSearch-Logstash-Kibana (ELK) instances
5+ years of software development experience in Agile environment
5+ years of coding and development experience using Python 2/3, preferably using OO approach
1-2 years of Big Data deployment, monitoring and troubleshooting of microservices, and interactions with the following Big Data concepts:
Extract/Transform/Load workflows
Kafka or other message queues
Hive/Hadoop/Impala and Big Data data storage including NOSQL solutions
Big Data configuration and monitoring using a number of technologies
Extensive experience working in a multi-threaded environment
Experience working with SQL databases and/or Big Data datastores (HDFS, etc)
Exposure to web-based application development – optimally Dash (with Python), React or Angular to facilitate workflows and graphic visualization
Extra Spice:
Strong communication and problem-solving skills – possess the ability to translate business requirements into application code
Ability to take ownership of the complete software development cycle from requirements gathering to design to implementation
Team player who will work in a collaborative environment with users and the engineering team
Passionate about well-designed software that is modifiable, efficient, reliable and meets coding standards
Experience customizing/extending ElasticSearch-Logstash-Kibana (ELK) instances

Role Responsibilities:

What will you do as a Big Data Machine Learning Software Engineer?
Implement Machine Learning solutions that live on Big Data systems, with input and guidance from Data Scientists and the algorithms they develop to effect Machine Learning
Work as part of a Scrum team to analyze requirements, scope, estimate, implement, and test changes to meet these requirements in a Big Data system
Debug existing source code, analyze logs and fix bugs as needed
Work independently and collaboratively as needed
Take ownership of assigned tasks and finish in a timely manner
Continuously learn and improve skills
Apply significant attention to detail to ensure all tasks are carried out to the highest standard
What will make you succeed in the role?
Extensive experience in Python software development
Experience configuring, deploying, and monitoring micro services in a Big Data system
Experience with User Experience (UX) and implementation of python approaches to meet UX needs
Working knowledge of GIT
Working knowledge of JIRA
Test driven development
Database application development and data modeling techniques
Experience with Scrum/Agile",$100 to $500 million (USD),Machinery Manufacturing,Company - Public,Manufacturing
Sr. Software Engineer - Big Data,san-jose,"Workday
4.2","Pleasanton, CA",4.2,Employer Provided Salary:$149K - $264K,3.9,4.3,3.8,4.2,4.2,10000+ Employees,2005,"Your work days are brighter here.
At Workday, it all began with a conversation over breakfast. When our founders met at a sunny California diner, they came up with an idea to revolutionize the enterprise software market. And when we began to rise, one thing that really set us apart was our culture. A culture which was driven by our value of putting our people first. And ever since, the happiness, development, and contribution of every Workmate is central to who we are. Our Workmates believe a healthy employee-centric, collaborative culture is the essential mix of ingredients for success in business. That’s why we look after our people, communities and the planet while still being profitable. Feel encouraged to shine, however that manifests: you don’t need to hide who you are. You can feel the energy and the passion, it's what makes us unique. Inspired to make a brighter work day for all and transform with us to the next stage of our growth journey? Bring your brightest version of you and have a brighter work day here.
About the Team
Special Note: LinkedIn and other job boards' estimated pay range does NOT represent the pay range of Workday. Please contact a Workday Talent Acquisition team member to discuss the role and compensation.

The Data Platform and Observability team is based in Pleasanton, CA, Boston, MA and Dublin, Ireland. We enable real time insights across Workday’s platforms, infrastructure and applications. Our focus is on the development of a large scale distributed data platform to support critically important Workday applications.

The team provides software for collection, ingestion, storage & visualization of critical data assets. We handle 100s of terabytes of data in the form of billions of messages produced daily by Workday applications and underlying services. If you enjoy writing efficient software or tuning and scaling large distributed systems you will enjoy working with us.

Do you want to solve exciting challenges at substantial scale across private and public clouds for our 4000+ global customers? Do you want to work with premier engineers and facilitate the development of the next generation Observability & Data Platforms? If so, we should chat.
About the Role
Design, build and manage Workday’s multi-Petabyte scale Operational Data Lakehouse.
Work on all aspects of the Data Lakehouse - building and managing large hadoop clusters, Performance and Scaling aspects of ingestion and query services, Security(Authn/Authz)
Be responsible for all operational aspects of the Data Lakehouse - Monitoring, Logging & Alerting
Be responsible for HA/DR design and implementation
Evaluate/implement new open source and cloud native tools and technologies, as needed.
Voice support for the platform capabilities, standard methodologies and be an advocate for the modern data stack.
Participate in the on-call rotation supporting the data platform.
About You
Basic Qualifications:
Five (5) plus years of experience with the following:
Software development work in Java/Scala/Python/Go).
Apache Hadoop ecosystem - FileSystems, Security(authn/authz), Distributed query engines.
Spark (Stream & Batch Processing Implementations)
SQL on Hadoop technologies like Hive, Presto & Spark SQL
Performance optimization of analytics workloads - persistence(HDFS/object storage), storage formats(Parquet/ORC), compression, partitioning, Query layer optimization etc.
Bachelor’s Degree in Computer Science, or equivalent experience..
Other Qualifications:
Ability to deal with a high degree of ambiguity and handle things with autonomy.
Ability to prioritize multiple tasks in a fast-paced environment.
Strong written and verbal communication skills
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, veteran status, or disability status. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

Workday Pay Transparency Statement - United States
The annualized base salary ranges for the primary location and any additional locations in the United States (US) are listed below. Workday pay ranges vary based on work location. As a part of the total compensation package, this role may be eligible for the Workday Bonus Plan or a role-specific commission/bonus, as well as annual refresh stock grants. Recruiters can share more detail during the hiring process. Each candidate’s compensation offer will be based on multiple factors including, but not limited to, geography, experience, skills, job duties, and business need, among other things. For more information regarding Workday’s comprehensive benefits, please
click here
.

Primary Location: USA.CA.Pleasanton
Primary Location Base Pay Range: $176,000 - $264,000
Additional US Location(s) Base Pay Range: $148,800 - $264,000

Our Approach to Flexible Work

With Flex Work, we’re combining the best of both worlds: in-person time and remote. Our approach enables our teams to deepen connections, maintain a strong community, and do their best work. We know that flexibility can take shape in many ways, so rather than a number of required days in-office each week, we simply spend at least half (50%) of our time each quarter in the office or in the field with our customers, prospects, and partners (depending on role). This means you'll have the freedom to create a flexible schedule that caters to your business, team, and personal needs, while being intentional to make the most of time spent together. Those in our remote ""home office"" roles also have the opportunity to come together in our offices for important moments that matter.
Pursuant to applicable Fair Chance law, Workday will consider for employment qualified applicants with arrest and conviction records.
Workday is an Equal Opportunity Employer including individuals with disabilities and protected veterans.
Are you being referred to one of our roles? If so, ask your connection at Workday about our Employee Referral process!",$1 to $5 billion (USD),Enterprise Software & Network Solutions,Company - Public,Information Technology
Data Center Night Chief Engineer,san-jose,"Amazon Data Services, Inc.
3.8","Santa Clara, CA",3.8,Employer Provided Salary:$74K,3.8,3.7,3.4,3.9,3.3,10000+ Employees,1994,"Technical (Military/Trade School) training or degree in a relevant field (for example: electrical, mechanical).
5+ years of electrical or mechanical experience.
4+ years of data center or mission critical facilities (example: hospital, military facility, public safety facility, etc.) experience.
5+ years of experience MS Office Suite experience.

How would you like to be a part of Earth’s most customer-centric company? You would work with teams of front-line responders who support the operations of some of the world’s most powerful data centers. Our Data Center Engineering Operations team maintain and operate our critical infrastructure systems so that they are prepared to stand up against any situation.

AWS has the world’s largest cloud computing portfolio. As an Amazonian you will work in some of the most sophisticated, safe, and secure data centers in the world. Our Chief Engineers help keep them that way by working with the brightest minds from around the globe to help test and implement the newest technology and work practices to meet the demands of a changing market.

We have a passion for learning and evolving, it’s how we have helped define ourselves as leaders in the industry. Let’s work hard, have fun, and make history!

This position will work with the night teams to ensure training and drills are conducted and completed successfully, ensuring properly trained night staff.

Day in the Life of a Night Shift Chief Engineer
This is a Night Chief Engineer position.
Operate independently with limited direct management.
Act as an escalation point for all facilities-related issues.
Oversee operation and management of routine and emergency services on a variety of critical systems such as: switchgear, generators, UPS systems, power distribution equipment, chillers, cooling towers, computer room air handlers, building monitoring systems, etc.
Drive projects with moderate complexity.
Perform root cause analysis of equipment failures.
Provide training and guidance to Engineering Operations Technicians and responsible for working with Facility Manager (FM) to set team culture.
Responsible for drills that are building specific and identifying team/individual areas for improvement. Also responsible for working with FM to help improve on the identified weakness.
Create and deploy ensure compliance for new standard practices for Engineering Operations Technicians, and vendor support teams.
Establish building performance benchmarks, conduct analyses, and prepare reports on all aspects of the critical facility operations and maintenance.
Communicate complex technical information to a non-technical audience.
May assist in the design and build out of new facilities.
Work with IT managers and other business leaders to coordinate projects, manage capacity, and optimize plant safety, performance, reliability and efficiency.
Respond to out of hours emergency calls – second level escalation point for Data Center facilities related issues / failures.
Working outside of normal business hours for routine maintenance as required.
Some travel may be required.
Walk job sites in uneven terrain. Maintain balance and perform construction tasks while on a ladder.
Regularly lift and/or move up to 39 pounds independently and participate in group lifts for 40+ pounds.
Regularly walk, use hands and fingers, handle or touch, reach with hands and arms, stoop, kneel, crouch or crawl

4+ years of Data Center Engineering Experience.
Associates or Bachelor’s Degree.

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $73,900/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. Applicants should apply via our internal or external career site.",$10+ billion (USD),Internet & Web Services,Company - Public,Information Technology
Senior Data Engineer,san-jose,"Electric Hydrogen
5.0","San Carlos, CA",5.0,$123K - $164K (Glassdoor est.),4.8,4.8,4.8,4.6,4.2,51 to 200 Employees,2020,"Electric Hydrogen's mission is to make molecules to decarbonize our world! Our outstanding people are our most important asset and will allow us to deliver hydrogen from renewable electrolysis for heavy industry, at prices below fossil fuels.
We are searching for a Senior Data Engineer who will work on Electric Hydrogen's numerous test equipment and manufacturing lines.
You will be based in San Carlos, CA.[and can work on a hybrid basis], or Remote. You will report to a Staff Engineer on the Software Engineering team.
PRIMARY RESPONSIBILITIES
Ensure data availability to internal and external stakeholders from internal devices and deployed plants
Architect streaming pipelines, analysis triggers, and notifications
Work with data from industrial PLCs and other connected devices
Coalesce data from manufacturing and deployed plant data for use in analysis
Design data systems for machine learning applications
BASIC QUALIFICATIONS
Familiarity with industrial streaming protocols such as MQTT and Kafka
Familiarity with OPC servers, OPC UA, and PLC communication
8+ years working with data pipelines and industrial networks
PREFERRED QUALIFICATIONS
A 4-year engineering degree in a relevant domain (all candidates with suitable experience will be considered)
Knowledge of process historians (OSI PI, FactoryTalk Historian)
Experience with GCP cloud resources including pub/sub and triggers.
Experience working with time series data and time series databases
Knowledge of OSI PI ecosystem including asset framework
Experience with machine learning data pipelines
Compensation & Benefits
Electric Hydrogen has three compensation zones: the San Carlos Zone, the Natick Zone, and the National Zone. All employees are assigned to a compensation zone depending on their work location. Remote employees will be assigned a compensation zone once their work location is determined. This can be discussed with your recruiter.
Senior Data Engineer (P4):
San Carlos Zone
$157,000—$208,000 USD
Natick Zone
$133,000—$177,000 USD
National Zone
$119,000—$159,000 USD
Actual base salary offered to the hired applicant will be determined based on their work location, level, qualifications, job-related skills, as well as relevant education or training and experience.
Base salary is just one part of Electric Hydrogen's total rewards package. We feel strongly that our team should not have to worry about having quality healthcare. In addition to the base salary offered, the hired applicant may receive:
an equity grant
time off programs
a $75/month cell phone allowance
a 4% employer 401(k) match
100% fully paid premiums for employees and their families: medical, dental, vision, life insurance, short-term & long-term disability coverage
a discretionary bonus
Electric Hydrogen's benefits programs are subject to eligibility requirements.
COVID-19 vaccination required for all employees and contingent workers, unless a reasonable accommodation is approved. All prospective hires will be expected to provide proof of vaccination to attend an onsite interview or at their first day of employment.
About Electric Hydrogen
Electric Hydrogen is a team of the world's experts in scaling technologies for the post-carbon world, with a proven record in transforming the grid and transportation sectors. Backed by some of the world's top venture capital firms, we design and manufacture electrolytic hydrogen systems matched to renewable power sources to create green hydrogen by splitting water. We are building a cost-effective and transformative path between renewable energy and multiple large industrial sectors. Abundant and low-cost renewable energy sources will power the world, and Electric Hydrogen technology will use this energy to decarbonize industry through sustainable materials. We were founded in 2020 and are based in California and Massachusetts.
Electric Hydrogen is proud to be an equal opportunity employer. We are dedicated to building a diverse, inclusive, and authentic workplace for all to belong. We are aware that people from historically underrepresented groups are less likely to apply if they don't meet 100% of the job requirements. We are actively working on efforts to change this social norm. If you are excited about this role, we encourage you to apply!",Unknown / Non-Applicable,Energy & Utilities,Company - Private,"Energy, Mining & Utilities"
"Senior Staff Software Engineer, Data",san-jose,"Spotnana Technology
5.0","Palo Alto, CA",5.0,Employer Provided Salary:$230K,4.7,5.0,4.8,4.7,4.8,201 to 500 Employees,2020,"Are you ready for the best destination of your career?
Spotnana is modernizing the infrastructure of the $1.4 trillion travel industry in order to bring freedom, simplicity, and trust to travelers everywhere. With over $115M in funding from top tier investors, including ICONIQ and Madrona Venture Group, we are tackling the hardest problems the travel industry has to offer and we need your help.
Culture is always fluid. It evolves as a business grows, along with the people who drive it forward. We seek people who have different perspectives, but shared values. Before you embark on this journey, quickly check in on whether you are aligned with our company values:
Obsessed with Customer Needs: We earn the trust and loyalty of our customers by solving their problems.
Do the Impossible: We solve tough problems through innovation and are inspired by unprecedented challenges.
Build Globally, Serve Locally: We embrace a global mindset and celebrate diversity as we serve customers around the world.
Act Like Owners: We constantly find problems to solve. Decisions are not made in isolation. We work hard, work smart, and work together.
Constantly Change, Learn & Evolve: We flourish by adapting quickly to new challenges and by learning from everyone around us. Building something new is not always glamorous work. Roll up your sleeves, get your hands dirty, and evolve.
Respect Above All: We are humble and treat others with the same respect we desire for ourselves. Our work culture is a safe environment where everyone is open to feedback and new ideas.
How you'll make an impact
You will work with cross-functional teams of product managers, data scientists, engineers, and designers to shape the data infrastructure of our product and influence product decisions using data. We are looking for an experienced data engineer who is independent and collaborative, appreciates moving quickly, and can work on multiple product initiatives and connect the dots between them.
What you'll own
Be the primary driver to define and develop the requirements for our product data infrastructure including data collection, metrics creation, modeling, and reporting on product performance
Build high-performance scalable data warehouses and design data models for optimal storage and retrieval
Design, build, and launch efficient and reliable data pipelines to move and transform data
Define, compute, track, visualize, and continuously validate product metrics, leveraging analytics and business intelligence platforms
Collaborate with cross-functional teams to define problem statements, and goals and build analytical models and measurement frameworks to assess progress and make recommendations
Maximize efficiency in a constantly evolving environment where the process is fluid and creative solutions are the norm
Experience you'll bring with you
12+ years of experience in designing and implementing real-time pipelines
Experience in large implementations of Cloud Platforms - Hadoop, BigQuery, AWS, Snowflake
Advanced SQL, Python and knowledge of Java, Scala, C/C++ or comparable programming language
Ability to work with a variety of cloud data tools and technologies and recommend best tools for various needs
Advanced analytical and problem-solving skills, with familiarity/comfortability, using mixed methods and/or types of data (i.e. qualitative, quantitative, cross-sectional, longitudinal)
Be a self-starter, motivated by an interest in developing the best possible data-driven solutions
BS/MS in Computer Science, Mathematics, Statistics, or a relevant technical field

Let's talk compensation
Spotnana strives to offer fair, industry-competitive and equitable compensation. Our approach holistically assesses total compensation, including cash, company equity and comprehensive benefits. Our market-based compensation approach uses data from trusted third party compensation sources to set salary ranges that are thoughtful and consistent with the role, industry, company size, and internal equity of our team. Each employee is paid within the minimum and maximum of their position's compensation range based on their skills, experience, qualifications, and other job-related specifications.
The annual cash compensation for this role is: $230,000 USD
We care for the people who make everything possible - our benefits offerings include:
Equity in the form of stock options which provides partial ownership in the company so you can share in the success of the company as it grows
Pre-tax and ROTH 401(k) options via Fidelity with up to a 4% company match
Comprehensive benefit plans covering medical, dental, vision, life, and disability effective on your hire date. We cover 100% of your employee premiums and 85% of your eligible dependents
Pre-tax flexible spending account options for health, dependent care and commuter expenses
20 vacation days per year in additional to 10 company holidays, 4 company recharge/wellness days and an end of year company shutdown
Up to 26 weeks of Parental Leave
Monthly cell phone / internet stipend
Additional benefits including access to RocketLawyer's online legal platform, International Airlines Travel Agent Network (IATAN) membership, Pet Insurance through Fetch, Financial Wellness through Origin and SoFi, EAP through Mutual of Omaha, The Calm app through Kaiser, pre-tax parking/transit program and more.
We are committed to fostering a diverse, inclusive environment and to encourage these values in everyone on our team. We provide an environment of mutual respect where opportunities are available without regard to race, color, religion, sex, pregnancy (including childbirth, lactation and related medical conditions), national origin, age, physical and mental disability, marital status, sexual orientation, gender identity, gender expression, genetic information (including characteristics and testing), military and veteran status, and any other characteristic protected by applicable law. We believe that diversity and inclusion for people from all walks of life is key to our success as a company.",Unknown / Non-Applicable,Software Development,Company - Private,Information Technology
Distributed Data Systems - Staff Software Engineer,san-jose,"Databricks
4.5","Mountain View, CA",4.5,$133K - $190K (Glassdoor est.),4.5,4.5,4.4,4.4,3.9,1001 to 5000 Employees,2013,"At Databricks, we are obsessed with enabling data teams to solve the world's toughest problems, from security threat detection to cancer drug development. We do this by building and running the world's best data and AI infrastructure platform, so our customers can focus on the high value challenges that are central to their own missions.
Founded in 2013 by the original creators of Apache Spark, Databricks has grown from a tiny corner office in Berkeley, California to a global organization with over 1000 employees. Thousands of organizations, from small to Fortune 100, trust Databricks with their mission-critical workloads, making us one of the fastest growing SaaS companies in the world.
Our engineering teams build highly technical products that fulfill real, important needs in the world. We constantly push the boundaries of data and AI technology, while simultaneously operating with the resilience, security and scale that is critical to making customers successful on our platform.
We develop and operate one of the largest scale software platforms. The fleet consists of millions of virtual machines, generating terabytes of logs and processing exabytes of data per day. At our scale, we regularly observe cloud hardware, network, and operating system faults, and our software must gracefully shield our customers from any of the above.
Modern data analysis employs sophisticated methods such as machine learning that go well beyond the roll-up and drill-down capabilities of traditional SQL query engines. As a software engineer on the Runtime team at Databricks, you will be building the next generation distributed data storage and processing systems that can outperform specialized SQL query engines in relational query performance, yet provide the expressiveness and programming abstractions to support diverse workloads ranging from ETL to data science.
Below are some example projects:
Apache Spark: Develop the de facto open source standard framework for big data.
Data Plane Storage: Deliver reliable and high performance services and client libraries for storing and accessing humongous amount of data on cloud storage backends, e.g., AWS S3, Azure Blob Store.
Delta Lake: A storage management system that combines the scale and cost-efficiency of data lakes, the performance and reliability of a data warehouse, and the low latency of streaming. Its higher level abstractions and guarantees, including ACID transactions and time travel, drastically simplify the complexity of real-world data engineering architecture.
Delta Pipelines: It's difficult to manage even a single data engineering pipeline. The goal of the Delta Pipelines project is to make it simple and possible to orchestrate and operate tens of thousands of data pipelines. It provides a higher level abstraction for expressing data pipelines and enables customers to deploy, test & upgrade pipelines and eliminate operational burdens for managing and building high quality data pipelines.
Performance Engineering: Build the next generation query optimizer and execution engine that's fast, tuning free, scalable, and robust.
What we look for:
BS in Computer Science, related technical field or equivalent practical experience.
Optional: MS or PhD in databases, distributed systems.
Comfortable working towards a multi-year vision with incremental deliverables.
Driven by delivering customer value and impact.
5+ years of production level experience in either Java, Scala or C++.
Strong foundation in algorithms and data structures and their real-world use cases.
Experience with distributed systems, databases, and big data systems (Spark, Hadoop).
Benefits
Comprehensive health coverage including medical, dental, and vision
401(k) Plan
Equity awards
Flexible time off
Paid parental leave
Family Planning
Gym reimbursement
Annual personal development fund
Work headphones reimbursement
Employee Assistance Program (EAP)
Business travel accident insurance
About Databricks
Databricks is the data and AI company. More than 5,000 organizations worldwide — including Comcast, Condé Nast, H&M, and over 40% of the Fortune 500 — rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark™, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world's toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.
Our Commitment to Diversity and Inclusion
At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.
About Databricks
Databricks is the data and AI company. More than 9,000 organizations worldwide — including Comcast, Condé Nast, and over 50% of the Fortune 500 — rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark™, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world’s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.
Our Commitment to Diversity and Inclusion
At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.
Compliance
If access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.",Unknown / Non-Applicable,Computer Hardware Development,Company - Private,Information Technology
"Senior Data Scientist / Data Engineer, Drive Systems",san-jose,"Tesla
3.6","Palo Alto, CA",3.6,$132K - $189K (Glassdoor est.),3.7,3.3,3.1,3.7,2.9,10000+ Employees,2003,"What to Expect
The Drive Systems team is looking for an exceptionally talented and self-directed data scientist/data engineer to manage a large scope of data improvement projects across our production processes, validation tests, and field reliability failures. This role requires a well-rounded individual who can build, scale, and maintain data pipelines and warehousing systems and also analyze data to evaluate process health, sleuth problem areas, and drive and quantify improvements. The role will include creating and improving robust global databases and data quality standards, as well as developing scalable evaluation models and reporting systems. A strong candidate will be able to work with existing factory data and process engineering teams to build data solutions as well as drive focused investigations and improvement projects based on analysis of the data.
What You’ll Do
Define data standards and storage requirements and collaborate with IT to design efficiently structured storage solutions across a range of applications and users
Work with factory operations and field reliability teams to identify useful data sets and quantitative metrics across a range of processes and use cases and build visualizations and investigation tools
Develop and improve automated reporting and monitoring systems for key performance metrics and statistical process control
Perform exploratory analysis, correlation studies, design experiments, and analyze results to drive investigations and improvement projects
Define data formatting and fidelity requirements with suppliers and internal users, build data pipelines for structured and unstructured quality and process data, and move/transform data into structured database formats in automated pipelines to enable real-time analysis
What You’ll Bring
Bachelor’s degree or higher in quantitative discipline (Statistics, Data Analytics, Computer Science, Applied Mathematics, Physics, Engineering) or the equivalent in experience and evidence of exceptional ability
Minimum 4 years relevant working experience in analytical or quantitative roles
Proficiency in programming languages such as Python, R, SQL, C#, JavaScript, Golang
Proficiency in data visualization methods and tools such as Tableau, R Shiny, Dash, Plotly, etc.
Proficiency in software deployment/management tools such as Docker, Kubernetes, Kafka, Jenkins, GitHub
Strong working knowledge of relational and/or non-relational databases
Significant experience with real-world automation, high volume manufacturing, and process control
Strong working knowledge of physics and engineering principles, mathematics, and statistics
Exceptional organization and self-direction, collaboration skills, and ability to drive efficient execution across multiple projects and priorities",$1 to $5 billion (USD),Transportation Equipment Manufacturing,Company - Public,Manufacturing
Senior Software Engineer - Data Infrastructure,san-jose,"Applied Intuition
3.8","Mountain View, CA",3.8,Employer Provided Salary:$65K - $400K,4.4,4.2,4.1,3.9,3.0,51 to 200 Employees,2017,"About Applied
Autonomy is one of the leading technological advances of this century that will come to impact our lives. The work you'll do at Applied will meaningfully accelerate the efforts of the top autonomy teams in the world. At Applied, you will have a unique perspective on the development of cutting-edge technology while working with major players across the industry and the globe.
Applied Intuition provides software solutions to safely develop, test, and deploy autonomous vehicles at scale. The company's suite of simulation, validation, and drive log management software enables development teams to create thousands of scenarios in minutes, run simulations at scale, and verify and validate algorithms for production deployment. Headquartered in Silicon Valley with offices in Los Angeles, Detroit, Washington, D.C., Munich, Stockholm, Seoul, and Tokyo, Applied consists of software, robotics, and automotive experts with experiences from top global companies. Leading autonomy programs and 17 of the top 20 global OEMs use Applied's solutions to bring autonomy to market faster.
About the role
(We are hiring for all levels of experience.)
We are looking for a Senior Data Infrastructure Engineer who is excited about building products that wrangle autonomous vehicle (AV) data to supercharge our customers. You will drive the design and development of data infrastructure across our products and internal tools. At Applied, we encourage all engineers to take ownership over technical and product decisions, interact closely with users to collect feedback, and contribute to a thoughtful, dynamic team culture.
At Applied, you will:
Design powerful data pipelines that efficiently process large volumes of AV sensor and telemetry data
Enable product workflows that expose performant query interfaces and offer easy-to-use integration hooks
Build features to tune processing pipeline for fast data ingestion and indexing depending on customer's needs and workloads
Develop and deploy high-quality software using modern tooling and frameworks
Work with products and teams across Applied Intuition
Work with customers across the AV ecosystem to understand their needs and the innards of their data systems
We're looking for someone who has:
Experience with open source data processing frameworks (Spark, RabbitMQ, Kafka, etc.)
Experience with different data lakes or warehouses
Experience with containerization and other modern software development workflows
Ability to take initiative and ownership in a fast-paced environment
Nice to have:
Expertise with multiple modern programming languages (Python, C++, Go, etc.)
Prior work in enterprise software, including on-prem and/or cloud deployments
Prior work in either autonomy or simulation products
The salary range for this position is $65,000 USD to $400,000 USD annually. This salary range is an estimate, and the actual salary may vary based on the Company's compensation practices.
Don't meet every single requirement? If you're excited about this role but your past experience doesn't align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.
Applicants will be required to be fully vaccinated against COVID-19 upon commencing employment. Reasonable accommodations will be considered on a case-by-case basis for exemptions to this requirement in accordance with applicable federal and state law. Applicants should be aware that for external-facing roles that involve close contact with Company employees or other third parties on the Company's premises, accommodations that involve remaining unvaccinated against COVID-19 may not be deemed reasonable. The Company will engage in the interactive process on an individualized basis taking into account the particular position.
Applied Intuition is an equal opportunity employer and federal contractor or subcontractor. Consequently, the parties agree that, as applicable, they will abide by the requirements of 41 CFR 60-1.4(a), 41 CFR 60-300.5(a) and 41 CFR 60-741.5(a) and that these laws are incorporated herein by reference. These regulations prohibit discrimination against qualified individuals based on their status as protected veterans
or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. These regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status or disability. The parties also agree that, as applicable, they will abide by the requirements of Executive Order 13496 (29 CFR Part 471, Appendix A to Subpart A), relating to the notice of employee rights under federal labor laws.",Unknown / Non-Applicable,Enterprise Software & Network Solutions,Company - Private,Information Technology
Staff ML Engineer (Perception / Data),san-jose,"Acubed
4.0","Sunnyvale, CA",4.0,Employer Provided Salary:$160K - $220K,3.6,4.0,3.5,4.1,4.3,51 to 200 Employees,Company - Public,"WAYFINDER
Wayfinder is building scalable, certifiable autonomy systems to power the next generation of commercial aircraft. Our team of experts is driving the maturation of machine learning and other core technologies for autonomous flight; we are creating a reference architecture that includes hardware, software, and a data-driven development process to allow aircraft to perceive and react to their environment. Autonomous flight is transforming the transportation industry, and our team is at the heart of this revolution.
The Opportunity
As a Staff ML Engineer, you will lead the technical execution of our data and ML pipelines with an overall focus into improving the overall end to end perception pipeline (labeling, training and deployment).
This is a hands-on role, so you will be responsible for implementing things yourself, while also acting as a tech lead for the ML and Data engineering teams.
Responsibilities
Be an architect for our overall perception pipeline (training, testing, monitoring and labeling)
Explore, prototype and validate new algorithms/solutions
Be a mentor for other team members within the ML and Data teams
Champion highest quality of engineering excellence
Be able to move from research to productize ML models (fast iteration)
Negotiate initiatives and deliverables with stakeholders
Have deep understanding of the business and operational impact for different technology tradeoffs
Capable of influencing and building consensus in technical debates
Requirements
BS, MS, or higher degree, in CS/CE/EE, or equivalent industry experience
Extensive experience with ML frameworks such as Tensorflow, Caffe, and PyTorch
Strong programming skills in Python and C++
Growing expertise with state-of-the-art perception related ML models
Excellent mathematical reasoning skills, especially with probability
8+ years of experience in computer vision and machine learning
Expertise in setting architectures that are scalable, fault-tolerant and extensible for changes.
Ability to design across multiple systems
Ability to wear several hats between coding, technical strategy, mentorship etc.
Proven record of productizing computer vision models
Strongly Preferred Qualifications
PhD in computer science or machine learning
Experience with MCAP, OpenCV
Experience with CUDA
Real-world experience applying machine learning techniques in autonomous systems such as robots, cars, and UAV
Benefits
Exceptional PPO medical, dental and vision benefits with 100% of premiums covered for employee and their family/dependents
Generous PTO of 5 weeks (6 weeks after two years) in addition to 11 national holidays and unlimited paid sick days
Professional development reimbursement or $15,750 for flight training
3 months paid parental leave from Day 1
Pay Transparency Notice: Depending on your work location and years of experience, the target annual salary for this position can range from $160,000 to $220,000 + target bonus + benefits (including medical, dental, vision, 401(k), and flight training).
Note that Acubed does not offer sponsorship of employment-based nonimmigrant visa petitions for this role.",-1,Aerospace & Defense,Aerospace & Defense,Less than $1 million (USD)
Data Engineer/Data Warehouse Engineer,san-jose,"ProIT Inc.
4.9","Cupertino, CA",4.9,Employer Provided Salary:$110K - $130K,4.8,4.6,4.9,4.6,4.6,51 to 200 Employees,Company - Private,"Level II – 3 – 5 years’ experience
( Skills needed :
i) Deep expertise in Data Engineering and Data Warehousing (minimum 4+ years)
ii) Azure synapse , Azure Data Factory , Spark Pool , SQL , SQL Pool (minimum 4+ yrs)
iii) CI/CD and Python/Java programming experience (minimum 3+ years)
iv) Ideal to have a 24 x 7 development i.e offshore presence or different time zones )
Job Type: Full-time
Pay: $110,409.45 - $130,417.83 per year
Benefits:
401(k)
Dental insurance
Health insurance
Paid time off
Vision insurance
Schedule:
8 hour shift
Monday to Friday
Ability to commute/relocate:
Cupertino, CA 95014: Reliably commute or planning to relocate before starting work (Required)
Work Location: Hybrid remote in Cupertino, CA 95014",-1,-1,Unknown / Non-Applicable,-1
Data Center Controls Engineer,san-jose,"Amazon Data Services, Inc.
3.8","Hayward, CA",3.8,Employer Provided Salary:$111K,3.8,3.7,3.4,3.9,3.3,10000+ Employees,1994,"Basic Qualifications

1. B.S. in Electrical, Mechanical or other related engineering degrees as well as 7 years Controls related experience; or Associates degree and 9 years of Controls related experience; or High School diploma with 12 years of Controls related experience.
2. 7+ Years of experience with industrial controls in critical environment (data center, pharmaceutical, manufacturing, oil & gas, petrochemical, laboratory, power, water etc.).

AWS Data centers have multiple components such as generators, uninterruptable power sources, diesel generators, electrical switchgear, power distribution units, variable frequency drives, automatic/static transfer switches, chillers [air-cooled and water-cooled], pumps, cooling towers, heat exchangers, CRAHs, air economizers, etc. All these components have local control systems that interact with each other via open and/or proprietary communications protocols. The building management system (BMS) is the primary method of control of all mechanical systems within a data center. The electrical power monitoring system (EPMS) is the primary method of monitoring all electrical systems within a data center. As part of the global controls team, you will work with highly motivated experts and innovators in the data center industry. You will be responsible for innovating, deploying, optimizing, and maintaining the BMS and EPMS. Using Amazon leadership principles, you will develop new processes and standards while innovating in the controls space. As a Controls Engineer you will: • Troubleshoot and perform Root Cause Analysis (RCA) or Corrective Action (CA) for Control Systems for AWS data centers. • Possess, understand and apply controls fundamental concepts, practices and procedures to manage scope of Building Management System (BMS) and Electrical Power Monitoring System (EPMS) in operational AWS Data Centers. • Train and assist internal customers and stakeholders with the creation, design, configuration, validation, installation, commissioning and operation of BMS and EPMS systems. • Provide technical assistance and support to internal customers during life cycle of the data center. • Complete and implement assigned work within agreed upon scope, schedule and budget to a high level of quality and safety. • Review controls sequence of operation and provide feedback for construction of AWS data centers. • Schedule and supervise Quarterly maintenances for BMS and EPMS. • Provide vendor management. • Participate in AWS global on-call schedule to provide immediate BMS and EPMS • Technical support to in-service data centers. • Attend project related meetings, coordinate with project leaders and regularly report status to Controls Management. • Review and provide feedback on mechanical, electrical, and plumbing (MEP) drawings. • Develop controls bill of material (BOM). • Develop and modify controls logic programming. • Develop and modify graphical user interface. • Grow in technical ability by learning a multitude of different automation platforms. • Develop scope of work for site improvement projects. • Manage and work under tight project timelines. • Manage multiple stakeholder deliverables, requirements and navigate difficult situations. • Financially manage BMS and EPMS service contracts. • Frequently visit (locally) assigned in-operation data centers to supervise vendor’s work to ensure compliance with the design, sequence of operations (SOO) and applicable local codes.
Preferred Qualifications

Master’s Degree (MS) with six years of relevant controls or data center mechanical/electrical work experience.
Knowledge computer networking and HVAC and/or electrical power distribution systems.
Proven track record for cultivating strong relationships with internal stakeholders, vendors, or customers
Excellent communication skills, teamwork, organizational and problem-solving skills.
Experience with automation controls in data centers or other critical facilities.
TCP/IP, BACnet and/or MODBUS communication protocol experience.

Why AWS?
About AWS
Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud
platform. We pioneered cloud computing and never stopped innovating — that’s why customers
from the most successful startups to Global 500 companies trust our robust suite of products and
services to power their businesses.

Inclusive Team Culture
Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster
a culture of inclusion that empower us to celebrate our differences. Ongoing events and learning
experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender
diversity) conferences, inspire us to never stop embracing our uniqueness.

Work/Life Balance
We value work-life harmony. Achieving success at work should never come at the expense of
sacrifices at home, which is why flexible work hours and arrangements are part of our culture.
When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the
cloud.

Mentorship & Career Growth
We have a career path for you no matter what stage you’re in when you start here. We’re continuously raising our performance bar as we strive to become Earth’s Best Employer.
That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing
resources here to help you develop into a better-rounded professional.

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $111,400/year in our lowest geographic market up to $239,300/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.",$10+ billion (USD),Internet & Web Services,Company - Public,Information Technology
Data Center Mechanical Commissioning Engineer II,san-jose,"CAI
4.1","Santa Clara, CA",4.1,Employer Provided Salary:$90K - $115K,4.2,4.0,3.9,4.0,3.4,501 to 1000 Employees,1996,"Position Description:
This position supports development and execution of all mechanical aspects of assigned commissioning projects from initial engagement, design reviews, checklists, safety support, script development, vendor coordination, testing and report development through turn over to the client. The Mechanical Commissioning Engineer will support the development of the mechanical test schedule, finalize mechanical test procedures, review project submittals for consistency with the design intent, basis of design and the owner’s project requirements, and maintain project cadence for the mechanical systems testing and associated Building Automation Systems. The Mechanical Commissioning Engineer is to support the planning and execution of commissioning for the mechanical infrastructure of the mission critical facility. They will be expected to execute against the project schedule through the coordination of contractors and/or vendors to complete the desired mechanical systems testing.
CAI DC Mechanical Commissioning Engineer will be exposed to cutting edge technologies in the Hyperscale and other spaces. You will have an opportunity to work with recognized subject matter experts allowing YOU to be a key player in bringing data technologies to market. As part of our company culture, we invest in YOUR future, and commit to hands on certifications as well as professional training. Our collaborative culture ensures that our customers benefit from exemplary work across our entire range of professional services.

Responsibilities:
Support and contribute to all aspects of safety for all mechanical tests.
Support complete commissioning and performance acceptance testing of the mechanical infrastructure systems.
Development of all mechanical test procedures, MOPS, SOO’s and checklists.
QA/QC of all mechanical test procedures.
Provide input and insight to the overall commissioning plan.
Develop reports for the mechanical testing and contribute to a daily report to the Commissioning Project Manager.
Attend and be an active participant of customer equipment Factory Witness Test
Assist with vendor coordination and management.
Perform equipment inspection to ensure build adherence to vendor submittal.
Provide test documentation that equipment is delivered, installed, and tested correctly and set to function properly for the customer.
Support and perform design specification review, manufacturer submittals, one line drawing sets, and project schedule documentation.
QA/QC of mechanical equipment installation\startup
Execute test scripts to confirm equipment and system operation to design specification.
Ensure safe work practices are followed by the commissioning team and customer site.
Engage with customers and vendors to ensure positive experience, goals achievement, and schedule adherence.
Provide daily status reports for mechanical commissioning team status.
Conduct facility walk downs, turnover, and punch list reviews.
General understanding of LEED specifications and requirements.
Look for new opportunities for CAI to provide service and value to customer.
Duties may be increased as experience and skill allow.

Requirements include:
Position Requirements:
Bachelor’s degree or equivalent experience
Minimum of 2 years Data Center Commissioning experience.
Knowledge of OSHA safety requirements.
Good written and verbal communication skills.
Ability to read and interpret mechanical drawings, P&ID’s and specifications.
Knowledge of mission critical design concepts.
Knowledge of various Building Automation/Monitoring Systems (BAS/BMS), Air Handlers, Humidifiers, Variable Refrigerant Flow, Computer Room Air Conditioners/Handlers (CRAC/CRAH), Evaporators, Adiabatic Coolers, Pressure/Temperature/Humidity sensors & Flowmeters.
Knowledge of basic thermodynamics and heat transfer and fluid flow.
Knowledge of the Test, Adjust and Balance (TAB) process.
Knowledge of mechanical trend analysis.
Strong experience with Word, Excel and PowerPoint. Can effectively create final products in all three programs.
Work under construction site conditions

Other Requirements:
Excellent oral and written English is required
Extensive travel may be required (75%)
Candidates must have a Passport or the ability to immediately get a Passport
Able to work in the US without sponsorship now or any time in the future.

About CAI
CAI is a 100% employee-owned company established in 1996, that has grown year over year to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and consulting services related to operational readiness to FDA regulated and other mission critical industries.

Meeting a Higher Standard
Our approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.
As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:
We act with integrity
We serve each other
We serve society
We work for our future

With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a can-do attitude. That is how we have grown exponentially.

Benefits
Our full-time positions offer competitive compensation and benefits which include: up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.
#LI-MR1
Average salary range.
We are an equal opportunity employer; we are proud to employ veterans and promote a diverse culture in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.
This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the FCO.",$25 to $100 million (USD),Architectural & Engineering Services,Company - Private,"Construction, Repair & Maintenance Services"
Data Engineer - CDW,san-jose,"California State University
4.2","San Jose, CA",4.2,Employer Provided Salary:$10K,3.7,4.2,4.0,3.6,4.3,10000+ Employees,1962,"Job no: 514379
Work type: Staff
Location: San José
Categories: Unit 9 - CSUEU - Technical Support Services, Probationary, Full Time, Information Systems & Technology
Job Summary
Reporting to the Interim Associate Chief Information Officer and Senior Director of Enterprise Solutions, the Data Engineer – Campus Data Warehouse (CDW) is responsible for SJSU’s Campus Data Warehousing/Business Intelligence implementation. This position will play an important role in the research, design, architecture, creation, development, implementation, and maintenance of Campus Data Warehouse. This includes identifying and pulling data from 500+ individual databases across SJSU and curating them into a single data source in order to facilitate data-driven decisions. Assist in conducting technical reviews, creating definitions of business problems, including the preparation of business/technical requirements to support the mission of the university and administrative departments, providing systems and technical support of vendor and locally developed software, and work with the Data Warehouse Project Manager, SJSU IT Enterprise Solutions resources, external vendors, and IT team members. Duties and system assignments can be temporarily or permanently changed to meet the needs and goals of the department and university.

Key Responsibilities
Develop and maintain ETL processes to populate the data warehouse
Build and maintain Google BigQuery data warehouse interfaces to house data from various sources such as Oracle, MySQL, and Web APIs, etc.
Building and maintaining production data pipelines for data analytics
Partner cohesively with campus stakeholders to align with their strategic goals and initiatives through the implementation of Campus Data Warehouse
Collaborate with key analytical vendors who can provide specialized expertise to assist with solution development while developing the in-house effort and managing CO interface
Follow project plans, timelines, and vendor relationships to ensure releases are delivered with the highest quality, on-time and within budget
Provide the data analytics infrastructure that supports and achieves operational organization goals and targets
Apply performance tuning techniques to existing and new ETL scripts and analytical reports
Develop efficient database manipulation code to ensure reliable and consistent result sets
Develop appropriate and reusable data validation scripts to ensure the analytical dashboards are meeting the business requirements
Assist the development team in performing the troubleshooting of Campus Data Warehouse components as identified by the Business groups
Develop and deploy ad-hoc query extracts from Campus Data Warehouse as desired by the Business groups
Participate in overall analytics architecture and application roadmap.
Assist in the improvement of organization performance by utilizing not only the data already available to the organization, but also utilizing new and innovative sources of data
Develop custom reports as necessary using visualization tools such as Google Data Studio, Tableau and other visualization tools
Identify, interpret, analyze and address critical business issues, questions and to develop use cases.
Organizing and creating an environment that makes data and information accessible with appropriate channels of access controls.

Knowledge, Skills & Abilities
Intermediate skills in a Data Engineer role
Knowledge of Google Cloud Platform components including but not limited to Composer, Airflow, Dataproc, Sqoop, Cloud Storage, and BigQuery
Advanced knowledge in high level programming languages like: Python, SQL, Java, and JavaScript
Advanced knowledge of application development, testing and deployment processes and tools
Knowledge of data visualizations tools like Tableau, Google Data Studio, or equivalent experience
Knowledge and skills working with large data sets
Solid knowledge of ETL, ELT, reporting and analytics tools and environments
Ability to strategically think and build a Data Warehouse to answer important questions across a variety of functional areas
Ability to collaborate with business stakeholders and IT management to understand solution requirements and system design
Strong interpersonal, communication, organization and planning skills
Proficiency in management of multiple priorities to produce quality products for customers

Required Qualifications
A bachelor’s degree, preferably in computer science or business, or equivalent training and applied experience
5+ years of experience in business applications analysis, design, and programming for medium or large scale, multi-programmed computers

Preferred Qualifications
3+ years’ experience developing, maintaining and collecting structured and unstructured data sets for analysis and reporting
3+ years of working experience in implementing cloud-based architecture (i.e. Google Cloud Platform or similar)

Compensation
Classification: Analyst/Programmer-Expert
Anticipated Hiring Range: $9,640/month - $9,834/month
CSU Hiring Range: $6,249/month - $12,100/month

San José State University offers employees a comprehensive benefits package typically worth 30-35% of your base salary. For more information on programs available, please see the Employee Benefits Summary.

Application Procedure
Click to complete the SJSU Online Employment Application and attach the following documents:
Resume
Letter of Interest
All applicants must apply within the specified application period: June 9, 2022 through June 26, 2022. This position is open until filled; however, applications received after screening has begun will be considered at the discretion of the university.

Contact Information
University Personnel
jobs@sjsu.edu
408-924-2252

CSU Vaccination Policy
The CSU requires faculty, staff, and students who are accessing campus facilities to be fully vaccinated against the COVID-19 virus (including all booster doses of an approved vaccine for which an individual is eligible per current CDC recommendations) or declare a medical or religious exemption from doing so. As a condition of employment, any candidates advanced in a currently open search process should be prepared to comply with this requirement as well as with other safety measures established on the campus. The system wide policy can be found at https://calstate.policystat.com/policy/9779821/latest/ and questions may be sent to jobs@sjsu.edu.

Additional Information
Satisfactory completion of a background check (including a criminal records check) is required for employment. SJSU will issue a contingent offer of employment to the selected candidate, which may be rescinded if the background check reveals disqualifying information, and/or it is discovered that the candidate knowingly withheld or falsified information. Failure to satisfactorily complete the background check may affect the continued employment of a current CSU employee who was offered the position on a contingent basis.

The standard background check includes: criminal check, employment and education verification. Depending on the position, a motor vehicle and/or credit check may be required. All background checks are conducted through the university's third party vendor, Accurate Background. Some positions may also require fingerprinting. SJSU will pay all costs associated with this procedure. Evidence of required degree(s) or certification(s) will be required at time of hire.

SJSU IS NOT A SPONSORING AGENCY FOR STAFF OR MANAGEMENT POSITIONS. (e.g. H1-B VISAS)

All San José State University employees are considered mandated reporters under the California Child Abuse and Neglect Reporting Act and are required to comply with the requirements set forth in CSU Executive Order 1083 as a condition of employment.

Jeanne Clery Disclosure of Campus Security Policy and Crime Statistics Act and Campus Housing Fire Safety Notification:
Pursuant to the Jeanne Clery Disclosure of Campus Security Policy and Campus Crime Statistics Act, the Annual Security Report (ASR) is also now available for viewing at https://www.sjsu.edu/clery/docs/SJSU-Annual-Security-Report.pdf. The ASR contains the current security and safety-related policy statements, emergency preparedness and evacuation information, crime prevention and Sexual Assault prevention information, and information about drug and alcohol prevention programming. The ASR also contains statistics of Clery crimes for San José State University locations for the three most recent calendar years. A paper copy of the ASR is available upon request by contacting the Office of the Clery Director by phone at 408-924-1501 or by email at clerycompliance@sjsu.edu.
Pursuant to the Higher Education Opportunity Act, the Annual Fire Safety Report (AFSR) is also available for viewing at https://www.sjsu.edu/clery/docs/SJSU-Annual-Fire-Safety-Report.pdf. The purpose of this report is to disclose statistics for fires that occurred within SJSU on-campus housing facilities for the three most recent calendar years, and to distribute fire safety policies and procedures intended to promote safety on Campus. A paper copy of the AFSR is available upon request by contacting the Housing Office by phone at 408-795-5600 or by email at uhs-frontdesk@sjsu.edu.

Equal Employment Statement
San José State University (SJSU) is an Equal Opportunity/Affirmative Action employer committed to nondiscrimination on the basis of age, ancestry, citizenship status, color, creed, disability, ethnicity, gender, genetic information, marital status, medical condition, national origin, race, religion or lack thereof, sex, sexual orientation, transgender, or protected veteran status consistent with applicable federal and state laws. This policy applies to all SJSU students, faculty and staff programs and activities. Title IX of the Education Amendments of 1972, and certain other federal and state laws, prohibit discrimination on the basis of sex in all education programs and activities operated by the university (both on and off campus).

Advertised: June 09, 2022 (9:00 AM) Pacific Daylight Time
Applications close:",$10+ billion (USD),Colleges & Universities,College / University,Education
Lead Data Engineer/Architect,san-jose,"Synopsys
4.1","Mountain View, CA",4.1,Employer Provided Salary:$111K - $194K,3.9,4.1,3.8,3.8,4.0,10000+ Employees,Company - Public,"43939BR
USA - California - Mountain View/Sunnyvale
Job Description and Requirements
Responsibilities
In this hands-on role and as a key member of the Business Applications team, the Data Engineer will help build the analytics infrastructure for our Enterprise Data Platform.
Leads, architects and develops data models/structures, transformations, data pipelines and insights to enable data-driven decision-making.
Works with the team to shape the design and direction of the platform
Works end-to-end on data products: from understanding the problem to designing and developing data pipelines (ELT/ETL), dimensional data models and visualizations
Provides support and advice to business users including data preparation for predictive and prescriptive modeling.
Ensure consistency of process and usage and champion best practices in data management.
Evaluates and recommend new data tools or processes
Responsible for analysis, design, configuration, development, testing and documentation for new projects, enhancements, and ongoing production support in various enterprise applications.
Provides day-to-day production support to internal business unit customers, working with business users to evaluate and implement enhancement and defect resolution.
Requirements
BS with 7+ years of relevant experience or MS with 5+ years of relevant experience. (Education degree in Computer Science, Mathematics, Engineering, or MIS).
5 years of experience in the functional & technical areas of working with business and key stakeholders in DW/BI development, reporting and analytics roles.
Advanced knowledge of Data Warehousing, SQL, ETL/ELT, dimensional modeling, databases (MySQL, Postgres, HANA, etc.) and business intelligence.
2+ years of hands-on development experience with modern data stack tools: Cloud data warehouses (Snowflake), Transformation tools (dbt), CI/CD and Cloud providers (Azure, AWS, etc).
Knowledge of data ingestion (e.g., Fivetran, HV-R, etc.) and orchestration (e.g., Airflow) tools is a plus
Able to develop custom BI products that require knowledge of scripting languages like Python for data extraction/exploration
Ability to understand business requirements in BI context and design data models to transform raw data into meaningful insights.
Understanding of data governance, data integrity, data quality design, development, and deployment best practices
Experience with agile development methodologies and change control processes.
Experience in writing both functional and technical documentation is required.
Excellent methodical problem-solving skills and a motivated team player with excellent interpersonal skills.
Passionate about data, technology and learning.
Good organizational & communication skills and ability to work effectively in a global, diverse team or autonomously as required.

At Synopsys, we’re at the heart of the innovations that change the way we work and play. Self-driving cars. Artificial Intelligence. The cloud. 5G. The Internet of Things. These breakthroughs are ushering in the Era of Smart Everything. And we’re powering it all with the world’s most advanced technologies for chip design and software security. If you share our passion for innovation, we want to meet you.
Stay Connected: Join our Talent Community

Inclusion and Diversity are important to us. Synopsys considers all applicants for employment without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, military veteran status, or disability.

The base salary range across the U.S. for this role is between $111,000-$194,000. In addition, this role may be eligible for an annual bonus, equity, and other discretionary bonuses. Synopsys offers comprehensive health, wellness, and financial benefits as part of a of a competitive total rewards package. The actual compensation offered will be based on a number of job-related factors, including location, skills, experience, and education. Your recruiter can share more specific details on the total rewards package upon request.

#LI-DNI

Job Category
Engineering
Country
United States
Job Subcategory
Software Engineering
Hire Type
Employee
Base Salary Range
$111,000-$194,000",-1,Information Technology,Computer Hardware Development,$1 to $5 billion (USD)
"Machine Learning Engineer, Risk Data Mining - USDS",san-jose,"TikTok
3.6","Mountain View, CA",3.6,Employer Provided Salary:$126K - $305K,3.4,3.4,3.1,3.6,3.0,1001 to 5000 Employees,2016,"Responsibilities
About TikTok
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About USDS
At TikTok, we're committed to a process of continuous innovation and improvement in our user experience and safety controls. We're proud to be able to serve a global community of more than a billion people who use TikTok to creatively express themselves and be entertained, and we're dedicated to giving them a platform that builds opportunity and fosters connection. We also take our responsibility to safeguard our community seriously, both in how we address potentially harmful content and how we protect against unauthorized access to user data.

U.S. Data Security (“USDS”) is a standalone department of TikTok in the U.S. This new security-first division was created to bring heightened focus and governance to our data protection policies and content assurance protocols to keep U.S. users safe. Our focus is on providing oversight and protection of the TikTok platform and user data in the U.S., so millions of Americans can continue turning to TikTok to learn something new, earn a living, express themselves creatively, or be entertained. The teams within USDS that deliver on this commitment daily span Trust & Safety, Security & Privacy, Engineering, User & Product Ops, Corporate Functions and more.

Responsibilities:
Build machine learning solutions to respond to and mitigate business risks in TikTok products/platforms. Such risks include and are not limited to abusive accounts, fake engagements, spammy redirection, scraping, fraud, etc.
Improve modeling infrastructures, labels, features and algorithms towards robustness, automation and generalization, reduce modeling and operational load on risk adversaries and new product/risk ramping-ups.
Uplevel risk machine learning excellence on privacy/compliance, interpretability, risk perception and analysis.
Qualifications
Master or above degree in computer science, statistics, or other relevant, machine-learning-heavy majors.
Solid engineering skills. Proficiency in at least two of: Linux, Hadoop, Hive, Spark, Storm.
Strong machine learning background. Proficiency or publications in modern machine learning theories and applications such as deep neural nets, transfer/multi-task learning, reinforcement learning, time series or graph unsupervised learning.
Ability to think critically, objectively, rationally. Reason and communicate in result-oriented, data-driven manner. High autonomy.
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or an accommodation, please reach out to us at usrc@tiktok.com.
Job Information
The base salary range for this position in the selected city is $126000 - $304704 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",Unknown / Non-Applicable,Internet & Web Services,Company - Private,Information Technology
Big Data Engineers,san-jose,"Sigma Data Systems
4.6","Sunnyvale, CA",4.6,$96K - $148K (Glassdoor est.),3.0,4.0,4.0,4.0,4.0,201 to 500 Employees,Company - Private,"Company Culture
Sigma is looking for talent, which believes in creating a difference. Sigma is always open to candidates passionate for playing with data and can understand the science behind it. It welcomes dynamic people who can break conventional methods.

Sigma believes in work-life balance. It provides time flexibility with 5 days working pattern to give our employees space and showcase their creativity.

Our Core Values
Innovation & Experience
We believe experience is necessary to deliver quality work, but along with the experience we believe in young new minds who can be innovative. We have a blend of all like-minded people.
Infrastructure
We provide our employees with a comfortable working space with a relaxing indoor games facility. We believe in a stress-free environment. Our employees enjoy their time being in office.
Integrity & Transparent culture
We have a very transparent and honest culture. Everyone has an equal opportunity to put their thoughts and ideas on the table. We have 360-degree reviews and appraisal processes.
Career Roadmap
We have a clear roadmap for each of our employees. By reviewing it, they can know their current status, and they can know what & how to plan for their next milestone. We believe in providing equal opportunity to every employee.

Are you up for the challenge?
If you believe Sigma is the right place for you, tell us about yourself and email your CV to career@sigmadatasys.com

We’re looking for strong Big Data Software Engineer having a passion for data, programming and visualization. The ideal candidate must have extensive experience in a fast-paced and innovative development environment.
Responsibilities:
Strong working experience in architecting data structures, writing scalable and efficient code.
Design and architect technical solutions for the business problems of large-scale projects.
You will be responsible for working with the cross-functional team, prioritize project requirements, manage development.
Follow coding standards and able to perform unit-testing.
Prior work experience in AWS and 3rd Party integration.
Ability to adapt latest technologies and implement the same on projects.
Skills And Qualifications:
Strong understanding of REST API development, ETL ( Extract Transform Load ), Data Logging and Warehousing.
Strong experience in client-side scripting, JavaScript frameworks like D3.js / React.js / Node.js / Vue.js / Angular.js and server-side framework like Java Spring Boot, Python etc.
Strong experience in Elastic Search ( ELK Stack ), Hadoop, Cassandra, Spark, Redis, MongoDB, DynamoDB etc will be an add-on.
Experience with various messaging systems, such as Kafka or RabbitMQ
Knowledge of code versioning tools, such as Git.
Strong Computer Science fundamentals in object-oriented design, data structures, algorithm design, problem solving and complexity analysis.
Qualifications / *Eligibility Criteria:
BE/B.Tech/MS in Computers / IT / EC.
HSC percentages : 65% +
No backlogs in engineering and academics
Mandatory Documents:
Passport size Photo
Resume
Photo ID Proof: Driving License, Aadhar Card & PAN Card
Mark-sheets of Engineering & HSC
Salary slips and bank statement with salary credit amount ( with company name )
Notes: Please carry photo copy of all documents.
Interview Process:
Document verification + HR interview — 30 minutes
Aptitude — 30 minutes
Technical interview — 40 minutes
Practical Task — 3-4 hours
Final Round — 30 minutes
Offer & documentation on selection — 1 hour",-1,-1,Unknown / Non-Applicable,-1
"Senior Frontend Software Engineer, Global E-Commerce Data Intelligence",san-jose,"TikTok
3.6","Mountain View, CA",3.6,Employer Provided Salary:$187K - $280K,3.4,3.4,3.1,3.6,3.0,1001 to 5000 Employees,2016,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Mountain View, Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul, and Tokyo.

Why Join Us

At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

Global e-commerce is content e-commerce business with international short video product as the carrier. It is committed to becoming the first choice for users to discover and purchase good products at affordable prices. Global e-commerce business team hopes to provide users with more tailored, active and efficient consumption experience, enabling merchants to receive stable and reliable platform services in different scenarios such as live e-commerce, short video content e-commerce, so as to make more affordable and high-quality products sell easily and a better life within reach.

The data insights team is responsible for development of data analytics & data-empowered platform capabilities across global e-commerce. Our mission is to empower our users to leverage and extract actionable insights from data to maximize their potential and efficiency on the global e-commerce platform. In essence, we want to extract facts, attribute causes and predict the future from oceans of data; and our fundamental goals are to reflect business impact, leverage data to support key decisions by lowering decision making complexity and optimising decision making efficacy and efficiency.

Responsibilities:
Architect and develop efficient and highly reusable front-end systems that drive complex web applications for e-commerce products.
Code optimisation to improve scalability, reliability, security and performance of web applications.
Collaborate with product design, product management and software engineering teams to deliver best in class user experience.
Qualifications
B. Sc or higher degree in Computer Science or related fields from accredited and reputable institutions.
5+ years experience in frontend engineering, with demonstrable experience with JavaScript/HTML/CSS, React/Vue/Angular and packaging frameworks like Webpack/Rollup/BaBel/AST/Gulp. Qualified fresh graduates would also be considered.
Familiar with key concepts like functional and asynchronous programming, closures and types, layouts, specificity, animation, cross browser compatibility, data security and accessibility.
Good understanding of multi-tier application architecture and protocols, familiarity with product and software development lifecycle process.
Demonstrable experience in developing data visualisation or data insights web/mobile applications is advantageous
Even Better if:
Agile, quick self-learner, highly self-motivated with a strong sense of product ownership, and creative problem solver.
Deeply passionate about software coding/development and building great mobile/web applications.
Ability to lead independent research to solve complex technical problems.
Good collaborator and team player, comfortable working in a fast-moving, culturally diverse, and globally distributed team environment.
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to us at allen.chen@bytedance.com.
Job Information
The base salary range for this position in the selected city is $187040 - $280000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",Unknown / Non-Applicable,Internet & Web Services,Company - Private,Information Technology
Big Data/Machine Learning Software Engineer,san-jose,"Nova Ltd.
4.5","Fremont, CA",4.5,$112K - $172K (Glassdoor est.),4.2,4.6,4.2,4.1,4.3,501 to 1000 Employees,1993,"The Data Analytics team at Nova is looking for a Big Data/Machine Learning Software Engineer to work with Data Scientists and other Software Engineers to gather requirements and implement solutions. For you, it is exciting to see your code interacting with algorithms and data to produce results via complex interactions in Big Data systems. In this role, you will work with Data Scientists to adapt new and existing Machine Learning algorithms to Big Data microservices and build functionality to access those via web-based user interfaces.
Nova Ltd. is a leading innovator and key provider of metrology solutions for advanced process control used in semiconductor manufacturing. Our products are used in-line by leading chip foundries as well as original equipment manufacturers. Nova’s technology serves critical sectors of patterning, thin film deposition, CMP and diffusion in leading logic and memory fabs worldwide. market.

About us:
Nova provides insights into process control in the world’s most technologically advanced industry. We employ physics, mathematics, algorithms, software and hardware expertise to redefine the limits of what is possible in semiconductor manufacturing.
We invite you to join our dreamers and winners and brilliant high- aimers who see impossible as the starting point to exciting challenges, and work together in multidisciplinary global teams to find answers.
We dive deep to extract unique insights and provide our customers and partners with crucial decision-making data. Each and every one of us helps redefine what people can achieve through technology.
Why Nova:
Fortune magazine chose Nova as one of the fastest growing companies in the world in 2019 and 2020
Great Place to Work-Certified™ 2022 & 2023
Opportunity to collaborate with the best in this field, our 1000+ employees love coming to work every day in our 12 offices across the globe and share their passion for technology and innovation

Requirements:
Self-starter and quick learner of new technologies and processes – we are using some technologies not easily found in current skill portfolios, so this is the most important requirement! If you are under-skilled in some of the other requirements below, evidence of your ability to learn quickly will be seriously considered. Example of technology needed to learn quickly is customization/extension of ElasticSearch-Logstash-Kibana (ELK) instances
5+ years of software development experience in Agile environment
5+ years of coding and development experience using Python 2/3, preferably using OO approach
1-2 years of Big Data deployment, monitoring and troubleshooting of microservices, and interactions with the following Big Data concepts:
Extract/Transform/Load workflows
Kafka or other message queues
Hive/Hadoop/Impala and Big Data data storage including NOSQL solutions
Big Data configuration and monitoring using a number of technologies
Extensive experience working in a multi-threaded environment
Experience working with SQL databases and/or Big Data datastores (HDFS, etc)
Exposure to web-based application development – optimally Dash (with Python), React or Angular to facilitate workflows and graphic visualization
Extra Spice:
Strong communication and problem-solving skills – possess the ability to translate business requirements into application code
Ability to take ownership of the complete software development cycle from requirements gathering to design to implementation
Team player who will work in a collaborative environment with users and the engineering team
Passionate about well-designed software that is modifiable, efficient, reliable and meets coding standards
Experience customizing/extending ElasticSearch-Logstash-Kibana (ELK) instances

Role Responsibilities:

What will you do as a Big Data Machine Learning Software Engineer?
Implement Machine Learning solutions that live on Big Data systems, with input and guidance from Data Scientists and the algorithms they develop to effect Machine Learning
Work as part of a Scrum team to analyze requirements, scope, estimate, implement, and test changes to meet these requirements in a Big Data system
Debug existing source code, analyze logs and fix bugs as needed
Work independently and collaboratively as needed
Take ownership of assigned tasks and finish in a timely manner
Continuously learn and improve skills
Apply significant attention to detail to ensure all tasks are carried out to the highest standard
What will make you succeed in the role?
Extensive experience in Python software development
Experience configuring, deploying, and monitoring micro services in a Big Data system
Experience with User Experience (UX) and implementation of python approaches to meet UX needs
Working knowledge of GIT
Working knowledge of JIRA
Test driven development
Database application development and data modeling techniques
Experience with Scrum/Agile",$100 to $500 million (USD),Machinery Manufacturing,Company - Public,Manufacturing
Distributed Data Systems - Staff Software Engineer,san-jose,"Databricks
4.5","Mountain View, CA",4.5,$133K - $190K (Glassdoor est.),4.5,4.5,4.4,4.4,3.9,1001 to 5000 Employees,2013,"At Databricks, we are obsessed with enabling data teams to solve the world's toughest problems, from security threat detection to cancer drug development. We do this by building and running the world's best data and AI infrastructure platform, so our customers can focus on the high value challenges that are central to their own missions.
Founded in 2013 by the original creators of Apache Spark, Databricks has grown from a tiny corner office in Berkeley, California to a global organization with over 1000 employees. Thousands of organizations, from small to Fortune 100, trust Databricks with their mission-critical workloads, making us one of the fastest growing SaaS companies in the world.
Our engineering teams build highly technical products that fulfill real, important needs in the world. We constantly push the boundaries of data and AI technology, while simultaneously operating with the resilience, security and scale that is critical to making customers successful on our platform.
We develop and operate one of the largest scale software platforms. The fleet consists of millions of virtual machines, generating terabytes of logs and processing exabytes of data per day. At our scale, we regularly observe cloud hardware, network, and operating system faults, and our software must gracefully shield our customers from any of the above.
Modern data analysis employs sophisticated methods such as machine learning that go well beyond the roll-up and drill-down capabilities of traditional SQL query engines. As a software engineer on the Runtime team at Databricks, you will be building the next generation distributed data storage and processing systems that can outperform specialized SQL query engines in relational query performance, yet provide the expressiveness and programming abstractions to support diverse workloads ranging from ETL to data science.
Below are some example projects:
Apache Spark: Develop the de facto open source standard framework for big data.
Data Plane Storage: Deliver reliable and high performance services and client libraries for storing and accessing humongous amount of data on cloud storage backends, e.g., AWS S3, Azure Blob Store.
Delta Lake: A storage management system that combines the scale and cost-efficiency of data lakes, the performance and reliability of a data warehouse, and the low latency of streaming. Its higher level abstractions and guarantees, including ACID transactions and time travel, drastically simplify the complexity of real-world data engineering architecture.
Delta Pipelines: It's difficult to manage even a single data engineering pipeline. The goal of the Delta Pipelines project is to make it simple and possible to orchestrate and operate tens of thousands of data pipelines. It provides a higher level abstraction for expressing data pipelines and enables customers to deploy, test & upgrade pipelines and eliminate operational burdens for managing and building high quality data pipelines.
Performance Engineering: Build the next generation query optimizer and execution engine that's fast, tuning free, scalable, and robust.
What we look for:
BS in Computer Science, related technical field or equivalent practical experience.
Optional: MS or PhD in databases, distributed systems.
Comfortable working towards a multi-year vision with incremental deliverables.
Driven by delivering customer value and impact.
5+ years of production level experience in either Java, Scala or C++.
Strong foundation in algorithms and data structures and their real-world use cases.
Experience with distributed systems, databases, and big data systems (Spark, Hadoop).
Benefits
Comprehensive health coverage including medical, dental, and vision
401(k) Plan
Equity awards
Flexible time off
Paid parental leave
Family Planning
Gym reimbursement
Annual personal development fund
Work headphones reimbursement
Employee Assistance Program (EAP)
Business travel accident insurance
About Databricks
Databricks is the data and AI company. More than 5,000 organizations worldwide — including Comcast, Condé Nast, H&M, and over 40% of the Fortune 500 — rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark™, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world's toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.
Our Commitment to Diversity and Inclusion
At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.
About Databricks
Databricks is the data and AI company. More than 9,000 organizations worldwide — including Comcast, Condé Nast, and over 50% of the Fortune 500 — rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark™, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world’s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.
Our Commitment to Diversity and Inclusion
At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.
Compliance
If access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.",Unknown / Non-Applicable,Computer Hardware Development,Company - Private,Information Technology
"Software Engineer, Big Data Privacy and Security",san-jose,"TikTok
3.6","San Jose, CA",3.6,Employer Provided Salary:$137K - $205K,3.4,3.4,3.1,3.6,3.0,1001 to 5000 Employees,2016,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

The team are missioned to ensure the safety of company-level big data products and compliance with local principals and regulations. We are adding privacy features to Apache's big data ecosystem (Spark, Hive Presto), and building world-class data security & privacy framework for big data tech stack. It's an emerging area where many companies and industry are heavily investing. Your work will impact billions of users and bring ""data for good"" social values.

Responsibilities
Build full life-cycle data protection solutions for big data infrastructures.
Design and develop privacy frameworks and products, and optimize infrastructures to achieve better performance and reliability.
Drive privacy and data protection efforts and work cross-functionally with Infra, Product and Policy teams.
Respond to emergency needs of privacy and establish collaboration processes.
Explore cutting-edge privacy technologies to ensure data usage complies with local regulations.
Qualifications
Bachelor or above degree in Computer Science or relevant disciplines with 3+ years working experience
Experienced in building large-scale backend services
Proficiency in at least one of following languages: Java, Python, Golang and C++
Solid communication and teamwork contribute to multi-functional teams
Preferred Qualifications
Industry experience developing and implementing privacy features and solutions
Experiences working on Big Data tech stack e.g., Hive, Spark, Kafka, Flink etc.
Experiences working on data lineage, scheduling services, and data protection.
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to us at usrc@tiktok.com.
Job Information
The base salary range for this position in the selected city is $136800 - $205000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",Unknown / Non-Applicable,Internet & Web Services,Company - Private,Information Technology
"Senior Data Scientist / Data Engineer, Drive Systems",san-jose,"Tesla
3.6","Palo Alto, CA",3.6,$132K - $189K (Glassdoor est.),3.7,3.3,3.1,3.7,2.9,10000+ Employees,2003,"What to Expect
The Drive Systems team is looking for an exceptionally talented and self-directed data scientist/data engineer to manage a large scope of data improvement projects across our production processes, validation tests, and field reliability failures. This role requires a well-rounded individual who can build, scale, and maintain data pipelines and warehousing systems and also analyze data to evaluate process health, sleuth problem areas, and drive and quantify improvements. The role will include creating and improving robust global databases and data quality standards, as well as developing scalable evaluation models and reporting systems. A strong candidate will be able to work with existing factory data and process engineering teams to build data solutions as well as drive focused investigations and improvement projects based on analysis of the data.
What You’ll Do
Define data standards and storage requirements and collaborate with IT to design efficiently structured storage solutions across a range of applications and users
Work with factory operations and field reliability teams to identify useful data sets and quantitative metrics across a range of processes and use cases and build visualizations and investigation tools
Develop and improve automated reporting and monitoring systems for key performance metrics and statistical process control
Perform exploratory analysis, correlation studies, design experiments, and analyze results to drive investigations and improvement projects
Define data formatting and fidelity requirements with suppliers and internal users, build data pipelines for structured and unstructured quality and process data, and move/transform data into structured database formats in automated pipelines to enable real-time analysis
What You’ll Bring
Bachelor’s degree or higher in quantitative discipline (Statistics, Data Analytics, Computer Science, Applied Mathematics, Physics, Engineering) or the equivalent in experience and evidence of exceptional ability
Minimum 4 years relevant working experience in analytical or quantitative roles
Proficiency in programming languages such as Python, R, SQL, C#, JavaScript, Golang
Proficiency in data visualization methods and tools such as Tableau, R Shiny, Dash, Plotly, etc.
Proficiency in software deployment/management tools such as Docker, Kubernetes, Kafka, Jenkins, GitHub
Strong working knowledge of relational and/or non-relational databases
Significant experience with real-world automation, high volume manufacturing, and process control
Strong working knowledge of physics and engineering principles, mathematics, and statistics
Exceptional organization and self-direction, collaboration skills, and ability to drive efficient execution across multiple projects and priorities",$1 to $5 billion (USD),Transportation Equipment Manufacturing,Company - Public,Manufacturing
Senior Data Engineer,san-jose,"SymphonyRM
3.5","Palo Alto, CA",3.5,$121K - $168K (Glassdoor est.),3.5,3.7,3.4,3.2,3.8,51 to 200 Employees,2014,"Introduction

SymphonyRM helps health systems thrive in the rapidly evolving US Healthcare industry by keeping patients healthy and physicians happy. By analyzing large amounts of data from many sources, we empower clients to make smarter decisions at every turn in their business. Our clients love SymphonyRM’s ability to guide them to take the next best action for both patients and physicians.

As a Senior Data Engineer, you’ll play a critical role in developing tools to automate data ETL processing, assess data quality from multiple sources, and build a powerful data pipeline, while working closely with our other engineers.

We care deeply about building long-term careers and offer opportunities for our employees to grow towards project leadership, engineering management, or other roles to make a difference in the lives of patients.

You’d be a great addition if…
You have a Master’s degree in Computer Science, Statistics or similar degree OR Bachelor’s degree with at least 3 year related experience with Python programming OR 5+ years related experience with Python programming (e.g. completion of a Python-focused bootcamp).
You seek to fully understand “big data” problems, and strategize to produce efficient, workable solutions.
You are curious about emerging technologies, and like to evaluate and adapt where you see fit.
You’re motivated by high-impact projects via automation or scaling data operations to drive business value.
You’re excited to work with cross-functional teams in an agile environment.
You appreciate working with people from diverse backgrounds.
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Bonus qualifications if...
You’ve worked on large-scale databases using cloud computing platforms like Amazon AWS
You have strong knowledge with SQL/Relational databases
You have experience in using data visualization tools (Looker, Matplotlib, Excel, etc.)
Experience with Apache Airflow and/or Pandas
You have studied or have experience designing data pipelines and loading large datasets into databases
What You’ll Do:
You will work closely alongside a small team of engineers to drive continuous improvements to our Python-based data platform.
Write and deploy Python code to automate data ingestion using Apache Airflow.
Support internal and external stakeholders in troubleshooting and resolving issues.
Contribute new ideas in design to development to our data infrastructure - we are always looking to improve.
Due to Covid-19, you will be working remotely for the time being. We are actively interviewing and hiring this position based out of our Palo Alto, CA office.",Unknown / Non-Applicable,Enterprise Software & Network Solutions,Company - Private,Information Technology
"Staff Software Engineer, Data Platform",san-jose,"Tesla
3.6","Palo Alto, CA",3.6,$142K - $196K (Glassdoor est.),3.7,3.3,3.1,3.7,2.9,10000+ Employees,2003,"What to Expect
Role
Data is deeply embedded in the product and engineering culture at Tesla. We rely on data – lots of it – to improve autopilot, to optimize hardware designs, to proactively detect faults, and to optimize load on the electrical grid. We collect data from each of our cars, superchargers, and stationary batteries and use it to make these products better and our customers safer.
We're the small but a core, high-impact team which is building and operating the IoT big data platform for the whole company. We collect massive amounts of IoT data, provide storage, access, and high-volume processing. Our stack is built on top of open source technologies, including Spark, Kafka, and related, and our own build from scratch technology.
We're looking for a talented engineer to join us as a foundational member of the team to deliver new and improved big data services and infrastructure. Your work will affect many hundreds of Tesla engineers daily, as well as improving the functionality of our cars, chargers, batteries, other connected devices worldwide, and enable new data-driven products such as Tesla Insurance.

What You’ll Do
Employ and improve industry-leading, scalable, distributed open-source technologies
Build back-end systems from scratch that are capable of handling 10s of trillions events per day
Facilitate operation of highly-available distributed systems at scale and across multiple locations
Facilitate others in deploying, operating, and extending upon your clean, tested code
Help define a platform that is highly leveraged, multi-tenant, and self-serviced
Work with data engineers and data scientists to drive efficient solutions from the platform
Help define the data story and enable data-driven solutions at Tesla, both technically and culturally

What You’ll Bring
5+ years of Software Development Experience
Expertise in Java, C++, or Rust
Strong programming fundamentals, particularly in data structures, concurrency
Deep understanding of a complex distributed system, such as Kafka, Spark, HBase, ElasticSearch
Have built and optimized highly available, scalable, distributed back-end services
Ability to break down and deeply understand complex problems and communicate complex matters efficiently
Strong problem solving skills, optimizing for the simplest, most robust yet practical solutions
Reliable, dependable, trustworthy, participating team member
Smart but humble, with a bias for action
Nice to Have
Proficiency in Python or Scala
Experience with cloud infrastructure such as AWS
Robust DevOps/SRE abilities",$1 to $5 billion (USD),Transportation Equipment Manufacturing,Company - Public,Manufacturing
Senior Technical Marketing Engineer (Data Protection),san-jose,"Palo Alto Networks
4.3","Santa Clara, CA",4.3,Employer Provided Salary:$126K - $204K,4.2,4.2,4.0,4.5,3.9,10000+ Employees,2005,"Company Description

Our Mission
At Palo Alto Networks® everything starts and ends with our mission:
Being the cybersecurity partner of choice, protecting our digital way of life.
We have the vision of a world where each day is safer and more secure than the one before. These aren’t easy goals to accomplish – but we’re not here for easy. We’re here for better. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.
We’re changing the nature of work. Palo Alto Networks is evolving to meet the needs of our employees now and in the future through FLEXWORK, our approach to how we work. From benefits to learning, location to leadership, we’ve rethought and recreated every aspect of the employee experience at Palo Alto Networks. And because it FLEXes around each individual employee based on their individual choices, employees are empowered to push boundaries and help us all evolve, together.

Job Description

Your Career
As a Sr. Technical Marketing Engineer (Data Loss Prevention) at Palo Alto Networks, you will join a team responsible for driving our Cloud Applications and Data security products, including SaaS, IaaS, Network and Endpoint Data Protection. You will work with cutting-edge technology, redefining the future of network security.
This role plays a key role in supporting our product managers, marketing teams, and customers by developing outbound technical communication, including product best practices, competitive reviews, demo environments, and ownership of product betas. You will perform competitive analysis, perform technical gap analysis and support the product management in identifying next-generation innovations. This is a critical customer facing role within the company and one where the right person can have significant impact.
The ideal candidate would be able to influence strategy, collaborate with marketing and sales teams to execute go to market strategies, act as a thought leader at the industry level, evangelizing the products and product strategy both internally and externally.
Your Impact
Develop, constantly refine, and execute the technical marketing plan
Be responsible for the creation, maintenance, and delivery of effective technical tools, whitepapers, demos, videos and technical training for sales, customers, and partners
Lead the automation within and across the cross-functional teams and strive to achieve technical and operational excellence in every step of the releases
Lead the competitive research and testing to identify key competitive advantages of our product lines and deliver them to sales, customers, and partners
Be a key technical evangelist for Palo Alto Networks, speaking at seminars, conferences, customer briefings, and with other groups within the company
Work with engineering in identifying product gaps based on competitive analysis and work with the PM to drive enhancements to bridge them
Be the domain authority on Palo Alto Networks products to help Systems Engineers with information on competitive questions
Identify Sales challenges based on any competitive situations and provide solutions
Document technical concepts to ensure our products are well understood and utilized to the greatest extent possible
Setup and maintain a competitive test lab including test harness, competitive products, automation environment, etc.
Configure and test competitive products, evaluate product strengths for security efficacy, product features, etc.
Work with marketing to develop collaterals with battle cards, presentations, and white papers

Qualifications

Your Experience
3+ years of experience as a Technical Marketing Engineer for network/cybersecurity area or a DevOps/Solution Architect, preferably for networking or data security products
Excellent written and verbal communication skills with strong presentation skills and trade show experience
Eagerness to learn new technologies, experiment with products and collaborate cross-functionally
Strong customer advocacy skills and experience, ability to work in difficult customer situations
Work towards getting things done, Fast learner with strong initiative and sense of ownership
Experience in automation tools, building dashboards, etc.
Experience with writing and editing technical documentation and operational procedures

Additional Information

The Team
To stay ahead of the curve, it’s critical to know where the curve is and how to anticipate the changes we’re facing. For the fastest-growing cybersecurity company, the curve is the evolution of cyberattacks and the products and services that proactively address them. Our Product Management team helps us do just that.
This team provides the behind-the-scenes support for our products by being a source of information for our Systems Engineers, staying on top of the environment we sell in and helping to implement technical solutions based on our clients' feedback and needs. As threats and technology evolve, we stay ahead to accomplish our mission.
Our Commitment
We’re trailblazers that dream big, take risks, and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.
We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at accommodations@paloaltonetworks.com.
Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.
All your information will be kept confidential according to EEO guidelines.
The compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/com-missioned roles) is expected to be between $125,800/yr to $203,500/yr. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.",$1 to $5 billion (USD),Enterprise Software & Network Solutions,Company - Public,Information Technology
Data Center Mechanical Commissioning Engineer II,san-jose,"CAI
4.1","Santa Clara, CA",4.1,Employer Provided Salary:$90K - $115K,4.2,4.0,3.9,4.0,3.4,501 to 1000 Employees,1996,"Position Description:
This position supports development and execution of all mechanical aspects of assigned commissioning projects from initial engagement, design reviews, checklists, safety support, script development, vendor coordination, testing and report development through turn over to the client. The Mechanical Commissioning Engineer will support the development of the mechanical test schedule, finalize mechanical test procedures, review project submittals for consistency with the design intent, basis of design and the owner’s project requirements, and maintain project cadence for the mechanical systems testing and associated Building Automation Systems. The Mechanical Commissioning Engineer is to support the planning and execution of commissioning for the mechanical infrastructure of the mission critical facility. They will be expected to execute against the project schedule through the coordination of contractors and/or vendors to complete the desired mechanical systems testing.
CAI DC Mechanical Commissioning Engineer will be exposed to cutting edge technologies in the Hyperscale and other spaces. You will have an opportunity to work with recognized subject matter experts allowing YOU to be a key player in bringing data technologies to market. As part of our company culture, we invest in YOUR future, and commit to hands on certifications as well as professional training. Our collaborative culture ensures that our customers benefit from exemplary work across our entire range of professional services.

Responsibilities:
Support and contribute to all aspects of safety for all mechanical tests.
Support complete commissioning and performance acceptance testing of the mechanical infrastructure systems.
Development of all mechanical test procedures, MOPS, SOO’s and checklists.
QA/QC of all mechanical test procedures.
Provide input and insight to the overall commissioning plan.
Develop reports for the mechanical testing and contribute to a daily report to the Commissioning Project Manager.
Attend and be an active participant of customer equipment Factory Witness Test
Assist with vendor coordination and management.
Perform equipment inspection to ensure build adherence to vendor submittal.
Provide test documentation that equipment is delivered, installed, and tested correctly and set to function properly for the customer.
Support and perform design specification review, manufacturer submittals, one line drawing sets, and project schedule documentation.
QA/QC of mechanical equipment installation\startup
Execute test scripts to confirm equipment and system operation to design specification.
Ensure safe work practices are followed by the commissioning team and customer site.
Engage with customers and vendors to ensure positive experience, goals achievement, and schedule adherence.
Provide daily status reports for mechanical commissioning team status.
Conduct facility walk downs, turnover, and punch list reviews.
General understanding of LEED specifications and requirements.
Look for new opportunities for CAI to provide service and value to customer.
Duties may be increased as experience and skill allow.

Requirements include:
Position Requirements:
Bachelor’s degree or equivalent experience
Minimum of 2 years Data Center Commissioning experience.
Knowledge of OSHA safety requirements.
Good written and verbal communication skills.
Ability to read and interpret mechanical drawings, P&ID’s and specifications.
Knowledge of mission critical design concepts.
Knowledge of various Building Automation/Monitoring Systems (BAS/BMS), Air Handlers, Humidifiers, Variable Refrigerant Flow, Computer Room Air Conditioners/Handlers (CRAC/CRAH), Evaporators, Adiabatic Coolers, Pressure/Temperature/Humidity sensors & Flowmeters.
Knowledge of basic thermodynamics and heat transfer and fluid flow.
Knowledge of the Test, Adjust and Balance (TAB) process.
Knowledge of mechanical trend analysis.
Strong experience with Word, Excel and PowerPoint. Can effectively create final products in all three programs.
Work under construction site conditions

Other Requirements:
Excellent oral and written English is required
Extensive travel may be required (75%)
Candidates must have a Passport or the ability to immediately get a Passport
Able to work in the US without sponsorship now or any time in the future.

About CAI
CAI is a 100% employee-owned company established in 1996, that has grown year over year to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and consulting services related to operational readiness to FDA regulated and other mission critical industries.

Meeting a Higher Standard
Our approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.
As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:
We act with integrity
We serve each other
We serve society
We work for our future

With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a can-do attitude. That is how we have grown exponentially.

Benefits
Our full-time positions offer competitive compensation and benefits which include: up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.
#LI-MR1
Average salary range.
We are an equal opportunity employer; we are proud to employ veterans and promote a diverse culture in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.
This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the FCO.",$25 to $100 million (USD),Architectural & Engineering Services,Company - Private,"Construction, Repair & Maintenance Services"
Senior Software Engineer in Test - Industrial & Data,san-jose,"Litmus Automation
4.7","Santa Clara, CA",4.7,$119K - $156K (Glassdoor est.),4.9,5.0,5.0,4.6,4.8,1 to 50 Employees,2014,"Who is Litmus
Litmus is a growth-stage software company that is transforming the way companies harness the power of machine data to improve operations. Our software is enabling the next wave of digital transformation for the biggest and most innovative companies in the World – making Industrial IoT, Industry 4.0 and Edge Computing a reality. We just completed our Series B financing round, and we are looking to expand our team.
Why join the Litmus team
You want to be a part of something great
We pride ourselves on building the most talented and experienced team in the industry who knows how to win. We work hard and the results speak for themselves. We're trusted by industry leaders like Google, Dell, Intel, Mitsubishi, Hewlett-Packard Enterprise and others as we partner to help Fortune 500 companies digitally transform.
You want to define and shape the future
At Litmus you'll have the opportunity to influence and enable Industrial Internet of Things, the next wave of technology essential for global digitization. We're leading the industry in machine data analytics and edge computing to feed machine learning, artificial intelligence and other applications that rapidly change the way companies operate.
You want to build and shape your career
Join a growth-stage Silicon Valley company to build and define your career path in an environment that allows you to progress rapidly. Bring your unique experience, talent and expertise and add to it by collaborating with and learning from the brightest people in the industry.
We are committed to hiring great people who are passionate about what they do and thrive on winning as a team. We welcome anyone and everyone who wishes to join the Litmus marketing team to apply and share their career experience, dreams and goals with us.
We are looking for a Senior Software Engineer in Test for the Industrials team to help us with complex Automated & Manual Testing for Litmus Edge. This role focuses on the industrial connectivity aspects of our Litmus Edge product and goes broader to Industrial DataOps at scale.

Responsibilities
Design, develop, and maintain automated test frameworks and test suites for Litmus Edge products.
The engineer will take responsibility for end-to-end quality and work with a team with a deep understanding of systems internals and Industrial protocols.
Collaborate with cross-functional teams to understand product features and create corresponding test plans.
Ensure the quality of the software by creating and modifying software test scenarios and scripts.
Create testing environments.
Design test strategies, develop test cases based on different customer use cases, and work closely with developers, product management, and Customer Success to understand the Litmus Edge product features.
Work alongside development, test, documentation, and product management teams to deliver high-quality products in a fast-paced environment.
Assist in manual testing when necessary.
Use the selected toolsets to automate test cases at scale or replace them with the ones that can scale.
Participate in product design reviews to provide input on functional requirements, product designs, schedules, or potential problems.
Recommend design improvements or corrections to engineers throughout the development process.
Perform regression testing, document the newly-identified test scenarios, and perform exploratory testing to identify further bugs.
Work closely with the Development Team to detect and analyze the root of each failure.
File defects and track them to closure
Document test procedures to ensure repeatability and compliance with standards.
Generate reports that show the progress of the initiative.

Qualifications
Experience in software testing (test case development, unit tests, test automation frameworks, test tools);
Hands-on experience with both white box and black box testing.
Hands-on experience with automated testing tools.
Experience with: Linux, Docker, Kubernetes, Web-based products,
Experience with: Industrial PLCs, Message brokers, Data Analytics
5+ years of experience in software development and testing.
Experience with performance and/or security testing is a plus.
Bonus skills: Golang, Python, Java, DevOps CI-CD knowledge
Bonus skills: Familiarity with Industrial Internet of Things (IIoT) concepts and technologies.Manufacturing or Manufacturing Software
Hoping to find someone passionate about technology, with a positive attitude and a confident approach to challenges, a great collaborator and team player, with a deep appreciation of quality

Find us at www.litmus.io",$1 to $5 million (USD),Enterprise Software & Network Solutions,Company - Private,Information Technology
Senior Software Engineer - Data Systems for Machine Learning,san-jose,Coactive AI,"San Jose, CA",-1,Employer Provided Salary:$153K - $180K,-1,-1,-1,-1,-1,Unknown,Company - Public,"Coactive makes it easy to search, filter, and analyze visual content. Increasingly image and video data captures the content we watch, the products we buy, and the work we do, and already represents 80% of internet traffic. But rather than being an asset, visual content is often a tax or even a liability because it is so hard to work with and understand. Coactive solves this by bringing structure to unstructured data. Rather than spending months (or years) building complex infrastructure, data teams can unlock the value of their visual data in minutes to power use cases such as content understanding and moderation, search, and analytics.
Coactive was founded by experts who shaped the fields of high-performance deep learning and data-centric AI. We have the scars from building and working with the first generation of modern machine learning systems at Google, Meta (formerly Facebook), Pinterest, eBay, Lyft, and other leading organizations. Through our decades of experience, we have developed a playbook to democratize the toughest parts of machine learning systems; no PhD required.
As a software engineer, you will work coactively with the best in ML and data systems, building the foundation for understanding unstructured image and video data.
What you'll do:
Build production-grade data systems that you'll be proud of
Tackle challenging problems at the intersection of machine learning and systems
Collaborate with a world-class team of engineers, researchers, and scientists
Shape engineering best practices and company culture as we grow
What we look for:
BS (or higher) in Computer Science or related fields, or equivalent experience.
5+ years of production-level experience in one of: Python, Java, C++, or similar language
Experience developing data intensive systems that power critical business processes
Experience working on enterprise software or cloud native platforms.
Experience with security and systems that handle sensitive data
Equally comfortable working on a white-board, pair programming, or presenting to small groups
Good knowledge of SQL
What you can expect from us:
The estimated annual base salary for this position is between $153,000-$180,000.*
At Coactive, base salary is only one part of our total compensation package. Other benefits for this position include, but are not limited to:
Market leading equity grants
100% medical, dental, & vision coverage for you
Medical, dental, & vision partially covered for your dependents
Unlimited PTO
Social events ranging from book clubs, happy hours, and hiking to board game nights and games of Mario Kart.
Further, you can expect a supportive work environment from us. We build products, but we develop people.

Actual pay is dependent on an individual candidate's professional background, experience, skills and qualifications, as well as market demand and business demands. This pay range is subject to change and may be modified in the future. The salary, other compensation, and benefits information is accurate as of the date of this posting.
We embrace and celebrate the diversity of our employees. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, national origin, gender, sex, gender identity or expression, sexual orientation, age, citizenship, marital or parental status, disability, veteran status, or other class protected by applicable law. We are proud to be an equal opportunity workplace.
We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.",-1,-1,Unknown / Non-Applicable,-1
Data Engineer with Computer Vision Knowledge,san-jose,"Phantom AI
5.0","Mountain View, CA",5.0,Employer Provided Salary:$130K - $180K,5.0,5.0,4.5,4.5,4.5,1 to 50 Employees,2016,"About Us
At Phantom AI, we've built a team of incredibly talented and ambitious people challenging the norm in the automotive industry. We are building cost-effective L2/L3 solutions to reduce the burden of everyday driving and make the roads safe for everyone. For instance, we believe democratizing technologies such as Automatic Emergency Braking and Emergency Lane Support is the first priority before tackling a fully self-driving vehicle. Our main customers are Tier 1 automotive manufacturers who are focused on delivering L2/L3 solutions and in the future will deliver full autonomy.
We differentiate ourselves from other autonomous driving startups through a combination of state-of-the-art technological know-how and real automotive experiences of shipping ADAS systems at a volume production scale. If you feel that you have the passion, commitment, and drive to challenge the status quo within the automotive industry, we would love to hear from you.

Responsibilities
Develop a metadata mining system for deep learning datasets.
Develop an automatic QC system for human-labeled annotation.
Work with internal teams and external companies to coordinate data in database servers and from data providers.

Required Qualifications
3-5+ years of relevant paid, professional, post-academic (not including research, internships, co-ops, practica, etc.) working experience with visual motion estimation.
Excellent Python programming and software design skills.
Excellent problem-solving capability.
Bachelor's degree or equivalent experience

Desired Qualifications
Master's degree or equivalent experience

Benefits
We offer our employees a comprehensive benefits package including:
Salary $130,000-$180,000
Medical, dental, and vision coverage
Office snacks & reimbursable meals*
Paid Time Off
FSA
401K

Work Type
Hybrid - Phantom AI follows this type of working experience to allow employees the flexibility to work weekly at the office 2x and from home 3x.

Equal Opportunity for Diversity & Inclusion
Phantom AI provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",Unknown / Non-Applicable,Computer Hardware Development,Company - Private,Information Technology
Field Project Engineer- Hyperscale Data Center,san-jose,"Eaton Corporation
3.9","Pleasanton, CA",3.9,Employer Provided Salary:$77K - $113K,3.6,3.9,3.4,3.7,3.7,10000+ Employees,1911,"Eaton’s NAS North American Sales division is currently seeking a Field Project Engineer- Hyperscale Data Center. The preferred remote work locations include Houston, TX, Chandler AZ, Littleton CO, Pleasanton CA, Tukwila WA, San Antonio, TX, Austin, TX, Dallas, TX, Nashville, TN, Waukesha, WI, Chicago, IL, Raleigh, NC and Wilsonville OR. However, this role is also open to other remote locations. This role will support customer locations in Eastern to Pacific time zones.

The expected annual salary range for this role is $77249.97 - $113299.96 a year.
Please note the salary information shown above is a general guideline only. Salaries are based upon candidate skills, experience, and qualifications, as well as market and business considerations.
What you’ll do:
The primary function of the Project Engineer is to serve as the technical liaison between the product lines, field sales and the customer during the execution of Large and Major complex project orders. In this role, you will have technical ownership of the order and creates a positive customer experience through a proactive approach to project support and issue resolution. The Project Engineer leverages centralized resources to manage documentation and resolve issues and builds relationships across customers and Eaton facilities to deliver a successful project. You will work independently on daily tasks, taking direction from Project Manager, Sales Engineers, and the Project Management Organization (PMO) Management Team.

In this function you will:
Develop and maintain relationships with internal and external customers in assigned territory.
Interpret customer plans and specifications to provide accurate information on project orders.
Develop and execute proactive order entry strategies that will facilitate order fulfillment and technical support as well as minimize order delay.
Serve as the customer’s advocate by relaying the appropriate level of urgency to peer contacts in the operations and escalating issues as required to management.
Use Bid Manager for product configuration, changes and pricing.
Provide technical support and follow through on warranty issues.
Coordinate and interpret Plant Drawings
Work closely with the Project Management Team including Project Managers, Sales Engineers, Project Coordinators, other Project Engineers and the Documentation Team.
Leverage centralized resources to create and manage project submittal and O&M documentation.
Manage daily phone and email activity, providing directions, solutions and updates.
Pursue continuous learning of products and applications related to engineered products.
Take leading role in developing, mentoring, and monitoring on-the-job training for new and existing less experienced Project Engineers.
Represent sales at customer witness tests, inspections, and on-board approval meetings/visits.
Perform all other duties as required by Management.
Qualifications:
Required (Basic) Qualifications:
Bachelor’s degree from an accredited institution
Minimum 3 years of work experience in sales, sales support, technical role or applicable field
Sponsorship is not available. Candidates must be legally authorized to work in the U.S. on an ongoing basis without requiring company sponsorship.
Preferred qualifications:
Bachelor’s degree in Engineering or other technical fields
Electrical industry expertise and product knowledge
Prior sales and/or sales support experience
Skills:
Position Criteria:
Possess technical sales aptitude, market channel knowledge and power distribution expertise
Capable of working in a team environment, using strong communication and interpersonal skills
Ability to establish customer relationships within the market area while maintaining and growing existing customer relationships
Knowledgeable of Eaton product and service capabilities and can assemble standard offerings to meet customer needs with occasional internal oversight
Possess necessary computer skills including: Adobe Acrobat, AutoCAD, Internet applications, Microsoft Office applications, and other product configuration tools
Possess organizational, presentation, training, and planning skills
Knowledgeable of market and industry issues, key trends, and surround competitors
We are committed to ensuring equal employment opportunities for all job applicants and employees. Employment decisions are based upon job-related reasons regardless of an applicant's race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability, marital status, genetic information, protected veteran status, or any other status protected by law.
Eaton considers qualified applicants regardless of criminal histories, consistent with local laws. To request a disability-related reasonable accommodation to assist you in your job search, application or interview process, please call us at 1-800-836-6345 to discuss your specific need. Only accommodation requests will be accepted by this phone number.
We know that good benefit programs are important to employees and their families. Eaton provides various Health and Welfare benefits as well as Retirement benefits, and several programs that provide for paid and unpaid time away from work. Click here for more detail: Eaton Benefits Overview. Please note that specific programs and options available to an employee may depend on eligibility factors such as geographic location, date of hire, and the applicability of collective bargaining agreements.",$10+ billion (USD),Electronics Manufacturing,Company - Private,Manufacturing
"Senior Principal Software Engineer, Core Data Platform",san-jose,"Atlassian
4.5","Mountain View, CA",4.5,$142K - $196K (Glassdoor est.),4.3,4.6,4.2,4.6,4.6,5001 to 10000 Employees,2002,"Working at Atlassian

Atlassian can hire people in any country where we have a legal entity. Assuming you have eligible working rights and a sufficient time zone overlap with your team, you can choose to work remotely or from an office (unless it’s necessary for your role to be performed in the office). Interviews and onboarding are conducted virtually, a part of being a distributed-first company.

Atlassian's mission ""to unleash the potential of every team"" is the guiding light behind what we do. We have developed well-known products such as Jira, Confluence, and Trello that fit into the fabric of teamwork across different types of teams and the processes to help every team succeed. Atlassian helps teams everywhere change the world. Our products are revolutionizing the software industry, and helping teams collaborate and create the magic that provides their best work. Think NASA launching the Rover on Mars or Cochlear gifting those born deaf with the ability to hear, your work directly impacts the products they use to promote humanity.

We’re transforming Atlassian and data is at the heart of that. Core Data platform is responsible for low latency, cost efficient compliant cloud storage and data processing capabilities at scale for services that power our products. Think of Data Abstraction, Streaming, Transformation, Replication, Governance and GraphAPIs.

We're looking for an experienced Senior Architect to provide architectural oversight and technical leadership to our growing Core Data Platform organization. You will bring a wealth of experience in architecting complex cloud scale systems. You will also need to be fairly comfortable working with senior leadership and in navigating cross org challenges. You will be working with the team to define architectural/organizational future states that we can scale to in years 2 and 3. We’ll need to make balanced calls that align with our forward-looking vision and current business & technology critical asks.
Your background:
BS in Computer Science or related technical field or equivalent experience
12+ years of experience developing large scale distributed systems.
4+ years of experience providing architectural oversight and technical leadership.
Great, but not required that you have:
A track record of cross-group/cross-discipline collaboration.
Broad experience architecting, designing, and building large-scale distributed systems.
Broad knowledge and understanding of SaaS, PaaS, IaaS with hands-on experience of one or more public cloud offerings (ideally AWS)
Fluency in any modern object-oriented programming language (e.g., Java, Kotlin, Python, Javascript, go etc.) and in architecture patterns for distributed systems
Deep Experience with Storage and streaming technologies such as Dynamo, S3, Kafka, flink
Ability to drive the long term vision and strategy
Strong empathy and a bias for action.
Ability to thrive in an ambiguous environment.
Compensation

At Atlassian, we tie our base pay ranges to role and level. In the United States, that means your base pay ranges will fall into one of three geographic pay zones depending on your location. Our current base pay ranges for new hires in each zone are:
Zone A: $217,500.00 - $333,500.00
Zone B: $195,750.00 - $300,200.00
Zone C: $180,525.00 - $276,900.00

Within each range, base pay is ultimately determined based on your skills, expertise, and experience. This role may also be eligible for benefits, bonuses, commissions, and/or equity.
Please visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter.
#LI-Hybrid #LI-Remote #LI-LS2

Our perks & benefits

To support you at work and play, our perks and benefits include ample time off, an annual education budget, paid volunteer days, and so much more.

About Atlassian

The world’s best teams work better together with Atlassian. From medicine and space travel, to disaster response and pizza deliveries, Atlassian software products help teams all over the planet. At Atlassian, we're motivated by a common goal: to unleash the potential of every team.

We believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines.

To learn more about our culture and hiring process, explore our Candidate Resource Hub.",Unknown / Non-Applicable,Software Development,Company - Public,Information Technology
"Sr. Software Engineer, Data",san-jose,"Liftoff
4.1","Redwood City, CA",4.1,$122K - $168K (Glassdoor est.),3.9,4.0,3.8,4.3,3.9,501 to 1000 Employees,2012,"Liftoff is the leading growth acceleration platform for the mobile industry, helping advertisers, publishers, game developers and DSPs scale revenue growth with solutions to market and monetize mobile apps.
Liftoff's solutions, including Accelerate, Direct, Influence, Monetize, Intelligence, and Vungle Exchange, support over 6,600 mobile businesses across 74 countries in sectors such as gaming, social, finance, ecommerce, and entertainment. Founded in 2012 and headquartered in Redwood City, CA, Liftoff has a diverse, global presence.
About Liftoff
At Liftoff, we're helping mobile businesses scale and succeed via our sophisticated technology that enables them to find their most engaged users. We are a trusted guide for growth and engagement, transforming how people discover and experience apps. Advertisers depend on us to reach, acquire, and retain high-value users worldwide. We are one of the world's largest independent, unbiased and privacy-friendly growth platforms that fuels the entire mobile app growth cycle across user acquisition, engagement, monetization, and analytics. Consistently ranked as one of the fastest growing companies and best places to work, we are a profitable company with strong product-market fit and tremendous growth opportunity. We have a creative, collaborative, and humble culture. We are data-driven, proactive, and have the courage to drive change.
Liftoff is the leading growth acceleration platform for the mobile industry, helping advertisers, publishers, game developers, and DSPs scale revenue growth with solutions to market and monetize mobile apps.
Liftoff's solutions, including Accelerate, Direct, Influence, Monetize, Intelligence, and Vungle Exchange, support over 6,600 mobile businesses across 74 countries in sectors such as gaming, social, finance, e-commerce, and entertainment. Founded in 2012 and headquartered in Redwood City, CA, Liftoff has a diverse, global presence.
Position
The Data Engineering team is responsible for the efficiency, quality, and availability of Liftoff+Vungle data for both internal and external consumption. This role will help drive the operational planning and success of Data Availability, Engineering, and Operations while also championing new technologies and methodologies which lead to more efficient Data ingestion, model training, serving, and utilization. The Sr. Engineer, Data/ML is responsible for working as a part of the Data Engineering team on data availability planning and capacity planning, and working collaboratively with data scientists, product, and the larger engineering organization to support data needs while assisting with data-related technical issues.
Location
SF Bay Area, Greater Seattle Area, or Greater Los Angeles Area
Although we are primarily remote, we would ideally like this hire to be based in the West Coast (Pacific timezone) for easier travel to our Redwood City, CA HQ for regular collaboration (each trip approx 3-5 days). This role is required to work Pacific hours (daily stand ups with Asia teams go as late as 7pm Pacific, some meetings potentially later).
Responsibilities
Build and maintain data pipelines and data infrastructure to support revenue tracking, analytics, and machine learning models
Work with data at petabyte scale and billions of events / day
Design, engineer, and implement robust, low latency data pipelines for model training
Collaborate with data scientists to develop and improve ML models
Take ownership and work with various groups spanning product management, engineering, data analytics, sales, and data science in a fast-paced environment
Focus on code readability, performance, testing, documentation, continuous integration
Contribute to the build of next-generation data solutions that maximize performance and reliability for our use cases, including data lakes, pipeline automation tools, and feature stores
Become familiar with core development, product release, and business processes
Implement new features and streamlining existing services
Minimize complexity and increase shared understanding
Mentor and share knowledge with team members
Qualifications:
BS in Computer Science with 8+ years of professional experience; or
MS in Computer Science with 5+ years of professional experience; or
PhD with 2+ years of experience; or equivalent work experience
Experience building/testing/deploying/maintaining streaming and batch-processing data pipelines
Expertise in query planning analysis, identifying hot spots, and optimizing large complex joins
Knowledge of various ETL techniques and frameworks and experience in integrating data from multiple data sources
Experience with data lakes, data warehouses, analytics databases, metastores, query engines, data visualization/BI tools, ETL automation frameworks
Experience with NoSQL databases, such as HBase, Cassandra, MongoDB etc
In-depth understanding of the inner workings of one or more big data technologies like Spark, Flink, Kafka, Hadoop, Hive, etc
Knowledge of machine learning is a plus but not required: exposure to ML frameworks, deep learning, model selection, data analysis, ML ops
Solid understanding of distributed system concepts
Have an excellent understanding of scheduling and workflow frameworks and principles
Proficient in at least one of the following languages: Scala, Python, Java
Demonstrated experience delivering value from data for a business
Nice to Have
Previous experience in ad-tech
Jenkins/TravisCI, Airflow, Docker, Kubernetes, AWS, Github, Databricks

Preferred location for this position is SF Bay Area, Greater Seattle Area, or Greater Los Angeles Area.

Liftoff's compensation strategy includes competitive market rate along with equity and benefits and perks that will give our employees what they need to do their best work. In order to ensure teams are compensated fairly for the work performed, we map out specific levels and take into consideration the cost of labor within each location.

The minimum base pay for this position in the US depends on the location and falls in the following zones:
SF Bay Area, New York City, Los Angeles, Orange County: $150,000
Seattle/Olympia, Austin, Boston, San Diego, Santa Barbara: $130,000
All other cities in our approved to hire states: $125,000

Working at Liftoff is fast-paced, fun, and challenging, and we thrive on innovation. Come join our team and help shape the future of the mobile app ecosystem. If this role sounds interesting to you, we would love to hear from you!

#LI-JH1
#LI-Remote
Liftoff is committed to providing and maintaining a work environment where all employees and candidates are treated with dignity and respect and that is free of bias, prejudice, and harassment. Liftoff is further committed to providing an equal employment opportunity for all employees and candidates for employment free from discrimination and harassment on the basis of sex, gender (including sexual harassment, gender harassment, and harassment due to pregnancy, childbirth, breastfeeding, and related conditions), sexual orientation, gender identity, gender expression, gender nonconformity, race, creed, religion, color, national origin, ancestry (including association, affiliation, or participation with persons or activities related to national origin, English-proficiency or accent, or immigration status), physical or mental disability, medical condition(s), genetic information of an individual or family member of the individual, marital or domestic partner status, age, veteran or military status, family care status, requesting or taking pregnancy, parental or disability leave, requesting an accommodation, or any other characteristic protected by federal, state, or local law, regulation, or ordinance. All such discrimination and harassment is unlawful and will not be tolerated. Liftoff maintains a continued commitment to equal employment opportunity and expects the full cooperation of all personnel.

Agency and Third Party Recruiter Notice:
Liftoff does not accept unsolicited resumes from individual recruiters or third-party recruiting agencies in response to job postings. No fee will be paid to third parties who submit unsolicited candidates directly to our hiring managers or Recruiting Team. All candidates must be submitted via our Applicant Tracking System by approved Liftoff vendors who have been expressly requested to make a submission by our Recruiting Team for a specific job opening. No placement fees will be paid to any firm unless such a request has been made by the Liftoff Recruiting Team and such a candidate was submitted to the Liftoff Recruiting Team via our Applicant Tracking System.",Unknown / Non-Applicable,Advertising & Public Relations,Company - Private,Media & Communication
"Staff Software Engineer, Data",san-jose,"Liftoff
4.1","Redwood City, CA",4.1,$137K - $183K (Glassdoor est.),3.9,4.0,3.8,4.3,3.9,501 to 1000 Employees,2012,"Liftoff is the leading growth acceleration platform for the mobile industry, helping advertisers, publishers, game developers and DSPs scale revenue growth with solutions to market and monetize mobile apps.
Liftoff's solutions, including Accelerate, Direct, Influence, Monetize, Intelligence, and Vungle Exchange, support over 6,600 mobile businesses across 74 countries in sectors such as gaming, social, finance, ecommerce, and entertainment. Founded in 2012 and headquartered in Redwood City, CA, Liftoff has a diverse, global presence.
About Liftoff
At Liftoff, we're helping mobile businesses scale and succeed via our sophisticated technology that enables them to find their most engaged users. We are a trusted guide for growth and engagement, transforming how people discover and experience apps. Advertisers depend on us to reach, acquire, and retain high-value users worldwide. We are one of the world's largest independent, unbiased and privacy-friendly growth platforms that fuels the entire mobile app growth cycle across user acquisition, engagement, monetization, and analytics. Consistently ranked as one of the fastest growing companies and best places to work, we are a profitable company with strong product-market fit and tremendous growth opportunity. We have a creative, collaborative, and humble culture. We are data-driven, proactive, and have the courage to drive change.
Liftoff is the leading growth acceleration platform for the mobile industry, helping advertisers, publishers, game developers, and DSPs scale revenue growth with solutions to market and monetize mobile apps.
Liftoff's solutions, including Accelerate, Direct, Influence, Monetize, Intelligence, and Vungle Exchange, support over 6,600 mobile businesses across 74 countries in sectors such as gaming, social, finance, e-commerce, and entertainment. Founded in 2012 and headquartered in Redwood City, CA, Liftoff has a diverse, global presence.
Position
The Data Engineering team is responsible for the efficiency, quality, and availability of Liftoff data for both internal and external consumption. This role will help drive the operational planning and success of Data Availability, Engineering, and Operations while also championing new technologies and methodologies which lead to more efficient Data ingestion, model training, serving, and utilization. The Staff Software Engineer, Data is responsible for working as a part of the Data Engineering team on data availability planning and capacity planning, and working collaboratively with data scientists, Product, and the larger Engineering organization to support data needs while assisting with data-related technical issues.
This role has the potential to grow into an Engineering Manager in 6-12 months.
Location
SF Bay Area, Greater Seattle Area, or Greater Los Angeles Area
Although we are primarily remote, we would ideally like this hire to be based in the West Coast (Pacific timezone) for easier travel to our Redwood City, CA HQ for quarterly collaboration (2x/quarter; 3-5 days per trip). This role is required to work Pacific hours (daily stand ups with Asia teams go as late as 7pm Pacific, some meetings potentially later).
Responsibilities
Take ownership and work with various product management, development, and quality assurance groups in a fast-paced environment
Build partnerships with cross-functional teams with clear ways of working - software engineering, data science, product managers, business
Design, engineer & implement robust, real-time data pipelines
Focusing on code readability, performance, testing, documentation, continuous integration
Focusing on building next-generation software solutions and implementing large-scale feature stores that maximize performance and reliability for our use cases
Become familiar with core development, product release, and business
Implementing new features and streamlining existing services
Minimizing complexity and increasing shared understanding
Mentor and share knowledge with team members
Qualifications:
BS in Computer Science with 10+ years of professional experience; or
MS in Computer Science with 6+ years of professional experience; or
PhD with 4+ years of experience; or equivalent work experience
Proficient in at least one of the following languages: Java, Scala, Python
Proficient in Apache Spark
Experience with orchestration tools like Airflow
Solid understanding of Object Oriented Design and Design Patterns
Experience with NoSQL databases, such as HBase, Cassandra, MongoDB, etc.
Have experience in building streaming or batch-processing data pipelines
Knowledge of various ETL techniques and frameworks and experience in integrating data from multiple data sources.
Solid understanding of distributed system concepts
Tech Lead for a team of 4 or more engineers in Data technologies.
Have an excellent understanding of scheduling and workflow frameworks and principles
Nice to Have
Previous experience in ad-tech
Work experience in building DataLake (Date Lakehouse) is a plus.
Jenkins/TravisCI, Airflow, Docker, Kubernetes, AWS, Github, Databricks
Knowledge of Machine learning
Experience in working with Presto/Trino
Experience with data visualization techniques and tools

Preferred location for this position is SF Bay Area, Greater Seattle Area, or Greater Los Angeles Area.

Liftoff's compensation strategy includes competitive market rate along with equity and benefits and perks that will give our employees what they need to do their best work. In order to ensure teams are compensated fairly for the work performed, we map out specific levels and take into consideration the cost of labor within each location.

The minimum base pay for this position in the US depends on the location and falls in the following zones:
SF Bay Area, New York City, Los Angeles, Orange County: $170,000
Seattle/Olympia, Austin, Boston, San Diego, Santa Barbara: $150,000
All other cities in our approved to hire states: $145,000

Working at Liftoff is fast-paced, fun, and challenging, and we thrive on innovation. Come join our team and help shape the future of the mobile app ecosystem. If this role sounds interesting to you, we would love to hear from you!

#LI-JH1
#LI-Remote
Liftoff is committed to providing and maintaining a work environment where all employees and candidates are treated with dignity and respect and that is free of bias, prejudice, and harassment. Liftoff is further committed to providing an equal employment opportunity for all employees and candidates for employment free from discrimination and harassment on the basis of sex, gender (including sexual harassment, gender harassment, and harassment due to pregnancy, childbirth, breastfeeding, and related conditions), sexual orientation, gender identity, gender expression, gender nonconformity, race, creed, religion, color, national origin, ancestry (including association, affiliation, or participation with persons or activities related to national origin, English-proficiency or accent, or immigration status), physical or mental disability, medical condition(s), genetic information of an individual or family member of the individual, marital or domestic partner status, age, veteran or military status, family care status, requesting or taking pregnancy, parental or disability leave, requesting an accommodation, or any other characteristic protected by federal, state, or local law, regulation, or ordinance. All such discrimination and harassment is unlawful and will not be tolerated. Liftoff maintains a continued commitment to equal employment opportunity and expects the full cooperation of all personnel.

Agency and Third Party Recruiter Notice:
Liftoff does not accept unsolicited resumes from individual recruiters or third-party recruiting agencies in response to job postings. No fee will be paid to third parties who submit unsolicited candidates directly to our hiring managers or Recruiting Team. All candidates must be submitted via our Applicant Tracking System by approved Liftoff vendors who have been expressly requested to make a submission by our Recruiting Team for a specific job opening. No placement fees will be paid to any firm unless such a request has been made by the Liftoff Recruiting Team and such a candidate was submitted to the Liftoff Recruiting Team via our Applicant Tracking System.",Unknown / Non-Applicable,Advertising & Public Relations,Company - Private,Media & Communication
Principal Customer Engineer – Instinct Data Center GPU Software,san-jose,"Advanced Micro Devices, Inc
4.2","Santa Clara, CA",4.2,$113K - $173K (Glassdoor est.),4.2,4.2,3.9,3.7,3.9,10000+ Employees,1969,"Overview:
WHAT YOU DO AT AMD CHANGES EVERYTHING

We care deeply about transforming lives with AMD technology to enrich our industry, our communities, and the world. Our mission is to build great products that accelerate next-generation computing experiences – the building blocks for the data center, artificial intelligence, PCs, gaming and embedded. Underpinning our mission is the AMD culture. We push the limits of innovation to solve the world’s most important challenges. We strive for execution excellence while being direct, humble, collaborative, and inclusive of diverse perspectives. This is who we are at our best. One Company. One Team.

AMD together we advance_
Responsibilities:
Principal Customer Engineer – Instinct Data Center GPU Software

THE ROLE:
AMD is unwavering in our dedication to delivering an exceptional customer experience. We understand that ease of use and responsive customer support are essential ingredients in achieving this objective. As a valued member of the Data Center GPU & Accelerated Processing applications engineering organization, your role as Principal Customer Engineer is pivotal in driving and sustaining best-in-class customer support for major cloud service providers and supercomputer deployments in the US & Europe.

THE PERSON:
As a leader in the customer engineering organization, you have a critical role in ensuring overall customer satisfaction for AMD's US & EMEA customer base through resolution & closure of complex technical support issues and managing needed collaboration between the customers, partners, software development, field applications, product management, and business leaders. You should possess excellent software debugging skills (C/C++ and Python required) and have a fundamental understanding of how to run high performance computing (HPC) and/or machine learning (ML) workloads on server systems with accelerated processing.

KEY RESPONSIBILITIES:
Lead the efforts of the DC GPU customer engineering (CE) team to ensure customer success in the deployment and use of AMD Instinct™ Accelerators. These activities include:
The replication and debug of customer issues (software stack, firmware, driver), working with cross-functional teams, and driving root cause investigation.
Understand customer requirements and schedule, identify gaps in AMD offering and work with key stakeholders to close them.
Act as the primary point of contact for the customer and ensure all issues for the account are prioritized, tracked, and resolved in a timely manner.
Facilitate technical discussions with the customer, their designated OEM/ODM partners, and relevant AMD subject matter experts, as needed.
Help recruit best-in-class technical engineering talent and provide guidance to management on how to improve performance and efficiency of the existing team.
Manage technical escalations from customers as well as your staff's internal escalations to AMD's various software development teams.
Represent technical support management during customer calls/escalations and act as an escalation point for customer issues, driving towards a resolution.
Jump in to help other members of the team in resolving customer issues as needed.
Proactively monitor customer tickets while ensuring all issues are handled properly.
Communicate the team's effectiveness in resolving major customer issues and overall support trends to management.
Serve as a mentor to other CE team regarding technical issues and soft skills.
Roll up weekly support highlights and red flags to management.
Provide recommendations to improve internal processes and tools to enhance customer experience with our products and software.

PREFERRED EXPERIENCE:
Python & C/C++ programming, employing best software design practices.
GPU software development or validation involving HIP, CUDA, ROCm, or OpenCL.
Software performance evaluations, optimizations and debugging.
Customer first mindset. Driven to meet or exceed customer expectations, resolve issues expeditiously and, when possible, proactively.
Able to size technical issues and articulate their impact to AMD and our customers
Effective communication & presentation skills and comfortable in a customer-facing environment. Experience with executive rollups.
History of using one or more GPUs, or similar offload accelerator, for deployment of Artificial Intelligence (AI) or HPC workloads

ACADEMIC CREDENTIALS:
BS in Computer Science, Computer Engineering, or Electrical Engineering. MS is preferred.

LOCATION:
Santa Clara, CA
#LI-RL1
Qualifications:
At AMD, your base pay is one part of your total rewards package. Your base pay will depend on where your skills, qualifications, experience, and location fit into the hiring range for the position. You may be eligible for incentives based upon your role such as either an annual bonus or sales incentive. Many AMD employees have the opportunity to own shares of AMD stock, as well as a discount when purchasing AMD stock if voluntarily participating in AMD’s Employee Stock Purchase Plan. You’ll also be eligible for competitive benefits described in more detail here.

AMD does not accept unsolicited resumes from headhunters, recruitment agencies, or fee-based recruitment services. AMD and its subsidiaries are equal opportunity, inclusive employers and will consider all applicants without regard to age, ancestry, color, marital status, medical condition, mental or physical disability, national origin, race, religion, political and/or third-party affiliation, sex, pregnancy, sexual orientation, gender identity, military or veteran status, or any other characteristic protected by law. We encourage applications from all qualified candidates and will accommodate applicants’ needs under the respective laws throughout all stages of the recruitment and selection process.",$10+ billion (USD),Computer Hardware Development,Company - Public,Information Technology
"Sr. Software Engineer - distributed systems, cloud & data analytics",san-jose,"Juniper Networks
4.3","Sunnyvale, CA",4.3,Employer Provided Salary:$159K - $228K,4.1,4.3,4.0,4.1,4.2,5001 to 10000 Employees,1996,"Juniper’s Architecture and Pathfinding team is looking for a driven and curious software engineer who is interested in building new solutions from scratch to join our team. The Pathfinding team ideates on and combines innovative technologies like cloud-native ML / AI to create new solutions that will help Juniper transform networking and connectivity for the cloud era.
Responsibilities will vary depending on groups:
Work on distributed systems, cloud/ cloud-native technologies, data analytics
Work with our engineering leaders to build prototypes in an agile manner
Expected to be hands-on in full stack software development
Required Experience and Skills:
Has a MS or PhD in CS/CE/EE
8+ years of relevant experience
Programming experience in one or more of C/C++, Java, Python, knowledge of algorithms and data structures
Good verbal and written communication and presentation skills
Self-motivated team player, and capable of working in a fast-paced R&D environment
Curious about learning new technologies and building new solutions from scratch
Strong background in networking technologies TCP/IP, Routing Protocols, Network Analytics, In-line Telemetry, SmartNICs
Good to have Qualifications:
Programming skills in Go, UI - Angular/React
Knowledge of public cloud like Aws, Azure, GCP would be added advantage.
Knowledge and/or hands-on experience in Kubernetes and Docker
Knowledge and/or hands-on experience with service-mesh technologies like istio, envoy proxies
Good understanding and knowledge of TCP/IP, application layer protocols: HTTP knowledge is a plus
Knowledge of data analytics, stream processing, AI/ML techniques
Knowledge and/or hands-on experience with MLOps framework like Kubeflow, AWS sagemaker , Databricks platform
Good understanding of systems software concepts, network/system security is a plus
Minimum Salary: $158,560.00
Maximum Salary:$227,930.00
The pay range for this position is expected to be between $158,560.00 and $227,930.00/year; however, the base pay offered may vary depending on multiple individualized factors, including market location, job-related knowledge, skills, and experience. The total compensation package for this position also includes medical benefits, 401(k) eligibility, vacation, sick time, and parental leave. Additional details of participation in these benefit plans will be provided if an employee receives an offer of employment.
If hired, employee will be in an “at-will position” and the Company reserves the right to modify base salary (as well as any other payment or compensation program) at any time, including for reasons related to individual performance, Company or individual department/team performance, and market factors.
Juniper’s pay range data is provided in accordance with local state pay transparency regulations. Juniper may post different minimum wage ranges for permanent residency petitions pursuant to US Department of Labor requirements.",$1 to $5 billion (USD),Telecommunications Services,Company - Public,Telecommunications
Senior Data Engineer,san-jose,"SafeAI
2.9","Santa Clara, CA",2.9,Employer Provided Salary:$130K - $180K,3.2,3.0,2.6,3.4,3.2,1 to 50 Employees,Company - Public,"About SafeAI
SafeAI sees the future of heavy industry with off-road autonomous vehicles reshaping industries like construction and mining. We are pioneering a new approach to autonomous off-road equipment with AI-powered, vehicle and manufacturer agnostic technology that enables heavy industry operations to retrofit any piece of equipment with autonomous technology. Since 2017, we’ve been steadily establishing a foundation for the future, targeting the most important, heavily used off-road vehicles and industry segments to drive meaningful impacts across safety, productivity and cost reduction. We are now entering an era of massive industry adoption and are excited to be a commanding force in accelerating this movement to transform heavy industry with connected autonomy.

About the Team
As a fast paced, high growth company serving a very important mission, our amazing and talented team is a huge part of bringing this mission to reality. The work that you do at SafeAI will give you a unique perspective on developing and deploying leading edge autonomous technology and solutions, while working with top tier participants in the industry, and across the globe. The leadership team at SafeAI brings a unique blend of autonomous technology and industry specific experience from some of the top companies in the world, such as Google, Apple, Tesla, Continental, Uber, Caterpillar, BHP and Rio Tinto. We are strategically headquartered in Silicon Valley, with team members and office locations established in Perth, Australia, Tokyo, Japan and New Delhi, India that you would collaborate with on a regular basis.

SafeAI is seeking a highly capable Senior Data Engineer to develop our data platform for managing large datasets critical to the development and evaluation of our autonomous vehicle software stack.
Key Responsibilities
Develop data set processes for data modeling, mining, and production
Build data pipelines for collecting & processing data from multiple data sources: from the point of ingestion to useful insight
Build data analysis and visualization pipelines for ML insights
Identify optimal approaches for resolving data quality or consistency issues
Ensure successful system delivery to the production environment and assist the operations and support team in resolving production issues, as necessary
Develop, test, and maintain architectures for data stores, databases, processing systems, and microservices
Automate everything for measuring, testing, updating, monitoring and alerting the data platform
Partner with MLOPS infrastructure engineers to build and implement support for versioned, traceable, and immutable datasets
Collaborate with ML engineers to build data annotation, ingestion and management platform
Minimum Qualifications
B.S. in computer engineering, web development, computer science or equivalent experience
5+ years of experience developing and orchestrating at scale business critical data pipelines in a cloud environment
Strong experience in data engineering technologies, large-scale storage, databases, analytics systems, visualization tools and their common architectures.
Hands-on experience setting up, configuring, and maintaining SQL and no-SQL databases (MySQL/MariaDB, PostgreSQL, MongoDB)
Good design and architectural skills to build microservices
Strong Python and/or SQL skills Ability to manipulate JSON/XML data and exposure with other data manipulation platforms
Preferred Qualifications
Experience with object detection and image segmentation
Experience with C99 and C++ programming
Experience with Git and GitLab
Experience with GIS data and mapping
Experience with dense pointcloud visualization
Knowledge of client-side scripting and JavaScript frameworks such as AngularJS, ReactJS and NodeJS
Knowledge of geographic projections
The base salary range for this position is $130K-$180K per year. SafeAI’s pay ranges are determined by role, level, and location. Within the range, the successful candidate’s starting base pay will be determined based on factors including job-related skills, experience, qualifications, relevant education or training, and market conditions. These ranges may be modified in the future.
The Perks
In addition to a very competitive compensation and benefits package, we offer a fantastic culture and place to work within an established start-up environment. We provide plenty of snacks, grab & go meals and drinks to get you through the day, and we celebrate our accomplishments with off-sites gatherings and frequent happy hours. As an Equal Opportunity Employer M/F/D/V/SO, we do not discriminate in employment and personnel practices on the basis of race, sex, age, handicap, religion, national origin or any other basis prohibited by applicable law.
Benefit highlights:
Competitive compensation package, including stock options
Medical, dental, and vision benefits for employees and dependents
401(k) plan
Flexible Spending Accounts (FSA) and Health Savings Accounts (HSA)
Flexible vacation policy
Free access to onsite Fitness Center
Learning and development programs
Employee assistance program
Adoption assistance program
Community snacks, meals & beverages
We hope that you’re a great candidate for this position and look forward to speaking with you!",-1,-1,Unknown / Non-Applicable,-1
Senior Software Engineer (Full Stack) - Big Data Solutions,san-jose,"U.S. Bank National Association
3.8","Palo Alto, CA",3.8,Employer Provided Salary:$140K - $181K,3.6,3.8,3.4,3.5,3.7,10000+ Employees,1863,"At U.S. Bank, we’re on a journey to do our best. Helping the customers and businesses we serve to make better and smarter financial decisions and enabling the communities we support to grow and succeed. We believe it takes all of us to bring our shared ambition to life, and each person is unique in their potential. A career with U.S. Bank gives you a wide, ever-growing range of opportunities to discover what makes you thrive at every stage of your career. Try new things, learn new skills and discover what you excel at—all from Day One.
Job Description
About the team:
Talech helps grow sales and delivers a positive in-store customer experience. Business Customers can manage inventory better and avoid tying up cash flow with excess stock levels. Run your business better. Everyday funding. No monthly minimum. Contactless payments. It is a Point Of Sale (POS) system allows you to create orders, apply discounts, manage inventory and view sales online with just a few taps

The role will plan, design, implement &/or test the talech’s big data applications and tools, ensure best system performance, data integrity and security.

Essential Responsibilities:
Responsible for designing, developing, testing, operating and maintaining products
Takes full stack ownership by consistently writing production-ready and testable code
Consistently creates optimal design adhering to architectural best practices; considers scalability, reliability and performance of systems/contexts affected when defining technical designs
Performs analysis on failures, propose design changes, and encourage operational improvements
Makes sound design/coding decisions keeping customer experience in the forefront
Takes feedback from code review and apply changes to meet standards
Conducts code reviews to provide guidance on engineering best practices and compliance with development procedures
Accountable for ensuring all aspects of product development follow compliance and security best practices
Exhibits relentless focus in software reliability engineering standards embedded into development standards
Basic Qualifications
Bachelor’s degree, or equivalent work experience
Five to Six years of relevant experience
Preferred Skills/Experience
Strong experience in Spark, PySpark, Sqoop, Pig, Hive, and No SQL data Stores
Previous experience as a full stack engineer.
Advanced knowledge of front-end languages including HTML5, CSS, JavaScript, and JQuery.
Strong programming skills in Python and/or Java required
Strong SQL skills and database knowledge required
Clear understanding of big data system concept and design methodology
Design thinking mind-set and results-oriented
Experience in an Agile Development environment
Experience in ReactJS development will be a strong plus
Knowledge with modern Server architecture, such as Spring Boot, Spring will be a plus
Experience in building microservices will be a plus
Familiarity with one of the core cloud provider services, preferably AWS or Google Cloud, will be a plus
Familiarity with Docker/Kubernetes will be a plus
Strong written and verbal communication skills
Proven collaboration and influencing skills
If there’s anything we can do to accommodate a disability during any portion of the application or hiring process, please refer to our disability accommodations for applicants.

Benefits:
Our approach to benefits and total rewards considers our team members’ whole selves and what may be needed to thrive in and outside work. That's why our benefits are designed to help you and your family boost your health, protect your financial security and give you peace of mind. Our benefits include the following (some may vary based on role, location or hours):
Healthcare (medical, dental, vision)
Basic term and optional term life insurance
Short-term and long-term disability
Pregnancy disability and parental leave
401(k) and employer-funded retirement plan
Paid vacation (from two to five weeks depending on salary grade and tenure)
Up to 11 paid holiday opportunities
Adoption assistance
Sick and Safe Leave accruals of one hour for every 30 worked, up to 80 hours per calendar year unless otherwise provided by law
EEO is the Law
U.S. Bank is an equal opportunity employer committed to creating a diverse workforce. We consider all qualified applicants without regard to race, religion, color, sex, national origin, age, sexual orientation, gender identity, disability or veteran status, among other factors.
E-Verify
U.S. Bank participates in the U.S. Department of Homeland Security E-Verify program in all facilities located in the United States and certain U.S. territories. The E-Verify program is an Internet-based employment eligibility verification system operated by the U.S. Citizenship and Immigration Services.
The salary range reflects figures based on the primary location, which is listed first. The actual range for the role may differ based on the location of the role. In addition to salary, US Bank offers a comprehensive benefits package, including incentive and recognition programs, equity stock purchase 401k contribution and pension (all benefits are subject to eligibility requirements). Pay Range: $139,995.00 - $164,700.00 - $181,170.00",$10+ billion (USD),Banking & Lending,Company - Public,Financial Services
Cellular 4G/5G Firmware Data and Automation Engineer,san-jose,"Apple
4.2","Cupertino, CA",4.2,-1,-1,-1,-1,-1,-1,10000+ Employees,1976,"Summary
Posted: Dec 12, 2022
Role Number:200448933
Do you have a passion for invention and self-challenge? As part of a world class modem team, you’ll craft sophisticated groundbreaking embedded firmware that deliver more performance in our products than ever before! We'll work across disciplines to transform improved hardware elements into a single, coordinated design. Join us, and you’ll help us innovate new wireless systems technologies that continually outperform the previous iterations. By collaborating with other product development groups across Apple, you’ll push the industry boundaries of what wireless systems can do and improve the product experience for our customers across the world. As a Cellular 4G/5G Firmware Data and Automation Engineer, you will be at the center of the embedded 5G/4G/multimode cellular firmware effort within a silicon design group responsible crafting and productizing powerful cellular SoCs.
Key Qualifications
Minimum BS and 3+ years of relevant industry experience
Ability to think creatively and identify, build, and support solutions and roadmaps focused on automation and reduction of manual processes
Strong critical thinking and communication skills with the ability and desire to learn and evaluate new technologies
Experience in utilizing analytics and statistical methods to transform data into useful insights and actionable results
Proficient Python developer with 3+ years of experience in developing data processing & test automation pipeline or similar projects
Good understanding of AWS components including S3, Kinesis firehose, Kibana, Elasticsearch, Redshift
Experience in creating data processing & visualization pipeline over AWS.
Proven knowledge and experience with relational database (e.g Postgres), SQL and non-relational database (e.g.Mango DB) is required
Experience with Testrail is a plus
Experience with popular data visualization tools is a plus
Description
Design and develop robust and modular data processing & automation systems across hardware and software that enable engineers to be more efficient produce quality work Develop scripts for implementing firmware verification test cases Use external tools and internal tools/services from other teams within Apple We are looking for someone with a passion for technology, automation, data and an ability to iterate quickly.
Education & Experience
Minimum BS and 3+ years of relevant industry experience
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $130,000 and $242,000, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",$10+ billion (USD),Computer Hardware Development,Company - Public,Information Technology
"Senior Software Engineer - Data Infrastructure,Live Streaming Infrastructure",san-jose,"TikTok
3.6","Mountain View, CA",3.6,Employer Provided Salary:$187K - $280K,3.4,3.4,3.1,3.6,3.0,1001 to 5000 Employees,2016,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About Team
Popular video products of Tiktok are all empowered by our cutting-edge cloud technologies. As a software engineer in this team, you will have the opportunity to tackle challenges of huge amounts of data from both server side and client side generated by traffic through billions of users around the world, while leveraging your expertise in data engineering. You will work with software engineers, data analysts and other stakeholders to use the data driven approach to build the best live streaming experience for billions of users.

The responsibility of this position:
Design, build, and maintain efficient and reliable data pipelines to move and transform data (both large and small amounts).
Design and build data solutions to drive data driven initiatives.
Drive internal process improvements and automate manual processes for data quality and SLA management.
Work efficiently with different cross-functional partners.
Qualifications
Bachelor's degree in Computer Science or a related technical background involving software/system engineering, or equivalent working experience.
Good programming experience with at least one of the following languages: C, C++, Java, Python, or Go.
Experience in custom ETL/data pipeline design, implementation, and maintenance to support business insights and directions.
Experience with data processing platforms (Hadoop, Spark, Hive, Flink, Kafka, ClickHouse).
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or an accommodation, please reach out to us at grey.liu@tiktok.com
Job Information
The base salary range for this position in the selected city is $187000 - $280000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",Unknown / Non-Applicable,Internet & Web Services,Company - Private,Information Technology
"Software Engineer, Data Engineering",san-jose,"Neuralink
4.1","Fremont, CA",4.1,Employer Provided Salary:$145K - $175K,4.1,3.7,3.6,3.6,2.8,201 to 500 Employees,2016,"Company Description:
We are creating the future of brain-computer interfaces: building devices now that have the potential to help people with paralysis regain mobility and independence and invent new technologies that could expand our abilities, our community, and our world.
Team Description:
Engineers on the Laboratory Systems software team work closely with other teams – neuroscientists, physicists, roboticists, chip designers, and mechanical engineers – to build Neuralink's centralized data aggregation and analysis platform. We are building a data platform to collect, organize, and visualize a diverse set of data ranging from neural signal recordings to brain histology images to microfabrication manufacturing data. As a member of our team, you will have the opportunity to own projects that drive engineering and experimentation at Neuralink.
About you:
You find large challenges exciting and enjoy discovering and defining problems as much as solving them.
You deliver. You may enjoy thoughtful conversations about problems and perfecting designs, but in the end, you know that what matters is delivering a manufacturable solution that works every time.
You are a cross-disciplinary team member. You are excited to work with and learn from software, mechanical, electrical, materials, biological engineers, and neuroscientists. You are comfortable communicating across teams.
Resourceful, flexible and adaptable; no task is too big or too small.
Key qualifications:
3+ years of software engineering experience
Experience with data engineering - ETL Pipelines, Data Lakes, Database Management, etc.
Preferred qualifications:
Experience with Apache Spark or other distributed compute systems
Experience building and shipping production-grade ETL Pipelines
Experience with workflow orchestration tools (e.g. Apache Airflow, AWS Step Functions)
Experience building Infrastructure for machine learning pipelines
Pay Transparency:
Based on California law, the following details are for California individuals only:
California base salary range:
$145,000—$175,000 USD
For full-time employees, your compensation package will include two major components: salary and equity. Guidance on salary for this role will be determined according to the level you enter the organization (with the ability to gain more through time as you contribute).
Full-Time Employees are eligible for equity and benefits listed below in addition.
What we offer:
An opportunity to change the world and work with some of the smartest and most talented experts from different fields.
Growth potential. We rapidly advance team members who have an outsized impact.
Excellent medical, dental, and vision insurance through a PPO plan; parental leave.
Flexible time off + paid holidays.
Equity + 401(k) plan.
Commuter Benefits.
Meals provided.
Multiple studies have found that a higher percentage of women and BIPOC candidates won't apply if they don't meet every listed qualification. Neuralink values candidates of all backgrounds. If you find yourself excited by our mission but you don't check every box in the description, we encourage you to apply anyway!
Neuralink provides equal opportunity in all of our employment practices to all qualified employees and applicants without regard to race, color, religion, gender, national origin, age, disability, marital status, military status, genetic information or any other category protected by federal, state and local laws. This policy applies to all aspects of the employment relationship, including recruitment, hiring, compensation, promotion, transfer, disciplinary action, layoff, return from layoff, training and social, and recreational programs. All such employment decisions will be made without unlawfully discriminating on any prohibited basis.",Unknown / Non-Applicable,Biotech & Pharmaceuticals,Company - Private,Pharmaceutical & Biotechnology
"Data Engineer, Palo Alto",san-jose,"Rhombus
4.0","Palo Alto, CA",4.0,$91K - $142K (Glassdoor est.),4.0,5.0,5.0,3.0,5.0,Unknown,Company - Public,"Rhombus is purposefully transforming the nation's defense and national security enterprises with Guardian, its Artificial Intelligence platform for strategic, operational, and tactical decision-making at the speed of relevance.
We are looking for people who are driven by a sense of purpose. In this role, you will serve as a Data Engineer to solve our customer's uniquely complex problems. We expect you to be a systems-level thinker and a real doer. You will excel in this role if you are hungry to make a difference and are intellectually bold. And we sure hope that you smile when you hear our clients say, ""If we can dream it, Rhombus can do it.""
Come join our cross-disciplinary and world-class team of technologists who are working hard every day to deliver game-changing solutions to transform national security.
Location
Palo Alto, CA
Job Description
Rhombus' Data Engineers are instrumental in designing and implementing data engineering activities on topical, mission-driven projects that inform our national security agenda. They analyze, build, and maintain our organization's data infrastructure and processing systems. As a Data Engineer, you'll perform various code development and query needs for integration with new and existing applications, dashboards and machine learning pipelines. You'll work cross functionally with other departments and utilize your skills at all stages of the analytics pipeline to create results that drive business values and customer success! You'll be asked to travel to client sites where you'll engage and collaborate directly with the client to discuss data pipelines, solutioning, and to ensure a strong client connection.
This role will require travel to client sites in Honolulu, HI; Omaha, NE and/or Colorado Springs, CO. Frequency will depend on business needs and may vary at times but can be upwards of twice per month. Last minute notice to travel to client sites may be given at times.
Responsibilities:
Develop code using various programming and scripting languages to automate data ingestion and improve data management processes.
Architect data repositories, stand up data platforms and develop data pipelines for ingestion, transformation, and aggregation.
Review existing architecture, data strategy, and improve processes for data governance, data quality, and metadata management.
Extract and analyze raw data from multiple data sources via APIs, SQL Stored Procedures, or Python scripts.
Ability to develop scripts and programs for converting various types of data into usable formats and support project team to scale, monitor and operate data platforms.
Collaborate with a multi-disciplinary team of analysts, data scientists, data engineers, developers, and data consumers in a fast-paced, agile environment.
You'll use your experience in analytical exploration and data examination while you manage the assessment, design, building, and maintenance of scalable platforms for clients.
Communicate project status and results to various levels of leadership.
Qualifications:
A Bachelor's degree in Data Analytics, Computer Science, Computer Engineering, Information Systems/Sciences, or other relevant area (or equivalent experience) and at least 1 year of professional experience, or a Master's degree with strong academic project experience.
Experience with 1 or more programming and scripting languages, with a strong focus on Python, Pandas and Numpy. Other languages include: Shell, PERL, Java, C/C++/C#, Scala, etc.
Experience with 1 or more of the following relational, noSQL and/or file based storage (e.g. MYSQL, MongoDB, SQL Server, Oracle, Postgres, Hbase, DynamoDB, etc.)
Experience building and maintaining ETL data pipelines
Experience with software development life cycle including testing, documenting, delivery and support
Working knowledge of AWS/cloud technologies
Experience using query optimization as well as data modeling techniques.
Familiarity with machine learning frameworks (such as TensorFlow, Scikit-Learn, etc.)
The ability to obtain and maintain a US security clearance. U.S. citizenship is required as only U.S. citizens are eligible for a security clearance
Must be eligible for Secret clearance and for TS/SCI
Personal Qualities:
Ability to contextualize data as it relates to Rhombus' vision. We want someone who can understand the ""why"" and ""so what"", and not just the ""how"". Our Data Engineers help us transmit the enthusiasm we have around the data work to the individuals doing that work.
Must have strong problem-solving skills and demonstrated excellent oral and written communication skills.
We're seeking folks with strong intellectual curiosity and creativity, with an ability and willingness to learn new skills and apply novel solutions to problems.
Comfort in a fast-paced start-up environment is crucial, with the ability to consistently revise your approach in response to new information, and to be flexible and adaptive.
Benefits
Full medical, dental, vision coverage for employee and dependents
401k matching program
PTO and Holidays
Bonus and other incentive programs
About Rhombus
Rhombus Power Inc. (Rhombus) is a NASA Research Park startup located in the heart of Silicon Valley at Stanford Research Park in Palo Alto. We use cutting-edge cross-disciplinary approaches to solve pressing Big Data and Sensing problems in security, energy and healthcare. Our advisory board includes two Nobel Laureates and a Draper Prize winner.
Rhombus compensates, motivates, and develops employees, who are trusted, empowered, and involved. Employees have clear roles and expectations – and their roles are flexible enough to move at the speed of innovation in order to meet and exceed client expectations. We have a unique culture of global purpose, rooted in the innovation and progress of Silicon Valley.
Rhombus knows that diversity is a condition for success. We are committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer.",-1,-1,Unknown / Non-Applicable,-1
"Senior Backend Engineer, Data",san-jose,"Recruiting From Scratch
3.9","Saratoga, CA",3.9,Employer Provided Salary:$120K - $200K,4.0,3.6,3.5,3.9,3.9,1 to 50 Employees,2019,"Who is Recruiting from Scratch:
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
From our client
We’re looking for engineers to join our founding team and help us invent the future of data analytics. We’re interested in talking to talented engineers up and down the stack, but for this role we're focused on engineers that lean towards backend and distributed systems development.
We’re an early team so we’re still establishing large parts of our software stack - you will have major ownership over the product and you’ll help us pick the right technologies. We have a culture of autonomy and ownership and want engineers who are excited to drive the company forward. As an early employee you’ll help us craft our culture and will be aware of (or participate in) customer development and go to market.

About you:
You love to build high-quality, reliable, well-tested systems that solve real problems.
You have experience designing scalable, reliable architectures that are secure and compliant.
You have experience identifying performance bottlenecks, triaging system failures and coming up with innovative solutions to prevent these failures in the future.
You are excited to research, drive, and own our data processing infrastructure.

Nice-to-have:
Experience building data analytics applications.
Experience building products in a regulated field.
Familiarity with our current application stack: Python, React / Redux, GraphQL, Redis, Flask, Celery, and Docker.
Experience using AWS services like S3, DynamoDB, and Cloudwatch.
Experience with analytics DBMS’s like Presto, BigQuery, Hive, Redshift and Snowflake.
Experience with data processing technologies like Spark, Dask, Presto, and Apache Arrow.
This role is on-site in New York City
Salary Range: $120,000-$200,000 base.",$1 to $5 million (USD),Staffing & Subcontracting,Company - Private,Human Resources & Staffing
"Senior Engineer, Data Pipeline Engineering",san-jose,"BoostUp.ai
4.1","Santa Clara, CA",4.1,$120K - $182K (Glassdoor est.),3.4,3.4,5.0,3.4,5.0,1 to 50 Employees,Self-employed,"About Us:

BoostUp.ai is the first Intelligent Revenue Management Platform built for the digital-selling and remote sales era. BoostUp solves the oldest problem in sales: the black box problem. The black box of Sales forecasting, pipelines, activity, and deals. Sales today operates on biased self-reported information and leaders are forced to use guess-work to make decisions causing forecasting slippage, lower win rates, inconsistent quota attainment, poor capacity allocation and inefficient pipeline management.
BoostUp’s AI platform brings holistic meaning to structured and unstructured sources of sales data - from emails, calendars, call recordings, transcripts, slack and such and helps sales leaders make better, more accurate decisions. Those capabilities are even more essential in the current, 100% distributed work model - which some sales teams are navigating for the first time.
BoostUp is founded by repeat SaaS entrepreneurs from Google, Yahoo & VMware and funded by top VCs. BoostUp’s market is composed of large B2B companies constituting $10B+ in initial TAM.
Experience and Skills
You are currently working on the team managing a large scale data processing pipeline.
You are a senior engineer, able to self-motivate and drive your work to completion.
You have 8+ years of professional software development experience
You have 5+ years of experience with developing data applications in Python.
You have a deep knowledge of building, scaling and managing a large scale real-time data pipeline (processing 100s of millions of events per day).
You have a deep knowledge and experience working with two or more of the following.
Large scale message queues like Kafka / Kinesis
Real-time stream processing systems like Spark, Apache Flink, Kinesis Data Streams
You have some experience understanding the trade-offs between scalability, reliability, developer/ops overhead and infrastructure cost of building scalable data pipelines.
You have significant knowledge of AWS. Should have built or managed a large scale data pipeline hosted within AWS.
You have significant experience working with either SQL based databases (PostGres, etc) or MongoDB.
Benefits
Full medical, dental and vision coverage
401(k) plan
Take as you need vacation plan",-1,-1,Unknown / Non-Applicable,-1
Senior Data Engineer - SFL Scientific,san-jose,"Deloitte
4.1","San Jose, CA",4.1,$107K - $161K (Glassdoor est.),4.3,4.0,3.8,3.8,3.3,10000+ Employees,1850,"Senior Data Engineer, Specialist Senior - SFL Scientific

The SFL Scientific, a Deloitte Business practice brings together several key capabilities to architect integrated programs that transform our clients' businesses, including Strategic Growth Transformation, Transformation Strategy & Design, Technology Strategy & Business Transformation, and AI & Data Strategy.

Professionals will serve as trusted advisors to our clients, working with them to make clear data-driven choices about where to play and how to win - ultimately driving growth and enterprise value.

We are hiring a Senior Data Engineer to support the design and develop solutions for various organizations looking to implement tools, software, and processes that support machine learning and AI initiatives across healthcare, life sciences, manufacturing, energy, and other sectors.

Work you'll Do:

As a Senior Data Engineer, you'll work cross-functionally with data scientists, machine learning engineers, project managers, and industry experts to develop robust AI infrastructure and deployment services for our novel machine learning applications. Key to this role is the ability to demonstrate both traditional data engineering expertise, leveraging cloud/enterprise/open-source solutions, and constructing IT infrastructure for organizations across a wide variety of industries.

In our consultative approach, we are committed to providing the best technical solutions for each client and solution. Our engineering team leverages emerging technologies and best practices across data security, documentation, cloud services and engineering architecture to create solutions and products that address complex issues and business problems faced by global organizations. Some of our novel use cases include cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, and renewable energy.

Join us to expand your technical career through the lens of consulting and work on many novel projects and use cases to expand your data engineering & AI skills!
Work with clients to design, develop, and deploy new architectures for machine learning applications such as ELT pipelines, database & data warehouse solutions, compute infrastructure, cloud services, and containerized solutions
Leverage skills in modern data architecture, cloud engineering, data transformation, and management of structured and unstructured data sources
Support and enhance data architecture, and data pipelines, and define database schemas (Graph DB, SQL, NoSQL) to support algorithm scalability and deployment based on agile business priorities and technology initiatives
Participate in architectural discussions to ensure solutions are designed for successful deployment, security, and high availability in the cloud or on-prem
Adopt and maintain engineering best practices in data security, retention, and sensitivity
Present to key stakeholders, including architecture findings and design of infrastructure, hardware, software, cloud, and deployment, etc.
Mentor, motivate and coach junior members on technical best practices and inspire professional development

The Team

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel, and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Basic Qualifications:
Bachelor's degree in a STEM field or equivalent experience (Computer Science, Engineering, Physics etc.); Master's degree preferred
2+ years in data engineering, data architecting or cloud engineering, while building highly scalable and secure solutions
1+ years leading project/ client engagement teams in the execution of data engineering solutions
Expert in languages such as Python, SQL, Shell scripting, Bash, & Linux commands
Expert in logging, monitoring, and data documentation best practices
Extensive hands-on experience with source version control (e.g., Git), containerization (e.g., Docker), container orchestration (e.g., Kubernetes), and supporting libraries
Experience with distributed computing frameworks (e.g., Spark, Dask), cloud platforms (e.g. AWS, Azure), multi-cloud service providers (e.g., Snowflake, Dataricks) & on-prem alternatives (e.g. MinIO)
Experience with workflow and data management solutions such as Fivetran, Airflow, Kafka, Glue, etc.
Experience designing data architectures and SQL, NoSQL & Graph databases
Strong analytical and problem-solving skills with the ability to develop novel and efficient solutions
Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve
Live within commuting distance to one of Deloitte's consulting offices
Limited immigration sponsorship may be available.

Preferred Qualifications:
Master's or Ph.D. degree in Computer Science, Information Technology, or related STEM field
AWS/Azure Certifications (AWS/Azure Certified: SysOps Administrator, DevOps Engineer, Solutions Architect)
Demonstrated experience launching AI/ML solutions into production environments, such as into cloud or HPC/GPU environments

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $138,000 to $230,000.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy23

#SFL23

#LI-WW1",$10+ billion (USD),Accounting & Tax,Company - Private,Financial Services
Sr. Data Engineer,san-jose,"Supernal
2.8","Fremont, CA",2.8,Employer Provided Salary:$152K - $233K,3.0,2.4,2.2,3.7,3.3,Unknown,Company - Private,"Supernal is at the forefront of creating emerging mobility solutions that will foster the development of human-centered cities. We are designing a completely new electric vertical take-off and landing (eVTOL) aircraft tailored to the mobility needs of future cities. This allows passengers a seamless intermodal journey that safely transports them to their final destination. We fuse research in autonomy, robotics, aviation and services to define a new category of mobility for the world's communities. We believe in creative thinking and collaboration to help build a better mobility experience for everyone, improving people's ability to move – whether for work or play.
What we do:
The Data Engineer is responsible for identifying, implementing, and supporting data use cases and owners throughout the business that can use data engineering and analytics to improve outcomes. Activities include collaboration with business units to identify ways data can improve their outcomes, designing use case ontologies, building, and maintaining start to finish data pipelines across disparate sources, standing up no code dashboards, and designing / guiding standard processes in code, data, and process management. This is a highly collaborative role and will work closely with collaborators and partners across the business and the rest of the Data team. It may also require collaboration with third party technology partners, Corporate IT, and the ERD Digital Tools team.
What you can do:
Transform noisy, real-world data into valuable information that enables the business to quickly and optimally make data driven decisions
Partner with your team and technical stakeholders and deliver internal data and analytics products on critical use cases where data can be used to excavate hidden insights (e.g., battery testing, testing and certification, AI, demand forecasting, cyber security)
Write, maintain, and improve code, pipelines, ontologies, visualizations, interactive tools, and dashboards to enable technical and non-technical users to leverage data
Identify key data sets through deep engagement with use cases and workflows
Design, build, and manage end to end data pipelines in a cohesive data platform
Develop scalable, reliable, manageable data pipelines
Develop and train CI/CD practices for data integrations
Partner with technical team members and collaborators to design solutions for MLOps, data quality verification, anomaly detection, real-time streaming pipelines
Design, integrate, and document technical components for seamless data discoverability and usage
Triage and address support requests (e.g., workflow and product issues)
Actively enable a data driven and innovative culture within Supernal
Communicate insights in a way that resonates with internal and external parties
Design and guide standard methodologies in data, code, and process management
Drive data strategy across the organization including leading training sessions in our data systems
Stay up to date on industry best practices and standards
Other duties as assigned
What you can contribute:
Bachelor's degree in relevant field such as computer science, mathematics, physics, software engineering, data science, or information sciences preferred
A minimum of five (5) years of proven experience with big data platforms across diverse use cases, including data management (an equivalent combination of education and experience may be considered)
Experience and architectural understanding working with one (1) or more cloud data warehouses—Azure Synapse, Snowflake, Google BigQuery, AWS Redshift.
Experience working with highly regulated data in the aerospace, automotive, healthcare, and/or financial industries
Professional experience with / comfortable using: Programming languages, cloud services such as Azure (preferable), databases and data lakes,
Using SQL, Spark (any interface, but PySpark preferred), Git, Command line, CI/CD
Solid expertise and skills in OO programming paradigm and implementation
Must have good understanding of the inner workings and hands-on skills with data technologies: Kafka, Spark, etc.
Knowledge of various ETL techniques and frameworks; experience integrating data from multiple data sources
Solid understanding of distributed system concepts, cloud computing
Robust development abilities and a strong predilection for automation
Ability to develop and handle data pipelines and lineage
Creative and curious problem solver, able to take an ambiguous and complex need and develop data / analytics solutions
Able to work in a rapidly changing and ambiguous environment
Excellent written and verbal communication skills with ability to work with diverse, technical, and non-technical colleagues
Forward-thinking, continuous learner, and strong decision maker
Collaborative teammate with commitment to Diversity, Equity, and Inclusion
You may also be able to contribute:
Master's degree preferred
Any offer of employment is conditioned upon the successful completion of a background check. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, citizenship, sex, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other category or class protected under applicable federal, state or local law. Individuals with disabilities may request a reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation at: ta-support@supernal.aero
The job responsibilities of this position require access to certain technology and/or software source code subject to U.S. export control laws and certain software that can only be used and accessed by U.S. Persons. Accordingly, this position is limited to applicants that are US Persons, i.e., U.S. citizens, lawful permanent residents as defined by 8 U.S.C. 1101(a)(20),or protected individuals as defined by 8 U.S.C. 1324b(a)(3).
Base pay offered may vary depending on skills, experience, job-related knowledge and location. This position is also eligible for a bonus as part of total compensation.
The pay range for this position is:
$151,840—$232,960 USD
Click HERE or visit: https://jobs.supernal.aero/benefits to view our benefits!",-1,Aerospace & Defense,Aerospace & Defense,Unknown / Non-Applicable
Field Project Engineer- Hyperscale Data Center,san-jose,"Eaton Corporation
3.9","Pleasanton, CA",3.9,Employer Provided Salary:$77K - $113K,3.6,3.9,3.4,3.7,3.7,10000+ Employees,1911,"Eaton’s NAS North American Sales division is currently seeking a Field Project Engineer- Hyperscale Data Center. The preferred remote work locations include Houston, TX, Chandler AZ, Littleton CO, Pleasanton CA, Tukwila WA, San Antonio, TX, Austin, TX, Dallas, TX, Nashville, TN, Waukesha, WI, Chicago, IL, Raleigh, NC and Wilsonville OR. However, this role is also open to other remote locations. This role will support customer locations in Eastern to Pacific time zones.

The expected annual salary range for this role is $77249.97 - $113299.96 a year.
Please note the salary information shown above is a general guideline only. Salaries are based upon candidate skills, experience, and qualifications, as well as market and business considerations.
What you’ll do:
The primary function of the Project Engineer is to serve as the technical liaison between the product lines, field sales and the customer during the execution of Large and Major complex project orders. In this role, you will have technical ownership of the order and creates a positive customer experience through a proactive approach to project support and issue resolution. The Project Engineer leverages centralized resources to manage documentation and resolve issues and builds relationships across customers and Eaton facilities to deliver a successful project. You will work independently on daily tasks, taking direction from Project Manager, Sales Engineers, and the Project Management Organization (PMO) Management Team.

In this function you will:
Develop and maintain relationships with internal and external customers in assigned territory.
Interpret customer plans and specifications to provide accurate information on project orders.
Develop and execute proactive order entry strategies that will facilitate order fulfillment and technical support as well as minimize order delay.
Serve as the customer’s advocate by relaying the appropriate level of urgency to peer contacts in the operations and escalating issues as required to management.
Use Bid Manager for product configuration, changes and pricing.
Provide technical support and follow through on warranty issues.
Coordinate and interpret Plant Drawings
Work closely with the Project Management Team including Project Managers, Sales Engineers, Project Coordinators, other Project Engineers and the Documentation Team.
Leverage centralized resources to create and manage project submittal and O&M documentation.
Manage daily phone and email activity, providing directions, solutions and updates.
Pursue continuous learning of products and applications related to engineered products.
Take leading role in developing, mentoring, and monitoring on-the-job training for new and existing less experienced Project Engineers.
Represent sales at customer witness tests, inspections, and on-board approval meetings/visits.
Perform all other duties as required by Management.
Qualifications:
Required (Basic) Qualifications:
Bachelor’s degree from an accredited institution
Minimum 3 years of work experience in sales, sales support, technical role or applicable field
Sponsorship is not available. Candidates must be legally authorized to work in the U.S. on an ongoing basis without requiring company sponsorship.
Preferred qualifications:
Bachelor’s degree in Engineering or other technical fields
Electrical industry expertise and product knowledge
Prior sales and/or sales support experience
Skills:
Position Criteria:
Possess technical sales aptitude, market channel knowledge and power distribution expertise
Capable of working in a team environment, using strong communication and interpersonal skills
Ability to establish customer relationships within the market area while maintaining and growing existing customer relationships
Knowledgeable of Eaton product and service capabilities and can assemble standard offerings to meet customer needs with occasional internal oversight
Possess necessary computer skills including: Adobe Acrobat, AutoCAD, Internet applications, Microsoft Office applications, and other product configuration tools
Possess organizational, presentation, training, and planning skills
Knowledgeable of market and industry issues, key trends, and surround competitors
We are committed to ensuring equal employment opportunities for all job applicants and employees. Employment decisions are based upon job-related reasons regardless of an applicant's race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability, marital status, genetic information, protected veteran status, or any other status protected by law.
Eaton considers qualified applicants regardless of criminal histories, consistent with local laws. To request a disability-related reasonable accommodation to assist you in your job search, application or interview process, please call us at 1-800-836-6345 to discuss your specific need. Only accommodation requests will be accepted by this phone number.
We know that good benefit programs are important to employees and their families. Eaton provides various Health and Welfare benefits as well as Retirement benefits, and several programs that provide for paid and unpaid time away from work. Click here for more detail: Eaton Benefits Overview. Please note that specific programs and options available to an employee may depend on eligibility factors such as geographic location, date of hire, and the applicability of collective bargaining agreements.",$10+ billion (USD),Electronics Manufacturing,Company - Private,Manufacturing
Senior Technical Marketing Engineer (Data Protection),san-jose,"Palo Alto Networks
4.3","Santa Clara, CA",4.3,Employer Provided Salary:$126K - $204K,4.2,4.2,4.0,4.5,3.9,10000+ Employees,2005,"Company Description

Our Mission
At Palo Alto Networks® everything starts and ends with our mission:
Being the cybersecurity partner of choice, protecting our digital way of life.
We have the vision of a world where each day is safer and more secure than the one before. These aren’t easy goals to accomplish – but we’re not here for easy. We’re here for better. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.
We’re changing the nature of work. Palo Alto Networks is evolving to meet the needs of our employees now and in the future through FLEXWORK, our approach to how we work. From benefits to learning, location to leadership, we’ve rethought and recreated every aspect of the employee experience at Palo Alto Networks. And because it FLEXes around each individual employee based on their individual choices, employees are empowered to push boundaries and help us all evolve, together.

Job Description

Your Career
As a Sr. Technical Marketing Engineer (Data Loss Prevention) at Palo Alto Networks, you will join a team responsible for driving our Cloud Applications and Data security products, including SaaS, IaaS, Network and Endpoint Data Protection. You will work with cutting-edge technology, redefining the future of network security.
This role plays a key role in supporting our product managers, marketing teams, and customers by developing outbound technical communication, including product best practices, competitive reviews, demo environments, and ownership of product betas. You will perform competitive analysis, perform technical gap analysis and support the product management in identifying next-generation innovations. This is a critical customer facing role within the company and one where the right person can have significant impact.
The ideal candidate would be able to influence strategy, collaborate with marketing and sales teams to execute go to market strategies, act as a thought leader at the industry level, evangelizing the products and product strategy both internally and externally.
Your Impact
Develop, constantly refine, and execute the technical marketing plan
Be responsible for the creation, maintenance, and delivery of effective technical tools, whitepapers, demos, videos and technical training for sales, customers, and partners
Lead the automation within and across the cross-functional teams and strive to achieve technical and operational excellence in every step of the releases
Lead the competitive research and testing to identify key competitive advantages of our product lines and deliver them to sales, customers, and partners
Be a key technical evangelist for Palo Alto Networks, speaking at seminars, conferences, customer briefings, and with other groups within the company
Work with engineering in identifying product gaps based on competitive analysis and work with the PM to drive enhancements to bridge them
Be the domain authority on Palo Alto Networks products to help Systems Engineers with information on competitive questions
Identify Sales challenges based on any competitive situations and provide solutions
Document technical concepts to ensure our products are well understood and utilized to the greatest extent possible
Setup and maintain a competitive test lab including test harness, competitive products, automation environment, etc.
Configure and test competitive products, evaluate product strengths for security efficacy, product features, etc.
Work with marketing to develop collaterals with battle cards, presentations, and white papers

Qualifications

Your Experience
3+ years of experience as a Technical Marketing Engineer for network/cybersecurity area or a DevOps/Solution Architect, preferably for networking or data security products
Excellent written and verbal communication skills with strong presentation skills and trade show experience
Eagerness to learn new technologies, experiment with products and collaborate cross-functionally
Strong customer advocacy skills and experience, ability to work in difficult customer situations
Work towards getting things done, Fast learner with strong initiative and sense of ownership
Experience in automation tools, building dashboards, etc.
Experience with writing and editing technical documentation and operational procedures

Additional Information

The Team
To stay ahead of the curve, it’s critical to know where the curve is and how to anticipate the changes we’re facing. For the fastest-growing cybersecurity company, the curve is the evolution of cyberattacks and the products and services that proactively address them. Our Product Management team helps us do just that.
This team provides the behind-the-scenes support for our products by being a source of information for our Systems Engineers, staying on top of the environment we sell in and helping to implement technical solutions based on our clients' feedback and needs. As threats and technology evolve, we stay ahead to accomplish our mission.
Our Commitment
We’re trailblazers that dream big, take risks, and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.
We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at accommodations@paloaltonetworks.com.
Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.
All your information will be kept confidential according to EEO guidelines.
The compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/com-missioned roles) is expected to be between $125,800/yr to $203,500/yr. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.",$1 to $5 billion (USD),Enterprise Software & Network Solutions,Company - Public,Information Technology
Principal Customer Engineer – Instinct Data Center GPU Software,san-jose,"Advanced Micro Devices, Inc
4.2","Santa Clara, CA",4.2,$113K - $173K (Glassdoor est.),4.2,4.2,3.9,3.7,3.9,10000+ Employees,1969,"Overview:
WHAT YOU DO AT AMD CHANGES EVERYTHING

We care deeply about transforming lives with AMD technology to enrich our industry, our communities, and the world. Our mission is to build great products that accelerate next-generation computing experiences – the building blocks for the data center, artificial intelligence, PCs, gaming and embedded. Underpinning our mission is the AMD culture. We push the limits of innovation to solve the world’s most important challenges. We strive for execution excellence while being direct, humble, collaborative, and inclusive of diverse perspectives. This is who we are at our best. One Company. One Team.

AMD together we advance_
Responsibilities:
Principal Customer Engineer – Instinct Data Center GPU Software

THE ROLE:
AMD is unwavering in our dedication to delivering an exceptional customer experience. We understand that ease of use and responsive customer support are essential ingredients in achieving this objective. As a valued member of the Data Center GPU & Accelerated Processing applications engineering organization, your role as Principal Customer Engineer is pivotal in driving and sustaining best-in-class customer support for major cloud service providers and supercomputer deployments in the US & Europe.

THE PERSON:
As a leader in the customer engineering organization, you have a critical role in ensuring overall customer satisfaction for AMD's US & EMEA customer base through resolution & closure of complex technical support issues and managing needed collaboration between the customers, partners, software development, field applications, product management, and business leaders. You should possess excellent software debugging skills (C/C++ and Python required) and have a fundamental understanding of how to run high performance computing (HPC) and/or machine learning (ML) workloads on server systems with accelerated processing.

KEY RESPONSIBILITIES:
Lead the efforts of the DC GPU customer engineering (CE) team to ensure customer success in the deployment and use of AMD Instinct™ Accelerators. These activities include:
The replication and debug of customer issues (software stack, firmware, driver), working with cross-functional teams, and driving root cause investigation.
Understand customer requirements and schedule, identify gaps in AMD offering and work with key stakeholders to close them.
Act as the primary point of contact for the customer and ensure all issues for the account are prioritized, tracked, and resolved in a timely manner.
Facilitate technical discussions with the customer, their designated OEM/ODM partners, and relevant AMD subject matter experts, as needed.
Help recruit best-in-class technical engineering talent and provide guidance to management on how to improve performance and efficiency of the existing team.
Manage technical escalations from customers as well as your staff's internal escalations to AMD's various software development teams.
Represent technical support management during customer calls/escalations and act as an escalation point for customer issues, driving towards a resolution.
Jump in to help other members of the team in resolving customer issues as needed.
Proactively monitor customer tickets while ensuring all issues are handled properly.
Communicate the team's effectiveness in resolving major customer issues and overall support trends to management.
Serve as a mentor to other CE team regarding technical issues and soft skills.
Roll up weekly support highlights and red flags to management.
Provide recommendations to improve internal processes and tools to enhance customer experience with our products and software.

PREFERRED EXPERIENCE:
Python & C/C++ programming, employing best software design practices.
GPU software development or validation involving HIP, CUDA, ROCm, or OpenCL.
Software performance evaluations, optimizations and debugging.
Customer first mindset. Driven to meet or exceed customer expectations, resolve issues expeditiously and, when possible, proactively.
Able to size technical issues and articulate their impact to AMD and our customers
Effective communication & presentation skills and comfortable in a customer-facing environment. Experience with executive rollups.
History of using one or more GPUs, or similar offload accelerator, for deployment of Artificial Intelligence (AI) or HPC workloads

ACADEMIC CREDENTIALS:
BS in Computer Science, Computer Engineering, or Electrical Engineering. MS is preferred.

LOCATION:
Santa Clara, CA
#LI-RL1
Qualifications:
At AMD, your base pay is one part of your total rewards package. Your base pay will depend on where your skills, qualifications, experience, and location fit into the hiring range for the position. You may be eligible for incentives based upon your role such as either an annual bonus or sales incentive. Many AMD employees have the opportunity to own shares of AMD stock, as well as a discount when purchasing AMD stock if voluntarily participating in AMD’s Employee Stock Purchase Plan. You’ll also be eligible for competitive benefits described in more detail here.

AMD does not accept unsolicited resumes from headhunters, recruitment agencies, or fee-based recruitment services. AMD and its subsidiaries are equal opportunity, inclusive employers and will consider all applicants without regard to age, ancestry, color, marital status, medical condition, mental or physical disability, national origin, race, religion, political and/or third-party affiliation, sex, pregnancy, sexual orientation, gender identity, military or veteran status, or any other characteristic protected by law. We encourage applications from all qualified candidates and will accommodate applicants’ needs under the respective laws throughout all stages of the recruitment and selection process.",$10+ billion (USD),Computer Hardware Development,Company - Public,Information Technology
"Sr. Software Engineer - distributed systems, cloud & data analytics",san-jose,"Juniper Networks
4.3","Sunnyvale, CA",4.3,Employer Provided Salary:$159K - $228K,4.1,4.3,4.0,4.1,4.2,5001 to 10000 Employees,1996,"Juniper’s Architecture and Pathfinding team is looking for a driven and curious software engineer who is interested in building new solutions from scratch to join our team. The Pathfinding team ideates on and combines innovative technologies like cloud-native ML / AI to create new solutions that will help Juniper transform networking and connectivity for the cloud era.
Responsibilities will vary depending on groups:
Work on distributed systems, cloud/ cloud-native technologies, data analytics
Work with our engineering leaders to build prototypes in an agile manner
Expected to be hands-on in full stack software development
Required Experience and Skills:
Has a MS or PhD in CS/CE/EE
8+ years of relevant experience
Programming experience in one or more of C/C++, Java, Python, knowledge of algorithms and data structures
Good verbal and written communication and presentation skills
Self-motivated team player, and capable of working in a fast-paced R&D environment
Curious about learning new technologies and building new solutions from scratch
Strong background in networking technologies TCP/IP, Routing Protocols, Network Analytics, In-line Telemetry, SmartNICs
Good to have Qualifications:
Programming skills in Go, UI - Angular/React
Knowledge of public cloud like Aws, Azure, GCP would be added advantage.
Knowledge and/or hands-on experience in Kubernetes and Docker
Knowledge and/or hands-on experience with service-mesh technologies like istio, envoy proxies
Good understanding and knowledge of TCP/IP, application layer protocols: HTTP knowledge is a plus
Knowledge of data analytics, stream processing, AI/ML techniques
Knowledge and/or hands-on experience with MLOps framework like Kubeflow, AWS sagemaker , Databricks platform
Good understanding of systems software concepts, network/system security is a plus
Minimum Salary: $158,560.00
Maximum Salary:$227,930.00
The pay range for this position is expected to be between $158,560.00 and $227,930.00/year; however, the base pay offered may vary depending on multiple individualized factors, including market location, job-related knowledge, skills, and experience. The total compensation package for this position also includes medical benefits, 401(k) eligibility, vacation, sick time, and parental leave. Additional details of participation in these benefit plans will be provided if an employee receives an offer of employment.
If hired, employee will be in an “at-will position” and the Company reserves the right to modify base salary (as well as any other payment or compensation program) at any time, including for reasons related to individual performance, Company or individual department/team performance, and market factors.
Juniper’s pay range data is provided in accordance with local state pay transparency regulations. Juniper may post different minimum wage ranges for permanent residency petitions pursuant to US Department of Labor requirements.",$1 to $5 billion (USD),Telecommunications Services,Company - Public,Telecommunications
"Senior Engineer, Data Pipeline Engineering",san-jose,"BoostUp.ai
4.1","Santa Clara, CA",4.1,$120K - $182K (Glassdoor est.),3.4,3.4,5.0,3.4,5.0,1 to 50 Employees,Self-employed,"About Us:

BoostUp.ai is the first Intelligent Revenue Management Platform built for the digital-selling and remote sales era. BoostUp solves the oldest problem in sales: the black box problem. The black box of Sales forecasting, pipelines, activity, and deals. Sales today operates on biased self-reported information and leaders are forced to use guess-work to make decisions causing forecasting slippage, lower win rates, inconsistent quota attainment, poor capacity allocation and inefficient pipeline management.
BoostUp’s AI platform brings holistic meaning to structured and unstructured sources of sales data - from emails, calendars, call recordings, transcripts, slack and such and helps sales leaders make better, more accurate decisions. Those capabilities are even more essential in the current, 100% distributed work model - which some sales teams are navigating for the first time.
BoostUp is founded by repeat SaaS entrepreneurs from Google, Yahoo & VMware and funded by top VCs. BoostUp’s market is composed of large B2B companies constituting $10B+ in initial TAM.
Experience and Skills
You are currently working on the team managing a large scale data processing pipeline.
You are a senior engineer, able to self-motivate and drive your work to completion.
You have 8+ years of professional software development experience
You have 5+ years of experience with developing data applications in Python.
You have a deep knowledge of building, scaling and managing a large scale real-time data pipeline (processing 100s of millions of events per day).
You have a deep knowledge and experience working with two or more of the following.
Large scale message queues like Kafka / Kinesis
Real-time stream processing systems like Spark, Apache Flink, Kinesis Data Streams
You have some experience understanding the trade-offs between scalability, reliability, developer/ops overhead and infrastructure cost of building scalable data pipelines.
You have significant knowledge of AWS. Should have built or managed a large scale data pipeline hosted within AWS.
You have significant experience working with either SQL based databases (PostGres, etc) or MongoDB.
Benefits
Full medical, dental and vision coverage
401(k) plan
Take as you need vacation plan",-1,-1,Unknown / Non-Applicable,-1
Sr. Automation Data Center Design Engineer/Consultant,san-jose,Cypress Consulting,"Palo Alto, CA",-1,Employer Provided Salary:$115.00 - $125.00 Per Hour,-1,-1,-1,-1,-1,Unknown,Company - Public,"Sr. Automation Data Center Engineer/Network Security Consultant
The Sr Consultant will provide expert automation support, analysis and research into complex problems and processes relating to deployed Security network equipment. The Consultant will function as the Automation Subject Matter Expert (SME) and will interact directly with the customer's personnel and will also serve as the technical expert on executive-level project teams within the customer providing technical direction, interpretation, and alternatives. The ideal candidate contributes to the development of new principles and concepts, works on unusually complex technical problems and provides solutions which are highly innovative and ingenious. This is a highly technical, hands-on role and this person will be required to develop and maintain an expertise on the products and solutions deployed within the Customer's network/Data Centers.
Technical Skills needed:
Ansible, CI/CD tools, DevOps, Git, Python, Strong Automation experience for deployment, Terraform
Job Type: Full-time
Pay: $115.00 - $125.00 per hour
Benefits:
Dental insurance
Health insurance
Paid time off
Professional development assistance
Referral program
Retirement plan
Vision insurance
Schedule:
8 hour shift
Day shift
Monday to Friday
Ability to commute/relocate:
Palo Alto, CA: Reliably commute or planning to relocate before starting work (Required)
Experience:
Consultative/Customer-facing: 3 years (Required)
Terraform: 2 years (Required)
Data Center Design: 3 years (Preferred)
Ansible: 3 years (Required)
Python: 2 years (Required)
Work Location: In person",-1,-1,Unknown / Non-Applicable,-1
Sr. Software Engineer - Energy Service Data Infrastructure,san-jose,"Tesla
3.6","Palo Alto, CA",3.6,$120K - $176K (Glassdoor est.),3.7,3.3,3.1,3.7,2.9,10000+ Employees,2003,"What to Expect
Tesla is committed to having industry-leading uptime in our deployed fleet of stationary battery storage solutions. We use data collected from our highly connected systems to find problems before the customer does and to systematically eliminate the causes of downtime. The Tesla Service Engineering Infrastructure and Analytics team is seeking a Senior Software Engineer to join the team developing the software that supports Tesla’s service response to failures that occur in our fleet. You will build tools to identify components in Tesla’s Energy fleet that have malfunctioned, and then orchestrate our response to those failures. Ultimately, you will be a key stakeholder for improving the uptime in Tesla Energy’s products.

What You’ll Do
Be a core team member collaborating with internal and external stakeholders to develop the tools and data infrastructure to support the health of the energy fleet through large data set analysis, automated diagnostic tools, and automated responses.
Mine data from 100,000+ subsystems that in the field to identify trends in equipment failures that are affecting the systems’ up time, and deploy automated solutions to resolve the issues.
Build microservices with clearly defined interfaces to add functionality to the automated tools and infrastructure based on the needs of the service and product teams.
Contribute to the product management, product roadmaps and program management of the tools and infrastructure.
What You’ll Bring
BS in Computer Science or equivalent with 2+ years of experience or proof of exceptional skills in related fields with practical software engineering experience.
Experience developing software in Golang. Other language proficiency may also be considered if you can demonstrate a clear ability to write high quality software.
Experience with Kafka and event driven architectures.
Experience with microservices and writing clearly defined contracts between those services.
Proven cross-functional leadership and collaborative skills.
Excellent oral, written communication skills.
An ability to prioritize and execute many tasks in parallel. An excellent attention to detail and an ability to produce clear and concise written documents and diagrams.
Nice to Have

Experience with battery systems and power systems.
Experience in predictive failure analytics.",$1 to $5 billion (USD),Transportation Equipment Manufacturing,Company - Public,Manufacturing
Data Center Electrical Commissioning Engineer II,san-jose,"CAI
4.1","Santa Clara, CA",4.1,Employer Provided Salary:$90K - $115K,4.2,4.0,3.9,4.0,3.4,501 to 1000 Employees,1996,"Position Description:
This position supports development and execution of all electrical aspects of assigned commissioning projects from initial engagement, design reviews, checklists, safety support, script development, vendor coordination, testing and report development through turn over to the client. The Electrical Commissioning Engineer will support the development of the electrical test schedule, finalize electrical test procedures, review project submittals for consistency with the design intent, basis of design and the owner’s project requirements, and maintain project cadence for electrical systems testing and associated Building Automation Systems. The Electrical Commissioning Engineer is to support the planning and execution of commissioning for the electrical infrastructure of the mission critical facility. They will be expected to execute against the project schedule through the coordination of contractors and/or vendors to complete the desired electrical systems testing.
CAI DC Electrical Commissioning Engineer will be exposed to cutting edge technologies in the Hyperscale and other spaces. You will have an opportunity to work with recognized subject matter experts allowing YOU to be a key player in bringing data technologies to market. As part of our company culture, we invest in YOUR future, and commit to hands on certifications as well as professional training. Our collaborative culture ensures that our customers benefit from exemplary work across our entire range of professional services.

Responsibilities:
Support all aspects of safety for all electrical tests.
Support complete commissioning and performance acceptance testing of the electrical infrastructure systems.
QA/QC of all electrical test procedures.
Provide input and insight to the overall commissioning plan.
Develop reports for the electrical commissioning engineers and contribute to a daily report to the Commissioning Project Manager.
Attend and be an active participant of customer equipment Factory Witness Test
Assist with vendor coordination and management.
Perform equipment inspection to ensure build adherence to vendor submittal.
Provide test documentation that equipment is delivered, installed, and tested correctly and set to function properly for the customer.
Support and perform design specification review, manufacturer submittals, one line drawing sets, and project schedule documentation.
QA/QC of electrical equipment installation\startup
Execute test scripts to confirm equipment and system operation to design specification.
Ensure safe work practices are followed by all on commissioning team and customer site.
Engage with customers to ensure a positive experience, goals achievement, and schedule adherence.
Provide daily reports for electrical commissioning team status.
Conduct facility walk downs, turnover, and punch list reviews.
General understanding of LEED specifications and requirements.
Look for new opportunities for CAI to provide service and value to customer.
Duties may be increased as experience and skill allow.

Requirements include:
Position Requirements:
Bachelor’s degree or equivalent experience
Minimum of 2 years Data Center Commissioning experience.
Knowledge of OSHA and NFPA 70E safety requirements.
Good written and spoken communication skills.
Ability to read and interpret electrical schematics and specifications.
Knowledge of data center design concepts.
Knowledge and commissioning experience with Electrical Distribution Switchgear, Substations, Uninterruptable Power Supplies (UPS), Automatic Transfer Switches (ATS), Batteries, Emergency Diesel Generators & Load Banks.
Knowledge of power quality analysis.
Strong experience with Word, Excel and PowerPoint.
Ability to effectively write electrical commissioning scripts, daily reports, and final commissioning reports.

Other Requirements:
Excellent oral and written English is required
Extensive travel may be required (75%)
Candidates must have a Passport or the ability to immediately get a Passport.
Work under construction site conditions
Able to work in the US without sponsorship now or any time in the future.

About CAI
CAI is a 100% employee-owned company established in 1996, that has grown year over year to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and consulting services related to operational readiness to FDA regulated and other mission critical industries.

Meeting a Higher Standard
Our approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.
As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:
We act with integrity
We serve each other
We serve society
We work for our future

With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a can-do attitude. That is how we have grown exponentially.

Benefits
Our full-time positions offer competitive compensation and benefits which include: up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.
#LI-MR1
Average salary range.
We are an equal opportunity employer; we are proud to employ veterans and promote a diverse culture in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.
This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the FCO.",$25 to $100 million (USD),Architectural & Engineering Services,Company - Private,"Construction, Repair & Maintenance Services"
"Senior Staff Data Engineer, AI and MLOps",san-jose,"Samsung Research America
4.1","Mountain View, CA",4.1,Employer Provided Salary:$178K - $266K,3.8,3.8,3.6,3.9,4.1,1001 to 5000 Employees,1988,"Lab Summary:
Bixby is an intelligent personal assistant which is only available as a built-in application on Samsung flagship devices and wearables. This application uses Natural Language Understanding to perform tasks on these devices using voice/ text, including but not limited to making phone calls, sending text messages, setting up meetings, opening apps, setting alarms and timers, getting directions, answering general questions, providing information about restaurants and other businesses, etc.
Samsung Bixby Labs is working towards a vision of a voice assistant that provides a unified AI experience across multiple devices. Our industry-leading hardware platforms like the Galaxy phones, and home appliances like smart refrigerators and TVs, smart washers and dryers, etc. allow for deep integration of the AI services like Bixby voice assistant and hardware devices. Real-time AI services on these connected IoT devices enable users to interact with devices more naturally via spoken dialogue, visual interaction, continuous learning, and big data analysis. Researchers and engineers are working hard towards making the Samsung vision a reality.
Position Summary:
Modern AI services are delivered online, in real-time and 24x7. To adapt to this new world, we are building a continuously monitoring and updating platform centered around AI and machine-learned models. The platform manages model training, multiple production releases, data analytics, integration, bugs, rollbacks, patches, A/B testing, online monitoring, etc. The processes are independent of the type of real-time AI service – voice assistants, web search, autonomous vision systems, etc. If you are interested in data science, AI and machine learning platforms for the online AI services world, this is your dream job.
Position Responsibilities:
Design, streamline and implement MLOps processes for continuous ML modeling and monitoring
Leverage Data Science techniques to establish pipelines for continuous user satisfaction evaluation and monitoring processes, A/B testing, mining insights, and informing the engineers and executives with data-backed hypotheses
Evaluate and analyze pre-production AI model candidate releases and provide insights derived from production data logs
Facilitate integration of the AI system/software into existing production environment
Work with release engineering team and establish a proper model release certification process
Keep current with the fast-moving world of AI, from modeling techniques like generative AI to platform innovations
Required Skills:
Masters in Computer Science, Electrical Engineering, Experimental Physics, Statistics or equivalent combination of education, training, and experience
10+ years of working experience in related field after degree
Knowledge of statistical techniques (t-tests, confidence intervals, p-value, etc.), tools (R, SAS, etc.) and controlled experimentation (e.g. A/B testing
Experience with platforms like AI automation platforms like Kubeflow pipeline, MLFlow, Azure Pipeline, AWS SageMaker Pipeline; Airflow, Jenkins; Spark, Hadoop, Kafka; Jira, and Git
Experience with data visualization/dashboard tools like Superset, Elasticsearch and Kibana, Tableau, Grafana
Experience with building AI applications using Deep Learning platforms like PyTorch, TensorFlow on GPU, Jupyter Notebook
Strong programming skills (C++, Java, Javascript, etc.) and scripting skills (Python, R, Perl, SQL, etc.)
Strong problem-solving skills
Fluent in Linux, scripting in Python and other languages
Good communication and team-working skills
Special Attributes:
Experience with building Apps in Alexa, Google Assistant, or Siri a plus
Experience with cloud computing platforms like AWS, GCP and Azure a plus
Our total rewards programs are designed to motivate and engage exceptional talent. The base pay range for roles at this level is listed below, but may be higher or lower in other states due to geographic differentials in the labor market. Within the base pay range, individual rates depend on a number of factors—including the role’s function and location as well as the individual’s knowledge, skills, experience, education and training. This is part of our comprehensive compensation package with annual bonus eligibility and generous benefits to help you live life well.
Base Pay Range
$177,700—$266,450 USD
Additional Information
Essential Job Functions
This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, and frequently operate standard office equipment, such as telephones and computers.
Samsung Research America is committed to complying with all Federal, State and local laws related to the employment of qualified individuals with disabilities. If you are an individual with a disability and would like to request a reasonable accommodation as part of the employment selection process, please contact the recruiter or email sratalent@samsung.com.
Affirmative Action / Equal Opportunity
Samsung Research America is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, national origin, disability, or status as a protected veteran.
For more information regarding protection from discrimination under Federal law for applicants and employees, please refer to the links below.
Know Your Rights | Pay Transparency",$25 to $100 million (USD),Software Development,Subsidiary or Business Segment,Information Technology
Associate Engineer - Control and Data Systems Engineer,san-jose,"SLAC National Accelerator Laboratory
4.1","Menlo Park, CA",4.1,Employer Provided Salary:$108K - $163K,3.9,3.8,3.3,3.7,3.8,1001 to 5000 Employees,1962,"SLAC Job Postings

Position overview:
Do you enjoy collaborating with a diverse group of people to solve complex challenges? Does contributing to breakthrough discoveries in science and working with unique experimental instrumentation in a world-leading scientific research environment excite you? The Photon Controls and Data Systems (PCDS) Department within the Linac Coherent Light Source (LCLS) Directorate at SLAC is seeking a Controls and Data Systems Engineer to plan, implement, and operate customized experimental installations, and develop enhancements to our scientific instrumentation and supporting hardware and software for the Control, Data Acquisition, and Data Analysis systems for the Hard X-ray science instruments (X-ray Pump Probe (XPP), X-ray Correlation Spectroscopy (XCS), Molecular Femtosecond Crystallography (MFX), and Coherent X-ray Imaging (CXI)).
Reporting to the Experiment Control Systems Delivery Department Head, the Controls and Data Systems Engineer will be a member of a multidisciplinary team comprised of electronic engineers and software developers focused on developing software and hardware solutions to support scientific instrumentation, laser systems, controls, and data acquisition systems. This position will also work with scientific and operations support staff involved in advancing scientific instrumentation capabilities. LCLS is the world’s first hard x-ray free electron laser (FEL) with unprecedented capabilities in photon energy range, peak power, and pulse lengths. There are seven independent instruments currently in operation, which are specifically designed to utilize the exceptional beam characteristics of the LCLS to probe the structure and dynamics of matter at atomic size and timescales. The evolution of science and experimental techniques on these instruments, along with upgrades in the x-ray FEL source and optical lasers (LCLS-II), require regular improvements to the supporting software and hardware platforms.
See for more on LCLS and the unique capabilities of our instrument facilities.
Your specific responsibilities include:
Plan, implement, and operate customized experimental installations.
Reconfigure hardware and software to meet experimental need; develop software for data analysis, data acquisition, controls, and to support new instrumentation.
Manage hardware and software for the controls, data acquisition, and data-analysis systems and related infrastructure such as computers and local networks, x-ray detector systems, digitizers, scopes, cameras, power supplies, motion systems, vacuum and PLC systems, etc.
Participate in upgrades to scientific instrumentation and capabilities including laser systems, timing systems, hardware and software selection, and lead teams of engineers and technicians to implement and integrate the control, data acquisition, and analysis aspects of these upgrades.
Additional opportunities include development toward, or project leadership for core capabilities of the CDS systems including:
Real time Data Acquisition and EPICS (Experimental Physics and Industrial Control System) control system software and driver development.
Real-time and offline data analysis frameworks which run on Field Programmable Gate Arrays (FPGAs), Graphics Processing Units (GPUs), teraflop computing clusters, multi-petabyte storage systems at SLAC and NERSC.
Graphical User Interface framework.
New and unique instrumentation and electronics systems such as
Sample delivery systems.
Peta-Watt laser systems.
Femtosecond timing systems.
X-ray sensitive CCD cameras and detectors.
Machine and human protection systems.
To be successful in this position you will bring:
Bachelor's degree in physics, computer science, engineering or related discipline and 2 years of relevant work experience in data analysis, experimental process, design and development of prototypes, scientific instrumentation and/or systems. Advanced degree strongly preferred.
Ability to learn and understand the workings of a broad range of hardware and software.
Demonstrated programming skills with C and/or C++ and experience with Linux/Unix and a scripting language such as (and preferably) Python.
Exceptional communications skills and ability to work well in a research and development team.
Demonstrated project leadership, planning, and excellent organizational skills.
Ability to understand the basic functionality and scientific purpose of each part of the x-ray science instrument.
In addition, preferred requirements include:
Real-time and networking software, familiarity with EPICS framework, knowledge of motor, vacuum and camera controls.
Developing scientific instrumentation, laser and laser diagnostic systems.
Background in x-ray or material science.
SLAC Employee Competencies:
Effective Decisions: Uses job knowledge and solid judgment to make quality decisions in a timely manner.
Self-Development: Pursues a variety of venues and opportunities to continue learning and developing.
Dependability: Can be counted on to deliver results with a sense of personal responsibility for expected outcomes.
Initiative: Pursues work and interactions proactively with optimism, positive energy, and motivation to move things forward.
Adaptability: Flexes as needed when change occurs, maintains an open outlook while adjusting and accommodating changes.
Communication: Ensures effective information flow to various audiences and creates and delivers clear, appropriate written, spoken, presented messages.
Relationships: Builds relationships to foster trust, collaboration, and a positive climate to achieve common goals.
Physical requirements and Working conditions:
Consistent with its obligations under the law, the University will provide reasonable accommodation to any employee with a disability who requires accommodation to perform the essential functions of his or her job.
Given the nature of this position, SLAC will require onsite work.
Work Standard:
Interpersonal Skills: Demonstrates the ability to work well with Stanford colleagues and clients and with external organizations.
Promote Culture of Safety: Demonstrates commitment to personal responsibility and value for environment, safety and security; communicates related concerns; uses and promotes safe behaviors based on training and lessons learned. Meets the applicable roles and responsibilities as described in the ESH Manual, Chapter 1—General Policy and Responsibilities:
Subject to and expected to comply with all applicable University policies and procedures, including but not limited to the personnel policies and other policies found in the University's Administrative Guide,
As an organization that receives federal funding, SLAC and Stanford University have a COVID-19 vaccination requirement that will apply to all university employees, including those working remotely in the United States and applicable subcontractors.
-
Classification Title: Staff Engineer
Grade: K, Job Code: 0132
Duration: Regular Continuing
The expected pay range for this position is $108,000 to $163,000 per annum. SLAC National Accelerator Laboratory/Stanford University provides pay ranges representing its good faith estimate of what the university reasonably expects to pay for a position. The pay offered to a selected candidate will be determined based on factors such as (but not limited to) the scope and responsibilities of the position, the qualifications of the selected candidate, departmental budget availability, internal equity, geographic location and external market pay for comparable jobs.",Unknown / Non-Applicable,National Agencies,Government,Government & Public Administration
"Senior Software Engineer, Data",san-jose,"Pyze
4.3","Redwood City, CA",4.3,$117K - $163K (Glassdoor est.),4.6,4.6,4.6,4.2,4.3,1 to 50 Employees,2014,"Location: Redwood City, CA
Responsibilities
Design, build and launch robust & reliable pipelines to move large-scale data
Build distributed services for scheduling, triggering and routing events
Build predictive models and recommendations from user data to improve specific customer-defined business metrics like revenue, retention, and engagement
Work with Product teams to translate customer requirements to design and implement architectures and algorithms required to take new features to market
Requirements
5+ years of industry experience in working with Big Data pipeline
Deep knowledge of algorithms and data structures and when to use them
Extensive understanding of distributed data systems like Kafka, Storm, Redis, Spark and Cassandra
Significant coding experience in one or more programming languages (Java, Scala etc)
MS/PhD in a computer science related field from a top computer science / engineering program",Less than $1 million (USD),Enterprise Software & Network Solutions,Company - Private,Information Technology
"Senior Staff Software Engineer, Data",san-jose,"Coupang
3.6","Mountain View, CA",3.6,Employer Provided Salary:$171K,3.5,3.2,3.0,3.5,3.0,5001 to 10000 Employees,2010,"We exist to wow our customers. We know we're doing the right thing when we hear our customers say, ""How did we ever live without Coupang?"" Born out of an obsession to make shopping, eating, and living easier than ever, we're collectively disrupting the multi-billion-dollar e-commerce industry from the ground up. We are one of the fastest-growing e-commerce companies that established an unparalleled reputation for being a dominant and reliable force in South Korean commerce.
We are proud to have the best of both worlds — a startup culture with the resources of a large global public company. This fuels us to continue our growth and launch new services at the speed we have been since our inception. We are all entrepreneurial surrounded by opportunities to drive new initiatives and innovations. At our core, we are bold and ambitious people that like to get our hands dirty and make a hands-on impact. At Coupang, you will see yourself, your colleagues, your team, and the company grow every day.
Our mission to build the future of commerce is real. We push the boundaries of what's possible to solve problems and break traditional tradeoffs. Join Coupang now to create an epic experience in this always-on, high-tech, and hyper-connected world.
Role Overview
As our Senior Staff Software Engineer, Data for Search & Discovery organization, you will be in charge of designing and implementing durable & efficient software solutions that handle massive volume of structured and unstructured data.
The Search & Discovery organization is responsible for optimizing customers' navigation experience and driving long-term growth. Every week more than 20 million customers use search in our app or on coupang.com, more than one third of them make purchases. Over half of the Coupang sales are directly attributed to search and recommendation. Many business initiatives and growth strategies are driven or boosted by ranking and recommendation.

This role is an opportunity to build a solid data foundation to support ranking and recommendation, and business decision making. You will be handling billions of records of user interaction data, and petabytes of raw log files, and transform them into data objects that can be easily consumed by engineers and scientists. There are so many things to analyze, to design, and to build. If you are passionate about big data engineering and technology, you want to make real business impact, and you are a true problem solver, this is the right job for you.
What You Will Do
Proactively drive the execution of end-to-end data platform, data quality roadmap for Search & Discovery ML efforts
Take ownership, consolidate and optimize the Search & Discovery core data logging, processing, and ML model training pipelines
Drive design and implementation of durable & efficient platform solutions that handles massive amount of structured and unstructured data
Develop and scale data infrastructure that powers batch and real-time data processing, monitoring, and debugging for ML experiments
Build strong cross-functional partnerships with Data Scientists, Analysts, Product Managers, Indexing Platform Engineers, Ranking Engineers and Data Platform Engineers to understand data needs and deliver on those needs
Research, analyze and select technical approaches for solving difficult and challenging development and integration problems, coach and mentor other engineers in process and methodologies
Basic Qualifications
BS or MS degree in Computer Science or related field, or equivalent practical experience
8+ years of experience
Computer science fundamentals: data structures, algorithms, performance complexity, and implications of computer architecture on software performance (e.g., I/O and memory tuning)
Software engineering fundamentals: version control systems (i.e Git, Github) and workflows, and the ability to write production-ready code
Expert experience with Big Data tools and ETL frameworks (Hadoop, Hive, Presto, Spark, Scala, Apache Airflow, etc.)
Knowledgeable of modern data visualization and exploration platforms such as Apache Superset, Tableau, etc.
Experience deploying highly robust and scalable data pipelines processing petabytes of data
Experience with integrating applications and platforms with cloud technologies (i.e, AWS and GCP)
Strong verbal and written communication skills
Ability to conduct meetings and make professional presentations, and explain complex concepts and technical material to non-technical users
Experience with machine learning platform for search & discovery related rankings is a strong plus
Pay & Benefits
Our compensation reflects the cost of labor across several US geographic markets. At Coupang, your base pay is one part of your total compensation.
The base pay for this position ranges from $170,730 / year in our lowest geographic market to $317,070 / year in our highest geographic market. Pay is based on several factors including market location and may vary depending on job-related knowledge, skills, and experience.
General Description of All Benefits
Medical/Dental/Vision/Life, AD&D insurance
Flexible Spending Accounts (FSA) & Health Savings Account (HSA)
Long-term/Short-term Disability
Employee Assistance Program (EAP) program
401K Plan with Company Match
18-21 days of the Paid Time Off (PTO) a year based on the tenure
12 Public Holidays
Paid Parental leave
Pre-tax commuter benefits
MTV - [Free] Electric Car Charging Station
General Description of Other Compensation
""Other Compensation"" includes, but is not limited to, bonuses, equity, or other forms of compensation that would be offered to the hired applicant in addition to their established salary range or wage scale.

Coupang is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to actual or perceived race (including traits historically associated with race, including but not limited to hair texture and protective hair styles), color, religion, religious creed (including religious dress and grooming practices), sex or gender (including pregnancy, childbirth, breastfeeding, and medical conditions related to pregnancy, childbirth or breastfeeding), gender identity, gender expression, sexual orientation, ,ancestry, national origin (including language use restrictions), age (40 and over), physical or mental disability, medical condition, genetic information, HIV/AIDS or Hepatitis C status, family status (including but not limited to marital or domestic partnership status), military or veteran status, use of a trained dog guide or service animal, political activities or affiliations, ancestry, citizenship, family and medical leave status, status as a victim of any violent crime, or any other characteristic or class protected by the laws or regulations in the locations where we operate. Coupang is also committed to providing a safe work environment for its employees and its consumers. As a condition of employment, Coupang requires employees to be fully vaccinated against Covid-19, subject to legally required accommodations. If you need assistance and/or a reasonable accommodation in the application of recruiting process due to a disability, please contact us at usrecruiting@coupang.com.",Unknown / Non-Applicable,Internet & Web Services,Company - Public,Information Technology
Staff Software Engineer Data #2563,san-jose,"GRAIL
4.0","Menlo Park, CA",4.0,$102K - $136K (Glassdoor est.),3.5,3.8,3.6,3.9,3.9,1001 to 5000 Employees,2016,"GRAIL is a healthcare company whose mission is to detect cancer early, when it can be cured. GRAIL is focused on alleviating the global burden of cancer by developing pioneering technology to detect and identify multiple deadly cancer types early. The company is using the power of next-generation sequencing, population-scale clinical studies, and state-of-the-art computer science and data science to enhance the scientific understanding of cancer biology, and to develop its multi-cancer early detection blood test. GRAIL is headquartered in Menlo Park, CA with locations in Washington, D.C., North Carolina, and the United Kingdom. GRAIL, LLC is a wholly-owned subsidiary of Illumina, Inc. (NASDAQ:ILMN). For more information, please visit www.grail.com.

Are you passionate about unlocking the value of data to make an impact on the lives of patients? If so, join us in Software Engineering at GRAIL! We are looking for a Staff Cloud / Data Engineer to join our growing team to build out a data platform in support of GRAIL’s commercial products and research activities.
You Will:
Be part of a highly collaborative team that focuses on delivering value to our internal partners by providing secure access to data
Work cross-functionally to translate business needs into efficient, scalable, and easy to maintain data engineering solutions
Prototype, implement, scale, and maintain our cloud data platform as we continue to bring in new data sources
Develop batch and streaming data extraction pipelines
Contribute to the design and execution of a data governance framework
Grow together with the team as we meet the next set of business needs and technical challenges
Your Background Should Include:
B.S. / M.S. in a quantitative field (e.g. Computer Science, Engineering, Mathematics, Physics, Computational Biology) with at least 8 years of related industry experience, or Ph.D. with at least 3 years of related industry experience
Experience in architecting and delivering secure, scalable cloud-based data warehouses and data lakes on AWS, Azure, or GCP
Advanced knowledge in data warehousing architecture and concepts (ETL and ELT) and data modeling
Experience with relational databases, query authoring, and performance tuning
Solid object-oriented and/or functional programming experience
Excellent communication and interpersonal skills
Preferences Highly Considered:
Experience with AWS and data migration
Experience with Golang and Python
Experience with DevOps, e.g. CI/CD pipelines, containerized deployment, infrastructure as code, Terraform
Experience with data pipelining and workflow engines, e.g. Apache Airflow, Cadence, Beam, Spark
Experience building microservices and web applications
Experience with supporting data science/machine learning data pipelines
The estimated, full-time, annual base pay scale for this position is $154,000 - $232,000. Actual base pay will consider skills, experience, and location.

Based on the role, colleagues may be eligible to participate in an annual bonus plan tied to company and individual performance, or an incentive plan. We also offer a long-term incentive plan to align company and colleague success over time.

In addition, GRAIL offers a progressive benefit package, including flexible time-off, a 401k with a company match, and alongside our medical, dental, vision plans, carefully selected mindfulness offerings.

GRAIL is an Equal Employment Office and Affirmative Action Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other legally protected status. We will reasonably accommodate all individuals with disabilities so that they can participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. GRAIL maintains a drug-free workplace.

Following extensive monitoring, consideration of business implications, and advice from internal and external experts, GRAIL US has made the decision to require that all U.S. employees be “Fully Vaccinated” with the COVID-19 vaccine. “Fully Vaccinated” is defined as two weeks after both doses of a two-dose vaccine (e.g. Pfizer or Moderna) or two weeks since a single-dose vaccine (e.g. Johnson & Johnson) has been administered. Absent a qualifying exemption, all GRAIL US employees are to comply with this requirement, including providing documentation of such vaccination status, as a condition of employment. Anyone unable to be vaccinated, either because of a sincerely held religious belief or a medical condition or disability that prevents them from being vaccinated, can request a reasonable accommodation for consideration by GRAIL.",Unknown / Non-Applicable,Biotech & Pharmaceuticals,Company - Private,Pharmaceutical & Biotechnology
"Senior Software Engineer, Platform – Data + AI (Full-Stack)",san-jose,"C3 AI
3.9","Redwood City, CA",3.9,Employer Provided Salary:$155K - $190K,4.1,3.7,3.6,4.1,3.4,501 to 1000 Employees,2009,"C3.ai, Inc. (NYSE:AI) is a leading provider of Enterprise AI software for accelerating digital transformation. The proven C3 AI Platform provides comprehensive services to build enterprise-scale AI applications more efficiently and cost-effectively than alternative approaches. The core of the C3 AI offering is an open, data-driven AI architecture that dramatically simplifies data science and application development. Learn more at: www.c3.ai
C3 AI is looking for Senior Full-Stack Software Engineers to join the rapidly growing Data org within the Platform Engineering department. Successful candidates will get the opportunity to work on full-stack projects for AI/ML application development, including building user interfaces for data exploration, data integration, ML feature engineering, etc.
You will be given opportunities to take ownership of components and collaborate to drive technical direction. You will get to work on both front-end and back-end technologies, and you will have the option to focus on either of them. Join us in building the next-generation AI/ML platform at petabyte level scale that powers some of the world's most influential companies in Energy, Financial Services, Utilities, Health Care, Aerospace, Defense, etc. Accelerate your career in the leading enterprise AI company that is in a hyper-growth trajectory.
Responsibilities:
Develop and maintain visual tools and user interfaces for data science and large-scale AI/ML application development.
Design, develop, and maintain scalable components for a high-performant interface to a highly extensive AI/ML Platform.
Work with architects, product managers, back-end engineers, data scientists, and UX engineers in a highly collaborative environment.
Participate and provide insights in technical discussions.
Innovate ideas to enable faster AI/ML application development for users.
Write clean code following a test-driven methodology.
Rapidly fix bugs, solve problems, and proactively strive to improve our products and technologies.
Manage individual project deliverables and mentor junior team members on engineering best practices, industry coding standards, and design techniques.
Deliver commitments in a timely manner.
Qualifications:
Bachelor of Science in Computer Science, Computer Engineering, or related fields.
3+ years of professional software development experience with JavaScript and/or TypeScript.
Comfortable working with Java, C++, or Python.
Strong competency in object-oriented programming, data structures, algorithms, and software design patterns.
Experience with version control systems such as Git.
Experience with JavaScript frameworks such as React (preferred), Angular, or Vue.
Good understanding of client-side caching, session, and state management.
Experience with state management web frameworks (e.g., Redux).
Solid conceptual understanding of web framework components and related abstractions, bindings, etc.
Knowledge of at least one JavaScript testing framework (e.g., Jasmine, Jest).
Experience working with back-end APIs, and event-driven architectures.
Good technical communication ability including verbal and written communication skills to facilitate collaboration.
Thrive in a fast-paced, dynamic environment and value end-to-end ownership of projects.
Intellectually curious, eager to learn, and open to challenges.
Preferred Qualifications:
Advanced degree in engineering, sciences, or related field.
Experience working using Agile development methodology.
Proficiency with JavaScript.
Proficiency with React.
Knowledge of UI frameworks (e.g., Material UI, Semantic UI).
Knowledge of Webpack.
Familiarity with Machine Learning.
Knowledge of distributed systems.
Experience working with at least one public cloud platform (e.g., AWS, Azure, GCP).
Experience developing and working with REST and/or GraphQL APIs.
Conceptual understanding of orchestration and resource provisioning systems (Kubernetes).
Experience with developing tooling for large-scale Data systems or application development platforms.
Experience with building modular, scalable full-stack applications.
C3 AI provides excellent benefits and a competitive compensation package, which include:
Generous equity plan.
Salary range: $155,000 - $190,000 USD.
C3 AI is proud to be an Equal Opportunity and Affirmative Action Employer. We do not discriminate on the basis of any legally protected characteristics, including disabled and veteran status.",Unknown / Non-Applicable,Enterprise Software & Network Solutions,Company - Public,Information Technology
"Lead Data Engineer, Advanced Analytics Group",san-jose,"Bain & Company
4.5","Palo Alto, CA",4.5,Employer Provided Salary:$158K - $190K,4.5,4.5,4.2,4.4,3.5,10000+ Employees,1973,"WHAT MAKES US A GREAT PLACE TO WORK

We are proud to be consistently recognized as one of the world's best places to work, a champion of diversity and a model of social responsibility. We are a Glassdoor Best Place to Work and we have maintained a spot in the top four since its founding in 2009. We believe that diversity, inclusion and collaboration are key to building extraordinary teams. We hire people with exceptional talents, abilities and potential, then create an environment where you can become the best version of yourself and thrive both professionally and personally.

WHO YOU’LL WORK WITH

Working alongside our generalist consultants, Bain's Advanced Analytics Group (AAG) helps clients across industries solve their biggest problems using our expertise in data science, customer insights, statistics, machine learning, data management, supply chain analytics and data engineering. Stationed in our global offices, AAG team members hold advanced degrees in computer science, engineering, AI, data science, physics, statistics, mathematics, and other quantitative disciplines, with backgrounds in a variety of fields including tech, data science, marketing analytics and academia.

WHAT YOU’LL DO

As a member of the growing Cloud, Apps and Data Engineering team in Bain’s Advanced Analytics Group, you will:

Partner with Data Science, Machine Learning, and Platform Engineering teams to develop and deploy production quality code
Develop and champion modern Data Engineering concepts to technical audience and business stakeholders
Implement new and innovative deployment techniques, tooling, and infrastructure automation within Bain and our clients.
Travel is required (30%)
ABOUT YOU
Master’s degree in Computer Science, Engineering, or a related technical field.
3+ years at Senior or Staff level, or equivalent
3+ years of experience programming with Python, Scala, C/C++, Java, C#, Go, or similar programming language.
3+ years of experience with SQL or NoSQL databases: PostgreSQL, SQL Server, Oracle, MySQL, Redis, MongoDB, Elasticsearch, Hive, HBase, Teradata, Cassandra, Amazon Redshift, Snowflake.
Experience in deploying serverless data pipelines through containerization and terraform orchestration
Industry level experience of working with public cloud environments (AWS, GCP, or Azure), and associated deep understanding of failover, high-availability, and high scalability
Scaling and optimizing schema and performance tuning SQL and ETL pipelines in data lake and data warehouse environments.
Strong computer science fundamentals in data structures, algorithms, automated testing, object-oriented programming, performance complexity, and implications of computer architecture on software performance.
Data ingestion using one or more modern ETL compute and orchestration frameworks (e.g. Apache Airflow, Luigi, Spark, Apache Nifi, and Apache Beam).
Version control and git workflows
Strong interpersonal and communication skills, including the ability to explain and discuss complex mathematical and machine learning technicalities with colleagues and clients from other disciplines at their level of cognition
Curiosity, proactivity and critical thinking
ABOUT US

Bain & Company is a global consultancy that helps the world’s most ambitious change makers define the future.

Across 64 cities in 39 countries, we work alongside our clients as one team with a shared ambition to achieve extraordinary results, outperform the competition, and redefine industries. We complement our tailored, integrated expertise with a vibrant ecosystem of digital innovators to deliver better, faster, and more enduring outcomes. Our 10-year commitment to invest more than $1 billion in pro bono services brings our talent, expertise, and insight to organizations tackling today’s urgent challenges in education, racial equity, social justice, economic development, and the environment. We earned a gold rating from EcoVadis, the leading platform for environmental, social, and ethical performance ratings for global supply chains, putting us in the top 2% of all companies. Since our founding in 1973, we have measured our success by the success of our clients, and we proudly maintain the highest level of client advocacy in the industry.

U.S. Compensation and Benefit Information:
Compensation for this role includes base salary, annual discretionary performance bonus, 401(k) plan with an annual employer contribution based on years of service and Bain’s best in class benefits package (details listed below).

Some local governments in the United States require a good-faith, reasonable salary range be included in job postings for open roles. The estimated annualized compensation for this role is as follows:

In New York City, the good-faith, reasonable annualized full-time salary range for this role is between $157,500 - $189,500; placement within this range will vary based on several factors including, but not limited to experience, education, licensure/certifications, training and skill level

In California state, the good-faith, reasonable annualized full-time salary range for this role is between $157,500- $189,500; placement within this range will vary based on several factors including, but not limited to experience, education, licensure/certifications, training and skill level

In Washington state, the good-faith, reasonable annualized full-time salary range for this role is between $157,500- $189,500; placement within this range will vary based on several factors including, but not limited to experience, education, licensure/certifications, training and skill level

For all other U.S. locations, the good-faith, reasonable annualized full-time salary range for this role is commensurate with competitive geographic market rates for this role and will vary based on several factors including, but not limited to experience, education, licensure/certifications, training and skill level

Annual discretionary performance bonus

This role may also be eligible for other elements of discretionary compensation

4.5% 401(k) company contribution, which increases after 3 years of service and is 100% vested upon start date

Bain & Company's comprehensive U.S. benefits and wellness program is designed to help employees achieve personal independence, protection and stability in the areas most important to you and your family.",$5 to $10 billion (USD),Business Consulting,Company - Private,Management & Consulting
Lead Platform Data Engineer,san-jose,"Supernal
2.8","Fremont, CA",2.8,Employer Provided Salary:$175K - $289K,3.0,2.4,2.2,3.7,3.3,Unknown,Company - Private,"Supernal is at the forefront of creating emerging mobility solutions that will foster the development of human-centered cities. We are designing a completely new electric vertical take-off and landing (eVTOL) aircraft tailored to the mobility needs of future cities. This allows passengers a seamless intermodal journey that safely transports them to their final destination. We fuse research in autonomy, robotics, aviation and services to define a new category of mobility for the world's communities. We believe in creative thinking and collaboration to help build a better mobility experience for everyone, improving people's ability to move – whether for work or play.
What we do:
Data is the backbone of Supernal from developing our autonomous air vehicles to building the global ecosystem for advanced air mobility to building, scaling, and running an efficient, effective, and data driven business. The new Data team architects and manages UAM's internal data infrastructure, partners with users across the company to enable data driven solutions and runs strategic projects to stay at the forefront of data and analytical capabilities. We are a team of data engineers, data architects, data scientists, data analysts, data you-name-it, and we're building out a ground breaking data platform and capability for this new business comprised of modern leading technologies to enable the next generation of mobility solutions.
As a Platform Engineer, you are part cloud engineer, part database administrator with a strong focus on security and governance. You will be responsible for overseeing the heart of our data tech stack that delivers exciting and innovative internal data products. We want you to help us forge a new mobility eco-system and design the next generation of eVTOL aircraft. You will work within the digital operations group and partner with Engineering, Operations, R&D, Strategy, Manufacturing, Supply Chain, and our leadership team. You will be a leading voice in our data strategy and its delivery.
What you can do:
Own and manage secure and governed database administration
Partner with IT and Legal to design secure and automated processes and implement practices that enable data democracy and agility
Partner closely with critical team members (e.g., test and evaluation, systems engineering, simulations engineers, and more) to ensure safe and secure usage and transmission of our most critical data
Run, guide, and implement database administration responsibilities and continuously automate relevant processes
Help build, manage, and scale our data platform capabilities
Help design and build the data integrations for robust pipelines and serving business intelligence, analytics, and engineering needs
Work with data owners to design and implement role based, row level, and dynamic access control
Lead processes that ensure site reliability for our data stack.
Lead and guide standard processes around data governance, security, and quality
Architect scalable data solutions for Business, Engineering, and R&D with Data colleagues
Work closely with data engineers, scientists, and analysts across the business
Actively enable a data driven and innovative culture across the organization
Communicate insights, plans, architecture, and technology decisions clearly and effectively to team members around the company
Design, prototype, and implement solutions for Engineering groups
Mentor and guide more junior team members
What you can contribute:
B.S. in relevant field such as computer science or information science required
15+ years of relevant work experience (an equivalent combination of education and experience may be considered)
Excellent verbal and written communication skills
Excellent knowledge of software engineering fundamentals
Strong SQL skills
Strong programming skills with Python, Java, or Scala
Demonstrated experience in working with:
Data storage solutions in an administrative capacity
SCM solutions (Bitbucket/Github/Gitlab)
Data technologies (e.g., Snowflake, Databricks, Palantir)
Small, agile teams with rapid growth
Deep understanding of data management, administration, security, and access control processes and implementation
Experience and desire to set up data capabilities and platforms as well as managing them
Familiarity with Docker and K8s
Self-organizing and self-starting
Continuous learner, independent worker, and strong decision maker (with minimal supervision)
Collaborative teammate with dedication to Diversity, Equity, and Inclusion
Experience in industry working with highly regulated data, i.e., aerospace, automotive, healthcare, finance
You may also be able to contribute:
Graduate degree in relevant field
Experience with Cloud-based services (AWS/Azure)
Experience working with export-controlled data
Experience with serving business intelligence feeds
Experience with Azure, Snowflake, and Databricks administration and Data Lakes
Understanding of CI/CD practices
Any offer of employment is conditioned upon the successful completion of a background check. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, citizenship, sex, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other category or class protected under applicable federal, state or local law. Individuals with disabilities may request a reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation at: ta-support@supernal.aero
This position will include access to certain technology and/or software source code that will be subject to U.S. export control laws. If an export license or other export control authorization is required in connection with your employment, your employment is contingent upon Supernal's receipt of such license or authorization and approvals and your continued compliance with all conditions and limitations contained in such license or authorization.
Base pay offered may vary depending on skills, experience, job-related knowledge and location. This position is also eligible for a bonus as part of total compensation.
The pay range for this position is:
$174,720—$289,120 USD
Click HERE or visit: https://jobs.supernal.aero/benefits to view our benefits!",-1,Aerospace & Defense,Aerospace & Defense,Unknown / Non-Applicable
"Radiologic Data Systems Engineer - Radiology Administration (1.0 FTE, Days)",san-jose,"Lucile Packard Children's Hospital
4.0","Palo Alto, CA",4.0,$57K - $92K (Glassdoor est.),3.6,3.8,3.3,4.2,3.5,5001 to 10000 Employees,1991,"Information Technology
1.0 FTE, 8 Hour Day Shift
At Stanford Children's Health, we know world-renowned care begins with world-class caring. That's why we combine advanced technologies and breakthrough discoveries with family-centered care. It's why we provide our caregivers with continuing education and state-of-the-art facilities, like the newly remodeled Lucile Packard Children's Hospital Stanford. And it's why we need caring, committed people on our team - like you. Join us on our mission to heal humanity, one child and family at a time.
Job Summary
This paragraph summarizes the general nature, level and purpose of the job.
The Radiologic Data Systems Engineer will be responsible for day to day task of managing Diagnostic Imaging based infrastructure and end user computing. Develops, implements, and supports the core functions of the Diagnostic Imaging information systems to enable data driven, cost-effective, high quality, and safe patient care. Supports complex projects for enterprise-level application rollouts including technology system development, implementations, and enhancements to existing technology systems. Designs specifications to support business system changes including implementation, planning, and coordination, client testing and training. Collaborates with Clinical subject matter experts to optimize patient care using data while adhering to clinical regulations regarding privacy and system safety standards.
Essential Functions
The essential functions listed are typical examples of work performed by positions in this job classification. They are not designed to contain or be interpreted as a comprehensive inventory of all duties, tasks, and responsibilities. Employees may also perform other duties as assigned.
Employees must abide by all Joint Commission Requirements including but not limited to sensitivity to cultural diversity, patient care, patient rights and ethical treatment, safety and security of physical environments, emergency management, teamwork, respect for others, participation in ongoing education and training, communication and adherence to safety and quality programs, sustaining compliance with National Patient Safety Goals, and licensure and health screenings.
Must perform all duties and responsibilities in accordance with the hospital's policies and procedures, including its Service Standards and its Code of Conduct.
Designs and builds software to transform how the organization and the Department of Radiology uses data that is both clinical and patient focused
Investigates problem areas and develops software solutions by studying information needs, conferring with users, studying systems flow, data usage, and work processes.
Executes software solutions from idea generation, design, and prototyping to execution.
Provides technical expertise and advice on design for application and solutions including, planning, development, and resolving technical issues.
Provides architectural assessments following all healthcare cyber policies and regulations. Develops design requirements, concept builds, and supports implementations.
Collaborates with other IS teams to ensure smooth and reliable operation of software and infrastructure systems for fulfilling business objectives and processes.
Develops high-quality and reliable applications to merge data from various systems into user friendly views.
Designs and develops applications and dashboards used by physicians, researchers, and department operations that improve patient care, efficiency, quality, and reliability. Creates applications using Artificial Intelligence.
Monitors, administers, and documents systems, services, and applications. Maintains documented, up-to-date detailed system and component maps of data center facilities.
Monitors existing systems to ensure structural integrity. Performs data collection and analysis related to the system performance.
Minimum Qualifications
Any combination of education and experience that would likely provide the required knowledge, skills and abilities as well as possession of any required licenses or certifications is qualifying.
Education: Bachelor's degree in a work-related discipline/field from an accredited college or university

Experience: Two (2) years of progressively responsible and directly related work experience

License/Certification: None required
Knowledge, Skills, & Abilities
These are the observable and measurable attributes and skills required to perform successfully the essential functions of the job and are generally demonstrated through qualifying experience, education, or licensure/certification.
Knowledge to provide technical consultations and presentations
Familiarity with web development, databases, and network
Knowledge of data analysist processes and best practices
Proficiency with at least programming languages such as Java, C++, Python, JavaScript, or similar languages
Knowledge and working experience on backup technologies at enterprise level.
Ability to work with on-premises and on cloud servers
Ability to use good judgement, problem-solving and decision-making skills
Ability to gain, understand and apply information and data as it relates to Information Technology.¿
Physical Requirements and Working Conditions
The Physical Requirements and Working Conditions in which the job is typically performed are available from the Occupational Health Department. Reasonable accommodations will be made to enable individuals with disabilities to perform the essential functions of the job.
Pay Range
Compensation is based on the level and requirements of the role.
Salary within our ranges may also be determined by your education, experience, knowledge, skills, location, and abilities, as required by the role, as well as internal equity and alignment with market data.
Typically, new team members join at the minimum to mid salary range.
Minimum to Midpoint Range (1.0 FTE): $109,200.00 to $138,881.60
Equal Opportunity Employer
Lucile Packard Children's Hospital Stanford strongly values diversity and is committed to equal opportunity and non-discrimination in all of its policies and practices, including the area of employment. Accordingly, LPCH does not discriminate against any person on the basis of race, color, sex, sexual orientation or gender identity, religion, age, national or ethnic origin, political beliefs, marital status, medical condition, genetic information, veteran status, or disability, or the perception of any of the above. People of all genders, members of all racial and ethnic groups, people with disabilities, and veterans are encouraged to apply. Qualified applicants with criminal convictions will be considered after an individualized assessment of the conviction and the job requirements, and where applicable, in compliance with the San Francisco Fair Chance Ordinance.",Unknown / Non-Applicable,Health Care Services & Hospitals,Hospital,Healthcare
"Tech Lead Software Engineer, TikTok Data Access Architecture",san-jose,"TikTok
3.6","San Jose, CA",3.6,Employer Provided Salary:$210K - $358K,3.4,3.4,3.1,3.6,3.0,1001 to 5000 Employees,2016,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul, and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

TikTok Data Access Architecture team is responsible for data access control to all online TikTok data, managing data schema in code for attribution and governing, layout foundation for modernized data tracking, deletion, retention, and linkage. We are building an Infrastructure as Code experience for all data models and storage systems and help automate the development and deployment process by providing frameworks and systems based on metadata and schema.

We are looking for motivated individuals interested in complex engineering challenges around one of the most important aspects of TikTok. You will have the opportunity to work closely with a multidisciplinary team of Mobile Engineers, Frontend Engineers, Site Reliability Engineers, Data Engineers, and Data Scientists in a high-impact and fast-paced environment.

As a Software Engineer on our TikTok Data Access Architecture team, you will:
Design new massive-scale software systems that demand low latency, high reliability, and resilience against disaster, by applying the concept of Infrastructure as Code and Schema as Code.
Develop systems to handle the next phase of growth TikTok's business and ensure high stability and performance.
Collaborate with multiple cross-functional teams to identify new investments, solve critical problems, and deliver high-quality work in rapid product development.
Qualifications
BS Degree in Computer Science or related major, with at least 5 years of working experience.
Proficient in at least one OOP language, such as Java, Go, C++, Python, etc.
Experience in building backend services for large-scale consumer-facing applications.
Familiar with common open source distributed middleware and components such as MySQL, MongoDB, Redis, and MQ.
Understanding of design ideas for distributed system architecture, including but not limited to service-oriented, asynchronous, highly available, scalable, etc.
Deep understanding of computer architectures, data structures, and algorithms.
Good communication and collaboration skills.
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or an accommodation, please reach out to us at usrc@tiktok.com.
Job Information
The base salary range for this position in the selected city is $210000 - $358000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",Unknown / Non-Applicable,Internet & Web Services,Company - Private,Information Technology
MTS Software Development Engineer - Netlist Data Model,san-jose,"Advanced Micro Devices, Inc.
4.2","San Jose, CA",4.2,$125K - $178K (Glassdoor est.),4.2,4.2,3.9,3.7,3.9,10000+ Employees,1969,"What you do at AMD changes everything
We care deeply about transforming lives with AMD technology to enrich our industry, our communities and the world. Our mission is to build great products that accelerate next-generation computing experiences – the building blocks for the data center, artificial intelligence, PCs, gaming and embedded. Underpinning our mission is the AMD culture. We push the limits of innovation to solve the world’s most important challenges. We strive for execution excellence, while being direct, humble, collaborative and inclusive of diverse perspectives. This is who we are at our best. One Company. One Team.
AMD together we advance_
MTS SOFTWARE DEVELOPMENT ENGINEER
THE ROLE:
At AMD, we push the boundaries of what is possible. We believe in changing the world for the better by driving innovation in high-performance computing, graphics, and visualization technologies ' building blocks for gaming, immersive platforms, and the data center.

THE PERSON:
Developing great technology takes more than talent: it takes amazing people who understand collaboration, respect, and who will go the 'extra mile' to achieve unthinkable results. It takes people who have the passion and desire to disrupt the status quo, push boundaries, deliver innovation, and change the world. If you have this type of passion, we invite you to take a look at the opportunities available to come join our team.

KEY RESPONSIBILITES:
Work within and across teams to significantly improve runtime performance and memory usage for current and next-gen architecture
Assess new hardware architecture features in our device pipeline, drive recommendations for solutions in the tool chain
Work on EDA infra-structure projects in the domain of netlist, constraints, security, and licensing
Ensure on-time delivery of high-quality product that meets business and technical requirements
Engage with the application/field engineers to address critical customer designs issues

PREFERRED SKILLS:
Proven track record developing commercial software solutions
Expert software architecture, data structures/algorithm and C++ skills with emphasis on memory, runtime, quality, and scalability
VHDL, Verilog, or EDIF
C++ Code Debugger experience
Experience with FPGA or ASIC design flows is a plus
Experience with scripting languages (Python, Tcl)

ACADEMIC CREDENTIALS:
BS OR MS OR PhD in ELECTRICAL ENGINEERING / COMPUTER ENGINEERING / COMPUTER SCIENCE

LOCATION:
San Jose, Ca.

#LI-JT1

Requisition Number: 185141
Country: United States State: California City: San Jose
Job Function: Design
Benefits offered are described here.
AMD does not accept unsolicited resumes from headhunters, recruitment agencies or fee based recruitment services. AMD and its subsidiaries are equal opportunity employers. We consider candidates regardless of age, ancestry, color, marital status, medical condition, mental or physical disability, national origin, race, religion, political and/or third party affiliation, sex, pregnancy, sexual orientation, gender identity, military or veteran status. Please click here for more information.",$10+ billion (USD),Computer Hardware Development,Company - Public,Information Technology
Software Engineer - Data Engineer,san-jose,Tau,"Redwood City, CA",-1,$121K - $174K (Glassdoor est.),-1,-1,-1,-1,-1,Unknown,Company - Public,"Tau is a venture-backed advanced technology company based in the Bay Area (Redwood City, CA). We design and develop next-generation products for electrification. The company was started because we believe the key to a more sustainable future requires modern power conversion systems to increase the security of the world's energy. We have pioneered technologies that leverage software-enabled hardware to provide industry leading scale, economics, and efficiencies. Our systems include innovations across electric machines, inverters, controllers, thermal management, simulation, and charging systems.
Tau's team of engineers, scientists, technologists, operators, and industry leaders continue to advance our internal technology roadmap while collaborating with commercial partners to deploy our existing products to market in the relentless pursuit of creating efficient power conversion systems for a more sustainable future.
At our core, Tau is made of exceptionally talented and mission-aligned people. Developing complex electromechanical systems is an interdisciplinary challenge. We are looking to expand our team with diverse engineering, scientific, and operational expertise.
Tau is an equal opportunity employer that guarantees a work environment that respects and values diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, veteran status, or disability status.

About you
We are looking for people who aren't afraid to take on new challenges, and are as passionate about energy and electrification as we are:
You find large challenges exciting and enjoy discovering and defining problems as much as solving them.
You deliver. You may enjoy thoughtful conversations about problems and perfecting design, but in the end you know that what matters is delivering innovative, effective, and reliable solutions.
You are a cross disciplinary team member. You are excited to work with, learn from, and contribute to technology teams ranging from electromagnetics, power electronics, controls systems, mechanical, materials, software, computational physics, and beyond.
Prior experience in a relevant engineering field is valued, but the team has openings from early career to expert - candidates of all levels are encouraged to apply.

Job Description
We are looking for a Software Engineer - Data Engineer to join our growing team to both advance our internal technology roadmap and translate our innovative products to market with our commercial partners.
As a member of the controls team, you will model, design, implement, test and benchmark the motor controls of current and future Tau motor drives - including both high and low voltage applications.
What You'll Do
Utilize large-scale data and help Tau engineers design and validate the most compelling and reliable products for our customers
Collect real-time life data from test and simulation systems including retrieving, analyzing and summarizing results to cross-functional teams
Provide support through the whole design cycle by building software and statistical tools that orchestrate all the reliability physics analyses
Answer complex questions on design parameters and behavior
Build scalable data pipelines to deploy fleet health monitoring models
Apply modern statistical frameworks to support the engineering team
Work closely with cross-functional teams to create/interpret/validate numeric models of products and systems
Build visualizations to effectively communicate results
Advance Tau's multiphysics simulation infrastructure including scientific computing pipelines, computational cluster, data storage and retrieval, etc
What You'll Bring
Strong MLOps and DevOps skills
Solid understanding of statistics, probability, and machine learning, and optimization concepts
Strong experience with Python and data manipulation tools including SQL, Pandas, Numpy, Scipy, Matplotlib, Scikit-learn, Jupyter Notebooks, etc
Strong verbal and written communication skills
Familiarity with big data and scientific computing frameworks
Familiar with software engineering best practices including API design, version control, CI/CD, etc
Ability to thrive in a fast-moving and constantly evolving high growth environment
Desired Skills
(Bonus) Ideal candidates with have a background in physics and engineering
Bachelor's degree in Data Science, Computer Science, Industrial Engineering, Mathematics, Physics or a related field
Experience training and maintaining models for real world applications
Strong knowledge of data structures and architectures
Experience with scalable machine learning and time-series modeling
Ability to code robust-apps (potentially interfacing with data streams, etc)
Comfortable in an environment with unstructured, incomplete, and ambiguous data
Curious, open-minded, and driven to solve complex problems
The level will depend on the candidate's experience. Our ideal candidate exhibits a can-do attitude and approaches his or her work with vigor and determination. Candidates will be expected to demonstrate excellence in their respective fields, to possess the ability to learn quickly and to strive for perfection within a fast-paced environment.

Perks
Become part of an emerging company during a rapid growth phase—within an industry undergoing dramatic transformation for a global imperative.
Work with some of the smartest and most talented experts from different fields to: (1) attack some of the most pressing issues of today while (2) contributing to technically demanding and deeply innovative solutions.
Growth potential—we advance team members who have an outsized impact.
Competitive compensation based upon experience level, including stock options—we believe in capturing value in the future we create together.
Flexible time off and paid holidays.
Centrally located in the Bay Area on the Peninsula in vibrant downtown Redwood City
Blocks from the Caltrain
Walking distance to food and entertainment
Easy access to both the 101 and 280
Excellent medical, dental, vision, and life insurance for full time team members.
Comprehensive benefits including HSA and FSA benefits, commuter benefits, ancillary benefits including OneMedical membership, a variety of telehealth services, and more.",-1,-1,Unknown / Non-Applicable,-1
Sr. Network Engineer - Data Center,san-jose,"Feditc Llc
4.0","San Jose, CA",4.0,$80K - $113K (Glassdoor est.),3.9,3.9,3.7,4.0,4.5,51 to 200 Employees,Contract,"FEDITC, LLC is a fast-growing business supporting DoD and other intelligence agencies worldwide. FEDITC develops mission critical national security systems throughout the world directly supporting the Warfighter, DoD Leadership, & the country. We are proud & honored to provide these services.

Overview of position:
FEDITC is seeking a Sr. Network Engineer – Data Center to work in the San Jose area. A United States Citizenship and an DHS EOD is required to be considered for this position.
Support ongoing WAN engineering and operations, to include on-site data center activities at the DHS facility based in San Jose, CA. This candidate should be able to support a variety of network technologies to include, but not limited to, Cisco routing/switching, F5 GTM/LTM load-balancing, Palo Alto firewalls, Cisco SD-WAN powered by Vipleta, as well as experience with Cisco Hyperflex or Nutanix. The ideal candidate will be able to support solution designs and implementations, technology refresh projects, cloud integration and migration projects, and tier 3 and 4 level incident management troubleshooting.

Responsibilities:
Provide on-site data center support at the DHS San Jose facility on an as-needed basis, to include cable management, racking, consoling into devices for troubleshooting, etc.
Develop WAN network solutions to meet requirements, while complying with the DHS network architecture and design standards.
Perform “as is” analyzes of existing network technologies, make recommendations of changes as needed to optimize performance and improve network performance.
Produce DHS systems engineering project artifacts such as requirements, design documents, diagrams, and other required documentation.
Responsible for troubleshooting network incidents, providing root cause analysis and documenting information in ticketing system (ServiceNow) and knowledge repositories (MS SharePoint).
Willing to work nights for network Change Request (CR) implementations and be a part of the on-call rotation for any network incidents that may be escalated from the Network Operations Security Center (NOSC) for nights, weekends, and holidays.
Establish effective working relationships with industry vendors to ensure alignment of current and future set requirements.
Experience/ Skills
At least 3 years of experience working in a data center environment. Must have demonstrated experience working performing level one support (e.g., cabling, racking, consoling into devices for troubleshooting, etc.)
At least 4 years of experience with Cisco technologies to include (routing and switching) and firewall technology (e.g., ISR, ASR, CSR, ASA, Nexus, TACACS/ISE)
Demonstrated experience using SD-WAN technologies, specifically Cisco SD-WAN powered by Vipleta.
Strong knowledge of routing protocols (e.g., BGP, EIGRP, OSPF) and network protocols (e.g., TCP/IP, GRE, IPSEC, and VRF)
3+ years working in a WAN environment, strong experience in incident and operations management.
Strong knowledge of IT security topics to networks and applications with solutions to mitigate those issues.
Experience creating/writing design documentation, diagrams and other project artifact deliverables.
Must be resourceful in learning a very complex and dynamically changing network.
Must be able to work independently in fast paced, dynamic environment.
Must live in close proximity to the San Jose, CA data center facility to support both planned and unplanned activities.
Must be able to lift at least 50 pounds (i.e., support to data center physical devices)

Education:
BA / BS (relevant field); relevant IT experience may be a substitute for education.

Desired Certifications:
Cisco CCNA, Cisco CCNP, Cisco CCIE,
Palo Alto Networks Certified Network Security Engineer / Administrator, F5

Clearance:
DHS EOD is required.
Must be a US Citizen and pass a background check.
Maintain applicable security clearance(s) at the level required by the client and/or applicable certification(s) as requested by FEDITC and/or required by FEDITC’S Client(s)/Customer(s)/Prime contractor(s).

FEDITC, LLC. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex (including pregnancy), sexual orientation, gender identity or expression, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. FEDITC, LLC. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.",-1,Information Technology,Information Technology Support Services,$25 to $100 million (USD)
"Senior Software Engineer, Platform - Data + AI (Back-End)",san-jose,"C3 AI
3.9","Redwood City, CA",3.9,Employer Provided Salary:$155K - $190K,4.1,3.7,3.6,4.1,3.4,501 to 1000 Employees,2009,"C3.ai, Inc. (NYSE:AI) is a leading provider of Enterprise AI software for accelerating digital transformation. The proven C3 AI Platform provides comprehensive services to build enterprise-scale AI applications more efficiently and cost-effectively than alternative approaches. The core of the C3 AI offering is an open, data-driven AI architecture that dramatically simplifies data science and application development. Learn more at: www.c3.ai
C3 AI is looking for Senior Software Engineers to join the rapidly growing Data org within the Platform Engineering department. Successful candidates will get the opportunity to work on high-value technologies at the intersection of large-scale distributed systems, data infrastructure, and machine learning. You will design, develop, and maintain various features in a highly scalable and extensible AI/ML platform for large-scale applications, involving data science, distributed systems, and multi-cloud strategy.
You will be given opportunities to take ownership of components, collaborate to drive technical direction, and work on interesting, impactful projects. Join us in building the next-generation AI/ML platform at petabyte level scale that powers some of the world's largest companies in Energy, Financial Services, Utilities, Health Care, Aerospace, Defense, etc. Accelerate your career in the leading enterprise AI company that is in a hyper-growth trajectory.
Responsibilities:
Design and develop infrastructure and services to enable data pipelines for petabyte level scale and more.
Design and develop abstractions over datastores such as Cassandra, PostgreSQL, Snowflake, etc.
Design and develop file system abstractions over AWS S3, Azure Blobs, HDFS, etc.
Design and develop connectors to various external data stores.
Design and develop distributed system components for stream processing, queueing, batch processing, analytics engines, etc.
Develop and maintain industry-leading, high-performance APIs for AL/ML applications.
Develop and maintain features for distributed computations over large-scale data for ML workflows.
Design and develop ML-specific data-systems such as feature stores and behavioral frameworks such as recommendation engines.
Design and develop integrations with distributed computing technologies such as Apache Spark, Ray, etc. for data exploration and ML workload orchestration.
Design and develop integrations with data analysis libraries such as Pandas, Koalas, etc.
Develop and production AI/ML models for failure prediction, data schema inferencing, etc.
Work on frameworks for performance, scalability, and reliability tracking over different components of a highly extensible AI/ML platform.
Work with architects, product managers, and software engineers across teams in a highly collaborative environment.
Participate and provide insights in technical discussions.
Write clean code following a test-driven methodology.
Deliver commitments promptly following agile software development methodology.
Qualifications:
Bachelor of Science in Computer Science, Computer Engineering, or related fields.
Strong understanding of Computer Science fundamentals.
High proficiency in coding with Java, C++, C#, or some other compiled language. Python would also be acceptable.
Strong competency in object-oriented programming, data structures, algorithms, and software design patterns.
Experience with version control systems such as Git.
Experience with large-scale distributed systems.
Experience with any public cloud platform (AWS, Azure, GCP).
Some familiarity with distributed computing technologies (e.g., Hadoop, Spark, Kafka). Familiarity with managed versions of these technologies on public cloud platforms is also acceptable.
Familiarity with technologies in the modern data science/analysis and engineering ecosystem (e.g., Pandas, Koalas).
Good verbal and written technical communication ability to facilitate collaboration.
Thrive in a fast-paced, dynamic environment and value end-to-end ownership of components.
Intellectually curious and open to challenges.
Preferred Qualifications:
Advanced degree in engineering, sciences, or related field.
Experience with Agile development methodology.
Experience developing and working with REST and/or GraphQL APIs.
Experience building scalable and reliable data pipelines.
Experience with integration of data from multiple sources.
Experience working with analytics and/or data processing engines.
Experience developing distributed computation over large-scale data.
Experience working with distributed computing frameworks (e.g., Hadoop, Spark, Kafka).
Experience with data science/analysis libraries (e.g., Pandas, Koalas).
Experience with task schedulers in distributed computing (e.g., Spark, Ray, Dask).
Familiarity with machine learning workload orchestration in a distributed computing environment.
Familiarity with workflow execution and/or optimization using DAGs, ideally for machine learning use-cases.
Conceptual understanding of orchestration and resource provisioning systems (Kubernetes).
C3 AI provides excellent benefits and a competitive compensation package, which include:
Generous equity plan.
Salary range: $155,000 - $190,000 USD.
C3 AI is proud to be an Equal Opportunity and Affirmative Action Employer. We do not discriminate on the basis of any legally protected characteristics, including disabled and veteran status.",Unknown / Non-Applicable,Enterprise Software & Network Solutions,Company - Public,Information Technology
Controls & Data Systems Software Engineer,san-jose,"SLAC National Accelerator Laboratory
4.1","Menlo Park, CA",4.1,Employer Provided Salary:$140K - $198K,3.9,3.8,3.3,3.7,3.8,1001 to 5000 Employees,1962,"SLAC Job Postings

Position Overview:
Do you enjoy collaborating with a diverse group of people to solve complex challenges? Does contributing to breakthrough discoveries in science and working with unique experimental instrumentation in a world-leading scientific research environment excite you? The Controls & Data Systems (CDS) Division within the Technology and Innovation Directorate at SLAC is seeking a Software Engineer to plan, implement, and operate customized experimental installations, and develop enhancements to SLAC scientific instrumentation and supporting hardware and software solutions for SLAC experiments.
Reporting to the Advanced Data Systems Department Head, the Controls and Data Systems Software Engineer will be a member of a multidisciplinary team of physicists, electronic and software engineers developing software and hardware solutions to support scientific instrumentation, controls, and data acquisition systems. This position will also work with scientific and operations support staff involved in advancing scientific instrumentation capabilities.
Your specific responsibilities include:
Lead the planning and execution of customized experimental installations, delegating tasks to supporting staff and contractors, as appropriate.
Reconfigure hardware and software to meet experimental needs; develop software for data analysis, data acquisition, controls, and to support new instrumentation.
Manage hardware and software for the controls, data acquisition, and data-analysis systems and related infrastructure such as computers and local networks, detector systems, digitizers, oscilloscopes, cameras, power supplies, motion systems, vacuum and PLC systems, etc.
Participate in upgrades to scientific instrumentation and capabilities including laser systems, timing systems, hardware and software selection, and lead teams of engineers and technicians to implement and integrate the control, data acquisition, and analysis aspects of these upgrades.
Additional opportunities include development toward, or project leadership for core capabilities of the controls and data systems including:
Real-time and offline data analysis frameworks.
Experience with accelerators like Graphics Processing Units (GPUs)
Experience with computing clusters, and high concurrency storage systems.
Real time Data Acquisition and driver development.
Hardware-level data reduction and veto systems in custom FPGA based platform(s).
Graphical User Interfaces, monitoring and alerting systems, intelligent systems such as collision avoidance and equipment protection logic.
To be successful in this position you will bring:
A Bachelor’s degree in physical sciences, computing, or an engineering field such as mechatronics, electronics, or related STEM field and 4 years of experience including developing and operating software and hardware systems for instrumentation, data acquisition, and/or data analysis, performing hardware and software configuration in a scientific or R&D environment, and developing and managing software for data analysis, data acquisition, controls, and to support instrumentation and related infrastructure.
Demonstrated programming skills with C and/or C++ and experience with Linux/Unix and a scripting language such as Python.
Exceptional communications skills and ability to work well in a research and development team.
In addition, preferred requirements include:
Familiarity with EPICS framework, knowledge of motor, vacuum and camera controls.
Demonstrated project leadership, planning, and excellent organizational skills.
Developing scientific instrumentation.
SLAC Employee Competencies:
Effective Decisions: Uses job knowledge and solid judgment to make quality decisions in a timely manner.
Self-Development: Pursues a variety of venues and opportunities to continue learning and developing.
Dependability: Can be counted on to deliver results with a sense of personal responsibility for expected outcomes.
Initiative: Pursues work and interactions proactively with optimism, positive energy, and motivation to move things forward.
Adaptability: Flexes as needed when change occurs, maintains an open outlook while adjusting and accommodating changes.
Communication: Ensures effective information flow to various audiences and creates and delivers clear, appropriate written, spoken, presented messages.
Relationships: Builds relationships to foster trust, collaboration, and a positive climate to achieve common goals.
Physical requirements and Working conditions:
Consistent with its obligations under the law, the University will provide reasonable accommodation to any employee with a disability who requires accommodation to perform the essential functions of his or her job.
Work Standard:
Interpersonal Skills: Demonstrates the ability to work well with Stanford colleagues and clients and with external organizations.
Promote Culture of Safety: Demonstrates commitment to personal responsibility and value for safety; communicates safety concerns; uses and promotes safe behaviors based on training and lessons learned.
Subject to and expected to comply with all applicable University policies and procedures, including but not limited to the personnel policies and other policies found in the University’s Administrative Guide,
As an organization that receives federal funding, SLAC and Stanford University have a COVID-19 vaccination requirement that will apply to all university employees, including those working remotely in the United States and applicable subcontractors.
-
Classification Title: Staff Engineer 3
Grade: L, Job Code: 0133
Duration: Regular Continuing
The expected pay range for this position is $140,000 to $198,000 per annum. SLAC National Accelerator Laboratory/Stanford University provides pay ranges representing its good faith estimate of what the university reasonably expects to pay for a position. The pay offered to a selected candidate will be determined based on factors such as (but not limited to) the scope and responsibilities of the position, the qualifications of the selected candidate, departmental budget availability, internal equity, geographic location and external market pay for comparable jobs.",Unknown / Non-Applicable,National Agencies,Government,Government & Public Administration
Data Engineer/Senior Data Engineer,san-jose,"C3 AI
3.9","Redwood City, CA",3.9,Employer Provided Salary:$85K - $161K,4.1,3.7,3.6,4.1,3.4,501 to 1000 Employees,2009,"C3.ai, Inc. (NYSE:AI) is a leading provider of Enterprise AI software for accelerating digital transformation. The proven C3 AI Platform provides comprehensive services to build enterprise-scale AI applications more efficiently and cost-effectively than alternative approaches. The core of the C3 AI offering is an open, data-driven AI architecture that dramatically simplifies data science and application development. Learn more at: www.c3.ai
C3 AI has an opening for a Data Engineer/Senior Data Engineer. In this post-sales, customer-facing position, you will have the opportunity to build and maintain data models, integrations and pipelines for Enterprise AI Applications using the C3 AI Suite. The C3 AI product suite is entirely data-driven, so a great candidate will have a passion for acquiring, analyzing, and transforming data to generate insight. This role is very hands-on and requires a structured mindset and solid implementation skills.
Qualified candidates will have a solid knowledge of integration architecture and best-practice distributed data processing concepts.
Responsibilities:
Engage directly with customers to participate in design and development of data integration and architecture solution according to functional and performance requirements
Develop complex data integrations and pipelines on high volume, high frequency datasets to enable AI Application workflows (feature engineering, training, inference, alerting)
Participate in the development of documentation, technical procedures and user support guides
Perform debugging, troubleshooting, modifications and unit testing of integration solutions
Support, monitor, execute production application jobs and processes
Qualifications:
2+ years of experience (4+ for Senior Data Engineer) with system/data integration, development or implementation of enterprise and/or cloud software
Engineering degree in Computer Science, Engineering or related field
Extensive hands-on experience with data integration/EAI technologies (File, API, Queues, Streams), ETL Tools and building custom data pipelines
Demonstrated proficiency with Python, JavaScript and/or Java
Familiarity with version control/SCM is a must (experience with git is a plus)
Experience with relational and NoSQL databases (any vendor)
Solid understanding of cloud computing concepts
Strong organizational and troubleshooting skills with attention to detail
Strong analytical ability, judgment and problem-solving techniques
Interpersonal and communication skills with the ability to work effectively in a cross functional team
Preferred Qualifications:
Expertise in Postgres and Cassandra
Experience with Hadoop, Spark, Cloud Databases (Snowflake, BigQuery, Redshift)
Experience implementing and supporting DataOps in a highly available, mission critical environment
Working knowledge of Machine Learning algorithms
Experience with SaaS and business intelligence or advanced analytics implementations
C3 AI provides excellent benefits and a competitive compensation package, which includes:
Generous equity plan.
Salary range: $85,000 - $161,000 USD.
Candidates must be authorized to work in the United States without the need for current or future company sponsorship.
C3 AI is proud to be an Equal Opportunity and Affirmative Action Employer. We do not discriminate on the basis of any legally protected characteristics, including disabled and veteran status.",Unknown / Non-Applicable,Enterprise Software & Network Solutions,Company - Public,Information Technology
Sr. UAM Data Communication Engineer,san-jose,"Supernal
2.8","Fremont, CA",2.8,Employer Provided Salary:$166K - $233K,3.0,2.4,2.2,3.7,3.3,Unknown,Company - Private,"Supernal is at the forefront of creating emerging mobility solutions that will foster the development of human-centered cities. We are designing a completely new electric vertical take-off and landing (eVTOL) aircraft tailored to the mobility needs of future cities. This allows passengers a seamless intermodal journey that safely transports them to their final destination. We fuse research in autonomy, robotics, aviation and services to define a new category of mobility for the world's communities. We believe in creative thinking and collaboration to help build a better mobility experience for everyone, improving people's ability to move – whether for work or play.
What we do:
The Sr. UAM Data Communication Engineer is responsible for the design, development, and verification of several communication links for aircraft flight automation like real-time telemetry, ground link, vehicle to vehicle communication etc. from flight testing as well, flight simulator software. This role is also responsible for generating both high- and low-level requirements, performing peer reviews, developing unit and integration test plans, and completing verification and validation of several communication requirements for mission critical software.
What you can do:
Develop software and algorithms for aircraft communications, including like real-time telemetry, ground link, vehicle to vehicle communication, lost link, and user interface,
Surveying and contributing to V2V standardizations in various standard meeting.
Build software tools for simulation, log analysis, automated testing, and development prototyping.
Generate both high- and low-level software requirements, implement software algorithms, develop unit and integration test plans, and perform verification and validation of communication software.
Participate in the software architecture and design process of modular systems for embedded, desktop and hosted environments.
Analyze field reports, flight logs, fault analysis and bug reporting to ensure continued improvement of safety critical software.
Work collaboratively with other engineers working on software, algorithms, middleware and simulations.
Other duties as assigned
What you can contribute:
Bachelor's degree in a science, technology, engineering, or mathematics field, or equivalent experience.
A minimum of five (5) years of experience (an equivalent combination of education and experience may be considered)
Experience developing embedded software for aviation, automotive, or robotics applications.
Strong knowledge of wireless communication at physical layer and/or medium access control layers such as radio modulation/demodulation, channel coding, and channel access mechanism
Solid understanding of standardized communication technologies such as PC5-based C-V2X, LTE-V2V PC5, IEEE 802.11p/DSRC, IEEE 802.11ad etc
Experience with MAVLink, ADSB, Protocol development / integration experience (LCM, MAVLink, WiFi or others)
Strong proficiency in C required, Knowledge of C++,Python and ROS preferred
Experience with model based, code generation tools (e.g. MATLAB/Simulink, SCADE)
Experience in simulations and verification methodologies
Experience with ISO 26262, DO-178C, or other safety-related software and product development processes
Proficiency with Git, Linux and embedded RTOS(s)
Strong proficiency in modern software development workflows and practices, including version control, build and test systems, and peer review
You may also be able to contribute:
Master's degree preferred
Any offer of employment is conditioned upon the successful completion of a background check. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, citizenship, sex, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other category or class protected under applicable federal, state or local law. Individuals with disabilities may request a reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation at: ta-support@supernal.aero
This position will include access to certain technology and/or software source code that will be subject to U.S. export control laws. If an export license or other export control authorization is required in connection with your employment, your employment is contingent upon Supernal's receipt of such license or authorization and approvals and your continued compliance with all conditions and limitations contained in such license or authorization.
Base pay offered may vary depending on skills, experience, job-related knowledge and location. This position is also eligible for a bonus as part of total compensation.
The pay range for this position is:
$166,400—$232,960 USD
Click HERE or visit: https://jobs.supernal.aero/benefits to view our benefits!",-1,Aerospace & Defense,Aerospace & Defense,Unknown / Non-Applicable
"Sr./Staff Software Engineer, Big Data",san-jose,"ShareThis, Inc
4.0","Palo Alto, CA",4.0,$133K - $172K (Glassdoor est.),3.9,3.9,3.8,4.1,4.3,51 to 200 Employees,2007,"About Us:
ShareThis is a big data company that owns online behavior data of 1b+ users globally. We are developing an audience intelligence platform with cutting edge big data technologies. We are looking for innovative software engineer to join our exciting projects and platform development.
You will be responsible for big data software and platform architecture and development.
What we expect from you
5+ years of experience in big data software and platform development
Fluent in two or more of the programming languages such as Scala, Java, Python, GoLang
Knowledge of microservices & serverless architectures
Experience building large CI/CD pipelines
Hands-on experiences in Spark and AWS EMR
Strong experiences with AWS (S3, SQS, EMR etc)
Strong automation skills with Python and/or Bash
Experience working in fast-paced Agile teams
Ability to learn new tools and workflows with little or no supervision
Education· BS/MS in Computer Science or Software Engineering
Nice to have some of the following
Experience with AWS.
Experience with SQL/NoSQL Database
Working knowledge of Security and Privacy in big data platform
Google Bigquery
Experience with Azure, Snowflake is a plus
Experience with Airflow",$25 to $100 million (USD),Internet & Web Services,Company - Private,Information Technology
