Job Title,Glassdoor Location,Employer Name,Location,Rating,Salary,Carrier Opportunities,Culure And Values,Senior Management,Comp And Benefits,Life Balance,Company Size,Found year,Description,Company Revenue,Industry,Company Type,Company Sector
Data Engineer,atlanta,Mericaninc,"Atlanta, GA",-1,Employer Provided Salary:$60.00 - $65.00 Per Hour,-1,-1,-1,-1,-1,Unknown,Company - Public,"Job Role: Data engineer
Location: Hybrid model (Day 01 onsite)
Type: Contract
EXPERIENCE :
Python
Kafka or Kinesis
DevOps deployment model
AWS
Job Type: Contract
Salary: $60.00 - $65.00 per hour
Schedule:
Day shift
Evening shift
Monday to Friday
Ability to commute/relocate:
Atlanta, GA 30303: Reliably commute or planning to relocate before starting work (Required)
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: One location",-1,-1,Unknown / Non-Applicable,-1
Data Engineer,atlanta,"PrizePicks
4.8","Atlanta, GA",4.8,$82K - $117K (Glassdoor est.),4.7,4.8,4.6,4.2,4.6,51 to 200 Employees,2015,"At PrizePicks, we are the fastest growing sports company in North America, as recognized by Inc. 5000. As the leading platform for Daily Fantasy Sports, we cover a diverse range of sports leagues, including the NFL, NBA, and Esports titles like League of Legends and CS : GO. Our team of over 200 employees thrives in an inclusive culture that values individuals from diverse backgrounds, regardless of their level of sports fandom. Ready to reimagine the DFS industry together?
Our Analytics Team is responsible for building and maintaining analytics tools and workflows to support the PrizePicks business. By developing, maintaining, and testing data generation infrastructures, you will enable the PrizePicks business to make smarter, better, and faster data-driven decisions.
What you'll do:
Create, maintain and orchestrate optimal data pipeline architecture
Assemble large, complex data sets that meet functional / non-functional business requirements.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
Improve and streamline data systems to drive innovation within Prizepicks
What you have:
3+ years of experience building frameworks for data ingestion pipelines but real time and batch using data modeling, ETL/ELT processes
Stellar SQL skills, experience building DBT pipelines in production and know your way around structured, semi-structured and unstructured data.
Have built and optimized 'big data' data pipelines, architectures and data sets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Experience with Python and other object oriented scripting languages
Cloud experience: AWS, EC2, EMR, RDS, Redshift, GCP, etc..
Not required but would be awesome if you have experience with any of the following data pipeline and workflow tools: Azkaban, Luigi, Airflow, Prefect, etc.
Where you'll live:
Anywhere in the US is fine (we are based in Atlanta, GA)
Benefits you'll receive:
In addition to your great compensation package, company subsidized medical/dental/vision coverage plans and matching 401(k), we'll shower you with perks including:
Break room with ping pong, endless snacks and in-office lunch once a week
Unlimited PTO to encourage a healthy work/life balance (2 week min required!)
Modern work schedule focused on getting the job done, not hours clocked
Workplace flexibility
Company and team outings, we encourage a tight-knit workplace
Generous Maternity AND Paternity leave (16 weeks!)
Annual bonus & stock options
Wellness program
Company equipment provided (Windows & Mac options)
Annual performance reviews with opportunity for growth and career development
#LI-REMOTE

You must be authorized to work for any employer in the U.S. We are unable to sponsor or take over sponsorship or an employment Visa at this time.
PrizePicks is an Equal Opportunity Employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.",Unknown / Non-Applicable,Sports & Recreation,Company - Private,"Arts, Entertainment & Recreation"
Data Engineer,atlanta,"FanDuel
4.0","Atlanta, GA",4.0,$80K - $118K (Glassdoor est.),3.8,4.0,3.7,3.8,3.8,501 to 1000 Employees,2009,"ABOUT FANDUEL GROUP
There are more ways to win, here at FanDuel. We're willing to bet on it.
THE ROSTER…
At FanDuel Group, we give fans a new and innovative way to interact with their favorite games, sports and teams. We're dedicated to building a winning team and we pride ourselves on being able to make every moment mean more, especially when it comes to your career. So, what does ""winning"" look like at FanDuel? It's recognition for your hard-earned results, a culture that brings out your best work—and a roster full of talented coworkers. Make no mistake, we are here to win, but we believe in winning right. That means we'll never compromise when it comes to looking out for our teammates. From creatives professionals to cutting edge technology innovators, FanDuel offers a wide range of career opportunities, best in class benefits, and the tools to explore and grow into your best selves. At FanDuel, our principle of ""We Are One Team"" runs through all our offices across the globe, and you can expect to be a part of an exciting company with many opportunities to grow and be successful.
WHO WE ARE…
FanDuel Group is an innovative sports-tech entertainment company that is changing the way consumers engage with their favorite sports, teams, and leagues. The premier gaming destination in the United States, FanDuel Group consists of a portfolio of leading brands across gaming, sports betting, daily fantasy sports, advance-deposit wagering, and TV/media.
FanDuel Group has a presence across all 50 states with approximately 17 million customers and nearly 30 retail locations. The company is based in New York with offices in California, New Jersey, Florida, Oregon, Georgia, Portugal, Romania and Scotland.
Its network FanDuel TV and FanDuel+ are broadly distributed on linear cable television and through its relationships with leading direct-to-consumer OTT platforms.
FanDuel Group is a subsidiary of Flutter Entertainment plc, the world's largest sports betting and gaming operator with a portfolio of globally recognized brands and a constituent of the FTSE 100 index of the London Stock Exchange.
THE POSITION
Our roster has an opening with your name on it
FanDuel Group is looking for an experienced Data Engineer with deep understanding of large-scale data handling and processing best practices in a cloud environment to help us build scalable systems. As our data is a key component of the business used by almost every facet of the company, including product development, marketing, operations, and finance. It is vital that we deliver robust solutions that ensure reliable access to data with a focus on quality and availability.
Our competitive edge comes from making decisions based on accurate and timely data and your work will provide access to that data across the whole company. Looking ahead to the next phase of our data platform we are keen to do more with real time data processing and working with our data scientists to create machine learning pipelines
THE GAME PLAN
Everyone on our team has a part to play
Creating and maintain optimal data pipeline architecture
Designing and implementing data pipelines required in the data warehouse and data lake in batch or real-time using data transformation technologies.
Identifying, designing, and implementing internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability
Designing and deploying data models and views with large datasets that meet functional / non-functional business requirements
Delivering timely after-action reporting to state regulatory groups
Delivering quality production-ready code in an agile environment
Delivering test plans, monitoring, debugging and technical documents as a part of development cycle
Creating data tools for analytics and working with stakeholders across all departments to assist with data-related technical issues and supporting their data infrastructure needs
THE STATS
What we're looking for in our next teammate
Experience writing Python scripts
Working SQL knowledge and experience working with relational databases
Build processes supporting data transformation, data structures, metadata, dependency, and workload management,
Show proficiency understanding complex ETL processes
Demonstrate the ability to optimize processes
Knowledge of data integrity and relational rules
Understanding of AWS and Google Cloud knowledge of DMS tasks and processes are nice to have.
Ability to quickly learn new technologies is critical
Proficiency with agile or lean development practices
Understanding of regulated systems and sensitive data
PLAYER CONTRACT
We treat our team right
From our many opportunities for professional development to our generous insurance and paid leave policies, we're committed to making sure our employees get as much out of FanDuel as we ask them to give. Competitive compensation is just the beginning. As part of our team, you can expect:
An exciting and fun environment committed to driving real growth
Opportunities to build really cool products that fans love
Mentorship and professional development resources to help you refine your game
Flexible vacation allowance to let you refuel
Hall of Fame benefit programs and platforms
FanDuel Group is an equal opportunities employer and we believe, as one of our principal states, ""We Are One Team!"" We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status. We believe FanDuel is strongest and best able to compete if all employees feel valued, respected, and included. We want our team to include diverse individuals because diversity of thought, diversity of perspectives, and diversity of experiences leads to better performance. Having a diverse and inclusive workforce is a core value that we believe makes our company stronger and more competitive as One Team!
#LI-Hybrid",$100 to $500 million (USD),Sports & Recreation,Company - Private,"Arts, Entertainment & Recreation"
"Senior Data Engineer, Analytics",atlanta,"Standard AI
4.0","Atlanta, GA",4.0,$104K - $147K (Glassdoor est.),4.0,3.7,3.6,4.1,3.8,51 to 200 Employees,2017,"Standard AI has transformed retail as we know it. With the first autonomous retail solution that works in any existing store, we enable customers to walk in, grab what they need, and walk out - without waiting in line or stopping to pay. The company's computer vision solution is the only one that can be quickly and easily installed in retailers' existing stores, representing a giant leap forward for retail tech that enables retailers to rapidly deliver amazing new shopping experiences to customers. Standard has launched dozens of stores alongside Circle K, Compass Group, and others and have hundreds more on the way. We're the most well funded in our space, backed by some of Silicon Valley's leading investors including SoftBank, CRV, Initialized, EQT, Draper Associates, and Y Combinator.
The Analytics team is structured as a centralized Analytics team at the company with embedded partnerships with Engineering, Operations, Product, and Sales teams. The team plays a critical role in informing and evangelizing data-driven decision making across all these functional areas. As a Data Engineer on the Analytics team, you will be tasked with building data pipelines that underlie our product metrics. You will be focused on building ETL pipelines, developing data schemas, and building fundamental infrastructure to enable downstream analysts and data scientists.
This is a Full Time role and can be based remotely anywhere within the US on an ongoing basis. Standard AI is a remote first company. We want our employees to have the flexibility to create work habits, locations, and schedules that best fit their lives.
What you'll do here:
Build and maintain well-tested, up to date, documented datasets that underlie our key metrics like receipt accuracy
Partner with stakeholder teams to ingest and process raw datasets for downstream analysts/data scientists
Orchestrate data workflows to automate, schedule and monitor data pipelines with tools like Airflow
Troubleshoot data quality issues and resolve broken data pipelines
Democratize and productize our data by exposing derived data sources as APIs to other stakeholder teams
Help to define and improve our internal standards for style, maintainability, and software engineering best practices (i.e. version control and CI/CD) for a robust data infrastructure
Provide data engineering expertise for the rest of the Analytics Team. Lead designing the next generation of our data infrastructure
Who you are:
You are an expert with building, maintaining and optimizing scalable data pipelines and compute, architectures, queries, and datasets. We are looking for someone who values code simplicity and performance
You are an expert in SQL, Python and PySpark
You have experience querying and doing transformations on large structured/unstructured datasets in SQL/Hive, Spark, Apache Flink etc.
You are knowledgable of cloud data technologies like Snowflake and Databricks. We work with GCP services (Cloud SQL, BigQuery, Spanner)
You have proven experience building data pipelines with orchestration tools such as AirFlow or Luigi
You have outstanding written and verbal communication skills and comfortable presenting ideas to peers and across the company
You are able to thrive in a remote work environment and can manage and prioritize multiple initiatives
You have a passion for evangelizing best practices and creative problem solving. Things break, and we are looking for someone who thrives in getting to the bottom of issues
You have a desire to learn, and improve your skills. Data is an ever evolving field, the tools of today may not be the tools of tomorrow
Why you might want to work with us:
100% employer-paid medical, dental and vision premiums, as well as generous contributions towards dependent premiums.
An inclusive culture. Employee Resource Groups, DEI focused training and resources, and opportunities for community service and engagement.
Fertility and family planning assistance provided through Maven Clinic, as well as flexible scheduling to accommodate for childcare needs and generous parental leave policies.
Flexible Time Off to be used for vacations, sick time and/or mental health days, 12 US Company Holidays plus 2 additional Floating Holidays.
We offer very competitive compensation. In addition to the Base Salary, we also offer Stock Options and Best-in-Class Benefits. The total compensation package will depend on multiple factors such as location, level, related experience and interview performance.
Target Starting Salary - Remote, USA
$165,000—$180,000 USD
Standard provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity, or gender expression. We are committed to a diverse and inclusive workforce and welcome people from all backgrounds, experiences, perspectives, and abilities.",Unknown / Non-Applicable,Computer Hardware Development,Company - Private,Information Technology
Senior Data Engineer,atlanta,"Otomashen Inc
5.0","Atlanta, GA",5.0,Employer Provided Salary:$70.00 - $71.00 Per Hour,5.0,5.0,5.0,5.0,5.0,1 to 50 Employees,Company - Public,"Note: we don’t need Big Data Engineer
Senior Data Engineer
Atlanta, GA or NY - DAY 1 ONISTE
Main Skills to focus on: GCP, Reporting Tool: Power BI, SSIS/ SSRS, ETL
8+ years of experience with reporting tools like Google Data Studio, Power BI, MS Excel, Looker, Tableau, etc. Proficiency with TSQL, Python, R etc.
In-depth understanding of RDBMS systems and usage of OLAP, OLTP for BI needs - MS SQL, My SQL, Maria DB and Oracle hands on experience preferred.
Demonstrated Data Visualization experience (Power BI / SSRS / Tableau / Looker / Google Data Studio). ETL experience such as SSIS.
Ability to write complex SQL, cohort / comparative analysis, and Data modeling skills. Strong knowledge of Data Warehousing and Multidimensional Data Modeling. Multidimensional Vs Tabular Data modeling. Star Schema Vs Snowflake, Fact & Dimension tables etc.
Technical expertise with DB design / development, ETL, data mining and segmentation techniques, handling large volumes of data and building scalable systems.
Knowledge of back-end and front-end technologies: SQL, HTML, JSON etc.
Experience with GCP and migrate legacy ETL.
Experience with GCP tools like
Cloud Composer
Cloud Build
Cloud Functions
GCP ETL tools (Data Fusion or Data Prep or Data Proc)
BigQuery
Cloud Bucket Management
Job Duties
Ability to partner with the business in an extremely agile, iterative, and collaborative process to generate ""simplified” operational and business views of a complex and fragmented set of enterprise sales and operations data.
Experienced and comfortable with production prototyping and DevOps type delivery.
Hands on experience with BI / Data Analysis, collecting business needs and converting those into technical reporting and dashboards. Act as liaison between the end users & tech team.
Support users in the learning process for the reporting tools, User training on the data platform
Skilled communication, data presentation and storytelling skills. Promote the Self-Service BI culture.
Create and maintain replicable and scalable data pipelines for data generation, integration and dashboards displaying the metrics to facilitate business decisions.
Maintain the DW standardization guidelines and methodologies, design sampling strategies to achieve the precise metrics of data standardization algorithms and ensure the quality of assessment.
Experience conducting quantitative and qualitative financial & operational analyses working with complex unstructured datasets. Experience in Project Scoping, Process-Design, BA and PM work.
Maintain Web Analytics platform to track and analyze site visits, conversions, promo tracking, hit maps etc. Experience with tools like Google Analytics, Adobe Analytics etc.
Certifications a Plus: Any GCP Cloud Certification
Job Type: Contract
Salary: $70.00 - $71.00 per hour
Experience level:
9 years
Schedule:
8 hour shift
Monday to Friday
Ability to commute/relocate:
Atlanta, GA 30303: Reliably commute or planning to relocate before starting work (Required)
Experience:
GCP: 5 years (Preferred)
Google Cloud Platform: 5 years (Preferred)
GCP ETL: 5 years (Preferred)
License/Certification:
Google Cloud Platform (Preferred)
Work Location: One location",-1,-1,Unknown / Non-Applicable,-1
AWS Data Engineer,atlanta,"Experient Group
4.8","Atlanta, GA",4.8,$80K - $112K (Glassdoor est.),4.3,4.8,4.6,4.5,4.8,51 to 200 Employees,2001,"AWS Data Engineer
Work With Us
At Experient Group, we value community, collaboration and people who are willing to roll up their sleeves to get the job done. While functional and technical skills are critical, we place a priority on hiring people who match our values. Our philosophy is simple: we attract and hire talented people, then provide them with a supportive community, career opportunities and guidance from our experienced leadership so they can thrive. In short, we strive to serve our people better than anyone else.
We are seeking an AWS Data Engineer to join our Technology Solutions group and work with one of our major clients on a fast-paced, agile development team.
What you’ll do
Work as part of a team developing a new corporate communications application for a leading quick service restaurant chain.
Participate in AWS data architecture discussions and help determine the overall AWS data architecture.
Help build the AWS environment using your AWS data engineering and infrastructure skills.
What you will bring
5+ years of experience with the following:
ETL experience with AWS cloud
AWS Glue
Python
Data Streaming
REST APIs
Strong analytical and problem-solving skills
Excellent verbal and written communication skills
Passion for learning and a passion for solving business problems with technology.
A strong record of academic accomplishment and a 4-year college degree with a major in Computer Science or related field
Strong team player, self-motivated, and willing to learn
Preferred
Application development experience with GoLang.
Database experience with Postgres.

About Us
Experient Group is an Atlanta-based business + IT consultancy that offers flexible and innovative solutions tailored to our clients' business environment, culture and budget. We don't assume anything - we set out to continually prove ourselves by going above and beyond in every client engagement. We work collaboratively to understand our clients' business and provide guidance that enables them to achieve results.
Experient Group is an Equal Employment Opportunity (EEO) employer and welcomes all qualified applicants. Applicants will receive fair and impartial consideration without regard to race, sex, religion, national origin, age, sexual orientation, disability, veteran status, genetic data, or other legally protected status
3DyQHgoI74",$5 to $25 million (USD),Business Consulting,Company - Private,Management & Consulting
Data Engineer,atlanta,"Maven Workforce
4.1","Alpharetta, GA",4.1,Employer Provided Salary:$50.00 Per Hour,4.3,4.2,4.3,3.9,4.2,51 to 200 Employees,2008,"Must Have skills:
Building Data Pipeline exp is a must
ETL Tools – SSIS, Alteryx
Data modelling
SQL Server development
Microsoft SQL Stack
Responsibilities:
Data acquisition and ingestion - Identify data sources and build pipelines using various ETL tools such as but not limited to, SSIS, and Alteryx. Data sources including but not limited to SQL Server, SAP, Teradata, Hadoop\Hive, PostgreSQL, Oracle and flat files.
Identifying ways to improve data reliability, efficiency and quality by various data solution techniques.
Expertise in Data project management with JIRA stories. Work as a liaison between business and IT to ensure successful and timely completion of the projects.
Assist in defining the data architecture framework, standards and principles, including modeling, metadata, security and reference data.
Create and optimize data models to support various business applications.
Reviewing modifications of existing data systems for cross-compatibility.
Automate and support workflows to ensure timely delivery.
Must Have:
5+ years of SQL Server development experience.
3+ years ALTERYX Admin /User management experience and advance workflow management.
5+ years data modeling experience.
5+ years of ETL experience.
5+ years of experience in working on more than one database technologies Microsoft SQL server, Teradata.
2+ years big data experience, Hadoop, Hive, Spark
Expert knowledge of data warehousing.
DESIRED SKILLS:
BI Lifecycle management
Working understanding of Microsoft VBA, HTML, Python
Data model development using ERWIN
Job Type: Contract
Salary: $50.00 per hour
Ability to commute/relocate:
Alpharetta, GA 30005: Reliably commute or planning to relocate before starting work (Required)
Experience:
Building Data Pipeline: 8 years (Required)
ETL Tools – SSIS, Alteryx: 7 years (Required)
Data modelling: 6 years (Required)
SQL Server development: 8 years (Required)
Microsoft SQL Stack: 8 years (Required)
Work Location: One location
Speak with the employer
+91 7328456015",Unknown / Non-Applicable,HR Consulting,Company - Private,Human Resources & Staffing
Data Engineer,atlanta,"Elder Research Inc
4.4","Atlanta, GA",4.4,$88K - $128K (Glassdoor est.),3.9,4.5,4.1,3.7,4.8,51 to 200 Employees,1995,"Data Engineer
Location: Charlottesville, VA, Arlington, VA, Raleigh, NC, Atlanta, GA, Philadelphia, PA

At Elder Research Inc., a recognized leader in data science and machine learning solutions, we pride ourselves in our ability to find creative, cutting-edge solutions to real-world problems. We are looking for innovative and inquisitive self-starters who enjoy understanding a problem space and building fast, efficient, and tractable data infrastructure to deliver real value for our clients.

As a member of the Elder Research team, you will join a functional team of accomplished Data Scientists, Software Engineers, and Data Engineers that deliver custom analytic solutions. Some of your responsibilities will include: wrangling and fusing large and disparate data sets, assisting in the deployment of models and algorithms, automating the entire data pipeline, and communicating model results through user-focused data visualizations.

Job Description
A Data Engineer supports robust and repeatable data manipulation, large scale infrastructure for data ingestion, and stunning data visualization for custom client applications.
Essential Functions:
Work collaboratively with data scientists, business consultants, software engineers, and clients to create and deploy dynamic data applications that help our customers make meaningful business decisions.
Develop and deploy robust data pipelines and end-to-end systems
Participate in every stage of the engineering lifecycle, from ideation and requirements gathering through implementation, testing, deployment, and maintenance.
Provide leadership and coordination for certain stages of the engineering lifecycle as needed.
Perform other technical tasks as needed, including writing project reports, managing, implementing, and/or maintaining technical infrastructure, etc.
Ability and the willingness to tailor applications to a client’s business goals using an iterative methodology.
Ability to consider both long-term stability and scalability while taking a user-focused approach to development and deployment.
Communicate clearly, both verbally and in writing, to teammates and clients.
Ability to work independently in a collaborative, dynamic, cross-functional environment
Travel to and work on-site at clients both local and non-local. Number of days at client site vary depending on project requirements.
Required Skills:
Excellent written and verbal communication skills
Ability to work with high-level mathematical concepts and associated code-form representations
Ability to collaborate with others to accomplish a technical task
Ability to utilize a code base or repository with version control
Ability to ingest data into SQL or NoSQL databases
Ability to perform data transformations such as aggregations, joins, or data cleaning
Desired Education and Experience
Bachelor’s or Master’s degree in a technical field and 2-5 years’ experience OR 5+ years of experience Built and deployed a system for data extraction, transformation, and loading.
The ability to schedule and maintain jobs, working with tools like Jenkins or cron.
Provided access to transformed data for downstream applications or visualizations.
Interacted with SQL or NoSQL databases via a programming language such as R, Python, Java, JavaScript.
Utilized cloud resources (AWS, Microsoft, Google) to build or maintain services, especially as related to data pipelines.
Prior exposure to modeling and/or data analysis.
Configured a technical service such as a database, version control system, or operating system.
Minimum Requirements
Bachelor’s degree in Computer Science or related field, or equivalent experience in a technical role.
2+ years experience with at least one programming language
1+ years working extensively with at least one major cloud provider (AWS, Azure, GCP), certificates are a plus
The ability to travel 10%
What You Would Do
Work on small teams in a highly collaborative environment.
Contribute to consulting projects to solve interesting problems for multiple clients in various industries.
Communicate details of the technical architecture to fellow team members and clients in both technical and non-technical terms.
Work with Data Scientists to design and/or implement the technical architecture necessary to support analytics.
Work with Software Engineers to improve the robustness and scalability of software products.
Participate in every stage of the engineering lifecycle, from ideation and requirements gathering through implementation, testing, deployment, and maintenance.
Contribute to documentation of the technical architecture for internal and client use.
Design, create, and provision data stores.
Build trusted and lasting relationships with clients.
Provide value to our clients through analytics and software tools.
Manage and monitor pipelines to extract, transform, and load data (ETL).


About Elder Research, Inc.
Headquartered in Charlottesville, VA with offices in Arlington, VA, Baltimore, MD, and Raleigh, NC, Elder Research is a fast-growing solutions and consulting firm specializing in predictive analytics. At Elder Research, you’ll be part of a fun, friendly community. In keeping with our entrepreneurial spirit, we want candidates that are self-motivated with an innate curiosity and strong team work ethic. We work hard to provide the best value to our clients and allow each person to contribute their ideas and put their skills to use immediately.

Elder Research provides analytic solutions to hundreds of companies across numerous industries. Our team enjoys great variety in the type of work they do and exposure to a wide range of techniques and tools. If you are passionate about integrating data, technology, and analytics in a team-based environment to solve problems, then Elder Research may be a good fit for you.
Elder Research, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.
To be considered for this position, you must be legally eligible to work in the United States. Some of our positions will require U.S. Citizenship as they require working on Federal projects.",$5 to $25 million (USD),Business Consulting,Company - Private,Management & Consulting
Associate Data Engineer - Remote,atlanta,"AMERICAN CANCER SOCIETY
3.4","Atlanta, GA",3.4,Employer Provided Salary:$75K - $100K,2.9,3.5,2.9,3.2,3.6,5001 to 10000 Employees,1913,"At the American Cancer Society, we're leading the fight for a world without cancer. Our employees and 1.5 million volunteers are raising the bar every single day. We actively seek candidates from diverse backgrounds including communities of color, the LGBTQ community, veterans, and people with disabilities. The greater the diversity of our people, the better we can serve our communities.
The people who work at the American Cancer Society focus their diverse talents on our lifesaving mission. It is a calling. And the people who answer it are fulfilled.

Position Description
This position is a remote role, open anywhere throughout the United States.
JOB SUMMARY
American Cancer Society (ACS) is seeking a passionate data individual on the fight against cancer. This position sits within the Digital Solution’s Discovery Data Science team, where we work with a wide range of data sources and types from research grants, Salesforce, survey data, and genomics data. The associate data engineer will be working in tandem with our lead data engineer to continue to develop and implement a modern data pipeline for ACS.
MAJOR RESPONSIBILITIES
Complete data integration from a multitude of sources into our cloud infrastructure.
Document the architecture and solutions for business continuity.
Work with our analytics engineer and business intelligence analyst to build out best in class data models for data visualization.
Define and execute database and data movement standards, design reviews, pipeline CI/CD process, and data container policies to ensure high quality data management
Collaborate closely with data governance to identify gaps in documentation and standards

Position Requirements
FORMAL KNOWLEDGE
Bachelor’s degree in Computer Science, Engineering, or equivalent experience. Two or more years of relevant work experience.
SKILLS
Required Qualifications:
2+ years of building a modern data pipeline, including the ETL, cloud-storage, reporting, and deployment
Experience with cloud services such as, Azure Cloud, AWS, Google Cloud
Expertise with SQL, YAML
Experience with workflow orchestration (Prefect.io, Airflow. Etc.)
2+ years of experience with python
Experience with Git – Azure DevOps, GitHub, Gitlab, etc.
Preferred Qualifications:
Snowflake experience, particularly data integration from multiple sources.
Exposure to BI tools such as PowerBI, Tableau, Looker.
Ability to understand the data needs of researchers, such as epidemiologist and cancer researchers, guiding them to the best practices for their data.
Experience with healthcare data, such as claims, electronic health records, biospecimen, medical imaging, genomic data.
SPECIALIZED TRAINING OR KNOWLEDGE
Proven experience in data engineering for a modern data pipeline.
The estimated starting rate is $75,000-$100,000 annually. The final candidate's relevant experience/skills will be considered before an offer is extended. Actual starting pay will vary based on non-discriminatory factors including, but not limited to, geographic location, experience, skills, specialty, and education.
The American Cancer Society has adopted a vaccination policy that requires all staff, regardless of position or work location, to be fully vaccinated against COVID-19 (except where prohibited by state law).
ACS provides staff a generous paid time off policy; medical, dental, retirement benefits, wellness programs, and professional development programs to enhance staff skills. Further details on our benefits can be found on our careers site at: jobs.cancer.org/benefits. We are a proud equal opportunity employer.

Position Requirements:",Unknown / Non-Applicable,Civic & Social Services,Nonprofit Organization,Nonprofit & NGO
Data Engineer,atlanta,"Codoxo
4.1","Duluth, GA",4.1,$63K - $91K (Glassdoor est.),4.1,4.1,4.2,3.4,3.9,51 to 200 Employees,2016,"Role: Data Engineer (Mid to Senior Level)


PLEASE NOTE BEFORE APPLYING:
CODOXO IS NOT ABLE TO OFFER SPONSORSHIP OR ACCOMMODATE ANY CANDIDATES THAT ARE CURRENTLY BEING SPONSORED NOW OR IN THE FUTURE


Do you want to help make healthcare more effective and affordable for everyone? That’s our mission at Codoxo. The U.S. spends more on healthcare than any other country in the world, but not all of the $3.8 trillion goes to real patient care. A significant portion, up to 10% or $380 billion, is lost to fraud, waste, and abuse.



Codoxo’s patented artificial intelligence technology helps healthcare companies and agencies identify and act quickly to control costs. Codoxo now has six AI-powered applications that help every department across health insurance payers proactively bring down costs and reduce fraud, waste, and abuse – so more dollars to toward patient care.


Job Description
We have built a SaaS application that is supported by large volumes of healthcare data, on which we must frequently perform large queries very efficiently and return results in real-time to the user.
We are seeking a mid to senior level Data Engineer with experience in the following areas.
· Ingestion of large volumes of data
· Performing Data Validations/Cleansing
· Data integration/loading into target Data Objects.
· Building large reservoirs of data
· Performing efficient queries using SQL
NOTE: Claims loading experience in healthcare space is desired, but not required.

Required technical skills:
- Experience using Relational databases (PostgreSQL is preferred)
- Good experience in SQL scripting, including analytical queries
- Good experience in Python programming
- Good experience in UNIX Shell Scripting


Beneficial technical skills:
- PL/SQL or PL/pgSQL
- PySpark
- AWS Glue, S3, Aurora, Data Lake, Sagemaker
- Proven experience processing billions of records


Other Requirements:
- Bachelor or master's degree in Computer Science, Engineering or related field
- At least 4 years of experience in the software industry
- Authorization to work in the USA

Other Preferences:
- Experience processing medical claims or related health care data

Benefits for You
· Health, Dental, and Vision insurance with 100% employee premium coverage
· Unlimited PTO
· Annual Professional Development stipend
· Annual home office stipend
· 401K Match

We are an Equal Opportunity Employer:
Codoxo provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment.",Unknown / Non-Applicable,Enterprise Software & Network Solutions,Company - Private,Information Technology
Data Engineer,atlanta,"Azurity Pharmaceuticals, Inc.
3.1","Atlanta, GA",3.1,$85K - $122K (Glassdoor est.),3.2,3.0,3.0,3.1,3.3,201 to 500 Employees,1999,"Azurity Pharmaceuticals, Inc. is a fast-growing pharmaceutical company focusing on the needs of patients requiring customized, user-friendly drug formulations, especially children and the elderly. Azurity’s products have benefited millions of patients whose needs are not served by other commercially available therapies. For more information, visit www.azurity.com.
Azurity's success is attributable to our incredibly talented, dedicated team that focuses on benefiting the lives of patients by bringing the best science and commitment to quality into everything that we do.
Mission:
Implement the data models and data structures needed for each use case as defined by the Data Architect, in the most convenient format to be used by the Data Scientist
Own the structural elements of data, e.g., data storage, data piping, interfacing with analytics platforms
Participate in data requirements, modelling and testing
Tasks & responsibilities:
Provide technical support related to data structures, data models and meta data management to relevant stakeholders
Creates data models, providing the right format and structure for the use case solutions
Participate in early data modeling and testing for use case development, provide input on how to improve proposed solutions and implement necessary changes
Extract relevant data to solve analytical problems; ensure development teams have the required data
Interact with the business ([function]) to understand all data requirements to develop business insights and translates them into data structures and data models, in close collaboration with Data Architect
Work closely with IT/IM teams on internal data acquisition (e.g., CRM, ERP) and with Data Architect for external data acquisition
Knowledge & experience:
5+ years’ experience with advanced data management systems (e.g., PostgreSQL, etc.)
Deep expertise in data modeling and structuring
Experience in high volume data environments
Ability to quickly learn new technologies
Developing and maintaining formal documentation that describes data and data structures including data modelling
Strong attention to detail and an ability to think critically and conceptually
Team oriented and flexible with proven track record in collaborating with multiple stakeholders
Strong verbal and written",$100 to $500 million (USD),Biotech & Pharmaceuticals,Company - Private,Pharmaceutical & Biotechnology
"Sr. Data Engineer (Python,Spark & Databricks)",atlanta,"Virtualan Software LLC
4.5","Atlanta, GA",4.5,Employer Provided Salary:$60.00 - $70.00 Per Hour,5.0,-1,-1,5.0,-1,1 to 50 Employees,2019,"Role : Senior Data Engineer (Python, Spark & Databricks)
Location : Hybrid (Atlanta, GA)
Pay: 60-70$ on C2C / 1099
RESPONSIBILITIES:
Create or modify the conceptual, logical and physical data models.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of sources like Hadoop, Spark, AWS Lambda, etc.
Lead and/or mentor a small team of data engineers.
Design, develop, test, deploy, maintain and improve data integration pipeline.
Develop pipeline objects using Apache Spark , PySpark and/or Python.
Design and develop data pipeline architectures using Spark and related AWS Services.
Communicate effectively with client leadership and business stakeholders.
Participate in proposal and/or SOW development.
REQUIREMENTS:
5+ years of professional work experience designing and implementing data pipelines in a cloud environment is required.
2+ years of experience migrating/developing data solutions in the AWS cloud is required.
1+ years of experience building/implementing data pipelines using DataBricks is required.
Expert level knowledge of using SQL to write complex, highly-optimized queries across large volumes of data.
Hands-on object-oriented programming experience using Python is required.
Professional work experience building real-time data streams using Spark.
Knowledge or experience in architectural best practices in building data lakes.
Bachelor or Master degree in Computer Science, Engineering, Information Systems or relevant degree.
Hybrid work schedule, and must live in the Atlanta, GA metro area. Must be open to up to 25% national travel to client locations when on engagements outside of the Atlanta, GA area.
Job Type: Contract
Pay: $60.00 - $70.00 per hour
Schedule:
Monday to Friday
Application Question(s):
Apply only if you are interested in Hybrid Role in Atlanta, GA. Interested ?
Experience:
Data Engineer: 4 years (Required)
Databricks: 1 year (Required)
Willingness to travel:
25% (Required)
Work Location: On the road",Less than $1 million (USD),Computer Hardware Development,Company - Private,Information Technology
Associate Data Engineer,atlanta,"Watauga Group
3.6","Atlanta, GA",3.6,$59K - $93K (Glassdoor est.),3.5,3.6,3.1,2.8,3.3,1 to 50 Employees,2004,"WHO WE ARE:
At Watauga Group, we leverage two decades of specialized media expertise and our love for the outdoors and entertainment to help outdoor recreation & attraction brands maximize their sales and elevate advertising ROI.Our unique blend of marketplace intelligence and deep insights into the media behaviors and preferences of outdoor participants and attraction visitors enables us to surgically target untapped consumer audiences and connect brands with the greatest number of potential customers at every step of their buying journeys.Watauga’s brand and performance advertising experts navigate today’s complex media landscape to create fully integrated strategies encompassing the most effective mix of digital and traditional media channels, platforms, data, and technologies. Our end-to-end media solutions include Broadcast TV & Radio, OTT & Streaming Audio, Out-of-Home, Digital Display, Paid Search, Paid Social, Sponsorships, and more.
Certified by the WBENC, Watauga is one of the largest women-owned media agencies in North America with offices in Orlando, Atlanta, and Birmingham.
WHY JOIN US:
Generous health benefits package including employer contribution to medical insurance, employer-paid life insurance and disability insurance
Employer match to 401(k) retirement plan
Flexible PTO
Flexible Hybrid Schedule
Paid Parental Leave
Health Savings Account
Tuition Reimbursement
Career progression
Bonus and incentive plans
ABOUT THE JOB:
PRIMARY DUTIES:
The duties and responsibilities of this position include but are not limited to those listed below. These duties and responsibilities may be modified at any time by Management. Modifications will be in writing and will be acknowledged by both parties.
Assist with maintenance of Python/SQL ETL pipelines
Assist with administration of PostgreSQL databases
Assist with design of database architecture to support business analysts
Assist with maintenance of Azure Cloud environment
Create and maintain internal and external dashboards for reporting & data visualization in Power BI
Transform, improve, and integrate data from multiple sources, into accessible, understandable, and usable datasets.
Assist in building and maintaining DataMart tables to optimize BI performance.
Maintain thorough documentation of dashboard data requirements.
Provide quality assurance of imported data.
Assist with pipeline and database development and maintenance.
Work with Digital Media team to ensure the proper data needs are delivered with focus on accuracy and attention to detail.
CORE COMPETENCIES:
Achievement and Results Orientation
Adaptability and Flexibility
Analytical and Strategic Thinking
Attention to Detail with Accuracy
Communication – Written, Oral, Presenting
Learning Support and Continuous Learning
Process Orientation
Problem Solving
Teamwork, Cooperation, and Working with Others
EDUCATION AND EXPERIENCE REQUIREMENTS:
Bachelor’s degree (Computer Science, Data Analytics, Accounting, or Finance a plus)
Strong data analysis skills
Strong data visualization skills
Proficient in Microsoft Excel
Working knowledge of MS Power BI Development, Deployment, and Integration
SQL and Python experience is a plus
Familiarity with CM360 or other tag management systems is a plus
1 year relevant work experience with digital marketing or related industry is a plus
PHYSICAL CRITERIA:
Able to lift and carry 20 pounds
Able to sit for prolonged periods of time at a computer
Industry
Marketing & Advertising
Employment Type
Full-time",$5 to $25 million (USD),Advertising & Public Relations,Company - Private,Media & Communication
Data Engineer,atlanta,United Digestive,"Atlanta, GA",-1,$80K - $117K (Glassdoor est.),-1,-1,-1,-1,-1,Unknown,Company - Public,"GENERAL SUMMARY OF DUTIES: United Digestive’s Data Engineer will be responsible for developing and maintaining data pipelines, data warehouses, and data models to support the company's Business Intelligence reporting initiatives.
REPORTS TO: Director of Business Intelligence & Analytics
RESPONSIBILITIES:
Duties may include but are not limited to:
Implement, maintain, and improve data integration processes to collect, process, and manage large datasets
Collaborate with stakeholders to understand business requirements and design data solutions that meet their needs
Implement and maintain data quality checks and validations to ensure data accuracy and completeness
Optimize data processing and storage to ensure high availability, scalability, and performance
Develop and maintain automated data workflows and scheduling tools
Code ETL process using Azure Data Factory workflows and other technologies as appropriate
Troubleshoot and resolve data-related issues and incidents
Stay up to date with the latest technologies and trends in data engineering, specifically the Azure suite, and recommend improvements and optimizations to the data architecture and infrastructure
Ability to develop solutions and manage existing Azure DevOps pipelines
Maintains a high level of confidentiality with sensitive information
Performs any other duties and/or special tasks as assigned by United Digestive leadership
REQUIRED EDUCATION, SKILLS & EXPERIENCE:
Bachelor’s degree in Computer Science, Software Engineering, Information Technology, or in a related field required; healthcare-related Data Analytics experience preferred; 2+ years of data pipeline management required. Proficiency in SQL and experience with relational databases (e.g., Oracle, SQL Server, PostgreSQL); experience with data modeling, data warehousing, and ETL processes, proficiency in various programming language (e.g., Python, SQL, Java), experience with cloud platforms (e.g., AWS, Azure, GCP) and big data technologies (e.g., Databricks, Hadoop, Spark, Kafka, Cassandra). Must have knowledge of data visualization and BI tools (e.g., Tableau, Power BI) and how to support these tools in an efficient manner.
ADDITIONAL SKILLS AND EXPERIENCE:
Data Engineer must have:
Excellent verbal and written communication skills.
Excellent organizational skills and attention to detail.
Ability to multi-task and prioritize job needs
Ability to deal with patients, visitors, co-workers, and physicians with courtesy and respect
Work under pressure; assess, respond to, and communicate issues in a timely manner.
Self-motivation and be a proactive individual with a professional can-do attitude
PHYSICAL/MENTAL/ENVIRONMENTAL DEMANDS
Requires sitting and standing associated with a normal office environment. Travel as business needs dictate.
DRUG FREE WORKPLACE
United Digestive is a drug free workplace. All offers of employment are contingent upon passing a pre-employment drug screening.
EQUAL OPPORTUNITY EMPLOYER
United Digestive is an Equal Opportunity Employer and does not discriminate on the basis of race, religion, gender, color, or national origin in its employment practices.
Location: 1355 Peachtree Street NE STE 1600, Atlanta, GA 30309
Job Type: Full-time
Benefits:
401(k)
401(k) matching
Dental insurance
Health insurance
Health savings account
Paid time off
Referral program
Vision insurance
Schedule:
Monday to Friday
No nights
No weekends
Ability to commute/relocate:
Atlanta, GA 30309: Reliably commute or planning to relocate before starting work (Required)
Experience:
ETL: 2 years (Required)
Language:
English (Required)
Work Location: Hybrid remote in Atlanta, GA 30309",-1,-1,Unknown / Non-Applicable,-1
Data Center Operations Systems Engineer,atlanta,"Lambda
4.0","Atlanta, GA",4.0,Employer Provided Salary:$115K - $170K,4.1,4.1,3.6,4.0,3.8,1 to 50 Employees,2012,"Lambda's GPU cloud is used by deep learning engineers at Stanford, Berkeley, and MIT. Lambda's on-prem systems power research and engineering at Intel, Microsoft, Kaiser Permanente, major universities, and the Department of Defense.
If you'd like to build the world's best deep learning cloud, join us.
What You'll Do
Ensure new server, storage and network infrastructure is properly racked, labeled, cabled, and configured
Document data center layout and network topology in DCIM software
Work with supply chain & manufacturing teams to ensure timely deployment of systems and project plans for large-scale deployments
Participate in data center capacity and roadmap planning with sales and customer success teams to allocate floorspace
Assess current and future state data center requirements based on growth plans and technology trends
Manage a parts depot inventory and track equipment through the delivery-store-stage-deploy-handoff process in each of our data centers
Work closely with HW Support team to ensure data center infrastructure-related support tickets are resolved
Work with RMA team to ensure faulty parts are returned and replacements are ordered
Create installation standards and documentation for placement, labeling, and cabling to drive consistency and discoverability across all data centers
Serve as a subject-matter expert on data center deployments as part of sales engagement for large-scale deployments in our data centers and at customer sites
You
Have experience with critical infrastructure systems supporting data centers, such as power distribution, air flow management, environmental monitoring, capacity planning, DCIM software, structured cabling, and cable management
Have strong Linux administration experience
Have experience in setting up networking appliances (Ethernet and InfiniBand) across multiple data center locations
You are action-oriented and have a strong willingness to learn
You are willing to travel up to 25% of the time between CA, TX, UT, and GA locations
Nice to have
Experience with troubleshooting the following network layers, technologies, and system protocols: TCP/IP, DP/IP, BGP, OSPF, SNMP, SSL, HTTP, FTP, SSH, Syslog, DHCP, DNS, RDP, NETBIOS, IP routing, Ethernet, switched Ethernet, 802.11x, NFS, and VLANs.
Experience with working in large-scale distributed data center environments
Experience working with auditors to meet all compliance requirements (ISO/SOC)
About Lambda
We offer generous cash & equity compensation
Investors include Gradient Ventures, Google’s AI-focused venture fund
We are experiencing extremely high demand for our systems, with quarter over quarter, year over year profitability
Our research papers have been accepted into top machine learning and graphics conferences, including NeurIPS, ICCV, SIGGRAPH, and TOG
We have a wildly talented team of 130, and growing fast
Our remote workforce, based on role, is across the U.S., with headquarters in San Jose, CA
Health, dental, and vision coverage for you and your dependents
Commuter/Work from home stipends
401k Plan
Flexible Paid Time Off Plan that we all actually use
Salary Range Information
Based on market data and other factors, the salary range for this position is $115,000-$170,000. However, a salary higher or lower than this range may be appropriate for a candidate whose qualifications differ meaningfully from those listed in the job description.
A Final Note:
You do not need to match all of the listed expectations to apply for this position. We are committed to building a team with a variety of backgrounds, experiences, and skills.
Equal Opportunity Employer
Lambda is an Equal Opportunity employer. Applicants are considered without regard to race, color, religion, creed, national origin, age, sex, gender, marital status, sexual orientation and identity, genetic information, veteran status, citizenship, or any other factors prohibited by local, state, or federal law.",-1,Unknown / Non-Applicable,Company - Private,-1
Data Engineer,atlanta,Atticus,"Atlanta, GA",-1,Employer Provided Salary:$165K,-1,-1,-1,-1,-1,-1,-1,"// This position is fully remote but you need to be located in the Southeastern USA (NC to Texas) for in-person meetings when required. //
Atticus helps to match non-profit organizations with major donors that share their mission, vision, and values. This matching process involves collecting and transforming a significant amount of data from a variety of sources. The Data Engineer builds, maintains, and operates the integrations, systems, and datasets that automate this process.
As one of the first Engineering positions in the company, this role will require the candidate to influence and/or lead technology decision-making for a key part of the product. Consequently, Atticus is looking for candidates with significant professional experience and demonstrated leadership as a Data Engineer.
The Data Engineer will take ownership of an existing production system that collects and transforms data from client file uploads, several third-party web APIs, and a few internal databases. The system is hosted in Azure and currently uses Databricks/Spark to automate the data pipeline, ultimately feeding into an Azure Cosmos DB application database. No system is perfect, and the Data Engineer will be expected to review the design of the existing system and recommend improvements.
If this sounds like you, kick off the process by submitting your resume here on Indeed and spending a few minutes (~15) on a work-traits assessment that will give us some insight into how you prefer to work and communicate. https://assessment.predictiveindex.com/bo/849R/datasci
ESSENTIAL DUTIES AND RESPONSIBILITIES
· Ensure that data systems and datasets meet the needs of the business
· Find, analyze, and integrate new data sources, both structured and unstructured
· Build data systems that automatically collect, transform, and combine these data sources into consistent, up-to-date, and high-quality datasets for both human and machine learning use
· Conduct complex statistical analysis of data and report on the results
· Detect, diagnose, and correct data quality and reliability issues
· Optimize data systems’ costs and performance
· Collaborate regularly with software engineers, data scientists, and consumers of the data
Job Type: Full-time
Pay: From $165,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Health insurance
Health savings account
Paid time off
Professional development assistance
Vision insurance
Compensation package:
Bonus pay
Performance bonus
Experience level:
5 years
Schedule:
8 hour shift
Experience:
Relational databases: 3 years (Preferred)
Information Retrieval: 3 years (Preferred)
Work Location: Remote",-1,-1,-1,-1
DATA CENTER ENGINEER I Grade 19,atlanta,"Fulton County, GA
3.5",United States,3.5,Employer Provided Salary:$51K - $76K,3.2,3.3,3.1,3.3,3.3,5001 to 10000 Employees,Government,"Class Concept
Minimum Qualifications:
Bachelors Degree in Information Technology, Information Systems, Computer Science, or a related field or any equivalent combination of education, training, and experience which provides the requisite knowledge, skills, and abilities for this job.

Specific Knowledge, Skills, or Abilities: Automation and virtualization. Assembling an Infrastrucure Assembling an Infrastrucure. Understanding of data center environment. Understanding of data center hardware.Communication, technical design, and collaboration skills. Look at a data center in a holistic manner. Data center related Technical certification preferred (e.g. MCSE, VMAX, Cisco). Familiarity with Networks, Windows and Unix systems. Familiarity with one or more server side languages/scripting (e.g. ASP, NET, Perl, python, ruby).

ALL APPLICATIONS MUST BE COMPLETED IN FULL BEFORE THEY ARE SUBMITTED. PLEASE REVIEW ALL APPLICATIONS FOR ACCURACY AND MAKE ALL CORRECTIONS BEFORE SUBMITTAL BECAUSE ERRORS CAN RESULT IN NOT MEETING THE MINIMUM QUALIFICATIONS. ADDITIONAL INFORMATION WILL NOT BE ACCEPTED AFTER ALLOCATIONS ARE RECEIVED BY THE PERSONNEL DEPARTMENT.

Example of Duties
Purpose of Classification:
This is an entry level position to perform tasks necessary to maintain and operate the County's data center, cable plant, video surveillance and entry card access systems. Maintains and monitors infrastructure network and service monitoring applications and notifies appropriate staff of alerts and outages.

Essential Functions:
The following duties are normal for this position. The omission of specific statements of the duties does not exclude them from the classification if the work is similar, related, or a logical assignment for this classification. Other duties may be required and assigned.

Monitors and updates infrastructure monitoring applications and responds to alerts. Performs routine service requests for video surveillance and card entry systems. Monitors Data Center power and cooling and performs physical installations or moves of equipment residing in the data center, and updates data center documentation.

Responds to alerts by applying documented corrective procedures and/or notifying appropriate support staff. Notifies service desk of service outages and/or degradations. Responds to routine service requests for add, modify and delete accounts and permissions. Monitors uninterruptible power supply and power distributions systems and reports issues to management. Monitors room temperature and cooling units and reports issues to management. Installs or moves equipment into computer racking systems. Updates documentation and labeling for power capacity, cooling capacity rack tenancy and cable plant.

Works across the board to advise, assist, and inform many work groups including: Supporting Departmental Personnel, Technical Operations Managers, individual support and development teams, and the Configuration Manager.

Verifies that request for video surveillance and card access are properly authorized. Ensures proper placement of equipment to ensure adequate room for growth and minimize single points of failure. Recognizing when electrical, cooling and fire suppression systems issues begin the impact the live production environment.

Minimum Qualifications
Performance Aptitudes:
Data Utilization: Requires the ability to coordinate, manage, and/or correlate data. Includes exercising judgment in determining time, place and/or sequence of operations, referencing data analyses to determine necessity for revision of organizational components, and in the formulation of operational strategy.

Human Interaction: Requires the ability to provide formal training to others in specific fields typically involving preparation and/or modification of teaching materials. Requires the ability to act as a first-line supervisor, including instructing, assigning and reviewing work, maintaining standards, coordinating activities, and evaluating employee job performance.

Equipment, Machinery, Tools, and Materials Utilization: Requires the ability to operate and control the actions of equipment and machinery, requiring the monitoring, adjustment, regulation, and/or setting of multiple conditions.

Verbal Aptitude: Requires the ability to utilize a wide variety of reference, descriptive, advisory and/or design data and information.

Mathematical Aptitude: Requires the ability to perform addition, subtraction, multiplication and division; ability to calculate decimals and percentages; may include ability to perform mathematical operations with fractions; may include ability to compute discount, interest, and ratios; may include ability to calculate surface areas, volumes, weights, and measures.

Functional Reasoning: Requires the ability to apply principles of influence systems, such as motivation, incentive, and leadership, and to exercise independent judgment to apply facts and principles for developing approaches and techniques to resolve problems.

Situational Reasoning: Requires the ability to exercise judgment, decisiveness and creativity in situations involving the evaluation of information against sensory, judgmental, or subjective criteria, as opposed to that which is clearly measurable or verifiable.

Supplemental Information
It is the policy of Fulton County that there will be equal opportunity for every citizen, employee and applicant, based upon merit without regard to race, color, religion, national origin, gender, genetics, age, disability or sexual orientation.",-1,Government & Public Administration,State & Regional Agencies,Unknown / Non-Applicable
Data Harmonization Engineer,atlanta,"Global Enterprise Services, LLC
4.0","Atlanta, GA",4.0,Employer Provided Salary:$95K - $105K,4.0,5.0,5.0,5.0,5.0,1 to 50 Employees,Company - Public,"Data Harmonization Engineer

Collects data models for disparate datasets within a domain. Collaborates with CDC & STLT stakeholders to develop a conceptual model that defines the atomic concepts for that domain.
Constructs semantic mappings from the data elements in the source datasets to atomic or compound concepts in the conceptual model.
Develops sample transformation code to translate among representations.
Configures and manages vocabulary services to allow data modernization users to improve understanding of the relationships among data representations.

Data Harmonization Engineer - Junior [YoE, Edu, Certs: 0-3 yrs & BA/BS] [Salary Range: $81k - $91k]
Data Harmonization Engineer - Journeyman [YoE, Edu, Certs: 4-9 yrs & BA/BS] [Salary Range: $95k - $105k]
Data Harmonization Engineer - Senior [YoE, Edu, Certs: 10+ yrs & MA/MS] [Salary Range: $108k - $108k]",-1,-1,Unknown / Non-Applicable,-1
Sr. Data Engineer,atlanta,"Apolis
3.7","Atlanta, GA",3.7,Employer Provided Salary:$65.00 - $70.00 Per Hour,3.8,3.6,3.6,3.6,3.7,501 to 1000 Employees,1996,"Desired Qualifications & Experiences:
Five or more years’ experience in software engineering.
Five or more years’ experience in large scale RDBMS environments or Google BigQuery
Two or more years of Exadata experience OR Google BigQuery
Four or more years’ experience with Informatica PowerCenter or IICS
One or more years experience in Erwin
Experience in code automation (e.g. pattern based integration)
Experience in advanced SQL and PL/SQL techniques
Experience in building re-usable Utility packages
Experience with testing the code
Experience in Unix shell and Python scripting
Integration design & data modeling skills in Data lake and Data Warehousing environments
Exposure to both on-prem and cloud Integration solutions
Familiarity with non-relational DB technologies is a plus
Experience with automated testing
Experience with both batch and real-time patterns for integrations
Ability to build and analyze complex integration workflows from heterogeneous data sources
Experienced in large Enterprise Data Warehouse & Integration projects.
Strong background in full lifecycle development using multiple platforms or languages.
Ability to interact at a technical and non-technical level with Infrastructure, Network, Development, BA and QA teams.
Development experience in high transaction/high availability systems.
Experience with analyzing and recommending solutions for Production issues short-term and long term
Job Type: Contract
Salary: $65.00 - $70.00 per hour
Experience level:
10 years
11+ years
Experience:
Informatica: 4 years (Required)
SQL: 1 year (Preferred)
Data modeling: 1 year (Required)
Google Cloud Platform: 4 years (Required)
Work Location: One location
Speak with the employer
+91 7322856236",$25 to $100 million (USD),Information Technology Support Services,Company - Private,Information Technology
"Software Engineer, Data Streaming Platform",atlanta,"Block
3.5","Atlanta, GA",3.5,$88K - $134K (Glassdoor est.),3.1,3.2,3.2,3.3,3.3,1001 to 5000 Employees,1995,"Company Description Block is one company built from many blocks, all united by the same purpose of economic empowerment. The blocks that form our foundational teams — People, Finance, Counsel, Hardware, Information Security, Platform Infrastructure Engineering, and more — provide support and guidance at the corporate level. They work across business groups and around the globe, spanning time zones and disciplines to develop inclusive People policies, forecast finances, give legal counsel, safeguard systems, nurture new initiatives, and more. Every challenge creates possibilities, and we need different perspectives to see them all. Bring yours to Block.
Job Description

As a Software Engineer on the Data Streaming Platform team, you will develop and maintain data ingestion pipelines important to the continued growth of Square. You will collaborate with many teams across Square to understand data needs and turn them into platforms and services, maintain the health of the data streams, and have an impact on the data ecosystem within Square.
You will:
Build, enhance, and maintain our real-time data pipeline
Work with multiple infrastructure and operations teams to maintain our data infrastructure
Able to identify and document feature gaps, and implementing solutions to them
Help build services and tooling to ensure resiliency, fix data discrepancies, and enhance the customer experience
Monitor daily execution, diagnose and log issues, and fix pipelines to ensure SLAs are met with internal stakeholders
Mentor other engineers and help them grow; code reviews, guidance on best practices, using your experience in the field

Qualifications

2+ professional background in data infrastructure or backend software development.
Experience working with relational databases, such as MySQL and PostgreSQL
1+ years experience in at least one of Python or Java (preferably both), including writing backend services and data processing
Experience with distributed log systems, such as Kafka and AWS Kinesis
Experience with cloud environments, such as AWS and GCP
Experience with container deployment platforms and tools, such as Kubernetes, Docker, Helm, and Terraform
Experience with Airflow, Prefect, or other DAG orchestration tools
Experience with Javascript / Vue, Ruby, Python, Databricks.

Additional Information

Block takes a market-based approach to pay, and pay may vary depending on your location. U.S. locations are categorized into one of four zones based on a cost of labor index for that geographic area. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These ranges may be modified in the future.

Zone A: USD $152,100 - USD $185,900
Zone B: USD $144,500 - USD $176,700
Zone C: USD $136,900 - USD $167,300
Zone D: USD $129,300 - USD $158,100
To find a location’s zone designation, please refer to this resource. If a location of interest is not listed, please speak with a recruiter for additional information.
Benefits include the following:
Healthcare coverage
Retirement Plans including company match
Employee Stock Purchase Program
Wellness programs, including access to mental health, 1:1 financial planners, and a monthly wellness allowance
Paid parental and caregiving leave
Paid time off
Learning and Development resources
Paid Life insurance, AD&D. and disability benefits
Perks such as WFH reimbursements and free access to caregiving, legal, and discounted resources
This role is also eligible to participate in Block's equity plan subject to the terms of the applicable plans and policies, and may be eligible for a sign-on bonus. Sales roles may be eligible to participate in a commission plan subject to the terms of the applicable plans and policies. Pay and benefits are subject to change at any time, consistent with the terms of any applicable compensation or benefit plans.
US and Canada EEOC Statement
We’re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace. Block is a proud equal opportunity employer. We work hard to evaluate all employees and job applicants consistently, without regard to race, color, religion, gender, national origin, age, disability, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class.
We believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations to disabled applicants throughout the recruitment process. We encourage applicants to share any needed accommodations with their recruiter, who will treat these requests as confidentially as possible. Want to learn more about what we’re doing to build a workplace that is fair and square? Check out our I+D page.
Additionally, we consider qualified applicants with criminal histories for employment on our team, and always assess candidates on an individualized basis.

Block, Inc. (NYSE: SQ) is a global technology company with a focus on financial services. Made up of Square, Cash App, Spiral, TIDAL, and TBD, we build tools to help more people access the economy. Square helps sellers run and grow their businesses with its integrated ecosystem of commerce solutions, business software, and banking services. With Cash App, anyone can easily send, spend, or invest their money in stocks or Bitcoin. Spiral (formerly Square Crypto) builds and funds free, open-source Bitcoin projects. Artists use TIDAL to help them succeed as entrepreneurs and connect more deeply with fans. TBD is building an open developer platform to make it easier to access Bitcoin and other blockchain technologies without having to go through an institution.",$100 to $500 million (USD),Security & Protective,Company - Private,Management & Consulting
Data Engineer II,atlanta,"dv01
4.7","Atlanta, GA",4.7,$66K - $98K (Glassdoor est.),4.7,4.9,4.8,4.6,4.9,1 to 50 Employees,2014,"dv01 is lifting the curtain on the largest financial market in the world: structured finance. The $16+ trillion market is the backbone of everyday activities that empower financial freedom, from consolidating credit card debt and refinancing student loans, to buying a home and starting a small business.
dv01's data analytics platform brings unparalleled transparency into investment performance and risk for lenders and Wall Street investors in structured products. As a data-first company, we wrangle critical loan data and build modern analytical tools that enable strategic decision-making for responsible lending. In a nutshell, we're helping prevent a repeat of the 2008 global financial crisis by offering the data and tools required to make smarter data-driven decisions resulting in a safer world for all of us.
More than 400 of the largest financial institutions use dv01 for our coverage of over 75 million loans spanning mortgages, personal loans, auto, buy-now-pay-later programs, small business, and student loans. dv01 continues to expand coverage of new markets, adding loans monthly, and developing new technologies for the structured products universe.
To get a better idea of what a year at dv01 looks like, check out our 2022 Year in Review page here: https://dv01.co/year-in-review/2022/ If that looks like fun to you, get in touch because we'd love to hear from you.
YOU WILL:
Be at the heart of dv01. You will operate as the bridge between the engineering and finance teams, contributing to a variety of integral processes that drive dv01 on a daily basis. Every new dataset that gets integrated within dv01 will have your fingerprints all over it.
Be an owner of dv01's most valuable asset. You'll own the business logic in our data pipeline, encapsulating all the knowledge we've accumulated across hundreds of datasets. The output from the pipeline powers all of dv01's customer offerings and is critical to the success of our business.
Be customer-facing. You will have direct exposure to high-level contacts at hedge funds, banks, and asset originators, providing valuable insights to help them answer complex questions.
Work with state-of-the-art technology. You'll work with popular, modern, and exciting open source technologies like Apache Spark and Airflow. The skills you develop here will serve you well beyond dv01.

YOU ARE:
A well-rounded engineer. You have 3+ years of professional programming experience with Apache Spark, Scala, Java, R, or Python. You are able to write thought-out code while accounting for resource and performance constraints and are also capable of performing ad-hoc data investigations with SQL.
Interested and experienced in both engineering and finance. You're looking to grow your skills in both disciplines and are excited about the synergies between finance and technology. You're capable of understanding how investors evaluate loan portfolios and the complexities of amortization, prepay, and default.
A first-rate collaborator and communicator. You're comfortable working alongside analysts and subject matter experts and translating their requirements into code. You thrive on interacting with clients to best understand and satisfy their needs.
Excited about big data. You should have 2+ years of professional engineering experience working with large datasets, with exposure to large datasets related to loan products an added plus. You enjoy working with data, from expressing complex business logic as scalable data processing logic to configuring and debugging intricate big data pipelines. You love the intricate details of a thorough investigation, but also stay aware of the bigger picture while operating across multiple threads of work.
In good faith our salary range for this role is $120,000 - $145,000 but are not tied to it. Final offer amount will be at the company's sole discretion and determined by multiple factors, including years and depth of experience, expertise, and other business considerations.
Our community is fueled by diverse people who welcome differing points of view and the opportunity to learn from each other. Our team is passionate about building a product people love and a culture where everyone can innovate and thrive.

BENEFITS & PERKS:
Unlimited PTO. Unplug and rejuvenate, however you want—whether that's vacationing on the beach or at home on a mental-health day.
In-House Personal & Performance Development Coach. Recharge with our in-house personal & performance development coach, who is here to listen and help guide in your self-development and overall wellness.
$1,000 Learning & Development Fund. No matter where you are in your career, always invest in your future. We encourage you to attend conferences, take classes, and lead workshops. We also host hackathons, brunch & learns, and other employee-led learning opportunities.
Remote-First Environment. People thrive in a flexible and supportive environment that best invigorates them. You can work from your home, cafe, or hotel. You decide.
Health Care and Financial Planning. We offer a comprehensive medical, dental, and vision insurance package for you and your family. We also offer a 401(k) for you to contribute.
Free Equinox Membership or $1,650 Annual Fitness Fund. Regular exercise offers a plethora of mental and physical health benefits. You can either enroll in an all-access Equinox membership or at your preferred gym. Or take advantage of our fitness fund, which can be used toward at-home workout equipment (yes, including a Peloton).
New Family Bonding. Primary caregivers can take 12 weeks off 100% paid leave, while secondary caregivers can take 3 weeks. Returning to work after bringing home a new child isn't easy, which is why we're flexible and empathetic to the needs of new parents.
dv01 is an equal opportunity employer and all qualified applicants and employees will receive consideration for employment opportunities without regard to race, color, religion, creed, sex, sexual orientation, gender identity or expression, age, national origin or ancestry, citizenship, veteran status, membership in the uniformed services, disability, genetic information or any other basis protected by applicable law.",Unknown / Non-Applicable,Computer Hardware Development,Company - Private,Information Technology
Data Engineer (REMOTE OPPORTUNITY),atlanta,"Regions
3.5","Atlanta, GA",3.5,$52K - $78K (Glassdoor est.),3.5,3.7,3.3,3.6,3.7,10000+ Employees,1971,"Thank you for your interest in a career at Regions. At Regions, we believe associates deserve more than just a job. We believe in offering performance-driven individuals a place where they can build a career --- a place to expect more opportunities. If you are focused on results, dedicated to quality, strength and integrity, and possess the drive to succeed, then we are your employer of choice.

Regions is dedicated to taking appropriate steps to safeguard and protect private and personally identifiable information you submit. The information that you submit will be collected and reviewed by associates, consultants, and vendors of Regions in order to evaluate your qualifications and experience for job opportunities and will not be used for marketing purposes, sold, or shared outside of Regions unless required by law. Such information will be stored in accordance with regulatory requirements and in conjunction with Regions’ Retention Schedule for a minimum of three years. You may review, modify, or update your information by visiting and logging into the careers section of the system.

Job Description:
At Regions, the Data Engineer focuses on the evaluation, design, and execution of data structures, processes, and logic to deliver business value through operational and analytical data assets. The Data Engineer uses advanced data design and technical skills to work with business subject matter experts to create enterprise data assets utilizing state of the art data techniques and tools.

Primary Responsibilities
Partners with Regions Technology partners to Design, Build, and Maintain the data-based structures and systems in support of Data and Analytics and Data Product use cases
Builds data pipelines to collect and arrange data and manage data storage in Regions’ big data environment
Builds robust, testable programs for moving, transforming, and loading data using big data tools such as Spark.
Coordinates design and development with Data Products Partners, Data Scientists, Data Management, Data Modelers, and other Technical partners to construct strategic and tactical data stores
Ensures data is prepared, arranged and ready for each defined business use case
Designs and deploys frameworks and micro services to serve data assets to data consumers
Collaborates and aligns with technical and non-technical stakeholders to translate customer needs into Data Design requirements, and work to deliver world-class visualizations, data stories while ensuring data quality and integrity
Provides consultation to all areas of the organization that plan to use data to make decisions
Supports any team members in the development of such information delivery and aid in the automation of data products
Acts as trusted adviser and partner to business leads- assisting in the identification of business needs & data opportunities, understanding key drivers of performance, interpreting business case data drivers, turning data into business value, and participating in the guidance of the overall data and analytics strategy

This position is exempt from timekeeping requirements under the Fair Labor Standards Act and is not eligible for overtime pay.

Requirements
Bachelor's degree and five (5) years of experience in a quantitative/analytical/STEM field or technical related field
Or Master’s degree and three (3) years of experience in a quantitative/analytical/STEM field or technical related field
Or Ph.D. and one (1) year of experience in a quantitative/analytical/STEM field
Three (3) years of working programming experience in Python/PySpark, Scala, SQL
Three (3) years of working experience in Big Data Technology in Hadoop, Hive, Impala, Spark, or Kafka

P references
Prior banking or financial Services experience
Experience developing solutions for the financial services industry
Background in Big Data Engineering and Advanced Data Analytics
Experience in Agile Software Development
Experience or exposure to cloud technologies and migrations

Skills and Competencies
Experience building data solutions at scale
Experience designing and building relational data structures in multiple environments
Experience with Airflow, Argo, Luigi, or similar orchestration tool
Experience with DevOps principals and CI/CD.
Experience with Docker and Kubernetes
Experience with No-SQL databases such as HBase, Cassandra, or MongoDB
Experience with streaming technologies such as Kafka, Flink, or Spark Streaming
Experience working with Hadoop ecosystem building Data Assets at an enterprise scale
Proven record of accomplishment of delivering operational Data solutions including Report and Model Ready Data Assets
Significant experience working with senior executives in the use of data, reporting and visualizations to support strategic and operational decision making
Strong ability to transform and integrate complex data from multiple sources into accessible, understandable, and usable data assets and frameworks
Strong background in synthesizing data and analytics in a large (fortune 500), complex, and highly regulated environment
Strong technical background including database and business intelligence skills
Strong communication skills through written and oral presentations

Additional Job Description
Candidates must have experience with DevOps principals and CI/CD.
Candidates must have experience with Docker and Kubernetes
Candidates must have experience with streaming technologies such as Kafka, Flink, or Spark Streaming.
Preferred experience in Snowflake, SQL and Python.
Preferred experience in developing API's.
Preferred experience with AWS Lambda functions.
This position may be filled at a higher level depending on the candidate's qualifications and relevant experience.

Position Type Full time

Compensation Details
Pay ranges are job specific and are provided as a point-of-market reference for compensation decisions. Other factors which directly impact pay for individual associates include: experience, skills, knowledge, contribution, job location and, most importantly, performance in the job role. As these factors vary by individuals, pay will also vary among individual associates within the same job.

The target information listed below is based on the national range and level of the position.

Job Range Target:
Minimum: $85,374.00 USD
Median: $122,800.00 USD
Incentive Pay Plans: This job is not incentive eligible.

Benefits Information
Regions offers a benefits package that is flexible, comprehensive and recognizes that ""one size does not fit all"" for associates. Listed below is a synopsis of the benefits offered by Regions for informational purposes, which is not intended to be a complete summary of plan terms and conditions.
Paid Vacation/Sick Time
401K with Company Match
Medical, Dental and Vision Benefits
Disability Benefits
Health Savings Account
Flexible Spending Account
Life Insurance
Parental Leave
Employee Assistance Program
Associate Volunteer Program

Please note, benefits and plans may be changed, amended, or terminated with respect to all or any class of associate at any time. To learn more about Regions’ benefits, please click or copy the link below to your browser.

https://www.regions.com/welcometour/benefits.rf

Location Details Regions Plaza Atlanta
Location: Atlanta, Georgia

Bring Your Whole Self to Work

We have a passion for creating an inclusive environment that promotes and values diversity of race, color, national origin, religion, age, sexual orientation, gender identity, disability, veteran status, genetic information, sex, pregnancy, and many other primary and secondary dimensions that make each of us unique as individuals and provide valuable perspective that makes us a better company and employer. More importantly, we recognize that creating a workplace where everyone, regardless of background, can do their best work is the right thing to do.

OFCCP Disclosure: Equal Opportunity Employer/Disabled/Veterans",$5 to $10 billion (USD),Banking & Lending,Company - Public,Financial Services
Data Analytics Engineer (REMOTE),atlanta,"State Farm
3.6","Dunwoody, GA",3.6,Employer Provided Salary:$107K - $171K,3.5,3.6,3.2,3.4,3.5,10000+ Employees,1922,"Overview:
We are not just offering a job but a meaningful career! Come join our passionate team!
As a Fortune 50 company, we hire the best employees to serve our customers, making us a leader in the insurance and financial services industry. State Farm embraces diversity and inclusion to ensure a workforce that is engaged, builds on the strengths and talents of all associates, and creates a Good Neighbor culture.
We offer competitive benefits and pay with the potential for an annual financial award based on both individual and enterprise performance. Our employees have an opportunity to participate in volunteer events within the community and engage in a learning culture. We offer programs to assist with tuition reimbursement, professional designations, employee development, wellness initiatives, and more!
Visit our Careers page for more information on our benefits, locations and the process of joining the State Farm team!
REMOTE: Qualified candidates (outside of hub locations listed below) may be considered for 100% remote work arrangements based on where a candidate currently resides or is currently located.
HYBRID: Qualified candidates (in or near hub locations listed below) should plan to spend time working from home and some time working in the office as part of our hybrid work environment.
SPONSORSHIP: Applicants are required to be eligible to lawfully work in the U.S. immediately; employer will not sponsor applicants for U.S. work authorization (e.g.H-1B Visa) for this opportunity.
Responsibilities:
As a Data Analytics Engineer you will:
Work closely with data scientists and business experts to develop modeling solutions for various internal business partners.
Build and maintain data pipelines for the development, implementation, execution, validation, monitoring, and improvement of data science solutions.
Establish business domain knowledge for State Farm data sources.
Investigate, recommend, and initiate acquisition of new data resources from internal and external data sources.
Identify critical and emerging technologies, techniques, tools, data sources, and platforms in the data engineering field, including cloud-based solutions, that support and extend quantitative analytical solutions.
Qualifications:
Required Skills:
Bachelor’s degree in computer science, software engineering, or related field.
Experience in programming languages such as Python, R, or SAS.
Familiarity with building SQL and No-SQL queries.
Experience with developing solutions on AWS or other distributed compute platforms.
Ability to learn and adopt new technologies and languages.
Critical thinking skills to challenge current thinking and apply right technology to solve problems.
Preferred Skills:
Experience with the model development lifecycle, from project intake to deployment.
Experience building and maintaining data pipelines.
Experience with CI/CD systems, preferably GitLab.
Experience with AWS technologies such as Lambda, Athena, Glue, S3, IAM and Redshift
Experience using deployment automation technologies, preferably Terraform.
Excellent communication skills and the ability to work with multiple, diverse stakeholders across business areas and leadership levels.
For Los Angeles candidates: Pursuant to the Los Angeles Fair Chance Initiative for Hiring, we will consider for employment qualified applicants with criminal histories.
For San Francisco candidates: Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
For Colorado candidates:
Salary Range: $85,460 - $150,700
For NYC and CT candidates:
Potential salary range: $106,825- $171,250
Potential yearly incentive pay- 4%-12% of base salary
Competitive Benefits, including:
401k Plan
Health Insurance
Dental/Vision plans
Life Insurance
Paid Time Off
Annual Merit Increases
Tuition Reimbursement
Health Initiatives
For more details visit the benefits summary.

SFARM
#LI-LP1
#LI-Remote
#LI-Hybrid",$10+ billion (USD),Insurance Carriers,Company - Private,Insurance
Data Engineer,atlanta,"Comtec IT Services
4.6","Peachtree Corners, GA",4.6,$85K - $123K (Glassdoor est.),4.6,4.4,4.6,4.3,4.6,501 to 1000 Employees,1996,"Position: DevOps / Data Engineer
Location: Peachtree Corners, GA - 30092
Duration: 3 Months
Description:
Position: Dev Ops / Data Engineer
Preferred location: Atlanta, GA metro area
~75% travel required to Atlanta, GA if not locally based
Skills:
Required Skills:
o Python
o Linux
o Docker and Docker Swarm
o ZeroMQ / a good understanding in messaging
Desired Skills:
o NVIDIA Deepstream SDK
o Websockets
o Flask
o Protobuf
• Possible:
o GStreamer (if different than RTSP / H264 / MJPEG)
General Tasks:
o Understanding the basics of our architecture/setup to be able to do setup/support for demos, testing, etc.
o Basic computer hardware assembly and set-up
o Possible set-up/installation of application(s) on client servers
o Possible development tasks depending on what the rest of the development team has for them
Job Type: Contract
Schedule:
8 hour shift
Experience:
DevOps: 10 years (Required)
Programming: 7 years (Required)
Python: 7 years (Required)
Linux: 7 years (Required)
Docker: 7 years (Required)
Testing: 7 years (Required)
Messaging: 7 years (Required)
SDLC: 7 years (Required)
Work Location: One location",$25 to $100 million (USD),Information Technology Support Services,Company - Private,Information Technology
GCP Data Engineer Lead,atlanta,"cyberThink
3.7","Atlanta, GA",3.7,Employer Provided Salary:$60.00 - $70.00 Per Hour,3.3,3.2,3.4,3.4,3.4,201 to 500 Employees,1996,"EST time zone profiles only.
Client : LTIMindtree
Role : GCP Data Engineer Lead
Location : Atlanta, GA || Onsite
Duration : Long Term
Job Description
• Development experience with any GCP Cloud ETLs and Databases.
Strong understanding of Dataflow, BigQuery, Cloud SQL, Airflow
Excellent with Java/Python and Google Cloud SDK & API Scripting
Perform role of Lead and guide junior members in understanding requirements and in delivery.
Work with client teams to design and implement modern, scalable data solutions using a range of new and emerging technologies from the Google Cloud Platform.
Work with Agile and DevOps techniques and implementation approaches in the delivery.
Required to showcase your GCP Data engineering experience when communicating with clients on their requirements, turning these into technical data solutions.
Required to build and deliver Data solutions using GCP products and offerings.
Knowledge and understanding of DevOps.
Thanks & Regards,
Tushar Chaudhary
Sr Technical Recruiter
9089882599
Tushar.Chaudhary@cyberthink.com
www.cyberthink.com
Job Type: Contract
Salary: $60.00 - $70.00 per hour
Experience level:
10 years
Schedule:
8 hour shift
Ability to commute/relocate:
Atlanta, GA: Reliably commute or planning to relocate before starting work (Required)
Experience:
GCP: 10 years (Required)
LEAD: 3 years (Required)
Data warehouse: 10 years (Required)
Work Location: One location
Speak with the employer
+91 9089882599",Unknown / Non-Applicable,Staffing & Subcontracting,Company - Private,Human Resources & Staffing
Azure Data Engineer,atlanta,"Qualified Recruiter Pvt Ltd
4.3","Atlanta, GA",4.3,Employer Provided Salary:$77K - $95K,4.5,4.3,4.3,4.2,4.1,201 to 500 Employees,2017,"MUST BE A US CITIZEN OR A GREEN CARD HOLDER ONLY.
3+ years of experience on developing Data warehouse/Lakehouse/Data platform on Azure Synapse Analytics/Azure Data Bricks/Azure Cloud Platform.
Should have experience in ETL/ELT. Hands on experience ADF/Synapse, configuration, parameters, variables, Integration services runtime.
Proficiency in SQL,T-SQL and Python/PySpark
No Relocation. Local to Atlanta, GA
Job Type: Full-time
Salary: $77,000.00 - $95,000.00 per year
Benefits:
401(k)
Health insurance
Experience level:
3 years
Application Question(s):
Are you a US Citizen or a Green Card Holder?
How many years of experience do you have with Data platform on Azure Synapse Analytics?
Experience:
Azure Data Engineer: 3 years (Required)
ETL or ELT: 3 years (Required)
Work Location: One location",Unknown / Non-Applicable,Staffing & Subcontracting,Company - Private,Human Resources & Staffing
Sr. Data engineer,atlanta,"Katalyst Healthcares & Life Sciences
3.6","Atlanta, GA",3.6,$84K - $119K (Glassdoor est.),4.0,3.6,3.6,3.8,3.7,51 to 200 Employees,Company - Private,"Responsibilities:
Getting data out of Oracle (tables and schemas) from existing implementation to Azure
Customer data - PCA tables
Financial data
Analyse the queries.
E business suite",-1,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,Unknown / Non-Applicable
Lead Data Engineer,atlanta,"CVS Health
3.1","Alpharetta, GA",3.1,$93K - $129K (Glassdoor est.),3.1,2.9,2.7,3.1,2.8,10000+ Employees,1963,"Caremark LLC, a CVS Health company, is hiring for the following role in Alpharetta, GA: Lead Data Engineer to Design, build and manage large scale data structures, pipelines and efficient Extract/Load/Transform (ETL) workflows to support business applications. Duties include: develop large scale data structures and pipelines to organize, collect and standardize data to generate insights and addresses reporting needs; write ETL (Extract/Transform/Load) processes, design database systems, and develop tools for real-time and offline analytic processing; collaborate with Data Science team to transform data and integrate algorithms and models into automated processes; leverage knowledge of Hadoop architecture, HDFS commands, and designing and optimizing queries to build data pipelines; utilize programming skills in Python, Java, or similar languages to build robust data pipelines and dynamic systems; build data marts and data models to support Data Science and other internal customers; integrate data from a variety of sources and ensure adherence to data quality and accessibility standards; analyze current information technology environments to identify and assess critical capabilities and recommend solutions; and experiment with available tools and advise on new tools to provide optimal solutions that meet the requirements dictated by the model/use case.

Required Qualifications
Master’s degree (or foreign equivalent) in Computer Information Systems, Computer Science, Data Science, Statistics, Analytics, or a related field and two (2) years of experience in the job offered or related occupation. Requires two (2) years of experience in each of the following: Defect/test management tool such as Rally, JIRA or Confluence; Cloud technologies: Azure, GCP, or AWS; Writing clean, high quality, high performing, scalable code; Software development lifecycle; SQL programming languages; Visualization tools, including PowerBI; and Informatica.

Preferred Qualifications
See Required Qualifications.

Education
See Required Qualifications.

Business Overview
Bring your heart to CVS Health Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver. Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an affirmative action employer, and is an equal opportunity employer, as are the physician-owned businesses for which CVS Health provides management services. We do not discriminate in recruiting, hiring, promotion, or any other personnel action based on race, ethnicity, color, national origin, sex/gender, sexual orientation, gender identity or expression, religion, age, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.",$10+ billion (USD),Health Care Services & Hospitals,Company - Public,Healthcare
Data Engineer (AWS),atlanta,"Emergent Software
4.7","Atlanta, GA",4.7,Employer Provided Salary:$100K - $120K,4.3,4.5,4.7,4.5,4.7,51 to 200 Employees,2015,"** This is a direct hire position for one of our clients. This position is fully remote but needs to be on EST or CST time zone. Candidates must be able to work in the US without sponsorship.**
We are seeking a highly skilled and experienced Data Engineer to join our team. In this role, you will be responsible for creating and maintaining a scalable ETL data pipeline, managing a multi-modal data storage system, and collaborating with the data science team to enable ML Ops. Your strong understanding of data and proficiency in SQL will be critical for efficiently querying and obtaining data. As a Data Engineer, you will take ownership of technical and business outcomes, assist the development and data science teams with data analysis, and document processes and methodologies. Excellent communication skills are essential for effectively conveying insights and findings to stakeholders.
Responsibilities
Create and maintain a scalable ETL data pipeline that ingests multiple large data sets, including structured financial and patent data, as well as unstructured data such as white papers and scraped websites. Enable entity resolution and other transformations for clean data integration and usage.
Develop and maintain a multi-modal data storage system that supports scalable and real-time processing for production-level data.
Collaborate with the data science team to enable ML Ops, ensuring the efficient integration and deployment of machine learning models into the platform.
Possess a deep curiosity and passion for data, demonstrating a strong and extensive understanding of data. Efficiently query and retrieve data using SQL.
Take ownership of technical and business outcomes, demonstrating a strong sense of responsibility for the success of data engineering projects.
Assist the development and data science teams with processing and integrating data analysis, enabling them to derive valuable insights from the data.
Clearly document processes, methodologies, and tools used, ensuring that knowledge is effectively shared within the team.
Required Experience
Bachelor's degree in a relevant technical field.
Significant experience (at least 3-5 years) as a data engineer in the AWS ecosystem, with a strong familiarity in working with structured and unstructured large data sets. Proficient in enabling scalable and distributed compute and ensuring real-time processing at scale.
Demonstrated expertise (at least 3-5 years) in writing complex SQL queries and conducting data correlations analysis.
Extensive experience (at least 3-5 years) with the AWS ecosystem, including tools, services, and resources that enable scalable and distributed compute.
Strong project management skills, with the ability to scope timelines, methodologies, and deliverables for development, testing, and integration into the platform.
Excellent communication and storytelling skills, both written and verbal, to effectively convey insights and findings to technical and non-technical stakeholders.
Our Vetting Process
At Emergent Software, we work hard to find the software engineers who are the right fit for our clients. Here are the steps of our vetting process for this position:
Application (5 minutes)
Online Assessment & Short Algorithm Challenge (40-60 minutes)
Initial Phone Interview (30-45 minutes)
2-3 Interviews with the Client
Job Offer!
Join our client's dynamic team as a Data Engineer and play a crucial role in developing and maintaining our client's data infrastructure, ensuring the seamless integration and utilization of large-scale data sets. Apply your expertise in data engineering and the AWS ecosystem to drive innovation and deliver impactful solutions.
Job Type: Full-time
Pay: $100,000.00 - $120,000.00 per year
Schedule:
8 hour shift
Monday to Friday
Work Location: Remote",$5 to $25 million (USD),Software Development,Company - Private,Information Technology
"Data Engineer, Operations Analysis, and Performance",atlanta,"Delta
4.3","Atlanta, GA",4.3,-1,-1,-1,-1,-1,-1,10000+ Employees,1928,"United States, Georgia, Atlanta
Operations Anlys & Performance
19-May-2023
Ref #: 21095
How you'll help us Keep Climbing (overview & key responsibilities)
Deltas brand is based on best-in-class operational performance, the foundation of which is providing safe and reliable operations for our customers travel experience. The role of Operations Analytics (OA) is to support this mission by providing strategic insights by first understanding business processes and then leveraging data and analytics to drive continuous improvement efforts.
Data has transformed the way Delta operates.The role of a data engineer is to further harness the power of data by making it accessible, available, and curated for reporting and analysis. Data engineering teams within Deltas Operations Analysis and Performance (OAP) division are typically responsible for: curating Single Source of Truth data tables to be used by analytics teams, producing and distributing automated reporting in a modular and scalable manner, leading efforts to transition to modern data and reporting tools, and acting as a center of expertise for efficient data processing and management.
Responsibilities:
Locate and extract data from a variety of sources for use in analysis, models and project development.
Clean and curate datasetsby researching new data sources and collaborating with other business units to determine the best source for the data,aggregating views into meaningful hierarchies
Be familiar with data environments and collaborate to improve automated reports and analyses in support of divisional leaders and business units
Leverage emerging technologies and proactively identify efficient and meaningful ways to communicate data and analysis in order to satisfy divisional needs.
Support process improvement and project management engagements for both individual business units and cross-divisional initiatives
Train and mentor other team members in various skillsets and subjects
Practice safety-conscious behaviors in all operational processes and procedures
Have a team first attitude with the success of our team and business partners as the top priority
Be intellectually curious, ask questions, and speak up when they have an idea
Enjoy working in a high-profile environment with fluid priorities, ambiguity and aggressive deadlines.

Benefits and Perks to Help You Keep Climbing
A career at Delta not only gives you a chance to see the world, but we also provide excellent benefits to help you keep climbing along the way!
Competitive salary, industry leading profit sharing and 401(k) with generous direct contribution and company match
Comprehensive health benefits including medical, dental, vision, short/long term disability and life benefits
A detailed wellness plan that recognizes the importance physical, emotional, financial, and social wellbeing
Domestic and International flight privileges

What you need to succeed (minimum qualifications)
3+ years of related experience
Proficiency in SQL and ETL/ELT patterns
Proficiency with Python, SAS or other similar tools and programming languages
Ability to troubleshoot a reporting database environment.
Strong attention to detail and ability to work autonomously and manage multiple requests with varying timelines.
Self-starter with a resilient, solution-minded approach to complex problems working individually or in a group.
Demonstrates that privacy is a priority when handling personal data.
Consistently prioritizes safety and security of self, others, and personal data.
Embraces diverse people, thinking, and styles.
Possesses a high school diploma, GED, or high school equivalency.
Is at least 18 years of age and has authorization to work in the United States.
What will give you a competitive edge (preferred qualifications)
Bachelor's degree or certificate in Computer Science, Engineering, Information Science, or other relevant quantitative field
Previous airline experience
Working knowledge of and/or experience with cloud-based solutioning (i.e. Azure, AWS, GPC, etc.)

< Go back",$10+ billion (USD),"Airlines, Airports & Air Transportation",Company - Public,Transportation & Logistics
Big Data Software Engineer II,atlanta,"JPMorgan Chase Bank, N.A.
3.8","Atlanta, GA",3.8,$96K - $128K (Glassdoor est.),3.6,3.7,3.4,3.7,3.5,10000+ Employees,1799,"We have an exciting and rewarding opportunity for you to take your software engineering career to the next level.

As a Software Engineer II at JPMorgan Chase, you serve as a seasoned member of an agile team to design and deliver trusted market-leading technology products in a secure, stable, and scalable way. You are responsible for carrying out critical technology solutions across multiple technical areas within various business functions in support of the firm's business objectives.

Job responsibilities
Executes software solutions, design, development, and technical troubleshooting with ability to think beyond routine or conventional approaches to build solutions or break down technical problems
Creates secure and high-quality production code and maintains algorithms that run synchronously with appropriate systems
Produces architecture and design artifacts for complex applications while being accountable for ensuring design constraints are met by software code development
Gathers, analyzes, synthesizes, and develops visualizations and reporting from large, diverse data sets in service of continuous improvement of software applications and systems
Proactively identifies hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture
Contributes to software engineering communities of practice and events that explore new and emerging technologies
Adds to team culture of diversity, equity, inclusion, and respect

Required qualifications, capabilities, and skills
Formal training or certification on software engineering concepts and 2+ years applied experience
Hands-on practical experience in system design, application development, testing, and operational stability
Proficient in Hadoop, Spark, Scala, Java
Experience in developing, debugging, and maintaining code in a large corporate environment with one or more modern programming languages and database querying languages
Overall knowledge of the Software Development Life Cycle
Solid understanding of agile methodologies such as CI/CD, Applicant Resiliency, and Security
Demonstrated knowledge of software applications and technical processes within a technical discipline (e.g., cloud, artificial intelligence, machine learning, mobile, etc.)

Required qualifications, capabilities, and skills
Formal training or certification on software engineering concepts and 2+ years applied experience
Hands-on practical experience in system design, application development, testing, and operational stability
Experience in developing, debugging, and maintaining code in a large corporate environment with one or more modern programming languages and database querying languages
Demonstratable ability to code in one or more languages
Experience across the whole Software Development Life Cycle * Exposure to agile methodologies such as CI/CD, Applicant Resiliency, and Security
Emerging knowledge of software applications and technical processes within a technical discipline (e.g., cloud, artificial intelligence, machine learning, mobile, etc.)

Preferred qualifications, capabilities, and skills
Familiarity with modern front-end technologies
Exposure to cloud technologies
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.
The health and safety of our colleagues, candidates, clients and communities has been a top priority in light of the COVID-19 pandemic. JPMorgan Chase was awarded the ""WELL Health-Safety Rating"" for all of our 6,200 locations globally based on our operational policies, maintenance protocols, stakeholder engagement and emergency plans to address a post-COVID-19 environment.
As a part of our commitment to health and safety, we have implemented various COVID-related health and safety requirements for our workforce. Employees are expected to follow the Firm's current COVID-19 or other infectious disease health and safety requirements, including local requirements. Requirements include sharing information including your vaccine card in the firm's vaccine record tool, and may include mask wearing. Requirements may change in the future with the evolving public health landscape. JPMorgan Chase will consider accommodation requests as required by applicable law.

We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, discretionary incentive compensation which may be awarded in recognition of individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.
Equal Opportunity Employer/Disability/Veterans",$10+ billion (USD),Banking & Lending,Company - Public,Financial Services
North America Principal Data Engineer (Remote Option*),atlanta,"Nike
4.2","Atlanta, GA",4.2,Employer Provided Salary:$131K - $285K,3.7,4.1,3.6,3.9,3.8,10000+ Employees,1972,"Rejoignez l'équipe NIKE, Inc.
Loin de se contenter d'équiper les plus grands athlètes mondiaux, NIKE, Inc. explore les potentiels, abolit les frontières et repousse les limites du possible. L'entreprise recherche des personnes capables d'évoluer, de réfléchir, de rêver et de créer. L'épanouissement de sa culture repose sur son ouverture à la diversité et sur sa façon d'encourager l'imagination. La marque a besoin de personnes talentueuses, de leaders et de visionnaires. Chez NIKE, Inc., chacun contribue, par ses compétences et sa passion, à jouer un match difficile en constante évolution.
NIKE est une entreprise de technologie. De notre site Web phare à nos applications mobiles cinq étoiles en passant par le développement de produits, la gestion des big data, l'ingénierie de pointe et la prise en charge des systèmes, les équipes NIKE Global Technology s'efforcent de révolutionner le futur, à la croisée de la technologie et du sport. Nous investissons dans la technologie et mettons au point des innovations ; nous employons les personnes les plus créatives au monde et leur donnons les clés pour innover, apporter les modifications nécessaires et servir les clients de façon plus directe et personnelle. Nos équipes innovantes, hétérogènes, multidisciplinaires et collaboratives imaginent les technologies de demain et en font profiter le monde entier.

WHO ARE WE LOOKING FOR
We are looking for an experienced Principal Data Engineer to guide and influence multiple engineering teams to deliver scalable data and analytics solutions, implement new technologies, participate in solution design and architecture discussions. The ideal candidate will have outstanding communication skills, shown data design and implementation capabilities, strong eye for business, and a drive to deliver results. The person in this role will be technically proficient and excel at collaborating with engineers, analysts, and business partners. This person will be a self-starter, comfortable with ambiguity, and will enjoy working in a fast-paced dynamic environment.


WHAT WILL YOU WORK ON
In this role, you will build and deliver scalable data and analytics solutions focused on Nike Direct, Supply Chain, and Commercial space. You will design, implement and integrate new technologies and evolve data and analytics products. You will be chipping in to all aspects of data engineering from ingestion, transformation, and consumption in addition to designing and building test-driven development, reusable frameworks, automated workflows, and libraries at scale to support analytics products. You will also participate in architecture and design discussions to process and store high-volume data sets.


WHO WILL YOU WORK WITH
This person will join the North America Data & Analytics Organization and you will work with world-class talent in the field of Data Engineering with a goal of better business insights and driving data-driven decisions across the organization. You’ll be working closely with hardworking teams - Internal partners, Product Owners, Engineering Leaders, Data Analysts, Big Data Leads, and Engineers. One of Nike’s maxims is “Win as a Team” and you will be working in a very collaborative environment and will find success in teamwork, a positive attitude, and hard work.

WHAT YOU BRING
Bachelor/Master degree in Computer Science or related technical subject area or equivalent combination of education and experience
10+ years relevant work experience in the Data Engineering field
5+ years validated experience working with Hadoop and Big Data processing frameworks (Spark, Hive, Nifi, Spark-Streaming, Flink, etc.)
2+ years experience building scalable, real-time and high-performance cloud data lake solutions
Strong experience with relational SQL and programming languages such as Python, Scala, or Java
Experience with source control tools such as GitHub and related CI/CD processes
Experience working with Big Data streaming services such as Kinesis, Kafka, etc.
Experience working with NoSQL data stores such as HBase, DynamoDB, etc.
Experience provisioning RESTful API’s to enable real-time data consumption
Experience working in AWS environment primarily EMR, S3, Kinesis, Redshift, Athena, etc
Experience with data warehouses/RDBMS like Snowflake & Teradata
Experience with workflow scheduling tools like Airflow
Experience providing guidance and mentorship to other engineers
Strong understanding of algorithms, data structures, data architecture, and technical designs.
Proven track record of rapidly learning new technologies and developing and implementing proof of concepts and practical, working code
Proven track record to influence and communicate effectively with team members and business partners
Proven track record to partner with teams in solving complex problems by taking a broad perspective to identify innovative solutions.
Remote Work Option – Open to remote work, except cannot work in South Dakota, Vermont, and West Virginia. These candidates will be required to relocate.

The annual base salary for this position ranges from $131,000 to $285,000. Actual salary will vary based on a candidate’s location, qualifications, skills, and experience.

Information about benefits
#LI-VB1
NIKE, Inc. est une entreprise en pleine croissance cherchant à intégrer à son équipe des personnes capables de se développer avec elle. Nike offre un généreux programme de rémunération globale, un environnement de travail décontracté, une culture variée et inclusive et une atmosphère dynamique propice au développement professionnel. Quels que soient le site ou le poste, les employés de Nike partagent tous la même mission stimulante : apporter inspiration et innovation aux athlètes* du monde entier.
NIKE, Inc. s'engage à embaucher un personnel diversifié. Les candidats qualifiés seront considérés sans tenir compte de leur origine, couleur de peau, religion, sexe, nationalité, âge, orientation sexuelle, identité de genre, expression de genre, statut de vétéran ou handicap.",$10+ billion (USD),Consumer Product Manufacturing,Company - Public,Manufacturing
Data Engineer Marketing Platforms,atlanta,"Humana
3.9","Atlanta, GA",3.9,-1,-1,-1,-1,-1,-1,10000+ Employees,1961,"Humana is a Fortune 60 market leader in integrated healthcare whose dream is to help people achieve lifelong well-being. As a company focused on the health and well-being of the people we serve, Humana starts from within, and is committed to providing progressive benefits that advance the employment experience and vitality of the associate community. Through offerings anchored in a whole-person view of human well-being, Humana embraces a focus on stimulating positive individual and population changes while nurturing a sense of security, enabling people to live life fully and be their most productive.

Against that backdrop Humana is building a best-in-class Consumer Marketing organization to drive profitable membership growth across diverse business lines. The Marketing Technology & Data Platform team within Humana’s Marketing Organization, provides marketing technology, strategy, and data management solutions to the enterprise. This team bridges technology & marketing to help deliver exceptional customer experiences. We champion advancement of marketing technology capabilities and bringing innovation to digital marketing strategy.
Responsibilities
Humana’s Marketing Technology Data Platforms team is seeking a Data Management Engineer to support the data efforts across the Marketing organization. As a Data Engineer, you will assist our Marketing organization & Marketing Practices teams specifically, in designing and delivering data to enable efficient and effective:
Communications execution - messaging to consumers across the consumer lifecycle – from prospect to member and across recipient roles (consumers, providers, agents, employers).
Marketing analytics - consumer segmentation and analysis to facilitate personalized communications and precision targeting.
Campaign reporting – automated, standardized reporting to measure operational, response, and outcomes to evaluate tests in market and adjust rapidly if/when needed.
Key responsibilities include:
Acquire, validate, store, & protect data, ensuring accessibility, reliability, and timeliness, specifically in support of our legacy data platforms while migration of the marketing data platform to the cloud and evolution and modernization of the MarTech stack is in progress.
Design, document & deliver automated processes & procedures to manage data – extract, transform, & load.
Support the Data Team in assisting Marketing partners throughout the lifecycle - from strategy & design through execution to measurement to ensure an end-to-end feedback loop is implemented and measurement is standardized and enabled.
Required Qualifications
B.S. degree in math, statistics/analytics, engineering, or a related technology field
2+ years of experience preparing and analyzing data to support messaging, reporting, and/or analytics.
Experience using SQL.
Working knowledge of ad-hoc query tools and data repositories that support data extraction and manipulation and, preferably, intermediate-to-advanced experience in programming, analytical work, research and/or statistics.
Strength in managing multiple priorities and/or projects by using appropriate methodologies and tools.
Strong attention to detail, excellent organizational skills, and ability to work independently.
Excellent written and verbal communication skills.
Prowess in introducing new ideas and processes that improve performance and productivity.
Preferred Qualifications
Healthcare industry experience
Salesforce Marketing Cloud, Adobe Experience or Audience Manager, and/or Azure experience
Experience with marketing performance measurement data, using tools such as Adobe Analytics, IBM Digital Analytics and/or Google Analytics
Familiarity with Data Management Platforms (DMP) and Customer Data Platforms (CDP) in data driven use cases, application in campaigns, and general adoption through strategy to connect to a wider spectrum of datasets, particularly first and second person data
Proficient in interpreting marketing data, finding gaps, and driving solutions
Proven understanding of MarTech/AdTech landscape and how different tools enhance marketing capabilities and the data strategy needed to enable them
Familiarity with data visualization tools such as Tableau or PowerBI and experience designing the underlying data to support dashboards & reporting
Scheduled Weekly Hours
40

Not Specified
0",$10+ billion (USD),Health Care Services & Hospitals,Company - Public,Healthcare
Software Engineer II - Enterprise Data Warehouse (Remote),atlanta,"Home Depot / THD
3.8","Atlanta, GA",3.8,Employer Provided Salary:$160K,3.6,3.8,3.4,3.6,3.5,10000+ Employees,1978,"Position Purpose:
The Software Engineer II is responsible for all of our Supply Chain data in the EDW (Enterprise Data Warehouse). As a Software Engineer II, you will be part of a dynamic team with engineers of all experience levels who help each other build and grow technical and leadership skills while creating, deploying, loading new data through approved ETL processes, support existing data loads and end user questions. In addition, Software Engineer IIs may be involved in configuration, security, resilience, performance tuning and production monitoring.
Key Responsibilities:
60% Delivery and Execution - Collaborates and pairs with other product team members (UX, engineering, and product management) to create secure, reliable, scalable software solutions; Documents, reviews and ensures that all quality and change control standards are met; Works with Product Team to ensure user stories that are developer-ready, easy to understand, and testable; Writes custom code or scripts to automate infrastructure, monitoring services, and test cases; Writes custom code or scripts to do destructive testing to ensure adequate resiliency in production; Program configuration/modification and setup activities on large projects using HD approved methodology; Configures commercial off the shelf solutions to align with evolving business needs Creates meaningful dashboards, logging, alerting, and responses to ensure that issues are captured and addressed proactively
20% Learning - Actively seeks ways to grow and be challenged using both formal and informal development channels; Learns through successful and failed experiment when tackling new problems
20% Plans and Aligns - Collaborates with other team members in agile processes; Assists in creating new and better ways for the team to be successful; Relates openly and comfortably with diverse groups of people; Builds partnerships and works collaboratively with others to meet shared objectives
Direct Manager/Direct Reports:
This position typically repots to Software Engineer Manager or Sr. Manager
This position has 0 Direct Reports
Travel Requirements:
No travel required.
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Working Conditions:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Minimum Qualifications:
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Preferred Qualifications:
1-3 years of relevant work experience
Experience in writing SQL queries against a relational database
Experience in Data Analysis
Experience in version control systems
Experience in front end technology such as HTML, CSS, and Javascript/Typescript frameworks
Experience in an object-oriented programming language (preferably Java)
Experience in source code version control
Experience in Relational or noSQL database technology
Experience in cloud computing techniques
Experience in CI/CD tools
Experience in microservice-based architecture
Experience with modern debugging and root cause analysis techniques
Exposure to security frameworks for user and services authorization and authentication
Exposure to creating and executing unit, functional, destructive and performance tests
Minimum Education:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Preferred Education:
No additional education
Minimum Years of Work Experience:
2
Preferred Years of Work Experience:
No additional years of experience
Minimum Leadership Experience:
None
Preferred Leadership Experience:
None
Certifications:
None
Competencies:
Global Perspective
Manages Ambiguity
Nimble Learning
Self-Development
Collaborates
Cultivates Innovation
Situational Adaptability
Communicates Effectively
Drives Results
Interpersonal Savvy",$10+ billion (USD),Home Furniture & Housewares Stores,Company - Public,Retail & Wholesale
Fellow Software Engineer - Data Scientist,atlanta,"New Relic
4.0","Atlanta, GA",4.0,Employer Provided Salary:$230K - $288K,3.8,4.0,3.5,4.2,4.3,1001 to 5000 Employees,2008,"Req ID
FY24|R&D|#5070
Location(s)
Atlanta, Georgia, USA; Charlotte, North Carolina, USA; Dallas, Texas, USA; Houston, Texas, USA; Miami, Florida, USA; Minneapolis, Minnesota, USA; New York City, New York, USA; Portland, Oregon, USA; San Francisco, California, USA; Seattle, Washington, USA;
Work arrangement(s)
Fully Remote (works exclusively from home)
Your opportunity
As a Fellow Engineer at New Relic, you will play a crucial role in exploring new innovations and performing proof of concepts to enhance our AI and machine learning solutions for optimizing and automating IT operations. You will be responsible for leading the evaluation of emerging technologies, identifying areas for improvement, and developing new features while ensuring the reliability and scalability of New Relic’s AIOps platform.
What you'll do
Lead the exploration of emerging AI and machine learning technologies and develop proof-of-concepts to assess their potential impact on New Relic’s AIOps platform.
Collaborate with cross-functional teams to gather requirements, prioritize features, and define technical solutions based on the latest innovations.
Design, develop, and maintain AIOps solutions that can monitor and analyze IT data in real time, predict incidents, and automate responses.
Develop and implement machine learning models for anomaly detection, root cause analysis, leveraging both supervised and unsupervised learning techniques.
Implement data processing pipelines that can handle petabytes of data in real-time, leveraging technologies such as Apache Kafka, Apache Flink, and Apache Spark.
Develop and maintain custom integrations with third-party IT tools and systems to enhance the AIOps platform’s capabilities.
Monitor the AIOps platform’s performance and troubleshoot issues as they arise.
Contribute to the documentation and knowledge base to help other teams understand and use the AIOps platform effectively.
What your playground will look like:
A constantly evolving architecture, with hundreds of containerized services across multiple agile teams.
A hybrid datacenter/cloud environment ingesting over 200 petabytes of data per month, and accepting over 70 billion HTTP requests a day from our customers.
Java, Kafka, Istio, Kubernetes, MySQL, Go and that’s just the beginning of the technologies in our stack.

This role requires
Bachelor’s or Master’s degree in Computer Science, Computer Engineering, Data Science, or a related field.
A minimum of 10 years of software or data engineering experience
3+ years of experience designing and implementing AIOps solutions in a SaaS or cloud environment.
Extensive experience in LLMs, AI, and machine learning, with a deep understanding of relevant technologies and tools.
Demonstrated experience building AI proof-of-concepts
Strong understanding of Observability and the challenges associated with monitoring complex distributed systems.
Experience with generative AI techniques, such as GANs and VAEs, and a track record of applying them in practical settings.
Passion for continuous learning and staying up-to-date with the latest trends and technologies in the AI and Observability industries.
Strong collaboration skills and ability to work effectively with cross-functional teams.
Proven track record of delivering results and meeting or exceeding business objectives.
Strong written and verbal communication skills.
Bonus points if you have
Experience with big data technologies such as Apache Kafka, Apache Flink, and Apache Spark.
Experience with machine learning frameworks such as TensorFlow, PyTorch, or scikit-learn.
We're looking for bold and passionate people to be a part of our mission to help every engineer do their best work, every day, using data, not opinions, at every stage of the software lifecycle. We'd love to have you apply, even if you don't feel you meet every single requirement. What's most important to us is finding authentic and accountable people who feel connected to our mission and values, not just candidates who check off all the boxes.
We believe in empowering all Relics to achieve professional and business success through a workforce model called Flex First. Flex First allows us to work in a variety of workplaces that best support our success, including fully office-based, fully remote, or hybrid.
Read more about Flex First.
Our hiring process

Please note that visa sponsorship is not available for this position.
In compliance with applicable law, all persons hired will be required to verify identity and eligibility to work and to complete employment eligibility verification. Note: Our stewardship of the data of thousands of customers’ means that a criminal background check is required to join New Relic.

We will consider qualified applicants with arrest and conviction records based on individual circumstances and in accordance with applicable law including, but not limited to, the San Francisco Fair Chance Ordinance.

Headhunters and recruitment agencies may not submit resumes/CVs through this website or directly to managers. New Relic does not accept unsolicited headhunter and agency resumes, and will not pay fees to any third-party agency or company that does not have a signed agreement with New Relic.

New Relic is an equal opportunity employer. We eagerly seek applicants of diverse background and hire without regard to race, color, gender identity, religion, national origin, ancestry, citizenship, physical abilities (or disability), age, sexual orientation, veteran status, or any other characteristic protected by law.

Estimated Base Pay Range: $ 230,000 - $ 288,000
Consistent with New Relic's values and applicable law, we provide the following information to promote pay transparency and equity. The base pay range above represents a good faith estimate of the low and high end base pay range for the listed position. This role may be eligible for the corporate bonus plan (or, if a sales role, a commission plan as defined in the sales incentive plan document), participation in our stock equity plan, short- and long-term incentives, and other department-specific awards that may be applicable. In addition, New Relic provides a variety of benefits to employees. The range provided may also represent candidate ranges and may not reflect the full range or geographic differential for an individual tenured employee.
Wage - midpoint
288,000
Wage - minimum
230,000
#LI-MP1 #LI-Remote
This field has no functionality and it was added so that we could display the separator above",$100 to $500 million (USD),Computer Hardware Development,Company - Public,Information Technology
Senior Data Engineer - Remote,atlanta,"IPG Corporate
3.7","Atlanta, GA",3.7,$83K - $117K (Glassdoor est.),3.7,3.8,3.7,3.7,3.5,5001 to 10000 Employees,1932,"Job ID: 482409
Exempt

Oldcastle Infrastructure™, a CRH company, is the leading provider of utility infrastructure solutions for the water, energy, and communications markets throughout North America. We’re more than just a manufacturer of precast concrete, polymer concrete, or plastic products. We’re a trusted and strategic partner to engineers, contractors, distributors, specifiers, and more. With our network of more than 80 manufacturing facilities and more than 4,000 employees, we’re leading the industry with innovation and a safety-first mindset.

Oldcastle Infrastructure - Built For Life from Oldcastle Infrastructure on Vimeo.

Our strategic focus on a combination of acquisition and organic growth along with our adoption of cloud-based technologies has quickly led to a massive shift toward rapid integration and delivery as a necessity to the business. To meet these challenges, we are building an “elite” data engineering team that will welcome the challenges to engineer, integrate, secure, operate and enhance these environments and to deliver exceptional and expedient value to the business while maintaining the delivery and direction of the overall IT strategy.

The Role

The Sr Data Engineer position will partner with IT and business to support the continued growth and success of the enterprise in a robust and cohesive team. To be successful, the Sr Data Engineer will need to demonstrate both business acumen and technological insight to execute our global data strategy. The position works closely with Business Analysts and Technical Engineers to design, develop, test, and implement data transformations to/from Enterprise Systems including various Cloud-based/external systems to effectively meet business requirements. In addition to project work, this position will also provide Business as Usual (BAU) support for the existing environment.

Reporting within the Data Analytics team, the role will be responsible for design, development, implementation and support of data transformation work utilizing SQL predominately in a Snowflake environment and as the role progresses, build/support various other analytic workflows like DataBricks and various data science tools for both on-premises and cloud solutions.

Responsibilities

Work with Data Architecture group to code integrations into Snowflake EDW
Monitor and manage ongoing integrations to maintain functionality
Participate in Solution Design meetings to understand the transformation design needs for a specific set of data and develop documentation around the designs
Build & test transformation jobs to transfer and transform the data between layers of the EDW and/or prep data for external integrations
Provides ongoing Business as Usual (BAU) support for the engineering jobs as needed
Work as a lead within the data engineering team with both onshore and offshore
Drive standardization of process and security requirements

Requirements

Bachelor's Degree in Computer Science, Mathematics, Statistics or related field
5+ years’ experience as a Data Engineer on large scale data warehouse initiatives
5+ years of experience designing, developing and implementing data transformations for an enterprise scale Enterprise Data Warehouse environment
2+ years’ experience with Cloud-based transformation implementations
Strong SQL (Structured Query Language) ability to view and understand data from common data base systems and applications (Oracle, SQL Server, Salesforce, SAP, etc.)
Understanding of full life cycle development methodology
Demonstrated ability to remain effective and productive in a fast-paced and changing environment
Ability to provide after-hours BAU support as required
Superior analytical and problem-solving skills
Experience working in an agile style project management environment
Excellent verbal and oral communication skills with both technical and non-technical colleagues from geographically distributed teams on all organizational levels
Experience in a manufacturing industry is a plus

What CRH Offers You

Highly competitive base pay
Comprehensive medical, dental and disability benefits programs
Group retirement savings program
Health and wellness programs
A diverse and inclusive culture that values opportunity for growth, development, and internal promotion

About CRH

CRH has a long and proud heritage. We are a collection of hundreds of family businesses, regional companies and large enterprises that together form the CRH family. CRH operates in a decentralized, diversified structure that allows you to work in a small company environment while having the career opportunities of large international organization.

If you’re up for a rewarding challenge, we invite you to take the first step and apply today! Once you click apply now, you will be brought to our official employment application. Please complete your online profile and it will be sent to the hiring manager. Our system allows you to view and track your status 24 hours a day. Thank you for your interest!

Oldcastle Infrastructure, a CRH Company, is an Affirmative Action and Equal Opportunity Employer.

EOE/Vet/Disability-If you want to know more, please click on this link.",Unknown / Non-Applicable,Consumer Product Manufacturing,Company - Public,Manufacturing
"Platform Data Engineer, Financial Services",atlanta,"Recruiting From Scratch
3.9","Atlanta, GA",3.9,Employer Provided Salary:$140K - $250K,4.0,3.6,3.5,3.9,3.9,1 to 50 Employees,2019,"Who is Recruiting from Scratch:
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
Data Engineer - Platform
A Career with our Market Intelligence Team:
Our Market Intelligence team is responsible for developing proprietary research products and providing data and research management services for investment teams to support their pursuit of superior, risk-adjusted returns. We leverage innovative alternative data sources, advanced data analytics and technologies, and deep fundamental research to create high-quality compliant and differentiated research. Backed by the full resources of our company, our sector aligned teams of fundamental researchers, data scientists, data strategists, relationship managers, and data engineers collaborate to solve important research problems in partnership with the Firm’s investment and compliance professionals.

What you’ll do
Platform Engineers build solutions for processing big and unstructured data sets. Our team works closely with portfolio managers and data scientists to understand the potential business value of data sets and ultimately build data processing pipelines around those data sources. In this role, you will:
Develop big data processing pipelines for new data sources containing structured and unstructured data
Build platform infrastructure using Hadoop technologies
Build and support visualization and exploration capabilities around our big data sets
Maintain knowledge of new technology developments and conduct proof of concepts to evaluate new technologies

What’s required
We want you to join us if you have extensive experience or demonstrated interest in big data technologies. Other requirements include:
2+ years of experience in Data Engineering or related field
Commitment to the highest ethical standards
Strong experience in Python Development
Experience with Spark or Scala
Ability to devise novel and innovative solutions to challenges
Knowledge of/experience with graph databases is a plus

We take care of our people
We invest in our people, their careers, their health, and their well-being. We want you to concentrate on success and leave the rest to us. When you work here, we provide:
Fully-paid health care benefits
Generous parental and family leave policies
Mental and physical wellness programs
Tuition assistance
A 401(k) savings program with an employer match and more
Salary Range: $140,000-$250,000 base.",$1 to $5 million (USD),Staffing & Subcontracting,Company - Private,Human Resources & Staffing
Lead Data Engineer,atlanta,"Macy’s
3.4","Johns Creek, GA",3.4,Employer Provided Salary:$121K - $202K,3.2,3.4,3.1,3.2,3.2,10000+ Employees,1858,"Macy's, Inc is building an Enterprise Data & Analytics team to further grow our capabilities in support of our mission to be a data - led, customer centric company. This team will focus on accelerating impact from analytics, coordinating an enterprise-wide roadmap, and ensuring proper data governance and management. As a member of this team, the engineer will help lead the charge to execute on our vision to build profitable lifetime customer relationships by embedding data & analytics at the heart of everything we do.
Position Overview:
The Lead Data Engineer is responsible for development and support of data products on a modern cloud-based data lake, leveraging expertise and knowledge of multiple technologies & data domains to help build a robust, scalable, and reliable data engineering platform.
The Lead Data Engineer is responsible for providing data services for enterprise-grade analytical environments, utilizing automated data pipelines at scale, and streamlining efficient data transformations for priority use cases, be involved hands on in development of the codebase and partner closely with business units and peer technology groups to support analytics execution.
Essential Functions
Solution Design & Implementation:

Work closely with business stakeholders, implement scalable solutions to meet requirements
Follow and improve existing processes and procedures
Lead a pod of data engineers, providing both technical oversight and supporting their growth
Build, maintain and simplify enterprise data pipelines with emphasis on reusability & data quality
Work with Legal and Privacy teams to adhere to data privacy and security requirements

Culture:
Train and mentor fellow engineers on both technical stack and data domain specifics
Establish a pro-active approach to data management, ensuring business stakeholders & platforms can access required data within the SLA window
Drive change management to increase user adoption of enterprise data repositories and leverage standardized data pipelines across use cases
Increase agility in identifying data issues and taking action to remediate

Qualifications
Education/ Experience:

Data engineering experience with:
3+ years of experience in designing and implementing cloud-based data solutions
3+ years of experience integrating with analytics reporting solutions (e.g. Tablaeu, PowerBI)
3+ experience with big data processing technologies such as Hadoop, Spark, etc.
5+ years of experience building & automating ETL data pipelines using enterprise grade tools
5+ years of experience building enterprise-grade data warehouses (either on-prem or on cloud)
8+ years of overall programming experience, including recent experience with Python & SQL
Ability to effectively share technical information, communicate technical issues and solutions to all levels of business stakeholders
Customer-centric and experienced with cross-functional collaboration
Excellent written and verbal communication skills

What we can offer you:

Exciting, challenging problems to solve - you'll never have a boring day at work
A refreshingly fun work environment where you will collaborate with a smart and talented team
Unique freedom to build and lead a team in next gen thinking
A chance to learn and participate in the growth of NYC’s largest retailer

This job description is not all inclusive. Macy’s Inc. reserves the right to amend this job description at any time. Macy's Inc. is an Equal Opportunity Employer, committed to a diverse and inclusive work environment.",$10+ billion (USD),"Department, Clothing & Shoe Stores",Company - Public,Retail & Wholesale
Data Engineer,atlanta,"Aspirent Consulting
4.3","Atlanta, GA",4.3,$85K - $127K (Glassdoor est.),4.1,4.1,4.0,4.2,4.5,51 to 200 Employees,2014,"Looking to reboot your career? Aspirent is transforming the way professional services are delivered by reducing complexity and focusing on outcomes—not only for our clients, but for our employees as well. We've replaced the traditional hierarchies and ladders with a flat and friendly organization that's open, collaborative, and all about facilitating the most direct path to your success.
You'll work on challenging projects with some world's biggest and best companies, learn from our team of seasoned data, digital, and delivery experts, and be encouraged to expand your career horizons through a variety of professional development opportunities. And you'll have the space and support you need to fulfill your personal goals thanks to our flexibility-first culture and generous benefits.
Learn more about how Aspirent makes it easy for you to put your unique talents and ambitions to work for our shared success.

What you will do:
Design and implement data solutions best suited to deliver on our customer needs and use cases — from streaming to data lakes, to analytics, and beyond across a progressively evolving technical stack.
Provide thought leadership by recommending the right technologies and solutions for a given use case, from the application layer to infrastructure.
Possess coding skills (e.g. Python, Java, and Scala) to get move solutions into production while ensuring performance, security, scalability, and robust data integrations.
Work seamlessly across a variety of technical stacks such as Cloudera, Databricks, Snowflake and AWS.
Create and deliver detailed presentations.
Build detailed solution documentation (ex. sequence diagrams, class hierarchies, logical system views, etc.)
What you will bring:
At least 4 years of experience as a Software Engineer, Data Engineer, or Data Analyst
Professional written and verbal communication skills.
Previous consulting experience.
Proven experience as a technical team lead and/or mentorship of other engineers.
Ability to develop end-to-end technical solutions.
Ways to stand out:
Production experience in core data platforms: Snowflake, Databricks, AWS, Azure, GCP, Hadoop, etc.
Hands-on knowledge of Cloud and Distributed Data Storage (HDFS, S3, ADLS, GCS, Kudu, ElasticSearch/Solr, Cassandra or other NoSQL storage systems)
Understanding of Data integration technologies: Spark, Kafka, eventing/streaming, Streamsets, NiFi, AWS Data Migration Services, Azure DataFactory, Google DataProc
Why Aspirent?
We're transforming the way professional services are delivered, by reducing complexity and focusing on outcomes. That's why we make it easy for clients to work with us and easy for employees to excel professionally and personally. We don't let complexity hold anyone back from achieving their goals. We offer:
An award-winning, entrepreneurial work environment that values creativity and prioritizes flexibility
A flat, transparent organization whose leaders are hands-on and always accessible
Competitive comp, excellent benefits, discretionary PTO plus 7 paid Holidays
Continuous, advanced training and certifications
Accelerated learning and professional growth working with top Data and Analytics, Digital Product Development, and Digital Enablement experts
Don't take our word for it: Watch the video to see what our employees have to say about life and work at Aspirent
As an NTT DATA Company, Aspirent is part of top-ten digital consulting and IT services company recognized as one the world's most valuable brands. NTT DATA pushes the boundaries on what's possible to simplify digital transformation for clients and create exciting career paths for employees. The NTT DATA teams numbers 140K+ and spans more than 50 countries and regions across the globe.",$25 to $100 million (USD),Information Technology Support Services,Company - Private,Information Technology
Cloud Data Application Engineer,atlanta,"Graphic Packaging International
3.3","Atlanta, GA",3.3,$71K - $97K (Glassdoor est.),3.2,2.9,2.8,3.4,2.8,10000+ Employees,1995,"POSITION SUMMARY:
The mission of this position is to analyze business issues and to identify and develop solutions to meet the needs. The engineer will formulate and defines objectives based on both business needs and a solid understanding of best practices. This position may also assist in routine maintenance for specific modules in the company’s suite of business applications which will involve understanding of SQLs simple and complex and Stored procedure. This position collaborates with business process owners to foster a positive IT customer relations environment. All the work this position involves will include On-Premise and Cloud platform understanding.

PRIMARY RESPONSIBILITIES are, but not limited to the following:
Support and manage Cloud based implementations.
Strong and demonstrable knowledge of writing and debugging complex SQL , Stored procedures.
Serve as a point of contact for System related escalations.
Act as a liaison between Cloud IT , Business and functional teams.
Support cloud-focused technology initiatives
Motivated problems solver who can identify the source of the problem in data and proactively work to solve it.
Ability to multitask and adapt in a fast paced customer focus environment.
Implement new processes and improve existing processes around data visibility and analysis.
Recommend solution to fix data issues.
Work Independently with little supervision.
Strong Communication skills

JOB REQUIREMENTS:
5 years of experience in software development.
2 years' experience in Azure cloud environment.
2 years' experience with databases like SQL Server, Oracle and/or other relational databases.
Strong Experience with SQL Simple and Complex.
Experience with Visualization tools like Qlik Sense, Power BI etc.
Experience with cloud based data solutions
Knowledge of cloud infrastructure and best practices.
Working Experience on GIT hub
Experience with working in Agile development process.
Experience working with CICD and DevOps
Working knowledge of Python

Educational Requirements:
4-year college degree in general or IT-Related field required. Equivalent work experience considered
Other Required Skills:
Demonstrated perceptual and analytical thinking
Excellent interpersonal communication skills and ability to translate technical information into language non-technical people will understand
Fortitude to demand excellence from self and others
Demonstrate ability to work effectively in a team environment.


Required Skills

Required Experience
At Graphic Packaging International (NYSE: GPK), we produce the box you may have poured your child's cereal from this morning, the microwaveable tray that heated your lunch, the paper cup that held your coffee throughout the day, and the carrier of those bottles of craft beer you may enjoy tonight! We're one of the largest manufacturers of paperboard and paper-based packaging for some of the world's most recognized brands of food, beverage, foodservice, household, personal care and pet care products. Headquartered in Atlanta, Georgia, we are a team of collaborative, innovative, passionate individuals who are committed to providing consumer packaging that makes a world of difference.

With almost 18,000 employees working in more than 70 locations in North and South America, Europe and the Pacific Rim, we strive to be an environmentally responsible leader in our industry and in the communities where we operate. We are committed to workplace diversity and offer compensation and benefits programs that are among the industry's best to reward the talented people who make our company successful.

If this sounds like something you would like to be a part of, we'd love to hear from you. Learn more about us at www.graphicpkg.com.

Inspired Packaging. A World of Difference.

Graphic Packaging is an Equal Opportunity Employer. All candidates will be evaluated on the basis of their qualifications for the job in question. We do not base our employment decision on an employee's or applicant's race, color, religion, age, gender or sex (including pregnancy), national origin, ancestry, marital status, sexual orientation, gender identity, genetic identity, genetic information, disability, veteran/military status or any other basis prohibited by local, state, or federal law. Click here to view the EEO is the Law Poster",$1 to $5 billion (USD),Machinery Manufacturing,Company - Public,Manufacturing
Sr. Lead Data Engineer,atlanta,"Chick-fil-A, Inc.
3.9","Atlanta, GA",3.9,$100K - $148K (Glassdoor est.),3.8,4.0,3.5,3.3,3.6,5001 to 10000 Employees,1946,"Overview:
As a Sr. Lead Data Engineer, you will be responsible for leading and executing complex data engineering project work of in support of multiple products within one-or-more advanced analytics portfolios. The person in this role will work as part of a larger, cross-functional, full-stack execution team charged with designing, building, and deploying advanced analytics products within the portfolios under the stewardship of the Advanced Analytics team within Enterprise Data & Analytics (ED&A).

Sr. Lead Data Engineers typically design and implement necessary data engineering on technically complex projects, focusing on developing solutions to data pipelining, data modeling, and/or Data Ops [MH1] needs. They must be able to quickly develop mastery of the needed subject across any line of business for which they are responsible. They will work under the direction of more senior data engineers if asked to take on the most complex work. Our Sr. Lead Data Engineers typically work with more latitude for action or decisions on projects that are more complex or cross-functional in nature. They may represent EA in external conversations and may assist with the selection or oversight of outside vendor partners. They are expected to influence the project execution of IT and analyst teams.

Successful candidates for this role must have strong analytical and data modeling skills, a deep understanding of database technology and data use within analytic platforms, and they must have strong programming skills with SQL and/or Python. We expect our Sr. Lead Data Engineers to have demonstrated fluency and competency in both the technology language of IT and the analytics language of data scientists and departmental analysts. They should have experience developing and implementing data models for analytic use and a moderate level of experience with cloud database architecture. They will need to be fast learners with a keen eye for detail, systems thinking, and process design. They must be team players who work steadfastly to create impactful change. This is a professional track role.

Our Flexible Future model offers a healthy mix of working in person and virtually, strengthening key elements of the Chick-fil-A culture by fostering collaboration and community.
Responsibilities:
Exhibits wider latitude in aligning business stakeholders, ED&A Program Leads, Portfolio Leads, Data Scientists, and IT teams to translate business logic into scalable data and analytic solutions on complex projects.
Designs and builds new up-stream production-grade data sources for Data Scientists' use in modeling, integrates data from across the business into modeling pipelines, and builds on-line and off-line feature stores to service both model production and model development activities.
Works with Data Scientists to design and implement complex, model-specific feature engineering.
Partners with DTT Deployment Engineers on complex software engineering solutions for delivering data to and from production model pipelines.
Designs and builds modeled data end-user consumption patterns.
Actively participates in the Community of Data Engineers (CODE).
Designs specific tool implementations, understanding both data visualization, ETL, and cloud compute performance requirements and expectations.
Manages any needed maintenance and quality control on data pipelines or data products they have built which are actively in use/production.
Helps design patterns for efficient use of cloud compute resources.
Owns and is accountable for data model and code quality and any relevant documentation.
Implements data governance and master data management principles across specific project execution, including data privacy and data ethics policy requirements.
Performs ad-hoc analysis as necessary to support specific project work.
Drives complex projects to success and enables others to own the impact.
Minimum Qualifications:
Strong analytical and data modeling skills
Deep understanding of database technology
Deep understanding of analytic platform data use
Strong programming skills in SQL and/or Python
Experience developing and implementing data models for analytic use
Moderate experience with cloud database architecture
Fast learner and proven problem solver
Skilled at partnering with cross-functional teams using strong written and verbal communication
Keen eye for system thinking and process design, especially with respect to scalability and automation
Keen eye for detail and thoughtful investigation of data
Has a steadfast focus on creating impactful change
Preferred Qualifications:
Some experience using the AWS big data technology stack
Extensive experience with Alteryx or similar ETL platforms
Extensive experience with Tableau or similar data visualization tools
Moderate experience implementing data governance principles
Some experience with Model Operations tools and processes in any context
Minimum Years of Experience: 5 Travel Requirements: 10% Required Level of Education: Bachelor's Degree Preferred Level of Education: Masters Degree Major/Concentration: MIS, Decision Sciences, Engineering, Business Analytics, Computer Science, or other similar fields",$5 to $10 billion (USD),Restaurants & Cafes,Company - Private,Restaurants & Food Service
"Sr. Data Engineer, Operations Decision Science",atlanta,"Delta
4.3","Atlanta, GA",4.3,-1,-1,-1,-1,-1,-1,10000+ Employees,1928,"United States, Georgia, Atlanta
Ops Control
19-May-2023
Ref #: 20489
How you'll help us Keep Climbing (overview & key responsibilities)
Ops Decision Science team seeks a data engineering analytics leader to take on developing data-driven solutions aimed at continually improving airline performance and decision making.
An appropriate candidate will have technical knowledge of BI systems design, big data architecture and technology landscape, API consumption, ETL/ELT orchestration, business intelligence tools. The candidate should have excellent organizational and communication skills and feel comfortable in a fast-paced environment.
Primary Functions:
Design, implement data engineering solutions (e.g. locate and extract data from a variety of sources for use in reporting, analysis, and statistical modeling to drive continuous improvement)
Define and execute the data engineering roadmap (e.g. establish an operational data lake and a real-time reporting environment for the operations)
Partner with Information Technology to optimize and enhance the database environment for optimal efficiency and best practices
Provide technical leadership to the Delta's business units
Leverage emerging technologies and identify efficient and meaningful ways to disseminate data and analysis in order to satisfy the business needs
Lead complex process improvement and project management engagements for both individual business units and cross-divisional initiatives.
Interface with business unit leaders to develop and maintain internal customer relationships
Practices safety-conscious environment resulting in employee safety and well-being

Benefits and Perks to Help You Keep Climbing
A career at Delta not only gives you a chance to see the world, but we also provide excellent benefits to help you keep climbing along the way!
Competitive salary, industry leading profit sharing and 401(k) with generous direct contribution and company match
Comprehensive health benefits including medical, dental, vision, short/long term disability and life benefits
A detailed wellness plan that recognizes the importance physical, emotional, financial, and social wellbeing
Domestic and International flight privileges


What you need to succeed (minimum qualifications)
5+ years' experience in Data Science, Statistics, Mathematics, Operations Research, or Computer Science
Consistently makes safety and security, of self and others, the priority
Consistently prioritizes safety and security of self, others, and personal data.
Embraces diverse people, thinking, and styles.
Possesses a high school diploma, GED, or high school equivalency.
Is at least 18 years of age and has authorization to work in the United States.
What will give you a competitive edge (preferred qualifications)
Bachelor's degree in Data Science, Statistics, Mathematics, Operations Research, Computer Science, or equivalent combination of education and experience (Master's degree preferred)
Working knowledge of statistical/machine learning tools (e.g. SAS,R, TensorFlow) preferred
Working knowledge of ""Big Data"" solutions such as Hadoop, NoSQL, MapReduce, etc preferred
Working knowledge of API Consumption preferred
Working knowledge with Modern development patterns and platforms (Azure, AWS, GCP, Microservices, Web Services (REST), Containers, Cloud Native)
Strong written, oral communication, and interpersonal skills
Strong project management, organizational, and prioritizations skills
Must be able to interact and collaborate at all levels within Operations Analysis & Performance, OCC, cross-divisional working groups, and outside entities
Must be performing satisfactorily in present position

< Go back",$10+ billion (USD),"Airlines, Airports & Air Transportation",Company - Public,Transportation & Logistics
Federal - Azure Data Engineer,atlanta,"Accenture
4.0","Atlanta, GA",4.0,-1,-1,-1,-1,-1,-1,10000+ Employees,1989,"We are:
Accenture Federal Services, helping our federal clients tackle their toughest challenges while unleashing their fullest potential…and then some. What makes our approach so unique? Operating from the nation’s capital, we expand Cloud adaption by bringing together commercial innovation and leading-edge technologies to deliver an integrated and interactive experience that far exceeds expectations. How? Our passion meets purpose! Through our diverse culture and inclusive thinking, we embrace our employees' ideas taking them from concept to practical solutions. Not to mention, we sleep well at night knowing our work directly impacts and improves the way the world works. We keep our tech smarts sharp by providing abundant training and certification opportunities. Through our diverse culture, workforce, and inclusive thinking, we embrace our employees' ideas, taking them from concept to practical solutions. Are you ready to learn and grow in a career, while making a difference?
You are:
Proud to know Cloud. A cloud enthusiast and ready to roll up your sleeves to tackle any complex, technological, cloud computing challenge that comes your way! From design, planning, management, maintenance, and support, you help keep our clients on Cloud9. What sets you apart? You have a knack for digging deeper (or should we say higher) into the possibilities with cloud. Voted best trendsetter, you are always in-the-know on the latest Cloud dish. Not only are you able to modernize clients’ systems to today, you take it a step further anticipating their tomorrow and beyond. After all, your head is always in the Cloud, because it’s where you thrive! Pun intended.
The work:
Create new pipelines and build reusable components at scale to support reporting & analytics data products
Write complex queries to transform raw data sources into accessible models by coding
Clean, prepare, transform, and optimize data at scale for integration and consumption
Implement data management projects and restructures current web architecture
Solve complex data issues and performs root cause analysis to proactively resolve product issues
Own the data pipeline and supports systems failures

Here’s what you need:
One year of experience working with cloud native technologies (Azure or AWS)
Strong programming and/or scripting experience with back-end languages such as Python, Java, .NET, C# etc.
Experience with developing ETL pipelines in one or more of the following tools: Azure Data factory, Event hubs, Event grid, Azure functions, Data Flow, Hadoop, AWS Glue
Experience with Databricks and/or Spark
Bonus points if you have:
Experience with technologies such as CosmoDB, AzureSQL, Redis, Synapse
Experience with orchestration tool such as Airflow or Oozie
Strong experience with SQL
Experience with Kotlin’
Experience with migrations to major cloud
Knowledge with Public health/health care data (HL7, FHIR, vocabulary, and HHS data standards)
Certification: AWS Certified Solution Architect- Associate, Azure Data Engineer Associate, Databrick Certified Data Engineer Associate
Compensation for roles at Accenture Federal Services varies depending on a wide array of factors including but not limited to the specific office location, role, skill set and level of experience. As required by local law, Accenture Federal Services provides a reasonable range of compensation for roles that may be hired in California, Colorado, New York City or Washington as set forth below and information on benefits offered is here.

Role Location: Range of Starting Pay for role
California: $82,500 - $182,100
Colorado: $73,900 - $196,200
New York City: $85,500 -$198,800
Washington: $85,500 -$198,800

For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement

What We Believe

We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.

Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here

Equal Employment Opportunity Statement

Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Accenture is committed to providing veteran employment opportunities to our service men and women.

For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement.

Requesting An Accommodation

Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.

If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.

Other Employment Statements

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",$10+ billion (USD),Business Consulting,Company - Public,Management & Consulting
"Software Engineer II, Data Platform - Remote",atlanta,"Clari
4.6","Atlanta, GA",4.6,Employer Provided Salary:$108K - $162K,4.4,4.7,4.5,4.3,4.5,501 to 1000 Employees,2012,"Clari’s Revenue platform gives forecasting accuracy and visibility from the sales rep to the board room on revenue performance - helping them spot revenue leak to answer if they will meet, beat, or miss their sales goals. With insights like this, no wonder leading companies worldwide, including Okta, Adobe, Workday, and Zoom use Clari to drive revenue accuracy and precision. We never get tired of our customers singing our praises because it fuels us to help them continue to achieve remarkable. The next generation of revenue excellence is here…are you ready to achieve remarkable with us?

About the Team
The Engineering team at Clari is an Agile shop that practices Scrum across all of our teams. We layer in coordination practices such as Big Room Planning to stay aligned to Clari’s KPIs quarterly across sites and teams. If you love working in an Agile environment that values collaboration and continuous improvement then we can’t wait to meet you.

About the Role
We are looking for talented software engineers who are passionate about building products that customers love to use. You’ll work with truly remarkable colleagues on complex problems at enterprise scale, quality, and reliability. You’ll build a state-of-the-art time series data platform that processes 20M+ workflows a day. You’ll work closely with the product team to design and build a data platform that powers the best-in-class enterprise product suite that’s loved by our customers. The products you build will be used by many of the most well-known companies in the world. Don’t believe us? Hear what our customers have to say

Come join the fluid, dynamic, and growing team to learn, teach, and make a big, measurable impact every day. We work in an open, collaborative environment and seek exceptional developers who enjoy problem-solving and straying outside the routine.

This is a fully remote opportunity and can be worked from any location in the United States.
Responsibilities
Design and build configuration-driven data platform to power Clari ML, AI, and Analytics/Forecasting products
Design and build reusable data integration APIs for the data lake with optimal storage, compute scale, and observability
Build and accelerate our No-Code auto-ETL system to process millions of auto-generated workflows processing billions of records daily
Collaborate on product ideas and experiences to maintain a high bar of operational excellence

Qualifications
Minimum 3 years of Java backend development in one or more of these areas - building data/APIs/Microservices/Cloud integration products
Experience using design patterns and best practices
Experience using AWS or similar cloud technologies
Experience with testing frameworks such as Junit, Mockito, Serenity, or Jbehave
Experience with either relational or non-relational databases
Perks and Benefits @ Clari
Remote-first with opportunities to work and celebrate in person
Medical, dental, vision, short & long-term disability, Life insurance, and EAP
Mental health support provided by Modern Health
Pre-IPO stock options
Well-being and professional development funds
Retirement 401(k) plan
100% paid parental leave, plus fertility and family planning support provided by Maven
Discretionary paid time off, monthly ‘take a break’ days, and Focus Fridays
Focus on culture: Charitable giving match, plus in-person and virtual events

It is Clari’s intent to pay all Clarians competitive wages and salaries that are motivational, fair, and equitable. The goal of Clari’s compensation program is to be transparent, attract potential employees, meet the needs of all current employees and encourage employees to stay and grow at Clari.

Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to specific work location, skill set, depth of experience, education and certifications.

The salary range for this position is $108,000 to $162,000. The compensation package for this position also includes stock options and company-paid benefits, including well-being and professional development stipends.
#LI-Remote #BI-Remote

You’ll often hear our CEO talk about being remarkable. To Clari, remarkable means many things. We believe in providing interesting and meaningful work in a nurturing and inclusive environment. One that is free from discrimination for everyone without regard to race, color, religion, sex, sexual orientation, national origin, age, disability, gender identity, or veteran status. Efforts have to be recognized. Voices have to be heard. And work-life balance has to be baked into the very fiber of the company. We are honored to be recognized by Inc. Magazine and Bay Area News Group as a best place to work for several years running. We’d love to have you join us on our journey to remarkable!

If you feel you don’t meet 100% of the qualifications outlined above, we want you to apply! Clari believes in hiring people, not just skills. If you are passionate about learning and excited about what we are doing, then we want to hear from you.

Clari focuses on culture add, not culture fit. One of our values is One with Customers, and we know we can serve them better when we involve as many different perspectives as possible. Our team is made stronger by what makes you unique, so we hope you’ll bring your whole self to the job.",$100 to $500 million (USD),Software Development,Company - Private,Information Technology
Data Platform Engineer,atlanta,"Acuity Brands
3.6","Conyers, GA",3.6,$73K - $105K (Glassdoor est.),3.4,3.4,3.3,3.4,3.4,10000+ Employees,2001,"Acuity Brands, Inc. (NYSE: AYI) is a market-leading industrial technology company. We use technology to solve problems in spaces and light. Through our two business segments, Acuity Brands Lighting and Lighting Controls (“ABL”) and the Intelligent Spaces Group (“ISG”), we design, manufacture, and bring to market products and services that make the world more brilliant, productive, and connected. We achieve growth through the development of innovative new products and services, including lighting, lighting controls, building management systems, and location-aware applications.
Job Summary

WHY IS ACUITY BRANDS A GREAT PLACE FOR CLOUD DATABASE ENGINEERING?
Our Cloud Database Engineering team is a strategic part of the direction of our company
Our company is a very profitable market leader and provides financial stability
You will work with highly talented, fun, and supportive teams
We believe in a healthy work/life balance
We support continuous development through MS certification programs
Benefits program to meet the needs of you and your family
Environmental, social, and governance (ESG) factors are important, and we are committed to operating our business with high standards of ESG management
Our company culture Lights the way for you to Be Brilliant, Productive and Connected

We are seeking a talented and enthusiastic individual to be a hands-on Data Platform Standard for our Cloud Database Engineering Team as we transform Acuity Brands’ data and analytics platform using the Microsoft Azure Cloud. This position will be responsible for design, develop, test, deploy, maintain, and improve current database solutions. Day to day the data platform standard will apply technical knowledge to create and maintain the data platform components, act as a source of knowledge across the organization, design solutions with security and privacy guidelines, and support application development teams with data-centric applications.
Experience (minimum experience required)
Bachelor’s Degree in Computer Science, MIS, or related technical/analytical field
2 years required in the following:
Experience and understanding of one of the following database platforms: SQL Server, DB2, or Oracle
Strong analytical skills
Data modeling
Excellent written and oral communication skills
Experience with 2 or more of the following:
Monitoring
Performance tuning
Capacity planning
Replication
Data security
Preferred Experience (i.e. industry experience)
Python and/or Power Shell
Azure, AWS, or Google cloud data platforms
ETL processes and performance tuning
Data lake architecture
Scrum/agile tools
We invite you to apply today to join us as We Light the Way to a Brilliant, Productive, and Connected World!

We value diversity and are an equal opportunity employer. All qualified applicants will be considered for employment without regards to race, color, age, gender, sexual orientation, gender identity and expression, ethnicity or national origin, disability, pregnancy, religion, covered veteran status, protected genetic information, or any other characteristic protected by law.

Accommodation for Applicants with Disabilities: As an equal opportunity employer, Acuity Brands is committed to providing reasonable accommodations in its application process for qualified individuals with disabilities and disabled veterans. If you have difficulty using our online system due to a disability and need an accommodation, you may contact us at (770) 922-9000. Please clearly indicate what type of accommodation you are requesting and for what requisition.

Any unsolicited resumes sent to Acuity Brands from a third party, such as an Agency recruiter, including unsolicited resumes sent to an Acuity Brands mailing address, fax machine or email address, directly to Acuity Brands employees, or to Acuity Brands resume database will be considered Acuity Brands property. Acuity Brands will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.

Acuity Brands will consider any candidate for whom an Agency has submitted an unsolicited resume to have been referred by the Agency free of any charges or fees. This includes any Agency that is an approved/engaged vendor, but does not have the appropriate approvals to be engaged on a search.",$1 to $5 billion (USD),Electronics Manufacturing,Company - Public,Manufacturing
Senior Data Analytics Engineer,atlanta,"Papa John's
3.4","Atlanta, GA",3.4,$87K - $119K (Glassdoor est.),3.1,3.1,3.1,2.7,3.1,10000+ Employees,1984,"THIS IS A CORPORATE POSITION
Job Summary
Senior Data Analytics Engineer with Papa John’s International, Inc. (Atlanta, GA)
Duties: Design strategies for enterprise database, data warehouse systems, and multidimensional networks. Set standards for database operations, programming, queries, and security. Create and maintain analytics infrastructure for data warehousing, business intelligence, and data science. Work with functional leads, data analysts, software development engineers, and other technology partners to deliver data, tools, and dashboards. Design and implement secure, scalable, and supportable data platforms and data tools for business intelligence, analytics, and data science. Create ETL and other data integrations from data sources. Design and implement data models in Google BigQuery, relational, and NoSQL databases. Design, implement, and maintain data platform automation with DevOps principles and automation tools. Develop architecture solutions to improve performance Tableau dashboards. Develop frameworks to ensure quality of data provided to end-users. Develop monitoring solutions for data pipelines to timely address production job failures. Telecommuting is permitted, but applicants must live within reasonable commuting distance. Position reports to 788 Circle 75 Parkway, Atlanta, GA 30339.
Requirements:
Requires a Bachelor’s degree in Computer Science, Information Technology, or other closely related field. Requires 5 years of related progressive, post-bachelor’s experience. Must have some experience in each of the following skills: Python; Google BigQuery, Google Storage, Cloud Composer and Dataflow; Google PubSub; SQL; Ansible; Tableau APIs; and Jenkins, Groovy and Shell Scripting.
It is the policy of Papa John’s to provide equal employment opportunities for all applicants and team members without regard to race, color, religion, sex, age, marital status or civil partnership, national or ethnic origin, pregnancy or maternity, veteran status, uniformed service (as defined by 10 U.S.C. §101 (a)(5)), protected disability status, genetic information, sexual orientation, gender identity, gender reassignment, or gender expression, or any other characteristic protected by statute or law.",$1 to $5 billion (USD),Restaurants & Cafes,Company - Public,Restaurants & Food Service
Senior Cloud Data Operations Engineer,atlanta,"Loyal
3.9","Atlanta, GA",3.9,-1,-1,-1,-1,-1,-1,51 to 200 Employees,2015,"Loyal is an organization centered on experience and building a platform that allows consumers to make meaningful decisions when it comes to healthcare. We deeply understand providers, locations, services, appointments, business rules, and moreover, we understand patients - who they are, the preferred method of communication, upcoming appointments, lapsed appointments, outstanding bills, health risks, and more. With this intelligence, our platform fuels highly relevant and personalized experiences across all mediums (website, email, voice…) allowing patients to get healthy, stay healthy, and have a better relationship with the health care provider.
**This is a remote role**
Summary
The Senior Cloud Data Operations Engineer is responsible for delivering Loyal's cloud-based data warehouse. They interface with groups across the organization to ensure we are collecting and storing data in a way that makes it easy to create and consume. They identify best practices for big data management, select the right tooling, create a workable data architecture, and drive an implementation roadmap others can depend on. The Senior Cloud Data Operations Engineer also works closely with our security group to ensure data security and privacy. They also mentor others on the team, providing technical leadership to those they work with.
You will
Create data streams and consolidate data sources into a single cloud-based data warehouse
Architect and catalog data warehouse storage schema
Work with product teams to enable easy data aggregation
Work with data consumers (analysts, data scientists, and AI/ML engineers) to ensure data is easily accessible and consumable
Create and execute a roadmap that meets data storage and availability goals
Ensure data is secure through data analysis, access control, and encryption
You have
Bachelor's degree in computer science, information systems, applied math or related field, or equivalent work experience
Minimum 5 years of experience working with cloud data processing services (AWS, Azure, or GCP).
Minimum 3 year experience with Big Data technologies, such as Databricks, Snowflake, Spark, Hadoop, etc.
Strong experience in creating data architecture and storage schemas required
Significant working knowledge of SQL and other query languages and tools
Significant experience with building relational database systems strongly preferred
Experience with ETL tools a plus
Knowledge of Python preferred
Software development, data analytics, or data science experience is a plus.
Experience working within a software as a service (SaaS) company preferred.
Experience working within a high growth and/or ambiguous environment, with proven experience to be dynamic preferred.
#LI-REMOTE
We know that potential candidates are often less likely to apply to a position if they don't match 100% of the job qualifications. Don't let that be why you miss out on this opportunity! We encourage you to apply if you can demonstrate many of these skills and competencies.
Loyal to our employees
We are a remote-friendly company! We encourage you to apply from anywhere in the United States. We also believe in a work/life balance that fulfills you while you're here and supports you when you're not. We built our benefits package to prove that we're committed to you having everything you need (including a little fun). Here is what we offer full-time employees:
Flexible paid time off, sick and personal days
At least one holiday per month (sometimes, more!)
Full health, dental, and vision insurance - Loyal pays the premium for all employees!
One Time Home Office Setup Stipend For Remote & Hybrid Roles
Monthly Internet Stipend for Remote & Hybrid Roles
Long term & short term disability
401[k] plan
16 Weeks Paid Parental Leave
2 Volunteer days per year
Matching Gift Program
Participation Grant Program
Annual Travel/Team Events up to twice per year (post-COVID)
Our Commitment
We believe that the key to Loyal's success is you. Your unique background, life experience, knowledge, self-expression, and talent make you uniquely you. Who you are, what you have experienced, and how you think inspires us to be innovative and bold.
Loyal is an equal opportunity employer. We hire great people from a wide variety of backgrounds, not just because it's the right thing to do, but because it makes our company stronger. We welcome the unique contributions that you can bring in terms of your education, opinions, culture, ethnicity, race, ancestry, sex, gender identity and expression, national origin, citizenship, marital status, age, languages spoken, veteran status, color, religion, disability, sexual orientation, and beliefs.
We consider qualified applicants regardless of criminal histories, consistent with legal requirements.
Further, consistent with applicable federal and state law, Loyal provides reasonable accommodations when requested by qualified applicants or employees with disabilities, unless doing so would cause an undue hardship. Loyal's policy regarding requests for reasonable accommodation applies to all aspects of employment, including the application process. If you require a reasonable accommodation in connection with the application process, please contact the Talent Acquisition Department at talentacquisition@loyalhealth.com.
E-Verify
This employer participates in E-Verify and will provide the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S. If E-Verify cannot confirm that you are authorized to work, this employer is required to give you written instructions and an opportunity to contact Department of Homeland Security (DHS) or Social Security Administration (SSA) so you can begin to resolve the issue before the employer can take any action against you, including terminating your employment. Employers can only use E-Verify once you have accepted a job offer and completed the I-9 Form.
COVID-19 Vaccinations
Candidates who will be attending in-person conferences, visiting hospitals, and/or visiting or traveling to a third party location who may have their own specific requirements in place may be required to show proof of being fully vaccinated against COVID-19 before attending. Reasonable accommodations will be considered on a case-by-case basis for exemptions to this requirement in accordance with applicable law. If you require a reasonable accommodation, please contact the People Department at people@loyalhealth.com.",$5 to $25 million (USD),Health Care Services & Hospitals,Company - Private,Healthcare
Senior Data Engineer - SFL Scientific,atlanta,"Deloitte
4.1","Atlanta, GA",4.1,$96K - $143K (Glassdoor est.),4.3,4.0,3.8,3.8,3.3,10000+ Employees,1850,"Senior Data Engineer, Specialist Senior - SFL Scientific

The SFL Scientific, a Deloitte Business practice brings together several key capabilities to architect integrated programs that transform our clients' businesses, including Strategic Growth Transformation, Transformation Strategy & Design, Technology Strategy & Business Transformation, and AI & Data Strategy.

Professionals will serve as trusted advisors to our clients, working with them to make clear data-driven choices about where to play and how to win - ultimately driving growth and enterprise value.

We are hiring a Senior Data Engineer to support the design and develop solutions for various organizations looking to implement tools, software, and processes that support machine learning and AI initiatives across healthcare, life sciences, manufacturing, energy, and other sectors.

Work you'll Do:

As a Senior Data Engineer, you'll work cross-functionally with data scientists, machine learning engineers, project managers, and industry experts to develop robust AI infrastructure and deployment services for our novel machine learning applications. Key to this role is the ability to demonstrate both traditional data engineering expertise, leveraging cloud/enterprise/open-source solutions, and constructing IT infrastructure for organizations across a wide variety of industries.

In our consultative approach, we are committed to providing the best technical solutions for each client and solution. Our engineering team leverages emerging technologies and best practices across data security, documentation, cloud services and engineering architecture to create solutions and products that address complex issues and business problems faced by global organizations. Some of our novel use cases include cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, and renewable energy.

Join us to expand your technical career through the lens of consulting and work on many novel projects and use cases to expand your data engineering & AI skills!
Work with clients to design, develop, and deploy new architectures for machine learning applications such as ELT pipelines, database & data warehouse solutions, compute infrastructure, cloud services, and containerized solutions
Leverage skills in modern data architecture, cloud engineering, data transformation, and management of structured and unstructured data sources
Support and enhance data architecture, and data pipelines, and define database schemas (Graph DB, SQL, NoSQL) to support algorithm scalability and deployment based on agile business priorities and technology initiatives
Participate in architectural discussions to ensure solutions are designed for successful deployment, security, and high availability in the cloud or on-prem
Adopt and maintain engineering best practices in data security, retention, and sensitivity
Present to key stakeholders, including architecture findings and design of infrastructure, hardware, software, cloud, and deployment, etc.
Mentor, motivate and coach junior members on technical best practices and inspire professional development

The Team

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel, and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Basic Qualifications:
Bachelor's degree in a STEM field or equivalent experience (Computer Science, Engineering, Physics etc.); Master's degree preferred
2+ years in data engineering, data architecting or cloud engineering, while building highly scalable and secure solutions
1+ years leading project/ client engagement teams in the execution of data engineering solutions
Expert in languages such as Python, SQL, Shell scripting, Bash, & Linux commands
Expert in logging, monitoring, and data documentation best practices
Extensive hands-on experience with source version control (e.g., Git), containerization (e.g., Docker), container orchestration (e.g., Kubernetes), and supporting libraries
Experience with distributed computing frameworks (e.g., Spark, Dask), cloud platforms (e.g. AWS, Azure), multi-cloud service providers (e.g., Snowflake, Dataricks) & on-prem alternatives (e.g. MinIO)
Experience with workflow and data management solutions such as Fivetran, Airflow, Kafka, Glue, etc.
Experience designing data architectures and SQL, NoSQL & Graph databases
Strong analytical and problem-solving skills with the ability to develop novel and efficient solutions
Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve
Live within commuting distance to one of Deloitte's consulting offices
Limited immigration sponsorship may be available.

Preferred Qualifications:
Master's or Ph.D. degree in Computer Science, Information Technology, or related STEM field
AWS/Azure Certifications (AWS/Azure Certified: SysOps Administrator, DevOps Engineer, Solutions Architect)
Demonstrated experience launching AI/ML solutions into production environments, such as into cloud or HPC/GPU environments

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy23

#SFL23

#LI-WW1",$10+ billion (USD),Accounting & Tax,Company - Private,Financial Services
"Data Engineer, Senior",atlanta,"Booz Allen Hamilton
4.2","Atlanta, GA",4.2,Employer Provided Salary:$73K - $166K,4.1,4.3,3.9,3.9,4.3,10000+ Employees,1914,"The Opportunity:
Ever-expanding technology like IoT, machine learning, and artificial intelligence means that there’s more structured and unstructured data available today than ever before. As a data engineer, you know that organizing big data can yield pivotal insights when it’s gathered from disparate sources. We need an experienced data engineer like you to help our clients find answers in their big data to impact important missions—from fraud detection to cancer research to national intelligence.
As a big data engineer at Booz Allen, you’ll implement data engineering activities on some of the most mission-driven projects in the industry. You’ll deploy and develop pipelines and platforms that organize and make disparate data meaningful. Here, you’ll work with and guide a multi-disciplinary team of analysts, data engineers, developers, and data consumers in a fast-paced, Agile environment. You’ll use your experience in analytical exploration and data examination while you manage the assessment, design, building, and maintenance of scalable platforms for your clients. Work with us to use big data for good.
Join us. The world can’t wait.
You Have:
5+ years of experience working with Azure, AWS, or GCP
3+ years of experience with operationalizing data and advanced analytics solutions
2+ years of experience with building and operationalizing data pipelines, including ETL and ELT in Azure, AWS, or GCP
1+ year of experience designing or building complex data solutions using Azure services within the past 2 years
Experience with analytics and visualization tools, including Power BI, Tableau, or RShiny
Experience with SQL, Python, Scala or R
Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements
Bachelor’s degree
Nice If You Have:
Experience building production grade solutions using Azure Data factory, Azure Databricks, or Azure DataLake
Knowledge of Enterprise Data Management
Knowledge of CI and CD
Knowledge of Agile and Scrum processes
Master's degree in CS, Engineering, Machine Learning, or Data Science
Vetting:
Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client.
Create Your Career:
Grow With Us
Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.
A Place Where You Belong
Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time.
Support Your Well-Being
Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.
Your Candidate Journey
At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.
Compensation
At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,000.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
Work Model
Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.
If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.
EEO Commitment
We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",$5 to $10 billion (USD),Business Consulting,Company - Public,Management & Consulting
Data Center Applications Engineer,atlanta,"Alogent
3.6","Peachtree Corners, GA",3.6,$69K - $97K (Glassdoor est.),3.4,3.7,3.3,3.2,3.7,201 to 500 Employees,1995,"Alogent is the market leader in providing solutions for deposit automation to some of the largest banks in the world. With over 20 years’ experience in providing the technology, support, and expertise to overcome business challenges in premier financial institutions everywhere such as reliability, efficiency, and quality. Our partnership-based approach to working through business issues has been recognized by our clients and partners through maintaining long-term relationships as their business needs evolve. Alogent continues to forge ahead through the creation of specialized technologies and services that utilize imaging and automation to achieve proven results. Our goal is to be the premier financial technology partner to institutions everywhere.

The company is headquartered in Peachtree Corners, GA. Additional offices are located in Henderson, NV, and Carlsbad, CA, with regional teams across the US and internationally.

Job Overview:
The Data Center Applications Engineer works with the Data Center team, Development, Support and other internal Alogent Departments assisting them in resolving application and operational issues regarding Alogent’s proprietary software in our hosted environment. Excellent communication, analytical, troubleshooting, and organizational skills are crucial, in addition to a desire to understand how our solutions drive value and improve the growth of the Alogent Data Center and its operations.

This position is hybrid working from our Headquarters in Peachtree Corners, GA, or can be remote within the United States.

Important Note: Applicants for employment in the United States must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Alogent.

Responsibilities:
Assists with the maintenance, support, and upgrades of existing Alogent software applications and systems within our Alogent Cloud Environment. This includes Deploying application to pre-production and production environments, during schedule maintenance windows.
Works closely with the Alogent Cloud Data Center Infrastructure team to provide necessary application deployment requirements necessary to properly host Alogent applications
Manages application and data access for internal implementation and support teams
Assists with coordinating and communicating upgrades, enhancements, and changes within Alogent’s cloud environment
Partners with Development, Data Center and Product teams to troubleshoot and develop enhanced processes around business critical applications
Develops best practices for application implementations within Alogent’s Data Center
Supports Alogent Customer onboarding into the Data Center environment
Develops and documents functioning specs detailing Alogent application upgrade process
Creates/Documents application support knowledgebase and/or training articles
Approves onboarding application changes in Alogent Cloud Environment
Identifies, documents and reports potential issues with Alogent Application Interfaces and data import/export methodologies
Pre-performs Alogent Cloud Application testing prior to upgrading Production
Works closely with Development and Product to identify, evaluate and recommend application modifications to Alogent’s solutions
Reports and tracks any defects associated with Alogent Hosted Products pertaining to Alogent Cloud
Works Alogent Cloud internal ticketing system requests

The above statements are intended only to describe the general nature of the job, and should not be construed as an all-inclusive list of position responsibilities.

Knowledge, Skills, and Abilities:
At least 2 years of experience in a technical proprietary application support role
At least 2 years of experience in a Data Center
Provide great customer service under pressure
Experience with Microsoft Windows Desktop and Server Operating Systems
Experience with MS SQL Server, IIS, Active Directory
Experience with .NET Applications
Experience with WCF Windows Services and IIS Applications
Experience with Monitoring tools such as Splunk and Wireshark
Excellent written and verbal communication skills
Excellent troubleshooting and problem-solving skills
Strong communication, organization, prioritization, and written skills
Networking knowledge – LAN/WAN/Router/Firewall a plus
CITRIX XenApp/XenDesktop, VMWare Horizon experience a plus
Financial services IT/IS experience a plus
Platform performance monitoring / evaluation a plus
Technical degree or equivalent experience
Must be able to work weekends, nights and on Call Shifts when necessary
Ability to travel if required

Working Conditions:
Must be able to work with possible distractions in the work environment
May require sitting, standing or being on phone calls for long periods of time
Must be able to work weekend, nights and on call shifts

Benefits:
Competitive benefits including medical, dental, vision, life, disability, Employee Assistance Program, Flexible Spending Account, Group Accident, Critical Illness, and Identity Protection Program
Excellent 401(k) plan with company match
Paid time off (PTO) and Holidays
Wellness programs
Monthly Eat, Learn, Grow session on various topics
A knowledgeable, high-achieving, experienced, and fun team
A diverse work atmosphere

Employee Polygraph Protection Act
Equal Employment Opportunity
Family and Medical Leave Act

Alogent is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected Veteran status, or any other characteristic protected by federal, state or local laws.

Notice To Third-Party Agencies:
Alogent does not accept unsolicited resumes from recruiters or agencies. Any staffing/employment agency, person or entity that submits an unsolicited resume to this site does so with the understanding that the applicant's resume will become the property of Alogent. Alogent will have the right to hire that applicant at its discretion and without any fee owed to the submitting staffing/employment agency, person, or entity.",Unknown / Non-Applicable,Enterprise Software & Network Solutions,Company - Private,Information Technology
AWS Data Engineer (Hybrid),atlanta,Cox powered by Atrium,"Atlanta, GA",-1,Employer Provided Salary:$60.00 - $68.00 Per Hour,-1,-1,-1,-1,-1,-1,-1,"Minimum Qualifications:
Bachelor’s degree or equivalent work experience
A minimum of 3+ years’ experience in Microsoft Windows/ SQL Server Technologies, .Net development, AWS Administration.
Experience working on 24x7 environments oriented towards a zero downtime target.
Working knowledge or previous administration of SQL 2016-SQL 2022 and Windows Server 2012+ preferred.
Ability to work with minimal direction, in a team environment.
Performance tuning for AWS/DataLake systems.
Some Experience with SQL in virtual, physical and cloud-based environments.
Experience with Athena and data modeling for cloud technologies.
Proven ability to quickly learn and implement new technologies.
Experience with Administration, Security/Identity Management and Terraforms in AWS.
Preferred Qualifications:
Experience with SentryOne, a plus.
Ability to code Powershell commands and maintain code in GitHub, a plus.
Some Experience with Metabase and Collibra, a plus.
Experience with ETL in AWS, a plus.
Pay Range:
$60-$68/hr
Requisition Disclaimer:
This job posting is for a temporary role as an employee of Atrium on assignment at Cox. The individual selected for this role will be offered the role as an employee of Atrium; compensation, medical benefits, fringe benefits and other terms and conditions of employment shall be presented by Atrium upon offer. The pay rate range provided is a reasonable estimate of the anticipated compensation range for this job at the time of posting. The actual pay rate will be based on a number of factors, including skills, competencies, experience, location and/or being pursued and other job-related factors permitted by law. In addition, this role will be eligible for overtime pay, in accordance with federal and state requirements

By applying for this position you agree to the Atrium Terms and Conditions. Agreeing to these terms, includes permission to use the email address and mobile phone number you provide during the application process or throughout the duration of your prospective or actual employees to notify you of job openings, profiles, articles, news, and other employment-related information, as well as to notify you of special promotions or additional products and services offered by us or our affiliates and partners (collectively, “Atrium Alerts”). Atrium Alerts may be sent by email, phone or text message. Your personal information will be safely stored in our database. Atrium does not sell your personal information to third parties. Text message and data rates may apply. To OPT OUT of text messaging or to modify your communication preferences for Atrium Alerts at any time, please contact us at privacyadministrator@atriumstaff.com.

If you do not agree with the Atrium Terms and Conditions, you can still complete your application for this position by emailing your resume to our team at coxrecruit@atriumworks.com. Please include the job title in the subject of your email.

As a woman-owned firm, Atrium values diversity. We are an equal opportunity employer and will consider all applications without regard to race, sex, age, color, religion, national origin, veteran status, disability, genetic information or any other characteristic protected by law. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.
Posting: #zip",-1,-1,-1,-1
Lead Data Science Engineer - Remote US,atlanta,"Siemens
4.1","Peachtree Corners, GA",4.1,$76K - $109K (Glassdoor est.),3.8,4.1,3.7,3.8,4.1,10000+ Employees,1847,"Lead Data Science Engineer – Remote US

Are you looking for a company that empowers talent?
Here at Siemens, we take pride in enabling sustainable progress through technology. We do this through empowering customers by combining the real and digital worlds. Improving how we live, work, and move today and for the next generation!
From Day 1, you are empowered to create an impact with your full potential and creativity to make a difference for tomorrow.
We truly have an inclusive and diverse team culture where you can be yourself.
Our extensive global presence offers a diverse range of career opportunities across various industries, nations, and job domains, empowering our workforce to continuously enhance their skills and stay competitive.
Create a better tomorrow with us!

About EV Charging-As-A-Service (EV CaaS)
EV CaaS is redefining the EV charging market for private and public fleets, including autonomous driving fleets, transit bus agencies, and municipal and private fleets. We are building the next level of charging as a service, taking complete ownership and control of the charging infrastructure, the scheduling of the vehicles, the cloud platform, and the utility meter – in order to provide the highest availability and resilience in the market. In this way, we will accelerate the adoption of electric-powered fleets by optimizing the delivery of power and making refueling seamless and efficient. By taking control of the utility meter, and optimizing EV charge rate and vehicle process flow, EV CaaS provides the lowest cost of electric fueling possible.
In this role, you will be leading the effort to build and deliver innovative data services and solutions for our EV fleet management customers. You'll work with a team of talented engineers to build solutions that transform multiple data sources into critical insights, driving operational efficiency and strategy for our customers. From ideation to deployment, you'll be leading the effort to shape the future of EV fleet management.

As the Lead Data Science Engineer, you will:
Be a technical leader, mentor, collaborator, and champion of best practices
Architect, design, develop, and deploy solutions for predictive analytics and ongoing algorithm improvements
Develop real-time analytics based on multiple available data sources
Implement solutions using a range of internal and external data sources related to the performance of electric vehicles
Lead the implementation of solutions using machine learning, feature engineering, and heuristic algorithms
Measure performance of all solutions, and provide ongoing improvements based on real-world data
Develop predictive event monitoring and notification based on identified conditions
Influence and make decisions on tools and the technology roadmap to meet our analytics and reporting requirements
Be a valued member of an autonomous, cross-functional agile team
Mentor junior developers to help them improve their coding practices
Investigate and resolve system functionality and performance issues
You will make impact if you have the following qualifications:
Bachelor’s degree in computer science, engineering, or a related technical field
5+ years of experience with Python development
Development expertise with one or more machine learning toolkits, such as TensorFlow or Scikit-learn.
Experience developing and deploying machine learning models in a production environment
Experience in quantitative analysis and performance improvement of machine learning models using real-world ground truth data
Previous work that involved multiple data sources requiring analysis, cleansing, and feature engineering
Ability to lead analytical projects to derive critical business insights and identify future innovation in the industry
Experience with CI/CD processes for building and deploying high-quality services
Ability to collaborate across multiple development teams to ensure performance, quality, and a positive user experience
Strong analytical, planning, problem-solving, and decision-making skills
Ability to analyze requirements and define the design and tools necessary to build maintainable solutions
Preferred Qualifications:
Master’s degree with specialization in data science, analytics, machine learning, or similar
2+ years of team lead experience
Experience developing solutions with streaming data using PySpark or similar tools
Experience with vehicle navigation, including map attributes, routing, and/or traffic
Where permitted by applicable law, Siemens may require employees to be fully vaccinated against COVID-19 based on job requirements, and in accordance with accommodation based on legally protected reasons.
Benefits and Perks:
Competitive salary based on qualifications
Health, dental, and vision plans with options
Matching 401(k)
Competitive paid time off plan, holidays, and floating holidays
Paid parental leave
Wellness Program
Flexible Time off or Generous paid – time off depending on position level
Click here to learn more about our extensive benefits offerings.

#LI-REMOTE
#LI-ACR



Equal Employment Opportunity Statement
Siemens is an Equal Opportunity and Affirmative Action Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to their race, color, creed, religion, national origin, citizenship status, ancestry, sex, age, physical or mental disability unrelated to ability, marital status, family responsibilities, pregnancy, genetic information, sexual orientation, gender expression, gender identity, transgender, sex stereotyping, order of protection status, protected veteran or military status, or an unfavorable discharge from military service, and other categories protected by federal, state or local law.

EEO is the Law
Applicants and employees are protected under Federal law from discrimination. To learn more, Click here.

Pay Transparency Non-Discrimination Provision
Siemens follows Executive Order 11246, including the Pay Transparency Nondiscrimination Provision. To learn more, Click here.

California Privacy Notice
California residents have the right to receive additional notices about their personal information. To learn more, click here.",$10+ billion (USD),Electronics Manufacturing,Company - Public,Manufacturing
Data Center Applications Engineer,atlanta,"AccuSystems
2.8","Peachtree Corners, GA",2.8,$67K - $96K (Glassdoor est.),1.0,2.6,2.6,3.0,4.4,1 to 50 Employees,Company - Public,"Alogent is the market leader in providing solutions for deposit automation to some of the largest banks in the world. With over 20 years’ experience in providing the technology, support, and expertise to overcome business challenges in premier financial institutions everywhere such as reliability, efficiency, and quality. Our partnership-based approach to working through business issues has been recognized by our clients and partners through maintaining long-term relationships as their business needs evolve. Alogent continues to forge ahead through the creation of specialized technologies and services that utilize imaging and automation to achieve proven results. Our goal is to be the premier financial technology partner to institutions everywhere.
The company is headquartered in Peachtree Corners, GA. Additional offices are located in Henderson, NV, and Carlsbad, CA, with regional teams across the US and internationally.
Job Overview :
The Data Center Applications Engineer works with the Data Center team, Development, Support and other internal Alogent Departments assisting them in resolving application and operational issues regarding Alogent’s proprietary software in our hosted environment. Excellent communication, analytical, troubleshooting, and organizational skills are crucial, in addition to a desire to understand how our solutions drive value and improve the growth of the Alogent Data Center and its operations.
This position is hybrid working from our Headquarters in Peachtree Corners, GA, or can be remote within the United States.

*Important Note: Applicants for employment in the United States must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Alogent.


Responsibilities :
Assists with the maintenance, support, and upgrades of existing Alogent software applications and systems within our Alogent Cloud Environment. This includes Deploying application to pre-production and production environments, during schedule maintenance windows.
Works closely with the Alogent Cloud Data Center Infrastructure team to provide necessary application deployment requirements necessary to properly host Alogent applications
Manages application and data access for internal implementation and support teams
Assists with coordinating and communicating upgrades, enhancements, and changes within Alogent’s cloud environment
Partners with Development, Data Center and Product teams to troubleshoot and develop enhanced processes around business critical applications
Develops best practices for application implementations within Alogent’s Data Center
Supports Alogent Customer onboarding into the Data Center environment
Develops and documents functioning specs detailing Alogent application upgrade process
Creates/Documents application support knowledgebase and/or training articles
Approves onboarding application changes in Alogent Cloud Environment
Identifies, documents and reports potential issues with Alogent Application Interfaces and data import/export methodologies
Pre-performs Alogent Cloud Application testing prior to upgrading Production
Works closely with Development and Product to identify, evaluate and recommend application modifications to Alogent’s solutions
Reports and tracks any defects associated with Alogent Hosted Products pertaining to Alogent Cloud
Works Alogent Cloud internal ticketing system requests
The above statements are intended only to describe the general nature of the job, and should not be construed as an all-inclusive list of position responsibilities.
Knowledge, Skills, and Abilities :
At least 2 years of experience in a technical proprietary application support role
At least 2 years of experience in a Data Center
Provide great customer service under pressure
Experience with Microsoft Windows Desktop and Server Operating Systems
Experience with MS SQL Server, IIS, Active Directory
Experience with .NET Applications
Experience with WCF Windows Services and IIS Applications
Experience with Monitoring tools such as Splunk and Wireshark
Excellent written and verbal communication skills
Excellent troubleshooting and problem-solving skills
Strong communication, organization, prioritization, and written skills
Networking knowledge – LAN/WAN/Router/Firewall a plus
CITRIX XenApp/XenDesktop, VMWare Horizon experience a plus
Financial services IT/IS experience a plus
Platform performance monitoring / evaluation a plus
Technical degree or equivalent experience
Must be able to work weekends, nights and on Call Shifts when necessary
Ability to travel if required
Working Conditions :
Must be able to work with possible distractions in the work environment
May require sitting, standing or being on phone calls for long periods of time
Must be able to work weekend, nights and on call shifts
Benefits:
Competitive benefits including medical, dental, vision, life, disability, Employee Assistance Program, Flexible Spending Account, Group Accident, Critical Illness, and Identity Protection Program
Excellent 401(k) plan with company match
Paid time off (PTO) and Holidays
Wellness programs
Monthly Eat, Learn, Grow session on various topics
A knowledgeable, high-achieving, experienced, and fun team
A diverse work atmosphere



Alogent is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected Veteran status, or any other characteristic protected by federal, state or local laws.

Notice To Third-Party Agencies:
Alogent does not accept unsolicited resumes from recruiters or agencies. Any staffing/employment agency, person or entity that submits an unsolicited resume to this site does so with the understanding that the applicant's resume will become the property of Alogent. Alogent will have the right to hire that applicant at its discretion and without any fee owed to the submitting staffing/employment agency, person, or entity.",-1,-1,Unknown / Non-Applicable,-1
"Sr Lead Data Engineer, Analytics R&D",atlanta,"Chick-fil-A, Inc.
3.9","Atlanta, GA",3.9,$109K - $144K (Glassdoor est.),3.8,4.0,3.5,3.3,3.6,5001 to 10000 Employees,1946,"Overview:
As a Senior Lead Data Engineer for Future Capabilities, you will be responsible for leading and executing complex data engineering in support of multiple R&D experiments as part of team developing analytics R&D within Enterprise Data & Analytics (ED&A) Alignment group.

Our team's mission is to provide Chick-fil-A with best practices, research, and the development of leading-edge analytic capabilities that prepare Chick-fil-A for the future. The Sr. Lead Data Engineer for R&D will be responsible for identifying, tracking, learning, selecting, and applying trending and emerging data engineering technologies. Initially, R&D will focus on more imminently needed data and analytic capabilities such as large language analytics, geo-location analytics, IoT, and digital simulation of physical spaces which will require data engineering skills and knowledge of complex unstructured data. You can expect to split time between researching future data engineering technologies that will support analytics and performing data engineering R&D experiments.

Senior Lead Data Engineers typically design and implement necessary data engineering on technically complex projects, focusing on developing solutions to data pipelining, data modeling, and/or Data Ops needs, partnering with data engineers in DTT (Digital Transformation and Technologies). They will work under the direction of more senior data engineers if asked to take on the most complex work. Our Senior Lead Data Engineers typically work with more latitude for action or decisions on projects that are more complex or cross-functional in nature. They may represent ED&A in external conversations and may assist with the selection or oversight of outside vendor partners. They are expected to influence the project execution of IT and analyst teams.

Successful candidates for this role must have strong analytical and data modeling skills, a deep understanding of database technologies, including structured and unstructured, and real-time streaming data, and data uses within analytic platforms, and they must have strong programming skills with SQL and Python. We expect our Senior Lead Data Engineers to have demonstrated fluency and competency in both the technology language of IT and the analytics language of data scientists and departmental analysts. They should have experience developing and implementing data models for analytic use, and a moderate level of experience with cloud database architecture. They must be able to quickly develop mastery of the needed subject across any line of business for which they are responsible. They must be team players who work steadfastly to create impactful change. This is a professional track role.

Our Flexible Future model offers a healthy mix of working in person and virtually, strengthening key elements of the Chick-fil-A culture by fostering collaboration and community.
Responsibilities:
Designing, deploying, automating, and partnering with IT to support the tooling and software/hardware dependencies required to conduct proofs-of-concept (POCs) and experiments in a sandbox environment.
Design and build new up-stream production-grade data sources for Data Scientists' use in modeling, integrate data from across the business into modeling pipelines, and builds on-line and off-line feature stores to service both model production and model development activities.
Exhibit wide latitude in aligning business stakeholders, Enterprise Data & Analytics Program and Portfolio Leads, Data Scientists, and IT teams to translate business logic into scalable data and analytic solutions on complex projects.
Provide hands-on design and development expertise and technical abilities to deliver quality IoT solutions
Participate in the testing process including developing and executing R&D experiments.
Work with Data Scientists to design and implement complex, model-specific feature engineering.
Partner with IT Deployment Engineers on complex software engineering solutions for delivering data to and from production model pipelines.
Design and build modeled data end-user consumption patterns.
Actively participate in the Community of Data Engineers (CODE).
Design specific tool implementations, understanding both data visualization, ETL, and cloud compute performance requirements and expectations.
Manage any needed maintenance and quality control on data pipeline or data products they have built which are actively in use/production.
Help design patterns for efficient use of cloud compute resources.
Own and be accountable for data model and code quality and any relevant documentation necessary for IoT design and development work and to support existing IoT integrations.
Implement data governance and master data management principles across specific project execution, including data privacy and data ethics policy requirements.
Perform ad-hoc analysis as necessary to support specific project work.
Drive complex projects to success and enable others to own the impact.
Minimum Qualifications:
Strong analytical and data modeling skills
Moderate experience with cloud database architecture and technology stack, such as AWS, GCP and Azure
Deep understanding of database technology
Deep understanding of analytic platform data use
Strong programming skills in SQL and/or Python
Experience developing and implementing data models for analytic use
Fast learner and proven problem solver
Skilled at partnering with cross-functional teams using strong written and verbal communication
Keen eye for system thinking and process design, especially with respect to scalability and automation
Be curious, embrace uncertainty and be comfortable with failure while exploring innovative ideas
Commitment and adherence to the highest ethical standards
Keen eye for detail and thoughtful investigation of data
Has a steadfast focus on creating impactful change
Preferred Qualifications:
Extensive experience using the AWS big data technology stack
8 years experience
Extensive experience with Alteryx or similar ETL platforms
Extensive experience with Tableau or similar data visualization tools
Moderate experience implementing data governance principles
Some experience with Model Operations tools and processes in any context
Minimum Years of Experience: 5 Travel Requirements: 10% Required Level of Education: Bachelor's Degree Preferred Level of Education: Masters Degree Major/Concentration: MIS, Decision Sciences, Engineering, Business Analytics, Computer Science, or other similar fields",$5 to $10 billion (USD),Restaurants & Cafes,Company - Private,Restaurants & Food Service
Software Engineer - Data Engineer,atlanta,"Pluto7
3.7","Atlanta, GA",3.7,$90K - $121K (Glassdoor est.),3.8,3.3,3.6,3.6,3.5,51 to 200 Employees,2015,"In Data Engineer role, you will build systems that collect, manage, and convert raw data into usable information for data scientists to interpret and visualize. You will be working on Google Cloud Platform services, writing complex SQL queries, create data models, data pipelines and work on data ingestion framework.
Join Pluto7

Pluto7 is a tech-enabled solutions company and has expertise in Machine Learning, AI, Data Analytics services on Cloud Platform.

At Pluto7, our core business model is to deliver data driven platforms and solutions to enterprises globally, helping them solve their customer experience and supply chain challenges and making their supply chains intelligent and resilient.

Pluto7’s approach, solutions and transformation framework has been recognized by leading industry bodies and Cloud Providers such as Gartner and Google cloud respectively. We specialize in the Supply chain domain igniting transformation within Retail, CPG, Manufacturing, Hitech and Healthcare industries. Our customers span across the globe with complex, diverse supply chains.

Our mission is to build an intelligent supply chain platform using technology, data and Artificial Intelligence.

There is a sea of opportunity in the Supply Chain Tech space. Don't miss the boat! Apply here to begin the most exciting voyage!

Role: Data Engineer
Experience: 1-4 years
Work location: USA and India

Must have skills :

Hands-on experience in database systems (Structured and Unstructured).
Programming in Python, R, SAS.
Overall knowledge and exposure on how to architect solutions in cloud platforms like GCP, AWS, Microsoft Azure.
Develop and maintain scalable data pipelines, with a focus on writing clean, fault-tolerant code.
Hands-on experience in data model design, developing Big Query/SQL (any variant) stored.
Optimize data structures for efficient querying of those systems.
Collaborate with internal and external data sources to ensure integrations are accurate, scalable and maintainable.
Collaborate with business intelligence/analytics teams on data mart optimizations, query tuning and database design.
Execute proof of concepts to assess strategic opportunities and future data extraction and integration capabilities..
Data extraction, Data cleansing and transformation. ETL, ERP data Extraction skill plus. SAP Hana Analytics Migrations is a Plus.
Strong knowledge on REST APIs, Http Server, MVC architecture.
Knowledge on continuous integration/continuous deployment.

Preferred but not required :

Data Engineering with Real Time Streaming data for Machine learning experience
Certification on any cloud platform is preferred.
Experience of data migration from On-Prem to Cloud environment.
Exceptional analytical, quantitative, problem-solving, and critical thinking skills
Excellent verbal and written communication skills

Why pluto7 :

We invest in the personal and professional growth of every employee because we believe growth leads to both business impact and personal fulfillment.
An opportunity to join an experienced and ambitious team that is passionate about solving customers' needs and loves coming to work every day.
A culture that encourages and promotes professional growth and development with continuous learning.
Competitive salary, equity and benefits including health insurance and performance recognition.
Flexible working environment.
Global reach with multiple locations and a diverse group of talented individuals and customers and presence in the heart of Silicon Valley both in US & India.

Follow us on:

LinkedIn Twitter Facebook Instagram Youtube",Unknown / Non-Applicable,Enterprise Software & Network Solutions,Company - Private,Information Technology
Sr.Big Data Engineer,atlanta,Srichi,"Roswell, GA",-1,$78K - $114K (Glassdoor est.),-1,-1,-1,-1,-1,51 to 200 Employees,Company - Private,"Job ID: SR20160055
Location: Various, Duration: 6 months
Job Description
We are looking for an experienced Sr.Big Data Engineer who will play a key role in designing, building and supporting the enterprise Business Intelligence architecture including Data Warehouse and Reporting Solutions, which enable us to make business decisions.
The Sr. Big Data Engineer will work to create and document standards for internal reporting that will be utilized company-wide. This role will also maintain the reporting infrastructure by administering report security, report backups and source control.
Skills
5+ years experience in Data Warehouse systems and Business Intelligence development
3+ Years experience designing and building big data infrastructure from the ground up
Ability to work in an agile development environment a plus
Big Data Ecosystems:
Hadoop
MapReduce
Scripting Languages:
Python
PHP
Comfortable working in a fast-paced technical or engineering environmen",-1,-1,Unknown / Non-Applicable,-1
Federal - Cloud Data Engineer,atlanta,"Accenture
4.0","Atlanta, GA",4.0,-1,-1,-1,-1,-1,-1,10000+ Employees,1989,"We are:
Accenture Federal Services, helping our federal clients tackle their toughest challenges while unleashing their fullest potential…and then some. What makes our approach so unique? Operating from the nation’s capital, we bring together commercial innovation and leading-edge technologies to deliver an integrated and interactive experience that far exceeds expectations. How? Our passion meets purpose! Through our diverse culture and inclusive thinking, we embrace our employees' ideas taking them from concept to practical solutions. Not to mention, we sleep well at night knowing our work directly impacts and improves the way the world works. We keep our tech smarts sharp by providing abundant training and certification opportunities. Are you ready to learn and grow in a career, while making a difference?
You are:
A Data Engineering pro—someone who thrives in a team setting where you can use your creative and analytical prowess to obliterate problems. You’re passionate about digital technology, and you take pride in making a tangible difference. Complex issues don’t faze you thanks to your razor-sharp critical thinking skills. Working in an information systems environment makes you more than happy. As part of our AI & Technology group, you will lead cloud technology innovation for our clients through robust delivery of world-class data platforms. There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing cloud data landscape.
The work:
Develop and drive automated solutions. You help build the infrastructure to answer questions with data, using software engineering best practices, data management fundamentals, data storage principles, and recent advances in distributed systems.
Solve challenging data integration problems utilizing optimal ETL patterns, frameworks, query techniques, and sourcing from structured and unstructured data sources.
Ensure best practices by checking code for accuracy, testability, efficiency, and style guidelines
Come grow your career in Technology at Accenture!

Job Qualifications
Job Qualifications:
Experience with SQL, data modeling, and building ETL pipelines
Knowledge of data management fundamentals and data storage principles
Experience in coding and automating processes
Cloud Data Services experience through certification, education, or hands-on experience
US Citizenship required No Dual Citizens
Bonus Points:
Data Warehousing
Object-oriented languages,
Schema design
Compensation for roles at Accenture Federal Services varies depending on a wide array of factors including but not limited to the specific office location, role, skill set and level of experience. As required by local law, Accenture Federal Services provides a reasonable range of compensation for roles that may be hired in California, Colorado, New York City or Washington as set forth below and information on benefits offered is here.

Role Location: Range of Starting Pay for role
California: $73,900- $198,800
Colorado: $73,900- $171,700
New York City: $85,500- $198,800
Washington: $78,600- $182,800
Important information
An active security clearance or the ability to obtain one may be required for this role.

What We Believe

We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.

Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here

Equal Employment Opportunity Statement

Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Accenture is committed to providing veteran employment opportunities to our service men and women.

For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement.

Requesting An Accommodation

Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.

If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.

Other Employment Statements

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",$10+ billion (USD),Business Consulting,Company - Public,Management & Consulting
Senior Data Engineer,atlanta,"Cognira
4.3","Atlanta, GA",4.3,$104K - $151K (Glassdoor est.),4.4,4.4,4.2,4.1,4.0,51 to 200 Employees,2015,"About us:
At Cognira, we strongly believe that people are the biggest asset of our company.
Our hand-picked team consists of passionate, collaborative, and forward-thinking individuals from all over the globe.
Our industry-leading PromoAI Solution leverages data science and AI to effectively manage the entire end-to-end promotion lifecycle in a single tool, allowing retailers to effectively plan, optimize, and analyze all types of promotions.
For the last three years in a row, Cognira has been recognized as one of the fastest-growing companies in North America. We are proud to have a growing team of domain experts and data scientists, as well as a culture that fosters strong and long-lasting relationships with our clients.

Are you ready to grow with us?
To find out more about Cognira, please visit our website at www.cognira.com

About this role
Cognira is seeking a motivated and passionate Senior Data Engineer to join our fast-growing development teams. We are leveraging the latest cloud-native technologies and data science techniques to design and deploy scalable SaaS solutions for retailers.

What you will do
Create innovative, scalable, and fault-tolerant solutions
Design configurable and reusable components for a multi-tenant environment
Work closely with project and product management, data scientists, and QA in a fast-paced team environment
Investigate and resolve technical and performance issues
Experiment, fail-fast, and learn, as you build skills and experience
Ensure high quality with test automation

We would love to hear from you if you have
You have experience with Java, Scala, Python, and other programming languages
You have experience with scalable and resilient microservice orchestration with Kubernetes, Docker, and Helm
You are conversant in asynchronous programming techniques
You are familiar with database design techniques in a distributed NoSQL cloud environment
You are familiar with Apache Spark and big data analytics
You are aware of data science tools and techniques, including Tensorflow and Keras
You are conversant in agile team development using tools such as Git, Jenkins, Jira, and more
You have excellent communication and presentation skills

Perks
In addition to joining us on our journey to build a state-of-the-art, AI-enabled software we also get a ton of perks!

You get the choice to work on a Mac or a PC.
Casual dress code, social events, and after-works.
Flexible, diverse work environment.
Respectful, innovative team.
But it’s not all about the fun. You get a competitive salary and a progressive bonus while getting startup experience at a company with an awesome culture.
You get 21 days of PTO, and major national holidays.",Unknown / Non-Applicable,Enterprise Software & Network Solutions,Company - Private,Information Technology
Lead Software Engineer (AWS/Big Data),atlanta,"JPMorgan Chase Bank, N.A.
3.8","Atlanta, GA",3.8,$99K - $137K (Glassdoor est.),3.6,3.7,3.4,3.7,3.5,10000+ Employees,1799,"We have an exciting and rewarding opportunity for you to take your software engineering career to the next level within Cloud FinOps.

Job Summary

Our team is building out a set of solutions that will become the Firm's golden source for cloud cost and efficiency management. As a member of Cloud Financial Management Engineering, you will be:
Designing, building and delivering solutions that help application teams manage their cloud spend and optimize their operational cost efficiency
Iterating, maintaining and supporting these solutions
Learning new technologies so you can contribute to all elements of our stack

Job responsibilities
Executes software solutions, design, development, and technical troubleshooting with ability to think beyond routine or conventional approaches to build solutions or break down technical problems
Creates secure and high-quality production code and maintains algorithms that run synchronously with appropriate systems
Produces architecture and design artifacts for complex applications while being accountable for ensuring design constraints are met by software code development
Gathers, analyzes, synthesizes, and develops visualizations and reporting from large, diverse data sets in service of continuous improvement of software applications and systems
Proactively identifies hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture
Contributes to software engineering communities of practice and events that explore new and emerging technologies
Adds to team culture of diversity, equity, inclusion, and respect

Required qualifications, capabilities, and skills
Formal training or certification on software engineering concepts and 4+ years applied experience
Hands-on practical experience in data ingestion using Python or Java
Proficient in data transformation and EMR pipelines built on AWS (S3, Redshift, Athena, Glue)
Experience in developing, debugging, and maintaining code in a large corporate environment with one or more modern programming languages and database querying languages
Solid understanding of agile methodologies such as CI/CD, Applicant Resiliency, and Security
Demonstrated knowledge of software applications and technical processes within cloud

Preferred qualifications, capabilities, and skills
Experience in cloud billing
Web application development with HTML5 frameworks like React and Services frameworks like Spring Boot (Java 11+)
AWS Developer and/or Solutions Architect certification
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.
The health and safety of our colleagues, candidates, clients and communities has been a top priority in light of the COVID-19 pandemic. JPMorgan Chase was awarded the ""WELL Health-Safety Rating"" for all of our 6,200 locations globally based on our operational policies, maintenance protocols, stakeholder engagement and emergency plans to address a post-COVID-19 environment.
As a part of our commitment to health and safety, we have implemented various COVID-related health and safety requirements for our workforce. Employees are expected to follow the Firm's current COVID-19 or other infectious disease health and safety requirements, including local requirements. Requirements include sharing information including your vaccine card in the firm's vaccine record tool, and may include mask wearing. Requirements may change in the future with the evolving public health landscape. JPMorgan Chase will consider accommodation requests as required by applicable law.

We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, discretionary incentive compensation which may be awarded in recognition of individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.
Equal Opportunity Employer/Disability/Veterans",$10+ billion (USD),Banking & Lending,Company - Public,Financial Services
Data Engineer,atlanta,"MerchantE
3.5","Alpharetta, GA",3.5,$80K - $119K (Glassdoor est.),3.6,3.9,3.4,4.2,3.9,201 to 500 Employees,2000,"Who Are We?
MerchantE is an innovative, technology-focused company providing a full-service platform to support the payment processing needs for merchants of all sizes, including small business retail shops, B2B wholesalers, and global eCommerce enterprises. We partner with financial institutions, software developers, independent sales organizations, and agents to bring our solutions to market.
Why Join Us?
We're growing and we're looking for collaborative, innovative, and hard-working individuals to grow with us! We offer a modern and inspiring work environment where your ideas and contributions are valued. Come experience, first-hand, the impact of your contributions.
The Opportunity:
As we are embarking on our journey to a modern architecture on the cloud, we are looking for talented engineers to join us to build our future. You will get an opportunity to work on challenging problems in a high-volume and mission critical environment. You will be building data pipelines that support serverless data warehouses solving data issues that support a variety of merchants.
Your Responsibilities will require you to:
Build data pipelines to build state-of-the art data platform to support millions of daily transaction volume.
Build serverless data lakes utilizing programming languages like Java, Scala, Python and Open-Source RDBMS and NoSQL databases, and Cloud based data warehousing services such as Redshift and Snowflake.
Use tools like Kafka to stream real time data.
Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies.
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, mentoring other members of the engineering community.
Collaborate with digital product managers and deliver robust cloud-based solutions that drive powerful experiences to help drive small business in the world.
Conduct reviews with other team members to make sure code is rigorously designed, elegantly coded and effectively tuned for performance.
Drive automated CI/CD release pipelines.
Qualifications
Bachelor's Degree in Computer Science or related technical field.
2+ years of experience in SQL application development
(Internship experience does not apply)
Experience working on real-time data and streaming applications.
Preferred Qualifications:
Master's Degree in Computer Science or related technical field.
1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
1+ years of experience in application development, specifically Java
1+ years of experience with Distributed data/computing tools (Kinesis, MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)
1+ year experience working on real-time data and streaming applications.
1+ years of experience with NoSQL implementation (DynamoDB, Mongo, Cassandra)
1+ years of data warehousing experience (Redshift or Snowflake)
1+ years of experience with UNIX/Linux including basic commands and shell scripting.
1+ years of experience with Agile engineering practices
#LI-KB1
MerchantE is an Equal Opportunity Employer committed to a diverse workforce.",$100 to $500 million (USD),Financial Transaction Processing,Company - Private,Financial Services
Senior Data Analytics Engineer,atlanta,"Papa John's
3.4","Atlanta, GA",3.4,$87K - $119K (Glassdoor est.),3.1,3.1,3.1,2.7,3.1,10000+ Employees,1984,"THIS IS A CORPORATE POSITION
Job Summary
Senior Data Analytics Engineer with Papa John’s International, Inc. (Atlanta, GA)
Duties: Design strategies for enterprise database, data warehouse systems, and multidimensional networks. Set standards for database operations, programming, queries, and security. Create and maintain analytics infrastructure for data warehousing, business intelligence, and data science. Work with functional leads, data analysts, software development engineers, and other technology partners to deliver data, tools, and dashboards. Design and implement secure, scalable, and supportable data platforms and data tools for business intelligence, analytics, and data science. Create ETL and other data integrations from data sources. Design and implement data models in Google BigQuery, relational, and NoSQL databases. Design, implement, and maintain data platform automation with DevOps principles and automation tools. Develop architecture solutions to improve performance Tableau dashboards. Develop frameworks to ensure quality of data provided to end-users. Develop monitoring solutions for data pipelines to timely address production job failures. Telecommuting is permitted, but applicants must live within reasonable commuting distance. Position reports to 788 Circle 75 Parkway, Atlanta, GA 30339.
Requirements:
Requires a Bachelor’s degree in Computer Science, Information Technology, or other closely related field. Requires 5 years of related progressive, post-bachelor’s experience. Must have some experience in each of the following skills: Python; Google BigQuery, Google Storage, Cloud Composer and Dataflow; Google PubSub; SQL; Ansible; Tableau APIs; and Jenkins, Groovy and Shell Scripting.
It is the policy of Papa John’s to provide equal employment opportunities for all applicants and team members without regard to race, color, religion, sex, age, marital status or civil partnership, national or ethnic origin, pregnancy or maternity, veteran status, uniformed service (as defined by 10 U.S.C. §101 (a)(5)), protected disability status, genetic information, sexual orientation, gender identity, gender reassignment, or gender expression, or any other characteristic protected by statute or law.",$1 to $5 billion (USD),Restaurants & Cafes,Company - Public,Restaurants & Food Service
Senior Data Engineer - SFL Scientific,atlanta,"Deloitte
4.1","Atlanta, GA",4.1,$96K - $143K (Glassdoor est.),4.3,4.0,3.8,3.8,3.3,10000+ Employees,1850,"Senior Data Engineer, Specialist Senior - SFL Scientific

The SFL Scientific, a Deloitte Business practice brings together several key capabilities to architect integrated programs that transform our clients' businesses, including Strategic Growth Transformation, Transformation Strategy & Design, Technology Strategy & Business Transformation, and AI & Data Strategy.

Professionals will serve as trusted advisors to our clients, working with them to make clear data-driven choices about where to play and how to win - ultimately driving growth and enterprise value.

We are hiring a Senior Data Engineer to support the design and develop solutions for various organizations looking to implement tools, software, and processes that support machine learning and AI initiatives across healthcare, life sciences, manufacturing, energy, and other sectors.

Work you'll Do:

As a Senior Data Engineer, you'll work cross-functionally with data scientists, machine learning engineers, project managers, and industry experts to develop robust AI infrastructure and deployment services for our novel machine learning applications. Key to this role is the ability to demonstrate both traditional data engineering expertise, leveraging cloud/enterprise/open-source solutions, and constructing IT infrastructure for organizations across a wide variety of industries.

In our consultative approach, we are committed to providing the best technical solutions for each client and solution. Our engineering team leverages emerging technologies and best practices across data security, documentation, cloud services and engineering architecture to create solutions and products that address complex issues and business problems faced by global organizations. Some of our novel use cases include cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, and renewable energy.

Join us to expand your technical career through the lens of consulting and work on many novel projects and use cases to expand your data engineering & AI skills!
Work with clients to design, develop, and deploy new architectures for machine learning applications such as ELT pipelines, database & data warehouse solutions, compute infrastructure, cloud services, and containerized solutions
Leverage skills in modern data architecture, cloud engineering, data transformation, and management of structured and unstructured data sources
Support and enhance data architecture, and data pipelines, and define database schemas (Graph DB, SQL, NoSQL) to support algorithm scalability and deployment based on agile business priorities and technology initiatives
Participate in architectural discussions to ensure solutions are designed for successful deployment, security, and high availability in the cloud or on-prem
Adopt and maintain engineering best practices in data security, retention, and sensitivity
Present to key stakeholders, including architecture findings and design of infrastructure, hardware, software, cloud, and deployment, etc.
Mentor, motivate and coach junior members on technical best practices and inspire professional development

The Team

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel, and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Basic Qualifications:
Bachelor's degree in a STEM field or equivalent experience (Computer Science, Engineering, Physics etc.); Master's degree preferred
2+ years in data engineering, data architecting or cloud engineering, while building highly scalable and secure solutions
1+ years leading project/ client engagement teams in the execution of data engineering solutions
Expert in languages such as Python, SQL, Shell scripting, Bash, & Linux commands
Expert in logging, monitoring, and data documentation best practices
Extensive hands-on experience with source version control (e.g., Git), containerization (e.g., Docker), container orchestration (e.g., Kubernetes), and supporting libraries
Experience with distributed computing frameworks (e.g., Spark, Dask), cloud platforms (e.g. AWS, Azure), multi-cloud service providers (e.g., Snowflake, Dataricks) & on-prem alternatives (e.g. MinIO)
Experience with workflow and data management solutions such as Fivetran, Airflow, Kafka, Glue, etc.
Experience designing data architectures and SQL, NoSQL & Graph databases
Strong analytical and problem-solving skills with the ability to develop novel and efficient solutions
Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve
Live within commuting distance to one of Deloitte's consulting offices
Limited immigration sponsorship may be available.

Preferred Qualifications:
Master's or Ph.D. degree in Computer Science, Information Technology, or related STEM field
AWS/Azure Certifications (AWS/Azure Certified: SysOps Administrator, DevOps Engineer, Solutions Architect)
Demonstrated experience launching AI/ML solutions into production environments, such as into cloud or HPC/GPU environments

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy23

#SFL23

#LI-WW1",$10+ billion (USD),Accounting & Tax,Company - Private,Financial Services
AWS Data Engineer (Hybrid),atlanta,Cox powered by Atrium,"Atlanta, GA",-1,Employer Provided Salary:$60.00 - $68.00 Per Hour,-1,-1,-1,-1,-1,-1,-1,"Minimum Qualifications:
Bachelor’s degree or equivalent work experience
A minimum of 3+ years’ experience in Microsoft Windows/ SQL Server Technologies, .Net development, AWS Administration.
Experience working on 24x7 environments oriented towards a zero downtime target.
Working knowledge or previous administration of SQL 2016-SQL 2022 and Windows Server 2012+ preferred.
Ability to work with minimal direction, in a team environment.
Performance tuning for AWS/DataLake systems.
Some Experience with SQL in virtual, physical and cloud-based environments.
Experience with Athena and data modeling for cloud technologies.
Proven ability to quickly learn and implement new technologies.
Experience with Administration, Security/Identity Management and Terraforms in AWS.
Preferred Qualifications:
Experience with SentryOne, a plus.
Ability to code Powershell commands and maintain code in GitHub, a plus.
Some Experience with Metabase and Collibra, a plus.
Experience with ETL in AWS, a plus.
Pay Range:
$60-$68/hr
Requisition Disclaimer:
This job posting is for a temporary role as an employee of Atrium on assignment at Cox. The individual selected for this role will be offered the role as an employee of Atrium; compensation, medical benefits, fringe benefits and other terms and conditions of employment shall be presented by Atrium upon offer. The pay rate range provided is a reasonable estimate of the anticipated compensation range for this job at the time of posting. The actual pay rate will be based on a number of factors, including skills, competencies, experience, location and/or being pursued and other job-related factors permitted by law. In addition, this role will be eligible for overtime pay, in accordance with federal and state requirements

By applying for this position you agree to the Atrium Terms and Conditions. Agreeing to these terms, includes permission to use the email address and mobile phone number you provide during the application process or throughout the duration of your prospective or actual employees to notify you of job openings, profiles, articles, news, and other employment-related information, as well as to notify you of special promotions or additional products and services offered by us or our affiliates and partners (collectively, “Atrium Alerts”). Atrium Alerts may be sent by email, phone or text message. Your personal information will be safely stored in our database. Atrium does not sell your personal information to third parties. Text message and data rates may apply. To OPT OUT of text messaging or to modify your communication preferences for Atrium Alerts at any time, please contact us at privacyadministrator@atriumstaff.com.

If you do not agree with the Atrium Terms and Conditions, you can still complete your application for this position by emailing your resume to our team at coxrecruit@atriumworks.com. Please include the job title in the subject of your email.

As a woman-owned firm, Atrium values diversity. We are an equal opportunity employer and will consider all applications without regard to race, sex, age, color, religion, national origin, veteran status, disability, genetic information or any other characteristic protected by law. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.
Posting: #zip",-1,-1,-1,-1
"Sr. Data Engineer, Operations Decision Science",atlanta,"Delta
4.3","Atlanta, GA",4.3,-1,-1,-1,-1,-1,-1,10000+ Employees,1928,"United States, Georgia, Atlanta
Ops Control
19-May-2023
Ref #: 20489
How you'll help us Keep Climbing (overview & key responsibilities)
Ops Decision Science team seeks a data engineering analytics leader to take on developing data-driven solutions aimed at continually improving airline performance and decision making.
An appropriate candidate will have technical knowledge of BI systems design, big data architecture and technology landscape, API consumption, ETL/ELT orchestration, business intelligence tools. The candidate should have excellent organizational and communication skills and feel comfortable in a fast-paced environment.
Primary Functions:
Design, implement data engineering solutions (e.g. locate and extract data from a variety of sources for use in reporting, analysis, and statistical modeling to drive continuous improvement)
Define and execute the data engineering roadmap (e.g. establish an operational data lake and a real-time reporting environment for the operations)
Partner with Information Technology to optimize and enhance the database environment for optimal efficiency and best practices
Provide technical leadership to the Delta's business units
Leverage emerging technologies and identify efficient and meaningful ways to disseminate data and analysis in order to satisfy the business needs
Lead complex process improvement and project management engagements for both individual business units and cross-divisional initiatives.
Interface with business unit leaders to develop and maintain internal customer relationships
Practices safety-conscious environment resulting in employee safety and well-being

Benefits and Perks to Help You Keep Climbing
A career at Delta not only gives you a chance to see the world, but we also provide excellent benefits to help you keep climbing along the way!
Competitive salary, industry leading profit sharing and 401(k) with generous direct contribution and company match
Comprehensive health benefits including medical, dental, vision, short/long term disability and life benefits
A detailed wellness plan that recognizes the importance physical, emotional, financial, and social wellbeing
Domestic and International flight privileges


What you need to succeed (minimum qualifications)
5+ years' experience in Data Science, Statistics, Mathematics, Operations Research, or Computer Science
Consistently makes safety and security, of self and others, the priority
Consistently prioritizes safety and security of self, others, and personal data.
Embraces diverse people, thinking, and styles.
Possesses a high school diploma, GED, or high school equivalency.
Is at least 18 years of age and has authorization to work in the United States.
What will give you a competitive edge (preferred qualifications)
Bachelor's degree in Data Science, Statistics, Mathematics, Operations Research, Computer Science, or equivalent combination of education and experience (Master's degree preferred)
Working knowledge of statistical/machine learning tools (e.g. SAS,R, TensorFlow) preferred
Working knowledge of ""Big Data"" solutions such as Hadoop, NoSQL, MapReduce, etc preferred
Working knowledge of API Consumption preferred
Working knowledge with Modern development patterns and platforms (Azure, AWS, GCP, Microservices, Web Services (REST), Containers, Cloud Native)
Strong written, oral communication, and interpersonal skills
Strong project management, organizational, and prioritizations skills
Must be able to interact and collaborate at all levels within Operations Analysis & Performance, OCC, cross-divisional working groups, and outside entities
Must be performing satisfactorily in present position

< Go back",$10+ billion (USD),"Airlines, Airports & Air Transportation",Company - Public,Transportation & Logistics
Software Engineer- Big Data,atlanta,"State Farm
3.6","Dunwoody, GA",3.6,$87K - $131K (Glassdoor est.),3.5,3.6,3.2,3.4,3.5,10000+ Employees,1922,"Overview:
Do you crave innovation and want to work for a company that is the BEST at what they do in the industry? Does the opportunity to work remote and maintaining a work life balance appeal to you? Then we have the perfect job for you! We are seeking software engineers who push the envelope and strive to create the best product possible. This position will allow you to utilize different technologies, languages, and frameworks to drive solutions while working on inclusive teams that foster diversity of thought. You will be provided opportunities via in house training programs for upskilling to support your development and career goals!
Check out what our Software Engineers have to say about working at State Farm: https://youtu.be/1t5y2PHDypI
Responsibilities:
Looking for something that is pushing the envelope at State Farm and moving Enterprise Technology to the next level? If so, the Claims Data Marketplace (CDM) product may be your answer!
CDM is building out the next generation of a data warehouse in the cloud called ‘Marketplace’. The focus is on migrating Claim’s analytic data and consumers to the cloud. Consumers of this data include Data Scientists, Power Users and BI Reporting to name a few. The future will also include the integration with the Enterprise Marketplace, Unstructured data and other consumers wanting to integrate Claim’s data.
We work closely with the Claims Business and Data Science teams to enable analytic initiatives using the AWS technology stack. Qualified candidates should be high performers, able to work on multiple priorities with a strong desire to learn and grow.
The person filling this position will be responsible for working with consumers of the Claims analytic data to determine their data requirements and building the data pipeline for aggregated domains of data. They will also work closely with other team members on ETL activities associated with data modeling and data design, and ingestion of the data into AWS redshift for consumption.
Qualifications:
Required Skills:
Solution development and deployment on AWS
Experience with various software development tooling and techniques, (e.g., GIT, CI/CD, data pipelines)
Python development experience
Experience with AWS commonly used services (i.e. S3, Lambda, SNS, Glue, Terraform)
Preferred Skills:
Data movement experience (i.e. ETL)
Java
Claims Data Domain knowledge
AWS QuickSight
Join State Farm!
As a Fortune 50 company, we hire the best employees to serve our customers, making us a leader in the insurance and financial services industry. State Farm embraces diversity and inclusion to ensure a workforce that is engaged, builds on the strengths and talents of all associates, and creates a Good Neighbor culture.
We offer competitive benefits and pay with the potential for an annual financial award based on both individual and enterprise performance. Our employees have an opportunity to participate in volunteer events within the community and engage in a learning culture. We offer programs to assist with tuition reimbursement, professional designations, employee development, wellness initiatives, and more!
Visit our Careers page for more information on our benefits, locations and the process of joining the State Farm team!
HYBRID: Qualified candidates (in or near hub locations listed below) should plan to spend time working from home and some time working in the office as part of our hybrid work environment.
HUB LOCATIONS: Dunwoody, GA or Bloomington, IL
SPONSORSHIP: Applicants are required to be eligible to lawfully work in the U.S. immediately; employer will not sponsor applicants for U.S. work authorization (e.g. H-1B visa) for this opportunity
#LI-BS1
SFARM
#LI-Hybrid",$10+ billion (USD),Insurance Carriers,Company - Private,Insurance
Lead Data Science Engineer - Remote US,atlanta,"Siemens
4.1","Peachtree Corners, GA",4.1,$76K - $109K (Glassdoor est.),3.8,4.1,3.7,3.8,4.1,10000+ Employees,1847,"Lead Data Science Engineer – Remote US

Are you looking for a company that empowers talent?
Here at Siemens, we take pride in enabling sustainable progress through technology. We do this through empowering customers by combining the real and digital worlds. Improving how we live, work, and move today and for the next generation!
From Day 1, you are empowered to create an impact with your full potential and creativity to make a difference for tomorrow.
We truly have an inclusive and diverse team culture where you can be yourself.
Our extensive global presence offers a diverse range of career opportunities across various industries, nations, and job domains, empowering our workforce to continuously enhance their skills and stay competitive.
Create a better tomorrow with us!

About EV Charging-As-A-Service (EV CaaS)
EV CaaS is redefining the EV charging market for private and public fleets, including autonomous driving fleets, transit bus agencies, and municipal and private fleets. We are building the next level of charging as a service, taking complete ownership and control of the charging infrastructure, the scheduling of the vehicles, the cloud platform, and the utility meter – in order to provide the highest availability and resilience in the market. In this way, we will accelerate the adoption of electric-powered fleets by optimizing the delivery of power and making refueling seamless and efficient. By taking control of the utility meter, and optimizing EV charge rate and vehicle process flow, EV CaaS provides the lowest cost of electric fueling possible.
In this role, you will be leading the effort to build and deliver innovative data services and solutions for our EV fleet management customers. You'll work with a team of talented engineers to build solutions that transform multiple data sources into critical insights, driving operational efficiency and strategy for our customers. From ideation to deployment, you'll be leading the effort to shape the future of EV fleet management.

As the Lead Data Science Engineer, you will:
Be a technical leader, mentor, collaborator, and champion of best practices
Architect, design, develop, and deploy solutions for predictive analytics and ongoing algorithm improvements
Develop real-time analytics based on multiple available data sources
Implement solutions using a range of internal and external data sources related to the performance of electric vehicles
Lead the implementation of solutions using machine learning, feature engineering, and heuristic algorithms
Measure performance of all solutions, and provide ongoing improvements based on real-world data
Develop predictive event monitoring and notification based on identified conditions
Influence and make decisions on tools and the technology roadmap to meet our analytics and reporting requirements
Be a valued member of an autonomous, cross-functional agile team
Mentor junior developers to help them improve their coding practices
Investigate and resolve system functionality and performance issues
You will make impact if you have the following qualifications:
Bachelor’s degree in computer science, engineering, or a related technical field
5+ years of experience with Python development
Development expertise with one or more machine learning toolkits, such as TensorFlow or Scikit-learn.
Experience developing and deploying machine learning models in a production environment
Experience in quantitative analysis and performance improvement of machine learning models using real-world ground truth data
Previous work that involved multiple data sources requiring analysis, cleansing, and feature engineering
Ability to lead analytical projects to derive critical business insights and identify future innovation in the industry
Experience with CI/CD processes for building and deploying high-quality services
Ability to collaborate across multiple development teams to ensure performance, quality, and a positive user experience
Strong analytical, planning, problem-solving, and decision-making skills
Ability to analyze requirements and define the design and tools necessary to build maintainable solutions
Preferred Qualifications:
Master’s degree with specialization in data science, analytics, machine learning, or similar
2+ years of team lead experience
Experience developing solutions with streaming data using PySpark or similar tools
Experience with vehicle navigation, including map attributes, routing, and/or traffic
Where permitted by applicable law, Siemens may require employees to be fully vaccinated against COVID-19 based on job requirements, and in accordance with accommodation based on legally protected reasons.
Benefits and Perks:
Competitive salary based on qualifications
Health, dental, and vision plans with options
Matching 401(k)
Competitive paid time off plan, holidays, and floating holidays
Paid parental leave
Wellness Program
Flexible Time off or Generous paid – time off depending on position level
Click here to learn more about our extensive benefits offerings.

#LI-REMOTE
#LI-ACR



Equal Employment Opportunity Statement
Siemens is an Equal Opportunity and Affirmative Action Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to their race, color, creed, religion, national origin, citizenship status, ancestry, sex, age, physical or mental disability unrelated to ability, marital status, family responsibilities, pregnancy, genetic information, sexual orientation, gender expression, gender identity, transgender, sex stereotyping, order of protection status, protected veteran or military status, or an unfavorable discharge from military service, and other categories protected by federal, state or local law.

EEO is the Law
Applicants and employees are protected under Federal law from discrimination. To learn more, Click here.

Pay Transparency Non-Discrimination Provision
Siemens follows Executive Order 11246, including the Pay Transparency Nondiscrimination Provision. To learn more, Click here.

California Privacy Notice
California residents have the right to receive additional notices about their personal information. To learn more, click here.",$10+ billion (USD),Electronics Manufacturing,Company - Public,Manufacturing
Software Engineer - Data Engineer,atlanta,"Pluto7
3.7","Atlanta, GA",3.7,$90K - $121K (Glassdoor est.),3.8,3.3,3.6,3.6,3.5,51 to 200 Employees,2015,"In Data Engineer role, you will build systems that collect, manage, and convert raw data into usable information for data scientists to interpret and visualize. You will be working on Google Cloud Platform services, writing complex SQL queries, create data models, data pipelines and work on data ingestion framework.
Join Pluto7

Pluto7 is a tech-enabled solutions company and has expertise in Machine Learning, AI, Data Analytics services on Cloud Platform.

At Pluto7, our core business model is to deliver data driven platforms and solutions to enterprises globally, helping them solve their customer experience and supply chain challenges and making their supply chains intelligent and resilient.

Pluto7’s approach, solutions and transformation framework has been recognized by leading industry bodies and Cloud Providers such as Gartner and Google cloud respectively. We specialize in the Supply chain domain igniting transformation within Retail, CPG, Manufacturing, Hitech and Healthcare industries. Our customers span across the globe with complex, diverse supply chains.

Our mission is to build an intelligent supply chain platform using technology, data and Artificial Intelligence.

There is a sea of opportunity in the Supply Chain Tech space. Don't miss the boat! Apply here to begin the most exciting voyage!

Role: Data Engineer
Experience: 1-4 years
Work location: USA and India

Must have skills :

Hands-on experience in database systems (Structured and Unstructured).
Programming in Python, R, SAS.
Overall knowledge and exposure on how to architect solutions in cloud platforms like GCP, AWS, Microsoft Azure.
Develop and maintain scalable data pipelines, with a focus on writing clean, fault-tolerant code.
Hands-on experience in data model design, developing Big Query/SQL (any variant) stored.
Optimize data structures for efficient querying of those systems.
Collaborate with internal and external data sources to ensure integrations are accurate, scalable and maintainable.
Collaborate with business intelligence/analytics teams on data mart optimizations, query tuning and database design.
Execute proof of concepts to assess strategic opportunities and future data extraction and integration capabilities..
Data extraction, Data cleansing and transformation. ETL, ERP data Extraction skill plus. SAP Hana Analytics Migrations is a Plus.
Strong knowledge on REST APIs, Http Server, MVC architecture.
Knowledge on continuous integration/continuous deployment.

Preferred but not required :

Data Engineering with Real Time Streaming data for Machine learning experience
Certification on any cloud platform is preferred.
Experience of data migration from On-Prem to Cloud environment.
Exceptional analytical, quantitative, problem-solving, and critical thinking skills
Excellent verbal and written communication skills

Why pluto7 :

We invest in the personal and professional growth of every employee because we believe growth leads to both business impact and personal fulfillment.
An opportunity to join an experienced and ambitious team that is passionate about solving customers' needs and loves coming to work every day.
A culture that encourages and promotes professional growth and development with continuous learning.
Competitive salary, equity and benefits including health insurance and performance recognition.
Flexible working environment.
Global reach with multiple locations and a diverse group of talented individuals and customers and presence in the heart of Silicon Valley both in US & India.

Follow us on:

LinkedIn Twitter Facebook Instagram Youtube",Unknown / Non-Applicable,Enterprise Software & Network Solutions,Company - Private,Information Technology
Data Engineer Only W2 (no C2C),atlanta,"Infinity Quest
3.9","Atlanta, GA",3.9,Employer Provided Salary:$60.00 - $65.00 Per Hour,3.9,3.8,3.7,3.6,3.6,201 to 500 Employees,2006,"Hi
Position: Data Engineer
Location: Remote
JD
At least 3 years of Data Engineer experience is required preferably in a cloud Environment.
You should have at least 4 years of coding experience in python/java/ Scala and open source packages with at least 2 years of experience with Databases(SQL/NOSQL etc).
Experience with large scale Distributed databases like redshift/Snowflake is a big Plus.
You should have Experience with different aspects of data systems including database design, data modeling, performance optimization, SQL etc.
Some Experience with building data pipelines and Orchestration(Airflow ,ADF,glue etc) is required.
Strong communication skills (able to explain concepts to non-technical audiences as well as peers)
Self-starter who is highly organized, communicative, quick learner, and team-oriented
Technology Requirements:
Python/Java or Scala , SQL and Airflow. Cloud experience AWS/Azure
Daily tasks:
Developing, executing, monitoring and troubleshooting Data pipelines and workflows in our cloud environment.
Work on Data Lake/DW/DQ and other framework related items
Team and cross functional collaboration as needed.
Preferred background/prior work experience:
3 years of DE expertise building data pipelines and working in a DW/Data lake Cloud based environment
Job Type: Contract
Salary: $60.00 - $65.00 per hour
Experience level:
8 years
Schedule:
8 hour shift
Ability to commute/relocate:
Atlanta, GA 30303: Reliably commute or planning to relocate before starting work (Required)
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: One location",Unknown / Non-Applicable,Information Technology Support Services,Company - Private,Information Technology
"Engineer I, Cloud Data Platforms",atlanta,"Pilot Company
3.3","Roswell, GA",3.3,-1,-1,-1,-1,-1,-1,10000+ Employees,1958,"Company Description

Pilot Company is an industry-leading network of travel centers with more than 30,000 team members and over 750 retail and fueling locations in 44 states and six Canadian provinces. Our energy and logistics division serves as a top supplier of fuel, employing one of the largest tanker fleets and providing critical services to oil operations in our nation's busiest basins. Pilot Company supports a growing portfolio of brands with expertise in supply chain and retail operations, logistics and transportation, technology and digital innovation, construction, maintenance, human resources, finance, sales and marketing.
Founded in 1958 by Jim A. Haslam II and currently led by CEO Shameek Konar, our founding values, people-first culture and commitment to giving back remains true to us today. Whether we are serving guests, a fellow team member, or a trucking company, we are dedicated to fueling people and keeping North America moving.
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.

Job Description

The purpose of this job is to contribute to projects and the implementation of platforms and services to ensure high reliability, performance, and adoption of purpose-built cloud databases and data platforms.
Contribute to the provisioning, configuration, upgrading, and patching of cloud database services and data platforms
Contribute to work to meet near-zero RTO and RPO for cloud database services and data platforms including backups, high availability, and disaster recovery
Contribute to projects to improve or replace underperforming cloud database services or platforms
Work with purpose-built database technologies to optimize application performance, availability, and durability
Contribute to work to properly secure database services and data platforms including access control, encryption, integration, and auditing
Create and maintain documentation to support any service, platform, or process relating to cloud databases and platforms
Ensure changes and enhancements to cloud database services and platforms are in line with defined and approved architectures
Contribute to work to automatically scale cloud database services and data platforms
Contribute to standards and best practices for cloud database services and data platforms
Contribute to training plans for cloud database services and data platforms
Monitor costs associated with cloud database services and data platforms; make recommendations for cost optimization, ensure provisioned capacity is being used appropriately, and ensure protections are in place to prevent runaway costs
Contribute to work on proofs of concept for new database services and data platforms
Model behaviors that support the company’s common purpose; ensure guests and team members are supported at the highest level
Ensure all activities are in compliance with rules, regulations, policies, and procedures set forth by manager
Complete other duties as assigned

Qualifications
Bachelor’s degree in computer science, business administration, information technology, or related field required
Minimum three years’ technology operations experience with strong understanding of data structures, theories, principles, and practices required
Minimum one years’ experience with Amazon Web Services
Experience with AWS Database Services preferred
Basic understanding of structured query language
Basic knowledge of some AWS Database Services – RDS, Aurora, DynamoDB, Redshift, Elasticache, MemoryDB, DocumentDB, Neptune, QLDB, Keyspaces, etc…
Basic knowledge of either Snowflake or Redshift cloud data warehouse technologies
Basic knowledge of Databricks and its intended use
Basic knowledge of some other AWS services – Backup, S3, CloudTrail, CloudWatch, KMS, CLI, DMS, CostExplorer, ControlTower, SecretsManager
Basic knowledge of High Availability (HA) and Disaster Recovery (DR) solutions for AWS database services
Solid understanding of information security policies and how they relate with database services and platforms

Additional Information
This position is on-site at our Atlanta, GA (Rosewell) location
Nation-wide Medical Plan/Dental/Vision
401(k)
Flexible Spending Accounts
Adoption AssistanceTuition Reimbursement
Weekly Pay
Team Member Fuel Discounts
All your information will be kept confidential according to EEO guidelines",$10+ billion (USD),Convenience Stores,Subsidiary or Business Segment,Retail & Wholesale
"Senior Data Engineer, Business Intelligence",atlanta,"MerchantE
3.5","Alpharetta, GA",3.5,$91K - $132K (Glassdoor est.),3.6,3.9,3.4,4.2,3.9,201 to 500 Employees,2000,"Who Are We?
MerchantE is an innovative, technology-focused company providing a full-service platform to support the payment processing needs for merchants of all sizes, including small business retail shops, B2B wholesalers, and global eCommerce enterprises. We partner with financial institutions, software developers, independent sales organizations, and agents to bring our solutions to market.
Why Join Us?
We're growing and we're looking for collaborative, innovative, and hard-working individuals to grow with us! We offer a modern and inspiring work environment where your ideas and contributions are valued. Come experience, first-hand, the impact of your contributions.
The Opportunity:
As we are embarking on our journey to a modern architecture on the cloud, we are looking for talented engineers to join us to build our future. You will get an opportunity to work on challenging problems in a high-volume and mission critical environment.
US WORK AUTHORIZATION REQUIRED - No visa sponsorship is available for this position at this time.
Your Responsibilities will require you to:
Design, implement, and maintain systems used to collect and analyze business intelligence data
Create dashboards, databases, and other platforms that allow for efficient collection and evaluation of BI data
Build the reporting data model and help the data engineering team with creating views, SQL scripts
Perform ETL/ELT and SQL coding using AWS cloud-based solutions and downstream enablement in analytics
Provide data engineering with functional and technical requirements to improve efficiency of data pipelines.
Develop complex data models and design patterns for BI/Analytics reporting requirements
Design and develop scalable reporting, dashboards and data solutions using analytics
Take part in requirements gathering, logical design, physical design, implementation, testing, and deployment.
Provide best practices and guidance regarding the use of ELT/ETL, data modeling, and reporting deliverables.
Perform dataflow, system and data analysis and develop meaningful and useful presentation of data in BI applications
Collaborate closely with internal and external teams to understand and apply changes/modifications impacting data warehouse
Qualifications
Bachelor's Degree in Computer Science or related technical field.
Experience with Postgres, SQL, ETL, BI Tools
4+ years of experience delivering ETL processes and data visualization tools, including extracting data from various sources, modeling, and analysis.
At least 4 years of work experience in application development: specifically Java
(Internship experience does not apply)
BI report design, development, and implementation
Experience writing and executing complex SQL queries
Preferred Qualifications:
Master's Degree in Computer Science or related technical field.
2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
2+ years of data warehousing experience (Redshift or Snowflake)
2+ years of experience with Agile engineering practices
#LI-KB1
MerchantE is an Equal Opportunity Employer committed to a diverse workforce.",$100 to $500 million (USD),Financial Transaction Processing,Company - Private,Financial Services
Data Platform Engineer,atlanta,"Acuity Brands
3.6","Conyers, GA",3.6,$73K - $105K (Glassdoor est.),3.4,3.4,3.3,3.4,3.4,10000+ Employees,2001,"Acuity Brands, Inc. (NYSE: AYI) is a market-leading industrial technology company. We use technology to solve problems in spaces and light. Through our two business segments, Acuity Brands Lighting and Lighting Controls (“ABL”) and the Intelligent Spaces Group (“ISG”), we design, manufacture, and bring to market products and services that make the world more brilliant, productive, and connected. We achieve growth through the development of innovative new products and services, including lighting, lighting controls, building management systems, and location-aware applications.
Job Summary

WHY IS ACUITY BRANDS A GREAT PLACE FOR CLOUD DATABASE ENGINEERING?
Our Cloud Database Engineering team is a strategic part of the direction of our company
Our company is a very profitable market leader and provides financial stability
You will work with highly talented, fun, and supportive teams
We believe in a healthy work/life balance
We support continuous development through MS certification programs
Benefits program to meet the needs of you and your family
Environmental, social, and governance (ESG) factors are important, and we are committed to operating our business with high standards of ESG management
Our company culture Lights the way for you to Be Brilliant, Productive and Connected

We are seeking a talented and enthusiastic individual to be a hands-on Data Platform Standard for our Cloud Database Engineering Team as we transform Acuity Brands’ data and analytics platform using the Microsoft Azure Cloud. This position will be responsible for design, develop, test, deploy, maintain, and improve current database solutions. Day to day the data platform standard will apply technical knowledge to create and maintain the data platform components, act as a source of knowledge across the organization, design solutions with security and privacy guidelines, and support application development teams with data-centric applications.
Experience (minimum experience required)
Bachelor’s Degree in Computer Science, MIS, or related technical/analytical field
2 years required in the following:
Experience and understanding of one of the following database platforms: SQL Server, DB2, or Oracle
Strong analytical skills
Data modeling
Excellent written and oral communication skills
Experience with 2 or more of the following:
Monitoring
Performance tuning
Capacity planning
Replication
Data security
Preferred Experience (i.e. industry experience)
Python and/or Power Shell
Azure, AWS, or Google cloud data platforms
ETL processes and performance tuning
Data lake architecture
Scrum/agile tools
We invite you to apply today to join us as We Light the Way to a Brilliant, Productive, and Connected World!

We value diversity and are an equal opportunity employer. All qualified applicants will be considered for employment without regards to race, color, age, gender, sexual orientation, gender identity and expression, ethnicity or national origin, disability, pregnancy, religion, covered veteran status, protected genetic information, or any other characteristic protected by law.

Accommodation for Applicants with Disabilities: As an equal opportunity employer, Acuity Brands is committed to providing reasonable accommodations in its application process for qualified individuals with disabilities and disabled veterans. If you have difficulty using our online system due to a disability and need an accommodation, you may contact us at (770) 922-9000. Please clearly indicate what type of accommodation you are requesting and for what requisition.

Any unsolicited resumes sent to Acuity Brands from a third party, such as an Agency recruiter, including unsolicited resumes sent to an Acuity Brands mailing address, fax machine or email address, directly to Acuity Brands employees, or to Acuity Brands resume database will be considered Acuity Brands property. Acuity Brands will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.

Acuity Brands will consider any candidate for whom an Agency has submitted an unsolicited resume to have been referred by the Agency free of any charges or fees. This includes any Agency that is an approved/engaged vendor, but does not have the appropriate approvals to be engaged on a search.",$1 to $5 billion (USD),Electronics Manufacturing,Company - Public,Manufacturing
Senior Data Engineer/Developer,atlanta,"Amadeus
4.0","Atlanta, GA",4.0,$100K - $135K (Glassdoor est.),3.7,4.0,3.7,3.7,4.2,10000+ Employees,1987,"Job Title
Senior Data Engineer/Developer
Job Title: Senior Data Engineer/Developer
Job Description
Amadeus Hospitality Business Intelligence (BI) is looking for Senior Data Engineer for our BI Technology team. This role is responsible for building and supporting components responsible for all data ingestion activities in the Amadeus Hospitality Business Intelligence Product suite.
The Amadeus Hospitality BI products provide critical insights to our customers that assist them in increasing revenue and profitability. Ensuring access to the right data at the right time helps our customers accelerate revenue for long term growth.
With Amadeus’ Hotel Business Intelligence Solutions, customers unlock a complete, 360-degree view of rate, occupancy, and distribution trends with both forward-looking and historical data, as well as data from different competitive sets in their market.
Specific Accountabilities
We are seeking a highly skilled Senior Data Engineer/Developer with extensive experience in Data Ingestion technologies, methods, and cloud technologies. This role will be responsible for
Designing, building, and maintaining large-scale data pipelines, data warehousing/lake in a cloud environment.
Have solid understanding of data architecture, data modelling and data integration principles.
Collaborate with cross-functional teams to identify and implement solutions to complex data problems.
Implement ETL processes to integrate data from various sources and formats, transform and load data into a centralized data repository/store/lake.
Develop and maintain automated data quality checks and data governance processes.
Optimize database systems for performance, scalability, and reliability.
Ensure that all data solutions meet security, compliance, and regulatory requirements.
Required Skills:
Strong programming skills in languages like Python, Java, with experience in big data frameworks
Have abilities to develop common frameworks, common modules for data ingestion.
Have abilities to develop automated data quality and data governance mechanisms in the data ingestion processes.
Experience with cloud platforms such as Azure, AWS, including any cloud resident services tools for data ingestion.
Experience in developing Exceptions and Alerting models for data quality.
Proficiency in SQL and database query optimization.
Experience with data governance, data lineage, and data cataloging tools such as Collibra.
Familiarity with DevOps practices and tools such as Jenkins, Git, Docker, and Kubernetes is a Plus.
Excellent problem-solving skills, with the ability to work in a fast-paced, collaborative environment.
Education:
Bachelor’s or Master’s Degree in Computer Science, Information systems, or related discipline
Relevant work experience:
7+ years of experience as a Data Engineer or Developer.
2+ years in a Senior role
2+ years using Agile software development methodologies.
Technology:
Python
Java
Kubernetes
Kafka
Azure Big Data Solutions
Perl
What we can offer you:
The opportunity to work for one of the world’s top leading travel tech companies; a company that originated in technology innovation and sees the world with a technology-first perspective
Skills development and opportunities to try new ideas
A global diverse work environment
Diversity & Inclusion
Amadeus is an Equal Employment Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy, childbirth, or a related medical condition), ancestry, national origin, age, genetic information, military or veterans status, sexual orientation, gender expression, perception, or identity, marital status, mental or physical disability status, or any other protected federal, state, or local status unrelated to performance of work involved.",$1 to $5 billion (USD),Information Technology Support Services,Company - Public,Information Technology
Sr.Big Data Engineer,atlanta,Srichi,"Roswell, GA",-1,$78K - $114K (Glassdoor est.),-1,-1,-1,-1,-1,51 to 200 Employees,Company - Private,"Job ID: SR20160055
Location: Various, Duration: 6 months
Job Description
We are looking for an experienced Sr.Big Data Engineer who will play a key role in designing, building and supporting the enterprise Business Intelligence architecture including Data Warehouse and Reporting Solutions, which enable us to make business decisions.
The Sr. Big Data Engineer will work to create and document standards for internal reporting that will be utilized company-wide. This role will also maintain the reporting infrastructure by administering report security, report backups and source control.
Skills
5+ years experience in Data Warehouse systems and Business Intelligence development
3+ Years experience designing and building big data infrastructure from the ground up
Ability to work in an agile development environment a plus
Big Data Ecosystems:
Hadoop
MapReduce
Scripting Languages:
Python
PHP
Comfortable working in a fast-paced technical or engineering environmen",-1,-1,Unknown / Non-Applicable,-1
Senior Cloud Data Operations Engineer,atlanta,"Loyal
3.9","Atlanta, GA",3.9,-1,-1,-1,-1,-1,-1,51 to 200 Employees,2015,"Loyal is an organization centered on experience and building a platform that allows consumers to make meaningful decisions when it comes to healthcare. We deeply understand providers, locations, services, appointments, business rules, and moreover, we understand patients - who they are, the preferred method of communication, upcoming appointments, lapsed appointments, outstanding bills, health risks, and more. With this intelligence, our platform fuels highly relevant and personalized experiences across all mediums (website, email, voice…) allowing patients to get healthy, stay healthy, and have a better relationship with the health care provider.
**This is a remote role**
Summary
The Senior Cloud Data Operations Engineer is responsible for delivering Loyal's cloud-based data warehouse. They interface with groups across the organization to ensure we are collecting and storing data in a way that makes it easy to create and consume. They identify best practices for big data management, select the right tooling, create a workable data architecture, and drive an implementation roadmap others can depend on. The Senior Cloud Data Operations Engineer also works closely with our security group to ensure data security and privacy. They also mentor others on the team, providing technical leadership to those they work with.
You will
Create data streams and consolidate data sources into a single cloud-based data warehouse
Architect and catalog data warehouse storage schema
Work with product teams to enable easy data aggregation
Work with data consumers (analysts, data scientists, and AI/ML engineers) to ensure data is easily accessible and consumable
Create and execute a roadmap that meets data storage and availability goals
Ensure data is secure through data analysis, access control, and encryption
You have
Bachelor's degree in computer science, information systems, applied math or related field, or equivalent work experience
Minimum 5 years of experience working with cloud data processing services (AWS, Azure, or GCP).
Minimum 3 year experience with Big Data technologies, such as Databricks, Snowflake, Spark, Hadoop, etc.
Strong experience in creating data architecture and storage schemas required
Significant working knowledge of SQL and other query languages and tools
Significant experience with building relational database systems strongly preferred
Experience with ETL tools a plus
Knowledge of Python preferred
Software development, data analytics, or data science experience is a plus.
Experience working within a software as a service (SaaS) company preferred.
Experience working within a high growth and/or ambiguous environment, with proven experience to be dynamic preferred.
#LI-REMOTE
We know that potential candidates are often less likely to apply to a position if they don't match 100% of the job qualifications. Don't let that be why you miss out on this opportunity! We encourage you to apply if you can demonstrate many of these skills and competencies.
Loyal to our employees
We are a remote-friendly company! We encourage you to apply from anywhere in the United States. We also believe in a work/life balance that fulfills you while you're here and supports you when you're not. We built our benefits package to prove that we're committed to you having everything you need (including a little fun). Here is what we offer full-time employees:
Flexible paid time off, sick and personal days
At least one holiday per month (sometimes, more!)
Full health, dental, and vision insurance - Loyal pays the premium for all employees!
One Time Home Office Setup Stipend For Remote & Hybrid Roles
Monthly Internet Stipend for Remote & Hybrid Roles
Long term & short term disability
401[k] plan
16 Weeks Paid Parental Leave
2 Volunteer days per year
Matching Gift Program
Participation Grant Program
Annual Travel/Team Events up to twice per year (post-COVID)
Our Commitment
We believe that the key to Loyal's success is you. Your unique background, life experience, knowledge, self-expression, and talent make you uniquely you. Who you are, what you have experienced, and how you think inspires us to be innovative and bold.
Loyal is an equal opportunity employer. We hire great people from a wide variety of backgrounds, not just because it's the right thing to do, but because it makes our company stronger. We welcome the unique contributions that you can bring in terms of your education, opinions, culture, ethnicity, race, ancestry, sex, gender identity and expression, national origin, citizenship, marital status, age, languages spoken, veteran status, color, religion, disability, sexual orientation, and beliefs.
We consider qualified applicants regardless of criminal histories, consistent with legal requirements.
Further, consistent with applicable federal and state law, Loyal provides reasonable accommodations when requested by qualified applicants or employees with disabilities, unless doing so would cause an undue hardship. Loyal's policy regarding requests for reasonable accommodation applies to all aspects of employment, including the application process. If you require a reasonable accommodation in connection with the application process, please contact the Talent Acquisition Department at talentacquisition@loyalhealth.com.
E-Verify
This employer participates in E-Verify and will provide the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S. If E-Verify cannot confirm that you are authorized to work, this employer is required to give you written instructions and an opportunity to contact Department of Homeland Security (DHS) or Social Security Administration (SSA) so you can begin to resolve the issue before the employer can take any action against you, including terminating your employment. Employers can only use E-Verify once you have accepted a job offer and completed the I-9 Form.
COVID-19 Vaccinations
Candidates who will be attending in-person conferences, visiting hospitals, and/or visiting or traveling to a third party location who may have their own specific requirements in place may be required to show proof of being fully vaccinated against COVID-19 before attending. Reasonable accommodations will be considered on a case-by-case basis for exemptions to this requirement in accordance with applicable law. If you require a reasonable accommodation, please contact the People Department at people@loyalhealth.com.",$5 to $25 million (USD),Health Care Services & Hospitals,Company - Private,Healthcare
Lead Data Engineer,atlanta,"Chick-fil-A, Inc.
3.9","Atlanta, GA",3.9,-1,-1,-1,-1,-1,-1,5001 to 10000 Employees,1946,"Overview:
As a Lead Data Engineer, you will be responsible for executing significant data engineering project work in support of one or more products within a single advanced analytics portfolio. The person in this role will work as part of a larger, cross-functional, full-stack execution team charged with designing, building, and deploying advanced analytics products within the portfolios under the stewardship of the Advanced Analytics team within Enterprise Data & Analytics (ED&A).

The Lead Data Engineers typically leverage and implement pre-defined data engineering on projects of moderate technical complexity, focusing on developing solutions to data pipelining, data modeling, and/or data ops needs. They will work under the direction of more senior data engineers if asked to take on more complex work. They must be able to quickly learn new subject-matter in support of a specific project or task. Our Lead Data Engineers typically work with some decision-making latitude for action or decisions on specific projects, solutions, or technical issues related to their work. They may also represent Advanced Analytics team within ED&A in internal conversations.

Successful candidates for this role must have strong analytical and data modeling skills, a solid understanding of database technology and data use within analytic platforms, and they must have strong programming skills with SQL and/or Python. We expect Lead Data Engineers to have the capacity for fluency and competency in both the technology language of IT and the analytics language of data scientists and departmental analysts. They will need to be fast learners with a keen eye for detail, systems thinking, and process design. They must be team players who work steadfastly to create impactful change. This is a professional track role.

Our Flexible Future model offers a healthy mix of working in person and virtually, strengthening key elements of the Chick-fil-A culture by fostering collaboration and community.
Responsibilities:
The person who fills this role will be expected to do the following as a part of their regular work responsibilities:
Works with a variety of business stakeholders, ED&A Program Leads, Portfolio Leads, Data Scientists, and IT teams to translate business logic into scalable data and analytic solutions.
Works with more senior Data Engineers to build new up-stream production-grade data sources for Data Scientists' use in modeling, integrates data from across the business into modeling pipelines, and builds on-line and off-line feature stores to service both model production and model development activities.
Works with Data Scientists to design and implement complex, model-specific feature engineering.
Partners with DTT Deployment Engineers on complex software engineering solutions for delivering data to and from production model pipelines.
Works with more senior Data Engineers to build modeled data end-user consumption patterns.
Actively participates in the Community of Data Engineers (CODE).
Leverages tools efficiently, understanding both Tableau and Alteryx performance (including server) and cloud compute performance requirements and expectations.
Manages any needed maintenance and quality control on data pipelines or data products they have built which are actively in use/production.
Leverages cloud compute resources efficiently.
Implements data governance and master data management principles across specific project execution, including data privacy and data ethics policy requirements.
Owns and is accountable for model and code quality and documentation for the project work they execute.
Performs ad-hoc analysis as necessary to support specific project work.
Drives projects to success and enables others to own the impact.
Minimum Qualifications:
Strong analytical and data modeling skills
Solid understanding of database technology
Solid understanding of analytic platform data use
Strong programming skills in SQL and/or Python
Skilled at partnering with cross-functional teams using strong written and verbal communication
Fast learner and proven problem solver
Keen eye for systems thinking and process design, especially with respect to scalability and automation
Keen eye for detail and thoughtful investigation of data
Preferred Qualifications:
Some experience using the AWS big data technology stack.
Moderate experience with Alteryx or similar ETL platforms.
Moderate experience with Tableau or similar data visualization tools.
Some experience implementing data governance principles.
Any experience with Model Operations tools and processes in any context.
Minimum Years of Experience: 3 Travel Requirements: 10% Required Level of Education: Bachelor's Degree Preferred Level of Education: Masters Degree Major/Concentration: MIS, Decision Sciences, Engineering, Business Analytics, Computer Science or other similar fields",$5 to $10 billion (USD),Restaurants & Cafes,Company - Private,Restaurants & Food Service
Senior Data Engineer Consultant,atlanta,"Analytic Vizion
5.0","Atlanta, GA",5.0,-1,-1,-1,-1,-1,-1,1 to 50 Employees,2019,"Analytic Vizion is a data and analytic consulting firm built on love and service. We exist to equip and inspire the next generation of data and technology leaders by helping organizations thrive through data visualization and analytics.

We are looking for a Senior Data Engineer Consultant who enjoys connecting business needs to data and building out the data foundation to enable analytic solutions in order to serve our clients with excellence.
A day in a life for a Senior Data Engineer Consultant
Build authentic relationships, partnering with our clients to assess their needs through conversations to understand organizational and business goals.
Collaborate with clients and team members to determine data needs and potential solutions based on best practices and contextual understanding of the people, systems, and technology in the organization.
Develop, test, and deploy database architectures, both in the cloud and on-premise, to support analytic insights.
Monitor, optimize, and integrate data pipelines.
Bringing a depth of technical experience with a desire to grow into a leader worth following in the space of data and technology.
A desire to accept the challenges of growing into a servant leader through a multi-year development process.
Requirements for the role:
2+ years of professional experience with data engineering and data warehousing.
2+ years working experience with at least one cloud data warehouse platform: Snowflake/AWS/GCP BigQuery/Azure.
2+ years working experience with ETL, ELT tools.
Experience building intermediate to complex SQL data structures and data warehouse.
Comfortable with translating business needs to data models and SQL queries.
What will put you ahead:
Experience with visual analytics tools.
Key participant in decisions on technology and processes and data needs.
Certified or are willing to take certifications on modern data technologies.
What does ""Hybrid"" mean at Analytic Vizion?
In order to support our thriving culture, Analytic Vizion gets together once every three or four weeks in person in Atlanta.
For those that are not within driving distance of Atlanta, we invite you to travel for each of our four quarterly celebrations, our annual trip (a weekend in the summer or fall to an awesome destination), and our ""Thanks Giving"" holiday celebration in November.
Additionally, we balance the needs of our clients for hosting our consultants on site with the desires of our consultants. Where desired and where possible, we will continue to work remotely with our clients.
Analytic Vizion is an equal opportunity employer including disability/veteran",$5 to $25 million (USD),Business Consulting,Private Practice / Firm,Management & Consulting
Senior Data Engineer/Lead (Strong Databricks),atlanta,"Crackajack Solutions
3.3","Alpharetta, GA",3.3,Employer Provided Salary:$70.00 - $80.00 Per Hour,5.0,5.0,5.0,5.0,4.0,1 to 50 Employees,Company - Public,"Senior Data Engineer (Strong Data bricks)
Alpharetta, GA(Hybrid)
9-12 Months
The Databricks Engineer role will be part of our client’s Data Engineering practice team and will be focused on building Data pipelines and Data processing solutions based on AWS platform for Digital Marketing domain.
The candidate will contribute to Competency development & driving innovation through various internal initiatives within the organization. Databricks Engineer should have more than 3 years of experience with broad exposure to AWS services relevant to Analytics and Data engineering.
Description
Over 10+ years’ experience as a Data Engineer including extensive experience in Databricks.
Experience in Spark, SQL performance tuning, and optimization.
Experience with architectural design and development of large-scale data platforms and data applications.
Good hands-on experience in AWS services like EC2, S3, RDS, KMS, IAM, STS, Redshift etc.
Good knowledge and experience in creating, securing, and managing Databricks clusters of Amazon Elastic Compute Cloud (Amazon EC2) instances.
Strong programming background with Java, Python and Pyspark.
Practical exposure to end-to-end design and implementation process of Near-Real-Time and Batch Data Pipelines.
Strong knowledge and understanding of Databricks Lakehouse Platform.
Knowledge of Databricks scheduling features to automate Databricks jobs.
Strong knowledge and experience in Databricks Lakehouse platform and Delta Lake.
Experience in managing, using and scheduling notebooks in Databricks.
Good experience in integrating and ingesting data from external data sources with Databricks including automating ETL using Delta Live Tables and Databricks Autoloader.
Strong SQL (Hive/Spark/Databricks) skills and experience tuning complex queries.
Good to have Databricks Lakehouse Data Engineer Associate or Data Engineer Professional certification.
Job Type: Contract
Pay: $70.00 - $80.00 per hour
Experience level:
10 years
11+ years
Schedule:
8 hour shift
Monday to Friday
Ability to commute/relocate:
Alpharetta, GA 30009: Reliably commute or planning to relocate before starting work (Required)
Education:
Bachelor's (Preferred)
Experience:
Data Engineer: 10 years (Preferred)
Data Lake, Data IKU, Hadoop: 10 years (Preferred)
Databricks: 5 years (Preferred)
Python/Java: 10 years (Preferred)
Work Location: In person",-1,-1,Unknown / Non-Applicable,-1
Senior Software Engineer - Data Technologies,atlanta,"PRGX Global, Inc
3.7","Atlanta, GA",3.7,$97K - $136K (Glassdoor est.),3.3,3.5,3.4,3.1,4.0,1001 to 5000 Employees,1996,"SENIOR SOFTWARE ENGINEER, DATA INTELLIGENCE TECHNOLOGIES
This position is responsible for creating high priority differentiated technology solutions that solve important real-world problems. The position partners closely with the Head of Data Analytics, data scientists, business leaders, clients, and other stakeholders to create roadmaps, scope programs aligning with business priorities, define milestones and success metrics, and create scalable, secure, reliable, and efficient data products and platforms which meet our clients’ needs and contribute to the growth of PRGX.

Job Responsibilities:
Participate in the conceptualization of new products.
Work with our data scientists to turn large-scale, diverse, and often unstructured data into a meaningful source of insights for our clients.
Design, develop, deliver, implement, and maintain high-quality, secure, reliable, and scalable data applications on time and on budget.
Design, code, configure, test, and document deliverables using agile methodologies.
Collaborate with key stakeholders on coding standards, processes, tools, and frameworks required for the delivery of features.
Guide technical and design decisions based on experience.
Develop proof of concept work and prototyping when necessary.
Collaborate with business leaders to understand business requirements relating to features to be delivered.
Identify common patterns and foster development of reusable components and standards.
Contribute to an innovation culture by evaluating new processes and technologies that can be used to enhance future features.

Ideal Candidate Characteristics:
Enjoys and excels in environments where they must tackle and solve new and increasingly complex client business challenges and issues, incorporating the newest ideas and technologies to deliver solutions quickly.
Possesses a high level of self-awareness. Maintains composure and professionalism when under pressure.
Possesses strong systems and critical thinking skills and the ability to draw on disparate information to identify insights, and design and deliver solutions.
Driven to meet or exceed specific goals and objectives as quickly as possible.
Entrepreneurial spirit. Forward-thinking and adaptable in dynamic situations. Knowledge & Qualifications:
Bachelor’s degree in Computer Science, Computer Engineering, or related field. Master’s degree preferred.
Minimum of 10 years’ software development experience.
Minimum of 5 years’ experience working with complex data sets and developing data-centric applications.
Minimum of 5 years’ experience with commercializing and scaling white label Qlik applications.
Experience with big data and big data tools such as SQL and Python.
MySQL, Spark, Scala, Hive, Minio, Trino, Airflow, Presto and other ETL solutions experience desired.
Experience in CPG manufacturing, wholesale, distribution, or retail is highly desirable, and preference will be given to candidates with this experience.
Strong strategic thinking and problem-solving skills.
• Excellent communication, collaboration, and leadership skills. • Ability to build and maintain relationships with key stakeholders.
Strong business acumen.",$25 to $100 million (USD),Accounting & Tax,Company - Public,Financial Services
Senior Staff Data Engineer,atlanta,"SADA
4.3","Atlanta, GA",4.3,$96K - $145K (Glassdoor est.),4.3,4.5,4.3,4.4,4.5,501 to 1000 Employees,2000,"Join SADA as a Senior Staff Data Engineer, Corporate!
Your Mission
As a Senior Staff Data Engineer, Corporate at SADA, you will have the opportunity to work with big data and emerging Google Cloud technologies to drive corporate services. You will have an opportunity to design, develop, and maintain the best Enterprise Data Warehouse solution to fit our corporate needs. You will be interacting with all of our business units and Google Cloud subject matter experts.
From transforming business requirements, solution architecture, data modeling, architecting, ETL, metadata, and business continuity, you will have the opportunity to work collaboratively with architects and other engineers to recommend, prototype, build, and debug data infrastructures on Google Cloud Platform (GCP). You will have an opportunity to work on real-world data problems facing our customers today. Engagements vary from being purely consultative to requiring heavy hands-on work and covering a diverse array of domain areas, such as data migrations, data archival and disaster recovery, and big data analytics solutions requiring batch or streaming data pipelines, data lakes, and data warehouses.
You will be expected to run point on whole projects, end-to-end, and to mentor less experienced Data Engineers. You will be recognized as an expert within the team and will build a reputation with Google and our customers. You will demonstrate repeated delivery of project architectures and critical components that other engineers demur to you for lack of expertise. You will also participate in early-stage opportunity qualification calls, as well as guide client-facing technical discussions for established projects.
Pathway to Success
#BeOneStepAhead: At SADA, we are in the business of change. We are focused on leading-edge technology that is ever-evolving. We embrace change enthusiastically and encourage agility. This means that not only do our engineers know that change is inevitable, but they embrace this change to continuously expand their skills, preparing for future customer needs.
Your success starts by positively impacting the direction of a fast-growing practice with vision and passion. You will be measured quarterly by the breadth, magnitude, and quality of your contributions, your ability to estimate accurately, customer feedback at the close of projects, how well you collaborate with your peers and the consultative polish you bring to customer interactions.
As you continue to execute successfully, we will build a customized development plan together that takes you through the engineering or management growth tracks.
Expectations
Internal Facing - You will interact with internal customers and stakeholders regularly, sometimes daily, other times weekly/bi-weekly. Expectations will be to capture requirements and deliver solutions suitable for corporate divisions.
Onboarding/Training - The first several weeks of onboarding are dedicated to learning and will include learning materials/assignments and compliance training, and meetings with relevant individuals. Details of the timeline are shared closer to the start date.
Job Requirements
Required Credentials:
Google Professional Data Engineer Certified or able to complete within the first 45 days of employment
Required Qualifications:
Mastery in the following domain area:
Data warehouse modernization: building complete data warehouse solutions on BigQuery, including technical architectures, star/snowflake schema designs, query optimization, ETL/ELT pipelines, and reporting/analytic tools. Must have expert-level experience working with Google's batch or streaming data processing solutions (such as BigQuery, Dataform, and BI Engine)
Proficiency in the following domain areas:
Big Data: managing Hadoop clusters (all included services), troubleshooting cluster operation issues, migrating Hadoop workloads, architecting solutions on Hadoop, experience with NoSQL data stores like Cassandra and HBase, building batch/streaming ETL pipelines with frameworks such as Spark, Spark Streaming, and Apache Beam, and working with messaging systems like Pub/Sub, Kafka and RabbitMQ.
Data Catalog: Managing Data Catalogs, definitions, and data lineage.
Data Quality: Must have experience with DataForm, or other DQ solutions.
Data migration: migrating data stores to reliable and scalable cloud-based stores, including strategies for minimizing downtime. It may involve conversion between relational and NoSQL data stores, or vice versa
Backup, restore & disaster recovery: building production-grade data backup and restore, and disaster recovery solutions. Up to petabytes in scale
4+ years of experience with Data modeling, SQL, ETL, Data Warehousing, and Data Lakes
4+ years experience in writing production-grade data solutions (relational and NoSQL)in an enterprise-class RDBMS
2+ years of experience with enterprise-class Business Intelligence tools such as Looker, PowerBI, Tableau, etc.
Mastery in writing software in Python
Experience writing software in one or more languages, such as Javascript, Java, R, or Go
Experience with systems monitoring/alerting, capacity planning, and performance tuning
Hands-on experience building frontend applications with React
Hands-on experience with CI/CD solutions (Cloud Build / Terraform)
Useful Qualifications:
Experience working with Google Cloud data products (CloudSQL, Spanner, Cloud Storage, Pub/Sub, Dataflow, Dataproc, Bigtable, BigQuery, Dataprep, Composer, etc.)
Experience with IoT architectures and building real-time data streaming pipelines
Experience operationalizing machine learning models on large datasets
Demonstrated leadership and self-direction - a willingness to teach others and learn new techniques
Demonstrated skills in selecting the right statistical tools given a data analysis problem
Ability to balance and prioritize multiple conflicting requirements with great attention to detail
Excellent verbal/written communication & data presentation skills, including the ability to succinctly summarize key findings and effectively communicate with both business and technical teams

About SADA
Values: We built our core values on themes that internally compel us to deliver our best to our partners, our customers and to each other. Ensuring a diverse and inclusive workplace where we learn from each other is core to SADA's values. We welcome people of different backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer.
Make Them Rave
Be Data Driven
Think One Step Ahead
Drive Purposeful Impact
Do The Right Thing
Work with the best: SADA has been the largest partner in North America for Google Cloud portfolio of products since 2016 and has been named the 2021, 2020, 2019, and 2018 Google Cloud Global Reseller Partner of the Year. SADA has also been awarded Best Place to Work year after year by the Business Intelligence Group, Inc. Magazine, as well as LA Business Journal!
Benefits: Unlimited PTO, Paid Parental Leave, competitive and attractive compensation, performance-based bonuses, paid holidays, rich medical, dental, vision plans, life, short and long-term disability insurance, 401K/RRSP with match, as well as Google Certified training programs.
Business Performance: SADA has been named to the INC 5000 Fastest-Growing Private Companies list for 15 years in a row garnering Honoree status. CRN has also named SADA on the Top 500 Global Solutions Providers for the past 5 years. The overall culture continues to evolve with engineering at its core: 3200+ projects completed, 4000+ customers served, 10K+ workloads and 30M+ users migrated to the cloud.
SADA is a remote first company. Most roles are remote unless stated otherwise in the job description.",$100 to $500 million (USD),Information Technology Support Services,Company - Private,Information Technology
Big Data Engineer,atlanta,"CEDENT
5.0","Alpharetta, GA",5.0,$91K - $128K (Glassdoor est.),-1,-1,-1,-1,-1,1 to 50 Employees,Contract,"Title: Big Data Engineer @ Alpharetta, GA:
Terms of Hire: Full time.
Salary: $ Open / YR + Benefits
Job Description::

Seeking talented database engineers who will innovate and engineer solutions in the area of database technology. We need individuals who are enthusiastic about applying bold new ideas to solving real-world data problems. The Digital Innovation area is actively engaged in the ongoing Systems Modernization process, partnering with development groups, and providing deep subject matter expertise input as stakeholders to design reviews, and as an advocate for bringing forward and resolving customer issues.
Candidates must have::
Deep knowledge and experience designing and maintaining relational databases including PL/SQL, Oracle, MySQL, Postgres or SqlServer
Experience developing and supporting complex mission-critical production database systems
Broad awareness of customer workloads and use cases, including performance, availability, and scalability
Experience analyzing issues holistically, from the application tier through the database, down to the storage
Awareness of emerging technologies and approaches in IT
Working knowledge of relational database internals (locking, consistency, serialization, recovery paths)
Working knowledge of at least one scripting language (shell, Python, Perl)
Coding skills in the procedural language for at least one database engine a must (PL/SQL, T-SQL etc.)
Proven track record of automating tasks
Root cause analysis of production-related database issues
- On-call for production databases - daily maintenance, monitoring, problem resolution and internal customer and dev support
Excellent SQL and DB performance tuning skills
Experience with other Data Persistence platforms::
RDBMS (Postgres, Oracle, MySQL), Distributed SQL Engines (Cassandra, Foundation DB, Cockroach DB), NoSQL (Mongo DB), Hadoop, Data and Software Migration off/to RDBMS, AWS DBs (RDS, DynamoDB, EMR, Redshift, Aurora, etc.), Data Information Lifecycle Management, Data Security, Big Data....
Working with one or more streaming platforms, such as Apache Kafka, Spark Streaming, Storm, or AWS Kinesis
Track record of engineering performance and availability solutions
Exposure to cloud environments and architectures
experienced in various Clustering and Sharing architectures
Experience in Kubernetes will be a plus
Minimum Qualifications:
Bachelor's Degree
Relevant Experience or Degree in: Computer Science, Management Information Systems, Business, or related field
Typically, Minimum 8+ Years Relevant Exp
Four-year college degree and 8 or more years, and/or a high school diploma with 10 or more years professional experience in full life cycle design and development to include IT architecture, banking industry experience, and understanding client requirements
You Will Enjoy:
An opportunity to be a part of a great culture, an awesome team, a challenging work environment, and some fun along the way!
Apply today to learn more and be part of our Growth story.
All applications will be kept strictly confidential and once shortlisted, our team will be in touch with you for further discussions.",-1,Information Technology,Computer Hardware Development,Less than $1 million (USD)
"Senior Data Engineer, Advanced Analytics & Optimization",atlanta,"Cox Communications
4.0","Atlanta, GA",4.0,$86K - $121K (Glassdoor est.),3.8,4.0,3.7,4.1,3.9,10000+ Employees,1962,"Cox Communications, Technology Services team is looking for a Data Engineer to join the organization and use data to maximize value within team. This role will be responsible for developing actionable insights for Cox Communications' lines of businesses. The Data Engineer is required to be a proven data professional with development, systems, and problem-solving skills to drive actionable insights at scale.

Responsibilities:


Use data, analysis, and automation to generate value within the company (i.e., accelerate revenue, reduce operating expense, or improve return on capital) through advanced data modeling, transformation, and other advanced analytics principles
Implement foundational and advanced analytics methodologies to address key metrics to improve customer experience, network performance, quality of service, profitability of products, and personalized offerings
Perform data engineering implementations including data ingestion, data models, data structures, data storage, high-throughput data processing, data pipelines, and data monitoring at scale
Identify, research, interpret, and enrich Cox Communications' structured and unstructured data assets to facilitate effective analytics. Develop subject matter expertise in these data assets
Prepare documentation, reports, and visualizations to explain technical and data-driven insights to non-technical leadership outside the team
Coach junior resources across technical and functional domains to improve the overall quality and performance of the team
Test new technologies, tools, and data to determine best practices



Qualifications

Minimum:


Bachelor's degree in a related discipline and 4 years' experience in a related field. The right candidate could also have a different combination, such as a master's degree and 2 years' experience; a Ph.D. and up to 1 year of experience; or 8 years' experience in a related field
Expertise in (at least one) SQL language and Python. Experience with writing complex programs in these environments
Strong programming skills and ability to utilize a variety of data/analytic software/languages/tools; e.g., Spark, Tensorflow, Keras, SageMaker, Docker, Python, R, Gremlin, Scala, Java, SQL, Tableau, etc.
Deep understanding of the mathematical and computational concepts behind advanced analytics algorithms
Understanding cloud environments such as Google, Microsoft, or Amazon
Strong communication skills. Ability to successfully comprehend and communicate business insights to business partners. Ability to work in a diverse team



Preferred:


Graduate degree in Data Science, Computer Science, Analytics, or Statistics
Experience within telecommunications, cable industry, or high tech
Demonstrated experience in a similar role
Practical experience applying advanced analytics approaches to mass transaction reduction and customer experience optimization
Experience in data visualization solutions and tools



About Cox Communications

Cox Communications is the largest private telecom company in America, serving six million homes and businesses. That's a lot, but we also proudly serve our employees. Our benefits and our award-winning culture are just two of the things that make Cox a coveted place to work. If you're interested in bringing people closer through broadband, smart home tech and more, join Cox Communications today!

About Cox

Cox empowers employees to build a better future and has been doing so for over 120 years. With exciting investments and innovations across transportation, communications, cleantech and healthcare, our family of businesses - which includes Cox Automotive and Cox Communications - is forging a better future for us all. Ready to make your mark? Join us today!

Benefits of working at Cox may include health care insurance (medical, dental, vision), retirement planning (401(k)), and paid days off (sick leave, parental leave, flexible vacation/wellness days, and/or PTO). For more details on what benefits you may be offered, visit our benefits page .

Cox is an Equal Employment Opportunity employer - All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Cox accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Cox employees, Cox hiring manager, or send to any Cox facility. Cox is not responsible for any fees or charges associated with unsolicited resumes.",$10+ billion (USD),"Cable, Internet & Telephone Providers",Company - Private,Telecommunications
Azure Data Engineer,atlanta,"Berkley
4.0","Atlanta, GA",4.0,$93K - $126K (Glassdoor est.),3.9,4.2,4.1,4.1,4.0,1 to 50 Employees,2012,"Company Details:

W. R. Berkley Corporation, founded in 1967, is one of the nation’s premier commercial lines property casualty insurance providers. Founded in 2004, Berkley Environmental has underwriting and account executive units in seven regions. Berkley Environmental offers an array of coverages for virtually all classes traditionally known to have environmental liability exposures on both an admitted and non-admitted basis. We provide a comprehensive portfolio of commercial property casualty insurance, automobile liability and workers’ compensation, along with claim services, providing expertise to meet the unique business needs of our customers. W.R. Berkley Corporation has reached a milestone and is celebrating 50 years, click here to read more on the history of the company.
Responsibilities:
In your role as an Azure Data Engineer, you will be responsible for expanding and optimizing data and pipeline architectures, and for optimizing data collection and flow across functional teams. Your responsibilities include assisting software developers, database architects, data analysts, and data scientists with data initiatives and ensuring a consistent data delivery architecture is put in place throughout ongoing projects.

Design and implement data pipelines using Azure technologies such as Azure Data Factory, Azure Stream Analytics, and Azure SQL Database
Migrate on-premises data stores to Azure cloud platforms
Implement data transformations using Azure Databricks
Collaborate with data scientists to design and implement machine learning models using Azure Machine Learning
Optimize data pipelines for performance and scalability
Monitor and troubleshoot data pipelines within Azure Data Factory
Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions
Participates in the testing process through test review and analysis, test witnessing and certification of software.
Work with technical resources to ensure accurate translation of specifications into workable application code. Work with outside vendors and sister companies on coordinating data capture.
Qualifications:
3+ years of experience as a data engineer
Strong experience with Azure cloud technologies, including Azure Data Factory, Azure Data Bricks, Azure Synapse Analytics, and Azure SQL Database, T-SQL, SSIS, and SSAS Tabular
Experience with data transformation and manipulation using Azure Databricks or similar tools
Experience working in an Agile development environment
Familiar with a variety of the field’s concepts, practices, and procedures and a strong focus on data integrity.
Demonstrates strong written and oral communications skills. Ability, desire, and focus to meet deadlines Demonstrates ability to work with all levels of individuals.
Demonstrates organizational skills while working on multiple projects; and communicate effectively within the team.
Experience with machine learning is a plus

Education Requirement
Bachelor's degree in Computer Science, Information Technology, or a related field

Technology Stack
Azure SQL Data Warehouse
Azure Data Factory
Azure Data Lake
Azure Analysis Services
Azure Synapse Analytics
Azure DevOps
Databricks/Spark-SQL
Python
Azure Functions and Logic Apps
Serverless Architecture
Additional Company Details: We do not accept unsolicited resumes from third party recruiting agencies or firms.",$25 to $100 million (USD),Commercial Printing,Company - Private,Manufacturing
Azure Data Engineer,atlanta,"Rheem Manufacturing
3.9","Atlanta, GA",3.9,$87K - $120K (Glassdoor est.),3.8,3.8,3.6,4.0,3.8,10000+ Employees,1925,"Azure Data Engineer - (23000243)
Description

A Career at Rheem: Where Comfort Is Your Calling
As a leading global manufacturer of heating, cooling, and water heating equipment, Rheem Manufacturing is continually innovating new ways to deliver just the right degree of environmental comfort to every home and business while saving energy, water, and supporting a more sustainable future. It is an exciting challenge that requires a team of talented, passionate people with a diverse set of skills. From engineers to accountants, sales professionals to support experts, we depend on talented individuals to power our innovations. Join our team and help shape the future of products that impact lives—every day.
Rheem is looking to hire Azure Data Engineer. We are looking for experienced Azure Data Engineer to be part of our data & analytics team. You will develop solutions leveraging Azure cloud platform to create a Modern Enterprise data platform. You will work with cross-functional teams to ensure data is collected, stored, processed, and analyzed in a timely, efficient, and accurate manner.
You will support digital transformation journey of data and analytics team at Rheem. This exciting transformation will enable new cloud technologies that will transform the way we derive value from our data assets.
This position will serve our Enterprise Division located in Atlanta, Georgia
WHAT YOU'LL DO:
Design, develop, and deploy data solutions using Microsoft Azure cloud platform
Develop and maintain automated data ingestion, transformation, and validation processes to ensure data accuracy and consistency
Data Ingestion: Ingesting data from various sources, such as on-premises systems, cloud-based systems, and third-party services into
Data Transformation: Transforming data into the appropriate format, schema, and structure to meet business requirements
Data Loading: Loading transformed data into Azure Synapse SQL Warehouse/ Azure Data Lake Storage
Error Handling and Monitoring: Implementing error handling and monitoring processes to ensure data integration solutions operate smoothly and provide reliable data.
Performance Optimization: Optimizing data integration processes for performance and cost, by tuning queries, caching data, and managing resources.
Collaboration: Collaborating with other teams, such as, architects, developers, and business analysts, to ensure data solutions meet their requirements.
Qualifications

WHAT YOU'LL NEED:
Bachelor’s Degree in Computer Science or related field
3+ years of experience on developing Data warehouse/Lakehouse/Data platform on Azure Synapse Analytics/Azure Data Bricks/Azure Cloud Platform
Experience of creating data ingestion and transformation pipelines using Synapse Pipeline/Azure Data Factory(ADF).
Should have experience in ETL/ELT. Hands on experience ADF/Synapse, configuration, parameters, variables, Integration services runtime.
Strong understanding of Azure services such as Azure Synapse, Azure Synapse Pipeline, Azure Synapse, Spark Notebooks, Azure Synapse Dedicated SQL Pool Warehouse ,Azure Databricks, Azure Functions and Azure Data Lake storage
Have experience of dealing with various data formats like relational, json, parquet, streaming and others
Proficiency in SQL,T-SQL and Python/PySpark
Excellent problem-solving and analytical skills. Aptitude to adapt to new technologies
Excellent business facing and internal communication skills
HOW TO STAND OUT
Microsoft Azure Data Engineer Associate Certificate
Certification on Data Science/ML.

Rheem is an Equal Opportunity Employer
Notice to Third Party Recruitment Agencies:
Please note that Rheem and its subsidiaries do not accept unsolicited resumes from recruiters or employment agencies. In the absence of an executed Recruitment Services Agreement, there will be no obligation to any referral compensation or recruiter fee.
In the event a recruiter or agency submits a resume or candidate without an agreement, Rheem and its subsidiaries shall explicitly reserve the right to pursue and hire those candidate(s) without any financial obligation to the recruiter or agency. Any unsolicited resumes, including those submitted to hiring managers, shall be deemed the property of Rheem.

Primary Location: US-RC_US_GA-Atlanta
Work Locations: Rheem Atlanta Office (GA) 1100 Abernathy Road NE Suite 1700 Atlanta 30328
Job: Data Analytics
Organization: Enterprise
Schedule: Full-time
Shift: Day Job
Employee Status: Regular
Job Type: Standard
Job Level: Entry Level
Travel: No
Job Posting: Apr 14, 2023, 7:42:20 AM",$1 to $5 billion (USD),Machinery Manufacturing,Company - Private,Manufacturing
Data Engineer II,atlanta,"Meridian Cooperative, Inc.
3.1","Atlanta, GA",3.1,$83K - $112K (Glassdoor est.),3.0,3.4,2.9,3.4,3.5,501 to 1000 Employees,1971,"Meridian Cooperative is seeking a Data Engineer II to join a team of passionate innovators and problem-solvers, empowered to rise above challenges and swarm around solutions. Here at Meridian, we are energized by the fact that our work is important. We are driven to make work as easy as possible for our Members, Customers, Partners and Employees. Headquartered in Dunwoody, this role is Hybrid.
Help us lead the way in Utility Software, join a winning company and thrive.
Job Summary:
The ideal candidate participates in all stages of the development life cycle for proprietary software and/or database applications for market sale, to address user needs, and/or to improve operational efficiency. Core code, troubleshoot, and deep-dive analysis. May analyze databases within an application area, working individually or coordinating application development as part of a team. Designs and modifies proprietary company applications or specialized utility programs, using analysis and models to predict and measure the outcome of the design and providing direction to peers as needed. Modifies applications to correct errors, adapt to new technologies, or improve performance; analyzes code and/or data to identify causes of errors, as needed.
The Data Engineer will be responsible for the data component of the implementation life cycle for utilities of low to high complexity.
In addition to extracting, transforming and loading customer data, the ideal candidate is responsible to analyze, identify, troubleshoot, research and resolve issues throughout the implementation life cycle which includes after the customer is live on the new software platform.
Works effectively with other team members to perform in depth data analysis to write detailed data specifications and mapping which meet the customers business needs.
Responsible for identifying and working to resolve performance gaps and issues.
Analyzes data for transfer, designs and develops data migration process using Alteryx.
Conducts quality assurance testing and verification throughout the implementation lifecycle utilizing both SQL or PL/SQL, and application knowledge.
Demonstrate knowledge of working with queries/applications, including performance tuning, utilizing indexes, and materialized view to improve query performance.
Responsible of ensuring end to end data integrity throughout the system.
Uses organizational tools effectively in conjunction with sound judgement to independently make reasonable assumptions and decisions.
Delegates tasks to other team members as appropriate. With minimal oversight supports the implementation life cycle for the cross functional or interdepartmental teams.
Exhibits excellent customer service skills with both internal and external customers, which includes cross functional teams.
Take the initiative in thought leadership, innovation, and creativity.
Represent the company at conferences and networking events.
Adheres to all Meridian Cooperative corporate policies and procedures.
Travel as required.
Any additional responsibilities assigned by management.
Qualifications:
Bachelor's Degree or equivalent work experience in SQL, relational database design, and development.
5+ years of Oracle SQL and backend development experience with enterprise software systems.
3+ years of professional experience with detailed knowledge of data warehouse technical architectures, infrastructure components, and ETL development process using Alteryx or any ETL software.
3+ years of professional experience with writing, tuning and optimizing SQL complex queries.
Strong analytical, design, testing, problem-solving and time management skills.
Detail-oriented, able to manage competing priorities effectively within project timelines.
Knowledge of data integrity and relational rules
Interpersonal and communications skills, including ability to present and explain technical information within an interdisciplinary team setting.
Preferred Qualifications:
3+ years hands-on experience in any programming languages, preferably PL/SQL, C# or Java.
Understanding of, and ability to apply AGILE development methodology in performing duties.
Understanding of GIT concepts.
Understanding of putty environment and ftp process.
Alteryx experience.
DBA experience.

We Offer:

Outstanding Medical/Dental/Vision that starts on the first day of employment.
Education/Training Reimbursement
On-Site Education Courses
Flexible Spending Account
Health/Wellness Reimbursement (fitness tracking device up to $300)
Excellent Life Insurance & Disability
Vacation: 22 days of accrued time off (no waiting period). 9 holidays, which include the day after Thanksgiving & Christmas Eve. Up to 240 hours of vacation time can rollover to the following year.
Volunteer Time: 8 hours per year
Retirement: Very robust 401(k). Employees are 100% vested in the Company-funded employer basic contributions from the date they enter the plan. The Company will match 100% of each dollar you contribute on the first five percent (5%) of eligible compensation that you contribute to your account. Employer basic contribution eligibility occurs on the first day of the month following the employee’s completion of one year of continuous service (contribution of 4-11% of base salary based on years of service).
In Addition, We Also Offer:
Relaxed Dress Code
Flexible Hybrid Work Schedules: 3 days remote, 2 days onsite.
In Office Gym

About Us:
Meridian Cooperative was formed in 1976 by a group of Electric Membership Cooperatives with a vision for a single enterprise solution provider to serve data processing, IT, and operational needs to cooperatives, public utility districts, and municipal utilities. Through carefully curated acquisitions and partnerships, Meridian has unified multiple leading-edge companies under its umbrella in order to truly execute that vision. Today, the Meridian Co-op Suite serves over 500 utilities across the country with industry leading enterprise software solutions. Meridian is proud to be named as a 2022 Top Atlanta Workplace by the AJC!

Our employment practices are in accordance with the laws that prohibit discrimination against qualified individuals on the basis of race, religion, color, gender, age, national origin, physical or mental disability, genetic information, veteran’s status, marital status, gender identity and expression, sexual orientation, or any other status protected by applicable law.
Meridian Cooperative is an equal opportunity employer (Minority/Female/Disabled/Veteran).
We do not sponsor applicants for work visas.",Unknown / Non-Applicable,Enterprise Software & Network Solutions,Self-employed,Information Technology
"Senior Staff Engineer, Big Data",atlanta,"Nagarro
4.2","Atlanta, GA",4.2,-1,-1,-1,-1,-1,-1,10000+ Employees,1996,"Company Description

We're Nagarro.

We are a digital product engineering company that is scaling in a big way! We build products, services, and experiences that inspire, excite, and delight. We work at scale — across all devices and digital mediums, and our people exist everywhere in the world (18,000+ experts across 33 countries, to be exact). Our work culture is dynamic and non-hierarchical. We're looking for great new colleagues. That's where you come in!

Job Description

By this point in your career, it is not just about the tech you know or how well you can code. It is about what more you want to do with that knowledge. Were you given the tools to go beyond solving for X? Can you help your teammates proceed in the right direction? Can you tackle the challenges our clients face while always looking to take our solutions one step further to succeed at an even higher level? Yes? You may be ready to join us.

Additional Information

Click here to access the application privacy notice",$100 to $500 million (USD),Information Technology Support Services,Company - Public,Information Technology
Associate Data Engineer,atlanta,"DELUXE CORPORATION
3.3","Atlanta, GA",3.3,$68K - $100K (Glassdoor est.),3.0,3.3,3.0,3.3,3.5,5001 to 10000 Employees,1915,"The Associate Data Engineer is responsible for data ingestion and management of data for the Data Driven Marketing business at Deluxe. This role will work closely with other data professionals to design, develop and optimize data systems across the organization. This role will collaborate with the Product Management, Data Science and Compliance teams and will assist in data asset management, regulatory compliance, internal and external audits associated with supplier and/or customer data.
Job Functions:
Assist in the development, testing and optimization of data sets, data pipelines and architectures in support of customers’ product and analytic needs.
Provide ongoing operations and support of production systems to meet defined SLA’s
Work with Product Management and Data Science teams to understand how to design data solutions to meet their needs.
Maintain compliance according to supplier and/or regulatory requirements
Basic Qualifications:
Education and Experience: Bachelor’s and 0 years or HS/GED and 2 years
Familiarity with data pipeline management frameworks on cloud (AWS, Azure, Google)
Familiar with an ETL data ingestion framework/tool (e.g. Azure Data Factory, Google Data Fusion and SSIS)
Knowledge of programming languages (e.g. SQL, C#, Python and PySpark)
Knowledge of source control (e.g. GIT, Bitbucket, Beanstalk, Subversion, Codecommit)
Knowledge of software development methodologies (e.g.: Agile, Scrum, etc)
Strong problem solving, numerical and analytical skills
Strong attention to details
Strong oral and written communication skills
Ability to work with geographically distributed teams
Ability to partner with internal and external resources in solving business needs
Preferred Qualifications:
Education: Bachelors Degree
Experience: TBD
Previous experience as a data engineer or in a similar role
Familiarity with Amazon AWS/ Google GCP data solutions
Familiarity with high-volume data processing frameworks
Experience with scripting languages like Python, Bash or Powershell
Experience working with defect or incident tracking software (Jira, Bugzilla, Mantis, etc)
Familiarity of data warehouse or data lake design
Familiarity with data models, data mining, ad segmentation techniques
Familiarity with data access control and management tools
Worked in data supply chain management for a large data aggregator
Worked in data driven marketing businesses
Deluxe Corporation is an Equal Opportunity / Affirmative Action employer:
All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, disability, sex, age, ethnic or national origin, marital status, sexual orientation, gender identity or presentation, pregnancy, genetics, veteran status or any other status protected by state or federal law.

EOE/Minorities/Females/Vet/Disability
Please view the electronic EEO is the Law Poster which serves to inform you of your equal employment opportunity protections as part of the application process.
Reasonable Accommodation for Job Seekers with a Disability: If you require reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to deluxecareers@deluxe.com.

Department: Business Operations
Time Type: Full time",$1 to $5 billion (USD),Financial Transaction Processing,Company - Public,Financial Services
Senior Data Engineer,atlanta,"Dematic Corp.
3.8","Atlanta, GA",3.8,$99K - $135K (Glassdoor est.),3.6,3.7,3.3,3.5,3.2,5001 to 10000 Employees,1819,"The Senior Data Engineer position is integral to the success of the Global Data Enablement team. This role is responsible for designing and implementing modern data pipelines supporting the Enterprise Data Warehouse at Dematic. The GDE team coordinates the curation and maintenance of the Data Warehouse for an embedded team of Analysts across Dematic’s business units.
What we offer:
Dematic provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.
This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.
The base pay range for this role is estimated to be $65,000-$140,000 at the time of posting. Final compensation will be determined by various factors such as work location, education, experience, knowledge, and skills.
Tasks and Qualifications:
What You Will do in This Role:
Partner with department/function experts to identify relevant data sources including those from ERP and CRM systems
Building modern ELT data pipelines to Snowflake cloud data warehouse
Develop methods to improve transparency, reliability, and observability of integrations
Work closely with Architects to efficiently implement models and platform transformation layers
Create automated data quality monitoring for all data sources
Collect and harmonize data from disparate sources to support BI, advanced analytics, and AI/ML
Collaborate with business analysts and promote a Data Enablement/Self-Service culture
Demonstrate leadership in executing project goals as part of an agile environment
What We are Looking For:
Bachelor's Degree required.
5+ years of experience as a Data Engineer or DataOps Engineer
5+ years of experience developing with SQL Query Language
2+ years of experience with cloud-native data platform, preferably Snowflake
Proficient in Python, with emphasis on data-oriented packages
Experience working in an Agile environment
Experience utilizing orchestration tools such as Informatica, Matillion, Alteryx, etc.
Comfortable operating in a hybrid cloud environment, Microsoft Azure preferred.
Experience preparing data for BI and Data Science workloads
Familiarity with REST APIs and Messaging integrations",Unknown / Non-Applicable,Information Technology Support Services,Subsidiary or Business Segment,Information Technology
Principal-Big Data Engineer,atlanta,"AT&T
3.7","Alpharetta, GA",3.7,Employer Provided Salary:$127K - $212K,3.6,3.5,3.2,4.0,3.3,10000+ Employees,1876,"DUTIES: Create, design, and build core frameworks for cloud-based system platforms and end to end solutions. Build cloud platform and performance components. Enable data sharing across business units in support of BI and analytics related use cases. Collaborate with critical stakeholders to understand business needs, priority, and the quality of services to be created or enhanced. Drive solution to be compliant with target state architecture. Discover and identify bottleneck gaps including manual flows that can hinder services and impact cycle time. Resolve bottleneck gaps early during the solution, design, and construction phase. Drive research and standardization of platform components. Ensure integration of nonfunctional requirements such as security, scalability, resiliency, and performance in all solutions. Define and design functional, technical, performance, and reliability solutions in line with client inferred requirements. Create integrated solutions between legacy and target state solutions. Create vendor guidelines and best practices. Apply advanced knowledge of Linux and Unix. Utilize AWS. Display knowledge of Azure infrastructure including implementing, monitoring, and maintaining Azure compute, storage, network, and security services. Analyze large sets of data using Cloudera HDF NiFi, ADF, Ambari, Nifi, Kafka, Ranger, Kubernetes, and Docker. Manage data using Databricks and Hadoop. Apply knowledge of data domains of Telecomm including location, browsing, billing, and network.

REQUIREMENTS: Requires a Master’s degree, or foreign equivalent degree in Computer Science, Computer Engineering, or Electrical Engineering and Computers and two (2) years of experience in the job offered or two (2) years of experience in a related occupation building cloud platform and performance components; resolving bottleneck gaps early during the solution, design, and construction phase; creating vendor guidelines and best practices; applying advanced knowledge of Linux and Unix; utilizing AWS; displaying knowledge of Azure infrastructure including implementing, monitoring, and maintaining Azure compute, storage, network, and security services; analyzing large sets of data using Cloudera HDF NiFi, ADF, Ambari, Nifi, Kafka, Ranger, Kubernetes, and Docker; managing data using Databricks and Hadoop; and applying knowledge of data domains of Telecomm including location, browsing, billing, and network.

Our Principal Big Data Engineers earn between $127,100 - $211,900 yearly. Not to mention all the other amazing rewards that working at AT&T offers. From health insurance to tuition reimbursement and paid time off to discounts on products and services just to name a few. There is a lot to be excited about around here. Individual starting salary within this range may depend on geography, experience, expertise, and education/training.

AT&T is an Affirmative Action/Equal Opportunity Employer, and we are committed to hiring a diverse and talented workforce. EOE/AA/M/F/D/V

np*",$10+ billion (USD),Telecommunications Services,Company - Public,Telecommunications
Senior Data Engineer,atlanta,"Home Depot / THD
3.8","Atlanta, GA",3.8,Employer Provided Salary:$170K,3.6,3.8,3.4,3.6,3.5,10000+ Employees,1978,"Position Purpose
As the Senior Data Engineer and Technical Product Manager within Online and Marketing Analytics & BI, you will be responsible for development of the feature mart platform enabling the onsite and offsite personalization. You will ensure that the data pipeline infrastructure meets the analysis, reporting, and data science needs of the online and marketing organization. This position calls for top technical talent to implement continued design, development and optimization of the data pipelines & data prep infrastructure built on cutting-edge cloud technologies.
Additional Roles & Responsibilities
Driving product vision and strategy, and creating capabilities that data science teams can leverage when building solutions for onsite and offsite personalization
Apply strong technical skills in a data engineering team building industry-leading technology
Embrace an active team role to help design, implement, and launch efficient and reliable data pipelines moving data across a number of platforms including Data Warehouse, online caches and real-time systems.
Create data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Deploy workflow orchestration and demonstrate expertise in data modeling, feature engineering and data warehousing
Build industry-leading tools to increase productivity of Data Analysts, Data Scientists and Marketers
Help Online and Marketing organization to become a 100% data-driven organization by building a next generation data platform that brings accurate and timely data
Validate Data Engineering business data elements, organizational and business intelligence architecture designs for engineering functional areas from Dashboards, Data Lakes, Data Operations, ML - AI, and upstream/downstream intake and output processes
Evangelizing product roadmap internally and externally in informal and formal settings.

Key Responsibilities:
50% Design and develop robust, user friendly applications, reports and dashboards using BI tools like Microstrategy and SAS
25% Partner with leaders to identify needs and gather requirements. Provide solutions by building tools, reports and predictive models. Automate reporting as needed
25% Research and document best practices and standards for using our BI tools. Provide insight on industry trends

Direct Manager/Direct Reports:
Position reports to Sr Manager or Manager, Online Business Intelligence.
Position has no direct reports.

Travel Requirements:
Typically requires overnight travel less than 10% of the time.

Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.

Working Conditions:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.

Minimum Qualifications:
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.

Preferred Qualifications:
BA/BS Degree in Computer Science, any Engineering discipline, Statistics, Information Systems or another quantitative field.
4+ years of industry experience in data engineering, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets
Experience building and managing data pipelines and repositories in cloud environments such as Google Cloud, Microsoft Azure or AWS
Experience in Airflow is a must
Experience extracting/cleansing data and generating insights from large transactional data sets using Spark SQL, SQL, Python, and PySpark on cloud
Experience with optimizing Spark pipelines on Dataproc, Databricks or similar technologies.
Strong verbal and written communications skills at all levels; ability to communicate complex customer behavior information to both functional partners and Executive Leadership
Open to idea exploration with strong problem-solving/analytical abilities
Demonstrated strength in creating partnerships and in building relationships with other functions and associates within the organization

Minimum Education:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.

Preferred Education:
No additional education

Minimum Years of Work Experience:
3

Preferred Years of Work Experience:
No additional years of experience

Minimum Leadership Experience:
None

Preferred Leadership Experience:
None

Certifications:
None

Competencies:
Strong decision making and problem solving skills
Proficiency in Microsoft Excel and Access
Ability to lead and manage cross functionally
Strong organizational, analytical and customer service skills
Positive, upbeat, can-do, professional and responsible attitude, independent and self-directed yet also team oriented
Influential; practiced in negotiating with others in ways that result in win-win outcomes.",$10+ billion (USD),Home Furniture & Housewares Stores,Company - Public,Retail & Wholesale
Data Engineer,atlanta,"OneSource Regulatory
5.0","Atlanta, GA",5.0,$88K - $121K (Glassdoor est.),4.4,5.0,5.0,5.0,5.0,1 to 50 Employees,Company - Private,"Company Introduction
OneSource Regulatory Technology hosts a number of innovative solutions to enhance job performance in the Pharmaceutical space. OSR Technology is looking for an experienced and dedicated data engineer to join our product solutions team!

Job Description
OneSource Regulatory is trying to identify a full-time contractor with at least 4+ years of experience to assist us with ongoing R&D projects.
We are looking for a data engineer to pull data from various sources and do all the necessary steps to clean, normalize, possibly annotate, and finally load the data into databases. The candidate should be able to develop and implement a strategy for testing the data integrity of the collected data. This role requires extreme attention to detail to ensure data quality is top priority.

Responsibilities
Well versed in parsing and synthesizing of XML and/or JSON documents.
Curating of data that can involve some intermediate to advanced web scraping. (data may need to be fetched via SFTP, FTP, Wget, Curl, REST APIs, GraphQL queries from spots on the Internet)
Proficiency with Linux command line and various simple tools, such as grep, wc, sed, awk, find, ls, cat, piped commands and possibly some very light Bash shell scripting, setting up crontab schedules and programs
Must have basic knowledge of SQL with the following databases: PostGres, MySQL, Google BigQuery
Must have basic knowledge of No-SQL database knowledge such as MongoDB or similar
Familiarity with basic Cloud technology such as storage buckets, cloud serverless functions
Must have experience extracting text and images from PDF files
Knowledge of Puppeteer or other automatable web client technologies
Understanding JavaScript, HTML/CSS and HTTP methods (for understanding page structure for web scraping)

Skills
Solid experience with Python and Python Libraries such as Pandas, requests, etc
Skill set should match up with required responsibilities listed above
Strong English skills (e.g. grammatical analysis and rhetorical structure)
Team Player
Great communication skills

Bonus Skills
Experience within the Pharmaceutical Space
Ability to expose data via C# NETCore and/or GraphQL
Google Cloud Platform (Cloud Buckets, Google Cloud Functions (.NET, Python, Node.JS))
Ability to parallelize data manipulation and scraping via Python multi-threading, etc.
Python BeautifulSoup
Scrapy
Docker (setting up Kubernetes style processing if warranted for data scraping/data ingestion/normalization)
Multithreading concepts",-1,-1,Unknown / Non-Applicable,-1
"Engineer I, Cloud Data Platforms",atlanta,"Pilot Company
3.3","Roswell, GA",3.3,-1,-1,-1,-1,-1,-1,10000+ Employees,1958,"Company Description

Pilot Company is an industry-leading network of travel centers with more than 30,000 team members and over 750 retail and fueling locations in 44 states and six Canadian provinces. Our energy and logistics division serves as a top supplier of fuel, employing one of the largest tanker fleets and providing critical services to oil operations in our nation's busiest basins. Pilot Company supports a growing portfolio of brands with expertise in supply chain and retail operations, logistics and transportation, technology and digital innovation, construction, maintenance, human resources, finance, sales and marketing.
Founded in 1958 by Jim A. Haslam II and currently led by CEO Shameek Konar, our founding values, people-first culture and commitment to giving back remains true to us today. Whether we are serving guests, a fellow team member, or a trucking company, we are dedicated to fueling people and keeping North America moving.
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.

Job Description

The purpose of this job is to contribute to projects and the implementation of platforms and services to ensure high reliability, performance, and adoption of purpose-built cloud databases and data platforms.
Contribute to the provisioning, configuration, upgrading, and patching of cloud database services and data platforms
Contribute to work to meet near-zero RTO and RPO for cloud database services and data platforms including backups, high availability, and disaster recovery
Contribute to projects to improve or replace underperforming cloud database services or platforms
Work with purpose-built database technologies to optimize application performance, availability, and durability
Contribute to work to properly secure database services and data platforms including access control, encryption, integration, and auditing
Create and maintain documentation to support any service, platform, or process relating to cloud databases and platforms
Ensure changes and enhancements to cloud database services and platforms are in line with defined and approved architectures
Contribute to work to automatically scale cloud database services and data platforms
Contribute to standards and best practices for cloud database services and data platforms
Contribute to training plans for cloud database services and data platforms
Monitor costs associated with cloud database services and data platforms; make recommendations for cost optimization, ensure provisioned capacity is being used appropriately, and ensure protections are in place to prevent runaway costs
Contribute to work on proofs of concept for new database services and data platforms
Model behaviors that support the company’s common purpose; ensure guests and team members are supported at the highest level
Ensure all activities are in compliance with rules, regulations, policies, and procedures set forth by manager
Complete other duties as assigned

Qualifications
Bachelor’s degree in computer science, business administration, information technology, or related field required
Minimum three years’ technology operations experience with strong understanding of data structures, theories, principles, and practices required
Minimum one years’ experience with Amazon Web Services
Experience with AWS Database Services preferred
Basic understanding of structured query language
Basic knowledge of some AWS Database Services – RDS, Aurora, DynamoDB, Redshift, Elasticache, MemoryDB, DocumentDB, Neptune, QLDB, Keyspaces, etc…
Basic knowledge of either Snowflake or Redshift cloud data warehouse technologies
Basic knowledge of Databricks and its intended use
Basic knowledge of some other AWS services – Backup, S3, CloudTrail, CloudWatch, KMS, CLI, DMS, CostExplorer, ControlTower, SecretsManager
Basic knowledge of High Availability (HA) and Disaster Recovery (DR) solutions for AWS database services
Solid understanding of information security policies and how they relate with database services and platforms

Additional Information
This position is on-site at our Atlanta, GA (Rosewell) location
Nation-wide Medical Plan/Dental/Vision
401(k)
Flexible Spending Accounts
Adoption AssistanceTuition Reimbursement
Weekly Pay
Team Member Fuel Discounts
All your information will be kept confidential according to EEO guidelines",$10+ billion (USD),Convenience Stores,Subsidiary or Business Segment,Retail & Wholesale
Azure Big Data Engineer,atlanta,"Graphic Packaging International
3.3","Atlanta, GA",3.3,$94K - $134K (Glassdoor est.),3.2,2.9,2.8,3.4,2.8,10000+ Employees,1995,"MISSION / SUMMARY:

GPI is on the journey to build its Cloud data platform on Azure. The Big Data Engineer will be a very critical role that reports to Director- Data Technology & Operations will execute the data strategy for ingesting large volumes of data from multiple IT systems, SAP & Non-SAP ERP platforms, IoT data from our Paper Mills and Converting plants to build Enterprise data models.

JOB FUNCTIONS: Job functions include but are not limited to the following.
Architecting, designing, and implementing advanced analytics capabilities.
Build, Expand and optimize data and data pipeline architecture, as well as optimizing data flow.
Support software developers, database architects, data analysts and data scientists on data initiatives and ensure data delivery architecture is consistent throughout ongoing projects
Work with large datasets from Enterprise systems.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources like SAP, Semi-structured data etc using SQL and AZURE ‘big data’ technologies
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics
Work with Cross functional teams to assist with data-related technical issues and support their data infrastructure needs.
Continuously improve / optimize the in production systems.

BACKGROUND / EDUCATION/ EXPERIENCE:
8 to 10 Years of IT industry experience
5 to 7 Years Designing and implementing highly performance data ingestion & transformation pipelines from multiple sources using Databricks and ADF Azure Pipelines.
Domain and Data Modeling Experience with SAP/SAP BW.
Experience in Developing scalable and re-usable frameworks for ingestion and transformation of large data sets.
Experience building data lakes & data warehouses to support operational intelligence and business intelligence
Integrating the end to end data pipeline to take data from source systems to target data repositories ensuring the quality and consistency of data is maintained at all times.
3 Year's Experience with Optimization and Tuning Experience.
3 to 5 Year's experience with Azure Synapse, IOT hub, Event hub, Streaming analytics.
3 to 5 Year's experience with Github or other code repositories.
Good Understanding of Azure Cloud Architecture
Strong programming experience with back end languages such as Python and SQL
Strong Experience with Orchestration tools like Airflow


Required Skills

Required Experience

At Graphic Packaging International, we produce the paper cup that held your coffee this morning, the basket that transported those bottles of craft beer you enjoyed last weekend, and the microwave tray that heated your gourmet meal last night. We’re one of the largest manufacturers of paperboard and paper-based packaging for some of the world’s most recognized brands of food, beverage, foodservice, household, personal care and pet products. Headquartered in Atlanta, Georgia, we are collaborative, diverse, innovative individuals who create inspired packaging while giving back to our communities. With over 25,000 employees working in more than 130 locations worldwide, we strive to be environmentally responsible in our industry and in the communities where we operate. We are committed to workplace diversity and offer compensation and benefits programs that are among the industry’s best to reward the talented people who make our company successful. If this sounds like something you would like to be a part of, we’d love to hear from you. Learn more about us at www.graphicpkg.com.

Inspired Packaging. A World of Difference.
Graphic Packaging is an Equal Opportunity Employer. All candidates will be evaluated on the basis of their qualifications for the job in question. We do not base our employment decision on an employee's or applicant's race, color, religion, age, gender or sex (including pregnancy), national origin, ancestry, marital status, sexual orientation, gender identity, genetic identity, genetic information, disability, veteran/military status or any other basis prohibited by local, state, or federal law. Click here to view the Poster, EEO is the Law.",$1 to $5 billion (USD),Machinery Manufacturing,Company - Public,Manufacturing
"Senior Data Engineer, Business Intelligence",atlanta,"MerchantE
3.5","Alpharetta, GA",3.5,$91K - $132K (Glassdoor est.),3.6,3.9,3.4,4.2,3.9,201 to 500 Employees,2000,"Who Are We?
MerchantE is an innovative, technology-focused company providing a full-service platform to support the payment processing needs for merchants of all sizes, including small business retail shops, B2B wholesalers, and global eCommerce enterprises. We partner with financial institutions, software developers, independent sales organizations, and agents to bring our solutions to market.
Why Join Us?
We're growing and we're looking for collaborative, innovative, and hard-working individuals to grow with us! We offer a modern and inspiring work environment where your ideas and contributions are valued. Come experience, first-hand, the impact of your contributions.
The Opportunity:
As we are embarking on our journey to a modern architecture on the cloud, we are looking for talented engineers to join us to build our future. You will get an opportunity to work on challenging problems in a high-volume and mission critical environment.
US WORK AUTHORIZATION REQUIRED - No visa sponsorship is available for this position at this time.
Your Responsibilities will require you to:
Design, implement, and maintain systems used to collect and analyze business intelligence data
Create dashboards, databases, and other platforms that allow for efficient collection and evaluation of BI data
Build the reporting data model and help the data engineering team with creating views, SQL scripts
Perform ETL/ELT and SQL coding using AWS cloud-based solutions and downstream enablement in analytics
Provide data engineering with functional and technical requirements to improve efficiency of data pipelines.
Develop complex data models and design patterns for BI/Analytics reporting requirements
Design and develop scalable reporting, dashboards and data solutions using analytics
Take part in requirements gathering, logical design, physical design, implementation, testing, and deployment.
Provide best practices and guidance regarding the use of ELT/ETL, data modeling, and reporting deliverables.
Perform dataflow, system and data analysis and develop meaningful and useful presentation of data in BI applications
Collaborate closely with internal and external teams to understand and apply changes/modifications impacting data warehouse
Qualifications
Bachelor's Degree in Computer Science or related technical field.
Experience with Postgres, SQL, ETL, BI Tools
4+ years of experience delivering ETL processes and data visualization tools, including extracting data from various sources, modeling, and analysis.
At least 4 years of work experience in application development: specifically Java
(Internship experience does not apply)
BI report design, development, and implementation
Experience writing and executing complex SQL queries
Preferred Qualifications:
Master's Degree in Computer Science or related technical field.
2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
2+ years of data warehousing experience (Redshift or Snowflake)
2+ years of experience with Agile engineering practices
#LI-KB1
MerchantE is an Equal Opportunity Employer committed to a diverse workforce.",$100 to $500 million (USD),Financial Transaction Processing,Company - Private,Financial Services
Senior Data Engineer/Lead (Strong Databricks),atlanta,"Crackajack Solutions
3.3","Alpharetta, GA",3.3,Employer Provided Salary:$70.00 - $80.00 Per Hour,5.0,5.0,5.0,5.0,4.0,1 to 50 Employees,Company - Public,"Senior Data Engineer (Strong Data bricks)
Alpharetta, GA(Hybrid)
9-12 Months
The Databricks Engineer role will be part of our client’s Data Engineering practice team and will be focused on building Data pipelines and Data processing solutions based on AWS platform for Digital Marketing domain.
The candidate will contribute to Competency development & driving innovation through various internal initiatives within the organization. Databricks Engineer should have more than 3 years of experience with broad exposure to AWS services relevant to Analytics and Data engineering.
Description
Over 10+ years’ experience as a Data Engineer including extensive experience in Databricks.
Experience in Spark, SQL performance tuning, and optimization.
Experience with architectural design and development of large-scale data platforms and data applications.
Good hands-on experience in AWS services like EC2, S3, RDS, KMS, IAM, STS, Redshift etc.
Good knowledge and experience in creating, securing, and managing Databricks clusters of Amazon Elastic Compute Cloud (Amazon EC2) instances.
Strong programming background with Java, Python and Pyspark.
Practical exposure to end-to-end design and implementation process of Near-Real-Time and Batch Data Pipelines.
Strong knowledge and understanding of Databricks Lakehouse Platform.
Knowledge of Databricks scheduling features to automate Databricks jobs.
Strong knowledge and experience in Databricks Lakehouse platform and Delta Lake.
Experience in managing, using and scheduling notebooks in Databricks.
Good experience in integrating and ingesting data from external data sources with Databricks including automating ETL using Delta Live Tables and Databricks Autoloader.
Strong SQL (Hive/Spark/Databricks) skills and experience tuning complex queries.
Good to have Databricks Lakehouse Data Engineer Associate or Data Engineer Professional certification.
Job Type: Contract
Pay: $70.00 - $80.00 per hour
Experience level:
10 years
11+ years
Schedule:
8 hour shift
Monday to Friday
Ability to commute/relocate:
Alpharetta, GA 30009: Reliably commute or planning to relocate before starting work (Required)
Education:
Bachelor's (Preferred)
Experience:
Data Engineer: 10 years (Preferred)
Data Lake, Data IKU, Hadoop: 10 years (Preferred)
Databricks: 5 years (Preferred)
Python/Java: 10 years (Preferred)
Work Location: In person",-1,-1,Unknown / Non-Applicable,-1
Senior Software Engineer - Data Technologies,atlanta,"PRGX Global, Inc
3.7","Atlanta, GA",3.7,$97K - $136K (Glassdoor est.),3.3,3.5,3.4,3.1,4.0,1001 to 5000 Employees,1996,"SENIOR SOFTWARE ENGINEER, DATA INTELLIGENCE TECHNOLOGIES
This position is responsible for creating high priority differentiated technology solutions that solve important real-world problems. The position partners closely with the Head of Data Analytics, data scientists, business leaders, clients, and other stakeholders to create roadmaps, scope programs aligning with business priorities, define milestones and success metrics, and create scalable, secure, reliable, and efficient data products and platforms which meet our clients’ needs and contribute to the growth of PRGX.

Job Responsibilities:
Participate in the conceptualization of new products.
Work with our data scientists to turn large-scale, diverse, and often unstructured data into a meaningful source of insights for our clients.
Design, develop, deliver, implement, and maintain high-quality, secure, reliable, and scalable data applications on time and on budget.
Design, code, configure, test, and document deliverables using agile methodologies.
Collaborate with key stakeholders on coding standards, processes, tools, and frameworks required for the delivery of features.
Guide technical and design decisions based on experience.
Develop proof of concept work and prototyping when necessary.
Collaborate with business leaders to understand business requirements relating to features to be delivered.
Identify common patterns and foster development of reusable components and standards.
Contribute to an innovation culture by evaluating new processes and technologies that can be used to enhance future features.

Ideal Candidate Characteristics:
Enjoys and excels in environments where they must tackle and solve new and increasingly complex client business challenges and issues, incorporating the newest ideas and technologies to deliver solutions quickly.
Possesses a high level of self-awareness. Maintains composure and professionalism when under pressure.
Possesses strong systems and critical thinking skills and the ability to draw on disparate information to identify insights, and design and deliver solutions.
Driven to meet or exceed specific goals and objectives as quickly as possible.
Entrepreneurial spirit. Forward-thinking and adaptable in dynamic situations. Knowledge & Qualifications:
Bachelor’s degree in Computer Science, Computer Engineering, or related field. Master’s degree preferred.
Minimum of 10 years’ software development experience.
Minimum of 5 years’ experience working with complex data sets and developing data-centric applications.
Minimum of 5 years’ experience with commercializing and scaling white label Qlik applications.
Experience with big data and big data tools such as SQL and Python.
MySQL, Spark, Scala, Hive, Minio, Trino, Airflow, Presto and other ETL solutions experience desired.
Experience in CPG manufacturing, wholesale, distribution, or retail is highly desirable, and preference will be given to candidates with this experience.
Strong strategic thinking and problem-solving skills.
• Excellent communication, collaboration, and leadership skills. • Ability to build and maintain relationships with key stakeholders.
Strong business acumen.",$25 to $100 million (USD),Accounting & Tax,Company - Public,Financial Services
"Senior Staff Engineer, Big Data",atlanta,"Nagarro
4.2","Atlanta, GA",4.2,-1,-1,-1,-1,-1,-1,10000+ Employees,1996,"Company Description

We're Nagarro.

We are a digital product engineering company that is scaling in a big way! We build products, services, and experiences that inspire, excite, and delight. We work at scale — across all devices and digital mediums, and our people exist everywhere in the world (18,000+ experts across 33 countries, to be exact). Our work culture is dynamic and non-hierarchical. We're looking for great new colleagues. That's where you come in!

Job Description

By this point in your career, it is not just about the tech you know or how well you can code. It is about what more you want to do with that knowledge. Were you given the tools to go beyond solving for X? Can you help your teammates proceed in the right direction? Can you tackle the challenges our clients face while always looking to take our solutions one step further to succeed at an even higher level? Yes? You may be ready to join us.

Additional Information

Click here to access the application privacy notice",$100 to $500 million (USD),Information Technology Support Services,Company - Public,Information Technology
Cloud Data Application Engineer,atlanta,"Graphic Packaging International, Inc.
3.3","Atlanta, GA",3.3,$71K - $97K (Glassdoor est.),3.2,2.9,2.8,3.4,2.8,10000+ Employees,1995,"POSITION SUMMARY:
The mission of this position is to analyze business issues and to identify and develop solutions to meet the needs. The engineer will formulate and defines objectives based on both business needs and a solid understanding of best practices. This position may also assist in routine maintenance for specific modules in the company’s suite of business applications which will involve understanding of SQLs simple and complex and Stored procedure. This position collaborates with business process owners to foster a positive IT customer relations environment. All the work this position involves will include On-Premise and Cloud platform understanding.

PRIMARY RESPONSIBILITIES are, but not limited to the following:
Support and manage Cloud based implementations.
Strong and demonstrable knowledge of writing and debugging complex SQL , Stored procedures.
Serve as a point of contact for System related escalations.
Act as a liaison between Cloud IT , Business and functional teams.
Support cloud-focused technology initiatives
Motivated problems solver who can identify the source of the problem in data and proactively work to solve it.
Ability to multitask and adapt in a fast paced customer focus environment.
Implement new processes and improve existing processes around data visibility and analysis.
Recommend solution to fix data issues.
Work Independently with little supervision.
Strong Communication skills

JOB REQUIREMENTS:
5 years of experience in software development.
2 years' experience in Azure cloud environment.
2 years' experience with databases like SQL Server, Oracle and/or other relational databases.
Strong Experience with SQL Simple and Complex.
Experience with Visualization tools like Qlik Sense, Power BI etc.
Experience with cloud based data solutions
Knowledge of cloud infrastructure and best practices.
Working Experience on GIT hub
Experience with working in Agile development process.
Experience working with CICD and DevOps
Working knowledge of Python

Educational Requirements:
4-year college degree in general or IT-Related field required. Equivalent work experience considered
Other Required Skills:
Demonstrated perceptual and analytical thinking
Excellent interpersonal communication skills and ability to translate technical information into language non-technical people will understand
Fortitude to demand excellence from self and others
Demonstrate ability to work effectively in a team environment.


Required Experience

At Graphic Packaging International (NYSE: GPK), we produce the box you may have poured your child's cereal from this morning, the microwaveable tray that heated your lunch, the paper cup that held your coffee throughout the day, and the carrier of those bottles of craft beer you may enjoy tonight! We're one of the largest manufacturers of paperboard and paper-based packaging for some of the world's most recognized brands of food, beverage, foodservice, household, personal care and pet care products. Headquartered in Atlanta, Georgia, we are a team of collaborative, innovative, passionate individuals who are committed to providing consumer packaging that makes a world of difference.


With almost 18,000 employees working in more than 70 locations in North and South America, Europe and the Pacific Rim, we strive to be an environmentally responsible leader in our industry and in the communities where we operate. We are committed to workplace diversity and offer compensation and benefits programs that are among the industry's best to reward the talented people who make our company successful.

If this sounds like something you would like to be a part of, we'd love to hear from you. Learn more about us at www.graphicpkg.com.

Inspired Packaging. A World of Difference.

Graphic Packaging is an Equal Opportunity Employer. All candidates will be evaluated on the basis of their qualifications for the job in question. We do not base our employment decision on an employee's or applicant's race, color, religion, age, gender or sex (including pregnancy), national origin, ancestry, marital status, sexual orientation, gender identity, genetic identity, genetic information, disability, veteran/military status or any other basis prohibited by local, state, or federal law. Click here to view the EEO is the Law Poster",$1 to $5 billion (USD),Machinery Manufacturing,Company - Public,Manufacturing
Data Engineer,atlanta,"Genuine Parts Company
3.5","Atlanta, GA",3.5,$81K - $123K (Glassdoor est.),3.0,3.2,3.0,3.1,3.3,5001 to 10000 Employees,1928,"Company Background:
Genuine Parts Company (“GPC” or the “Company”), founded in 1928 and based in Atlanta, Georgia, is a leading specialty distributor engaged in the distribution of automotive and industrial replacement parts and value-added services. The Company operates a global portfolio of businesses with more than 10,000 locations across the world. GPC has approximately 50,000 global employees. The Company has operations in the United States, Canada, Mexico, Australia, New Zealand, Indonesia, Singapore, France, the U.K., Germany, Poland, the Netherlands, Belgium, Spain and China.

Position Purpose:
Seeking world-class talent to join the world’s leading distributor of automotive and industrial replacement parts and value-added services operating 5,500+ locations and servicing more than 20,000 locations in the U.S and Canada. Specifically, this role will function as the engineer to build the next generation commerce platforms for GPC. Working with a highly talented team, you'll play a key role to build and run one of the world’s largest automotive and industrial replacement parts operations.

This is an engineering role with responsibility for enabling cloud transformation and execution for GPC’s unified Data platforms.

This individual must be a technologist & engineer at heart and be comfortable in enabling new technology and being hands on with the execution of the strategy. They must exhibit a deep understanding of modern technology stack and agile delivery models, demonstrated focus on customer experience, and must have a proven track record of modernizing technologies.

Close collaboration and alignment with business teams, application development teams and security will be required. As such, exceptional abilities in building and maintaining strong working relationships and organizational savvy will be required. High level communication and presentation skills are required. Ability to attract, retain, and develop engineering talent will be critical.

Responsibilities:
The Data Engineer performs design, development and implementation of integration processes for both the Enterprise Data lake, Data Warehouse and Applications
Analyzes requirements and existing resources to create efficient database and integration designs that meet company IT standards.
Works with project and business analyst leads to develop and clarify in-depth technical requirements.
Participates in all phases of the integration development lifecycle, including unit testing, quality assurance (QA) and ongoing support.
Helps with Production support as needed
Helps define and adheres to team working agreements
Daily attend team standups and agile ceremonies
Collaborate and work closely with other teammates to achieve team goals and outcomes
Have a “test-first” attitude with a focus on automation
Employ best practices around observability, monitoring, and system resilience
Other duties as assigned

Location:
GPC has two work locations to choose from, Duluth or Atlanta office.
We offer a Flexible Work Policy that permits eligible employees to work remotely

Desired Qualifications & Experiences:
Five or more years’ experience (preferred) in software engineering.
Five or more years’ experience (preferred) in large scale RDBMS environments or Google BigQuery
Two or more years (preferred) of Exadata experience OR Google BigQuery
Four or more years (preferred) experience with Informatica PowerCenter or IICS
One or more years experience (preferred) in Erwin
Experience in code automation (e.g. pattern based integration)
Experience in advanced SQL and PL/SQL techniques
Experience in building re-usable Utility packages
Experience with testing the code
Focus on continuous improvement
Experience in Unix shell and Python scripting
Integration design & data modeling skills in Data lake and Data Warehousing environments
Experience with Streaming technologies is a plus( STRIIM, Kafka, etc)
Experience with other Informatica tools is plus – e.g., Metadata manager, Analyst, DVO, Data Quality
Exposure to both on-prem and cloud Integration solutions
Familiarity with non-relational DB technologies is a plus
Experience with automated testing
Experience with both batch and real-time patterns for integrations
Ability to build and analyze complex integration workflows from heterogeneous data sources
Experienced in large Enterprise Data Warehouse & Integration projects.
Strong background in full lifecycle development using multiple platforms or languages.
Ability to interact at a technical and non-technical level with Infrastructure, Network, Development, BA and QA teams.
Development experience in high transaction/high availability systems.
Experience with analyzing and recommending solutions for Production issues short-term and long term
Degree in Computer Science or Engineering fields, or equivalent experience",Unknown / Non-Applicable,Automotive Parts & Accessories Stores,Company - Public,Retail & Wholesale
"Senior Backend Engineer, Data",atlanta,"Recruiting From Scratch
3.9","Atlanta, GA",3.9,Employer Provided Salary:$120K - $200K,4.0,3.6,3.5,3.9,3.9,1 to 50 Employees,2019,"Who is Recruiting from Scratch:
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
From our client
We’re looking for engineers to join our founding team and help us invent the future of data analytics. We’re interested in talking to talented engineers up and down the stack, but for this role we're focused on engineers that lean towards backend and distributed systems development.
We’re an early team so we’re still establishing large parts of our software stack - you will have major ownership over the product and you’ll help us pick the right technologies. We have a culture of autonomy and ownership and want engineers who are excited to drive the company forward. As an early employee you’ll help us craft our culture and will be aware of (or participate in) customer development and go to market.

About you:
You love to build high-quality, reliable, well-tested systems that solve real problems.
You have experience designing scalable, reliable architectures that are secure and compliant.
You have experience identifying performance bottlenecks, triaging system failures and coming up with innovative solutions to prevent these failures in the future.
You are excited to research, drive, and own our data processing infrastructure.

Nice-to-have:
Experience building data analytics applications.
Experience building products in a regulated field.
Familiarity with our current application stack: Python, React / Redux, GraphQL, Redis, Flask, Celery, and Docker.
Experience using AWS services like S3, DynamoDB, and Cloudwatch.
Experience with analytics DBMS’s like Presto, BigQuery, Hive, Redshift and Snowflake.
Experience with data processing technologies like Spark, Dask, Presto, and Apache Arrow.
This role is on-site in New York City
Salary Range: $120,000-$200,000 base.",$1 to $5 million (USD),Staffing & Subcontracting,Company - Private,Human Resources & Staffing
Data Engineer Senior,atlanta,"Acuity Brands
3.6","Conyers, GA",3.6,$78K - $109K (Glassdoor est.),3.4,3.4,3.3,3.4,3.4,10000+ Employees,2001,"We Light the Way!

Acuity Brands, Inc. (NYSE: AYI) is a market-leading industrial technology company. We use technology to solve problems in spaces and light. Through our two business segments, Acuity Brands Lighting and Lighting Controls (“ABL”) and the Intelligent Spaces Group (“ISG”), we design, manufacture, and bring to market products and services that make the world more brilliant, productive, and connected. We achieve growth through the development of innovative new products and services, including lighting, lighting controls, building management systems, and location-aware applications.
Job Summary
Acuity’s Business Intelligence team is comprised of people who are passionate about data. We believe accurate, timely and understandable data is vital to a data driven culture. We are devoted to aligning Acuity’s data to serve the needs of the enterprise and its customers. You will be joining a team of seasoned Business Intelligence professionals well versed in architecting bespoke BI (Business Intelligence) applications and implementing Microsoft Azure BI products.
We are seeking a talented and enthusiastic individual to be a Senor Data Engineer on our Business Intelligence Team as we transform Acuity Brands analytics and migrate our BI platform to Azure and Power BI. This position will work closely with BI Architects to bring to deliver end to end BI solutions that are innovative, scalable, and responsive.
Key Tasks & Responsibilities (Essential Functions)
Research, architect, drive, and deploy scalable, resilient cloud agnostic BI solutions to address Acuity current and future business needs and obligations
Partner with Data Architect, Solution Architect, and BI Product Managers to drive technology transformation on the BI platform to ensure the BI platform remains current and responsive
Mentor and guide Senior BI Developers to ensure adherence to BI standards and procedures
Partner with Data Architect to deliver integrated end to end data engineering solutions
Write application and cloud-based data processing code to transform inbound data to meet business requirements
Design and develop data models leveraging advanced modeling techniques to handle large and or complex data
Modify and optimize data engineering processes to handle ever-growing, complex, diverse data formats, sources, and pipelines
Work with infrastructure partners to tune and optimize code and BI resources such as but not limited to (index tuning, partitioning, caching, buffer tuning, and data archiving strategies.
Proactively estimate and plan development work and track performance to deliver work on schedule
Create and maintain current documentation in GIT (c4 and Plant UML)
Education (minimum education required)
Bachelor of Science
Preferred Education (i.e. type of degree)
Bachelor of Science in Computer Science or Information Systems
Experience (minimum experience required)
Bachelor’s Degree in Computer Science, MIS (Management Information System), or other technical/analytical field (or equivalent experience)
2 Azure Certifications
Working knowledge of data warehousing principles (Kimball, Inmon, Hybrid)
4-7 years or more database programming experience (SQL (preferred), Oracle, DB2)
4-7 years or more of BI experience (Power BI, Tableau, Qlik Sense/View, D3.js, SAP Business Objects, IBM Cognos)
4-7 years or more of working with Microsoft BI stack (SSIS, SSAS, T-SQL)
4-7 years or more of developing and enhancing ETL packages
4-7 years or more of working with and or constructing API (Push, Get, Post)
4-7 years or more of advanced experience identifying and optimizing database objects
2 years or more of application development (C# or .NET)
3 years or more experience working in Python or Scala
We invite you to apply today to join us as We Light the Way to a Brilliant, Productive, and Connected World!

We value diversity and are an equal opportunity employer. All qualified applicants will be considered for employment without regards to race, color, age, gender, sexual orientation, gender identity and expression, ethnicity or national origin, disability, pregnancy, religion, covered veteran status, protected genetic information, or any other characteristic protected by law.
Please click here and here for more information.

Accommodation for Applicants with Disabilities: As an equal opportunity employer, Acuity Brands is committed to providing reasonable accommodations in its application process for qualified individuals with disabilities and disabled veterans. If you have difficulty using our online system due to a disability and need an accommodation, you may contact us at (770) 922-9000. Please clearly indicate what type of accommodation you are requesting and for what requisition.

Any unsolicited resumes sent to Acuity Brands from a third party, such as an Agency recruiter, including unsolicited resumes sent to an Acuity Brands mailing address, fax machine or email address, directly to Acuity Brands employees, or to Acuity Brands resume database will be considered Acuity Brands property. Acuity Brands will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.

Acuity Brands will consider any candidate for whom an Agency has submitted an unsolicited resume to have been referred by the Agency free of any charges or fees. This includes any Agency that is an approved/engaged vendor, but does not have the appropriate approvals to be engaged on a search.

E-Verify Participation Poster
e-verify.gov
eeoc.gov",$1 to $5 billion (USD),Electronics Manufacturing,Company - Public,Manufacturing
Security Data Engineer,atlanta,"Koch Global Services
3.8","Atlanta, GA",3.8,$75K - $116K (Glassdoor est.),3.9,3.9,3.4,3.7,3.7,10000+ Employees,1940,"Description
Your Job

The Koch Cyber Security Team is seeking a Security Data Engineer to join our global cyber security team. As a member of this team your primary duties will be to attend to the health and support of our SIEM tool and work closely with our analyst to ensure that data is available to them when needed.
Our Team

The Koch Cyber Security team is a dynamic and proactive force, fueled by an unwavering commitment to Koch's vision for value creation. With a relentless drive, we tackle cyber threats head-on, always ready to protect our stakeholders from any potential harm. Our team members are trailblazers, spearheading transformational efforts in areas such as Incident Response, Automation, exposure management, awareness, and the ever-evolving cyber landscape. We thrive on challenges and constantly seek innovative solutions to safeguard our organization and its interests.
What You Will Do
Oversee the ingestion and normalization of new data sources.
Maintain data availability
Detect and remediate any drop in data ingestion
Support, maintain and improve infrastructure for the data collection tools overall health
Respond to customer inquiries surrounding the collection of data
Work closely with Cyber Security team to ensure that analyst have access to the data they need and that it’s presented in a clear and concise manner
Stay up to date with the latest trends and technologies in data engineering and cloud infrastructure management and applying them to our data collection tool stack
Actively seek ways to improve our current data collection tool stack.
Who You Are (Basic Qualifications)
Experience supporting a SIEM tool at a global enterprise level
Experience deploying Infrastructure in cloud environments
Experience building and troubleshooting data pipelines.
What Will Put You Ahead
Experience with Global Information\Cyber Security Teams
Experience with Machine Learning
Experience with Multiple Operating Systems
Knowledge with PowerShell, JavaScript, or Python Scripting
Windows Or Linux Administration Experience
SOAR Platform Experience
Familiar with CIM date compliance
At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate’s knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.
Hiring Philosophy
All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here.
Who We Are
As a Koch company, Koch Global Services (KGS) creates solutions spanning technology, human resources, finance, project management and anything else our businesses need. With locations in India, Mexico, Poland and the United States, our employees have the opportunity to make a global impact.

At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.
Our Benefits
Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.
Equal Opportunities
Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf",$10+ billion (USD),Energy & Utilities,Company - Private,"Energy, Mining & Utilities"
"Lead Software Engineer, Data Engineering",atlanta,"S&P Global
4.1","Atlanta, GA",4.1,Employer Provided Salary:$85K - $170K,3.8,4.2,3.8,3.8,4.2,10000+ Employees,1860,"The Role: Data Engineer
Location: Team is in Boston, but is available for remote or on-site throughout CST and EST Time zones
GL (for internal use only): 11

Panjiva is a data-driven technology company that uses machine learning to provide powerful search, analysis, and visualization of billions of shipping records from nearly every country in the world. More than 3,000 customers in over 100 countries, ranging from Fortune 500 companies and startups to government agencies and hedge funds, rely on our platform for supply chain intelligence. In global trade, better insight means better decision making and stronger connections between companies and governments across the globe.
Recognizing Panjiva’s cutting-edge technology, S&P Global acquired Panjiva in 2018. This acquisition has grown our resources, dramatically expanded our access to data, and accelerated our growth plans. People are Panjiva’s greatest strength – join our engineering team as we map out a key part of the world economy!
Job Description
As a data engineer on our team, you will play a key role in developing our next-generation data science infrastructure and underlying core technologies. You will work with Panjiva’s world-class data scientists, analysts, and engineers to create products that solve important real-world business problems in a collaborative, fast-paced, and fun environment.

You’ll work closely with our data science team to develop new platforms, infrastructure, and tools that will allow for machine learning applications at production scale over ever-growing datasets.
You’ll design and leverage distributed computing technologies, data schemas, and APIs to construct data science pipelines. In addition, you’ll be expected to participate in augmenting our infrastructure to seamlessly integrate new data sets through constant R&D of the technologies and systems we use.
Join us in building the next generation of products as we continue to deliver valuable and actionable insights to decision-makers in the $15 trillion global trade industry.

Responsibilities
Architect and implement distributed systems that perform complex transformations, processing, and analysis over very large scale datasets
Develop processes to monitor and automate detection of quality regressions in raw data or in the output of Panjiva’s machine learning models
Working with our data scientists to turn large-scale messy, diverse, and often unstructured data into a source of meaningful insights for our customers
Optimizing slow-running database queries and data pipelines
Helping enhance our search engine, capable of running sophisticated user queries quickly and efficiently
Building internal tools and backend services to enable our data scientists and product engineers to improve efficiency

Qualifications
B.S., M.S., or Ph.D. in Computer Science (or a related field) or equivalent work experience
7+ years of experience working with data-at-scale in a production environment
Experience designing and implementing large-scale, distributed systems
Experience in multi-threaded software development (or some form of parallelism)
Significant performance engineering experience (e.g., profiling slow code, understanding complicated query plans, etc.)
Solid understanding of core algorithms and data structures, including the ability to select (and apply) the optimal ones to computationally expensive operations over data-at-scale
Strong understanding of relational databases and proficiency with SQL
Deep knowledge of at least one scripting language (e.g., Python, Ruby, JavaScript)
Deep knowledge of at least one compiled language (e.g., Scala, C++, Java, Go)
Experience developing software on Linux-based operating systems
Experience with distributed version control systems
Nice-to-Haves
Familiarity with relational database internals (especially PostgreSQL)
Proficiency with cloud computing platforms, specifically AWS
Working knowledge of probability & statistics
Contributions to open-source software
Experience building customer-centric products

Compensation/Benefits Information (US Applicants Only):
S&P Global states that the anticipated base salary range for this position is $85,300 - $170,000 . Base salary ranges may vary by geographic location.
In addition to base compensation, this role is eligible for an annual incentive bonus plan.

This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://www.spgbenefitessentials.com/newhires .
About S&P Global
S&P Global delivers essential intelligence that powers decision making. We provide the world’s leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you’ll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape.

S&P Global Market Intelligence partners with customers to broaden their perspective and operate with confidence by bringing them leading data sources and technologies that embed insight in their daily work.
We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can.

-----------------------------------------------------------

Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment.

If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.

US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law.

----------------------------------------------------------- 20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.2 - Middle Professional Tier II (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)

Job ID: 277527
Posted On: 2023-05-11
Location: Virtual, California, United States",$10+ billion (USD),Research & Development,Company - Public,Management & Consulting
"Lead Data Engineer, Advanced Analytics Group",atlanta,"Bain & Company
4.5","Atlanta, GA",4.5,Employer Provided Salary:$158K - $190K,4.5,4.5,4.2,4.4,3.5,10000+ Employees,1973,"WHAT MAKES US A GREAT PLACE TO WORK

We are proud to be consistently recognized as one of the world's best places to work, a champion of diversity and a model of social responsibility. We are a Glassdoor Best Place to Work and we have maintained a spot in the top four since its founding in 2009. We believe that diversity, inclusion and collaboration are key to building extraordinary teams. We hire people with exceptional talents, abilities and potential, then create an environment where you can become the best version of yourself and thrive both professionally and personally.

WHO YOU’LL WORK WITH

Working alongside our generalist consultants, Bain's Advanced Analytics Group (AAG) helps clients across industries solve their biggest problems using our expertise in data science, customer insights, statistics, machine learning, data management, supply chain analytics and data engineering. Stationed in our global offices, AAG team members hold advanced degrees in computer science, engineering, AI, data science, physics, statistics, mathematics, and other quantitative disciplines, with backgrounds in a variety of fields including tech, data science, marketing analytics and academia.

WHAT YOU’LL DO

As a member of the growing Cloud, Apps and Data Engineering team in Bain’s Advanced Analytics Group, you will:

Partner with Data Science, Machine Learning, and Platform Engineering teams to develop and deploy production quality code
Develop and champion modern Data Engineering concepts to technical audience and business stakeholders
Implement new and innovative deployment techniques, tooling, and infrastructure automation within Bain and our clients.
Travel is required (30%)
ABOUT YOU
Master’s degree in Computer Science, Engineering, or a related technical field.
3+ years at Senior or Staff level, or equivalent
3+ years of experience programming with Python, Scala, C/C++, Java, C#, Go, or similar programming language.
3+ years of experience with SQL or NoSQL databases: PostgreSQL, SQL Server, Oracle, MySQL, Redis, MongoDB, Elasticsearch, Hive, HBase, Teradata, Cassandra, Amazon Redshift, Snowflake.
Experience in deploying serverless data pipelines through containerization and terraform orchestration
Industry level experience of working with public cloud environments (AWS, GCP, or Azure), and associated deep understanding of failover, high-availability, and high scalability
Scaling and optimizing schema and performance tuning SQL and ETL pipelines in data lake and data warehouse environments.
Strong computer science fundamentals in data structures, algorithms, automated testing, object-oriented programming, performance complexity, and implications of computer architecture on software performance.
Data ingestion using one or more modern ETL compute and orchestration frameworks (e.g. Apache Airflow, Luigi, Spark, Apache Nifi, and Apache Beam).
Version control and git workflows
Strong interpersonal and communication skills, including the ability to explain and discuss complex mathematical and machine learning technicalities with colleagues and clients from other disciplines at their level of cognition
Curiosity, proactivity and critical thinking
ABOUT US

Bain & Company is a global consultancy that helps the world’s most ambitious change makers define the future.

Across 64 cities in 39 countries, we work alongside our clients as one team with a shared ambition to achieve extraordinary results, outperform the competition, and redefine industries. We complement our tailored, integrated expertise with a vibrant ecosystem of digital innovators to deliver better, faster, and more enduring outcomes. Our 10-year commitment to invest more than $1 billion in pro bono services brings our talent, expertise, and insight to organizations tackling today’s urgent challenges in education, racial equity, social justice, economic development, and the environment. We earned a gold rating from EcoVadis, the leading platform for environmental, social, and ethical performance ratings for global supply chains, putting us in the top 2% of all companies. Since our founding in 1973, we have measured our success by the success of our clients, and we proudly maintain the highest level of client advocacy in the industry.

U.S. Compensation and Benefit Information:
Compensation for this role includes base salary, annual discretionary performance bonus, 401(k) plan with an annual employer contribution based on years of service and Bain’s best in class benefits package (details listed below).

Some local governments in the United States require a good-faith, reasonable salary range be included in job postings for open roles. The estimated annualized compensation for this role is as follows:

In New York City, the good-faith, reasonable annualized full-time salary range for this role is between $157,500 - $189,500; placement within this range will vary based on several factors including, but not limited to experience, education, licensure/certifications, training and skill level

In California state, the good-faith, reasonable annualized full-time salary range for this role is between $157,500- $189,500; placement within this range will vary based on several factors including, but not limited to experience, education, licensure/certifications, training and skill level

In Washington state, the good-faith, reasonable annualized full-time salary range for this role is between $157,500- $189,500; placement within this range will vary based on several factors including, but not limited to experience, education, licensure/certifications, training and skill level

For all other U.S. locations, the good-faith, reasonable annualized full-time salary range for this role is commensurate with competitive geographic market rates for this role and will vary based on several factors including, but not limited to experience, education, licensure/certifications, training and skill level

Annual discretionary performance bonus

This role may also be eligible for other elements of discretionary compensation

4.5% 401(k) company contribution, which increases after 3 years of service and is 100% vested upon start date

Bain & Company's comprehensive U.S. benefits and wellness program is designed to help employees achieve personal independence, protection and stability in the areas most important to you and your family.",$5 to $10 billion (USD),Business Consulting,Company - Private,Management & Consulting
Lead Software Engineer (Full Stack) - Big Data Solutions,atlanta,"U.S. Bank National Association
3.8","Atlanta, GA",3.8,Employer Provided Salary:$140K - $181K,3.6,3.8,3.4,3.5,3.7,10000+ Employees,1863,"At U.S. Bank, we’re on a journey to do our best. Helping the customers and businesses we serve to make better and smarter financial decisions and enabling the communities we support to grow and succeed. We believe it takes all of us to bring our shared ambition to life, and each person is unique in their potential. A career with U.S. Bank gives you a wide, ever-growing range of opportunities to discover what makes you thrive at every stage of your career. Try new things, learn new skills and discover what you excel at—all from Day One.
Job Description
About the team:
Talech helps grow sales and delivers a positive in-store customer experience. Business Customers can manage inventory better and avoid tying up cash flow with excess stock levels. Run your business better. Everyday funding. No monthly minimum. Contactless payments. It is a Point Of Sale (POS) system allows you to create orders, apply discounts, manage inventory and view sales online with just a few taps

The role will plan, design, implement &/or test the talech’s big data applications and tools, ensure best system performance, data integrity and security.
Essential Responsibilities:
Responsible for designing, developing, testing, operating and maintaining products
Takes full stack ownership by consistently writing production-ready and testable code
Consistently creates optimal design adhering to architectural best practices; considers scalability, reliability and performance of systems/contexts affected when defining technical designs
Performs analysis on failures, propose design changes, and encourage operational improvements
Makes sound design/coding decisions keeping customer experience in the forefront
Takes feedback from code review and apply changes to meet standards
Conducts code reviews to provide guidance on engineering best practices and compliance with development procedures
Accountable for ensuring all aspects of product development follow compliance and security best practices
Exhibits relentless focus in software reliability engineering standards embedded into development standards
Basic Qualifications
Bachelor’s degree, or equivalent work experience
Six to eight years of relevant experience
Preferred Skills/Experience
Strong experience in Spark, PySpark, Sqoop, Pig, Hive, and No SQL data Stores
Previous experience as a full stack engineer.
Advanced knowledge of front-end languages including HTML5, CSS, JavaScript, and JQuery.
Strong programming skills in Python and/or Java required
Strong SQL skills and database knowledge required
Clear understanding of big data system concept and design methodology
Design thinking mind-set and results-oriented
Experience in an Agile Development environment
Experience in ReactJS development will be a strong plus
Knowledge with modern Server architecture, such as Spring Boot, Spring will be a plus
Experience in building microservices will be a plus
Familiarity with one of the core cloud provider services, preferably AWS or Azure Cloud, will be a plus
Familiarity with Docker/Kubernetes will be a plus
Strong written and verbal communication skills
Proven collaboration and influencing skills
If there’s anything we can do to accommodate a disability during any portion of the application or hiring process, please refer to our disability accommodations for applicants.

Benefits:
Our approach to benefits and total rewards considers our team members’ whole selves and what may be needed to thrive in and outside work. That's why our benefits are designed to help you and your family boost your health, protect your financial security and give you peace of mind. Our benefits include the following (some may vary based on role, location or hours):
Healthcare (medical, dental, vision)
Basic term and optional term life insurance
Short-term and long-term disability
Pregnancy disability and parental leave
401(k) and employer-funded retirement plan
Paid vacation (from two to five weeks depending on salary grade and tenure)
Up to 11 paid holiday opportunities
Adoption assistance
Sick and Safe Leave accruals of one hour for every 30 worked, up to 80 hours per calendar year unless otherwise provided by law
EEO is the Law
U.S. Bank is an equal opportunity employer committed to creating a diverse workforce. We consider all qualified applicants without regard to race, religion, color, sex, national origin, age, sexual orientation, gender identity, disability or veteran status, among other factors.
E-Verify
U.S. Bank participates in the U.S. Department of Homeland Security E-Verify program in all facilities located in the United States and certain U.S. territories. The E-Verify program is an Internet-based employment eligibility verification system operated by the U.S. Citizenship and Immigration Services.
The salary range reflects figures based on the primary location, which is listed first. The actual range for the role may differ based on the location of the role. In addition to salary, US Bank offers a comprehensive benefits package, including incentive and recognition programs, equity stock purchase 401k contribution and pension (all benefits are subject to eligibility requirements). Pay Range: $139,995.00 - $164,700.00 - $181,170.00",$10+ billion (USD),Banking & Lending,Company - Public,Financial Services
SR Data Engineer,atlanta,"PGA Tour Superstore
4.0","Roswell, GA",4.0,$86K - $119K (Glassdoor est.),3.4,3.6,3.3,3.4,3.5,1001 to 5000 Employees,2003,"Overview
At PGA TOUR Superstore, we’re always looking for enthusiastic, self-motivated, flexible individuals who will share a passion for helping transform our business. As one of the fastest growing specialty retailers, we’re dedicated to hiring selfless team players from different backgrounds to influence the growth of our organization. Part of the Arthur M. Blank Family of Businesses, PGA TOUR Superstore continuously strives to create a family culture for our Associates – driven by our vision to inspire people through golf and tennis.
Position Summary
PGA Tour Superstore is looking for a data enthusiast who can help take the golf industry’s premier retailer to new heights through unlocking the power of data. The Senior Data Engineer is a critical member of the Data Solutions team who will be responsible for designing and building the critical data pipeline network that powers the Enterprise Data Platform at PGA Tour Superstore. This individual will have opportunities that include designing and building end to end data integration functions, seeing them through all the way into production, working with teams producing and consuming data across the organization to understand complete data flows, and interacting with business stakeholders to understand data needs and opportunities.
Responsibilities
Working with various stakeholders to understand new sources of data, business needs, and define an integration pattern with an enterprise data platform
Designing, building, testing, and deploying efficient and reliable data integration pipelines
Providing team and project leadership
Automating data health checks and ensuring a high-quality data platform for end users
Supporting data pipelines deployed into a production data platform
Documenting data flows from source data systems into an enterprise data platform
Create visually appealing dashboards and other data presentation capabilities
Exploring and evaluating new technologies for consideration within the company’s data stack
Knowledge & Experience
A Bachelor’s degree in Computer Science, Computer Engineering, or equivalent.
5+ years’ experience designing and building data pipelines in an large business setting
Knowledge of data pipeline design and data management best practices
Knowledge of data cleansing, standardization, and metadata curation
Experience with at least 1 cloud-based data warehouse platform, e.g. Big Query, RedShift, Snowflake
Experience with developing data products on Snowflake preferred
Expertise in developing and querying against traditional relational and NoSQL databases
Expertise in performance tuning complex SQL queries
Expertise in at least 1 data pipeline orchestration framework or tool
Expertise in SQL for data retrieval and manipulation
Proficient in Python or another popular data transformation programming language
Experience using SQL for exploratory data analysis
Experience developing and deploying in a major cloud platform environment
Experience with at least 1 data visualization tool, e.g. PowerBI, Tableau.
Experience using GitHub
Familiar with at least one data visualization framework
Ability to work independently as well as lead and mentor junior team members
Ability to connect technical solutions to business purpose
Ability to communicate technical concepts to non-technical audiences
Strong oral and written communication skills
Retail industry experience is a plus
Other Duties:
Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.

PGA TOUR Superstores is an Equal Opportunity Employer, committed to a diverse and inclusive work environment.
We comply with all laws that prohibit discrimination based on race, color, religion, sex/gender, age (40 and over), national origin, ancestry, citizenship status, physical or mental disability, veteran status, marital status, genetic information, and any other legally protected status. Employment discrimination isn’t just unlawful, it violates our policies and is not who we are. Every associate at every level in the organization is prohibited from engaging in any form of discrimination.
An associate who believes s/he is being discriminated against should report it immediately to the Human Resources department. The law and our policies prohibit retaliation against anyone for making such a report.",Unknown / Non-Applicable,Sporting Goods Stores,Company - Private,Retail & Wholesale
Senior Data Engineer,atlanta,"Intercontinental Exchange
3.8","Atlanta, GA",3.8,$109K - $148K (Glassdoor est.),3.4,3.5,3.3,3.7,3.6,1001 to 5000 Employees,2000,"Job Purpose
Intercontinental Exchange presents a unique opportunity to work with cutting-edge technology and business challenges in the financial sector. ICE team members work across departments and traditional boundaries to innovate and respond to industry demand. By leveraging our core strengths in technology, we continue to identify new ways to serve our customers and transform global markets. A successful candidate will be able to multitask in a dynamic team-based environment demonstrating strong problem-solving and decision-making abilities and the highest degree of professionalism.
As a Senior Data Engineer, you will be part of a technology team supporting the New York Stock Exchange with responsibility for driving data collection, storage, processing, and analysis of huge dataset collection. Data loaded on daily basis and used for Regulatory Reporting, Market Surveillance, Capacity Planning and Customer reports.
Responsibilities
Create and maintain ETL jobs to populate storage farm and database loads
Develop various internal and external reports from Data Warehouse
Integrate new data management technologies and software engineering tools into existing structures and processes.
Learn and develop understanding of source data and transformed datasets.
Analyze large datasets: csv files and tables in database.
Performance tune ETL processes as well as queries to extract information from the databases
Troubleshoot production issues quickly and efficiently.
Support our team in the daily and weekend operational work and ad-hoc analysis and reports for business users.
Documentation
Knowledge and Experience
Bachelors degree in computer science, engineering, or related field with 7 years of relevant work experience OR Masters degree in computer science, engineering, or related field with 5 years work experience
Experience in data analysis, data cleansing, and data transformation (parsing, mapping, and serialization processes)
Proficiency in SQL and Linux system processing with shell scripting is MUST
Scripting language like python or similar language is a MUST
Prior Experience working with Snowflake, Oracle PL/SQL, Data Visualization Tools and Performance tuning large volume of data is a plus
Experience and understanding of database architecture and transformation tools
Understanding of Data Warehousing & ETL/ELT techniques
Experience working with development teams, business teams, and database administrators, within agile methodology
Communicate effectively with both technical and business resources
Self-starter with proven ability and initiative to learn and research new concepts, ideas, and technologies quickly
Schedule
This role offers work from home flexibility of up to 2 days per week.
Intercontinental Exchange, Inc. is an Equal Opportunity and Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, gender identity, national origin or ancestry, age, disability or veteran status, or other protected status.",$5 to $10 billion (USD),Stock Exchanges,Company - Public,Financial Services
"Sr. Lead Software Engineer, Data Ecosystem",atlanta,"Chick-fil-A, Inc.
3.9","Atlanta, GA",3.9,-1,-1,-1,-1,-1,-1,5001 to 10000 Employees,1946,"Overview:
Chick-fil-A has successfully implemented a modern cloud-native, self-service data ecosystem comprised of AWS S3, Glue, Redshift and Databricks. In this role you will drive the design and implementation of the software components and features required to evolve it into the next-generation architecture meeting the needs of data engineers throughout Chick-fil-A.

You will be responsible for architecting, designing, and leading the implementation of features for metadata management as well as advanced data management components related to our enterprise data lake, data warehouses, Spark platform, and other relational and non-relational data stores. Integration between components to deliver the best possible developer experience is key.

Your daily work will require partnering with fellow engineers, the product owner, data and enterprise architects, stakeholders, vendor teams, and other parties following an agile methodology, while being part of a diverse team that values high performance and excellence as much as work-life balance.

This role is based in the Atlanta, GA area. Relocation available for the selected candidate.

Our Flexible Future model offers a healthy mix of working in person and virtually, strengthening key elements of the Chick-fil-A culture by fostering collaboration and community.
Responsibilities:
Lead, mentor and assess multiple partner engineering teams with minimal supervision
Identify opportunities to improve the developer experience then design and architect revisions to reduce friction in the user experience.
Partner with data scientists and data engineers to fully understand emerging needs and unmet needs. Collaborate and promote value-based adoption.
Review the work of multiple partner led pods – ensuring conformance to standards, adoption of patterns, sound designs and good development practices.
Exercise skills in cloud infrastructure and deployment as well as areas like application security, data analytics, machine learning, and site reliability engineering (SRE)
Define patterns and processes for data transformation, movement, and manipulation using (among others) Hadoop/Spark, SQL, Airflow, Databricks, Amazon Aurora, DynamoDB, Athena, Redshift, ML libraries/tools
Identify & propose emerging technologies, methodologies and/or approaches related to data and analytics
Be a key participant of the team’s Agile process
Address engineering assignments by autonomously deciding which ones to delegate and which ones to execute hands-on
Note - Working in a DevOps model, this opportunity includes both building and running solutions that could require off hours support. This support is shared amongst the team members to cover weekends and weeknights. The goal is to design for failure and, using cloud-native infrastructure patterns, automate responses to issues so they can be worked during normal hours.
Minimum Qualifications:
5+ years or more related work experience
Master’s degree in Computer Science, Analytics Engineering or related technical field or the equivalent combination of education, training and experience from which comparable skills have been acquired
Broad and deep programming experience in Python, JavaScript, Java, Scala, or other comparable languages
Experience with SQL, data modeling, and the Hadoop ecosystem
Experience with source-control systems like Git or Subversion, and CI/CD tools like GitHub Actions or Jenkins
Experience implementing application security, software design patterns, and the SDLC
Good interpersonal and team collaboration skills
Preferred Qualifications:
Experience architecting software solutions on Amazon Web Services (AWS) or other major CSP
Experience working with an Agile development methodology featuring sprints, point-estimation, and daily standups
Proficiency in Spark programming or equivalent big data technology
Experience with Unix/Linux and container technologies such as Docker
Minimum Years of Experience: 5 Travel Requirements: 5% Required Level of Education: Master's Degree Major/Concentration: Computer Science, Analytics Engineering, or related technical field",$5 to $10 billion (USD),Restaurants & Cafes,Company - Private,Restaurants & Food Service
"Principal Engineer-Software, Inventory Data Platform",atlanta,"Genuine Parts Company
3.5","Atlanta, GA",3.5,$101K - $139K (Glassdoor est.),3.0,3.2,3.0,3.1,3.3,5001 to 10000 Employees,1928,"Company Background:
Genuine Parts Company (“GPC” or the “Company”), founded in 1928 and based in Atlanta, Georgia, is a leading specialty distributor engaged in the distribution of automotive and industrial replacement parts and value-added services. The Company operates a global portfolio of businesses with more than 10,000 locations across the world. GPC has approximately 50,000 global employees. The Company has operations in the United States, Canada, Mexico, Australia, New Zealand, Indonesia, Singapore, France, the U.K., Germany, Poland, the Netherlands, Belgium, Spain and China.

Position Purpose:
Seeking world-class talent to join the world’s leading distributor of automotive and industrial replacement parts and value-added services operating 5,500+ locations and servicing more than 20,000 locations in the U.S and Canada. Specifically, this role will function as the Principal Engineer of a newly formed team of Engineers to build the next generation commerce platforms at GPC. Working with a highly talented team, you'll play a key role to build and run one of the world’s largest automotive and industrial replacement parts operations.

This is an engineering leadership role with responsibility for enabling cloud transformation and execution for GPC’s unified commerce platforms.

This individual must be a technologist & engineer at heart and be comfortable in enabling new technology and being hands on with the execution of the strategy. She/he must exhibit a deep understanding of modern technology stack and agile delivery models, demonstrated focus on customer experience, and must have a proven track record of modernizing technologies.

Close collaboration and alignment with business teams, application development teams and security will be required. As such, exceptional abilities in building and maintaining strong working relationships and organizational savvy will be required. High level communication and presentation skills are required. Ability to attract, retain, and develop engineering talent will be critical.

Responsibilities:
Technical responsibility of architecture roadmap and vision of the Inventory Data Domain
Lead the development and build out of the unified commerce systems for the entire domain
Reviews business context for solutions to company challenges as well as defining the vision and requirements for the solution, recommending potential options, selecting the most optimal solution, and the development of a roadmap for the selected solution
Initiate both group and one-on-one meetings with senior management in order to gain a clear understanding of business drivers and functional requirements
Lead design and architecture discussions for IT platforms engaging with other principal engineers, engineering teams across different business units to ensure secure and scalable solutions
Directs the identification and recommendation of appropriate solutions, upgrades, replacements, or decommissioning options incorporating business and technology productivity, usability, and total cost of ownership
Communicates the architecture to the stakeholders and collaborates and coordinates with existing domain architects in the formalization and adoption of IT standards and procedures
Provides oversight on delivery to ensure industry best practices, standards, automation, quality, timeliness, operational readiness, continuous improvement, and cost-effective solutions
Provide technical leadership and guidance to lead engineers and the technical team within a domain
Other duties as assigned

Location:
GPC has two work locations to choose from, Duluth or Atlanta office.
We offer a Flexible Work Policy that permits eligible employees to work remotely

Desired Qualifications & Experiences:
Degree in Computer Science, Engineering, or related field
10+ years’ experience in software engineering & technology
Experience in design and building Inventory enabled systems, centralized Inventory Systems experience is a plus
Excellent oral and written communication
Analytical and problem-solving skills
Comfortable with ambiguity and time spent outside of comfort zone acquiring new skills
Technically creative and open-minded
Experience in enterprise level software development experience (non-academic) with demonstrable experience in Java, REST, SOAP, Spring Cloud, Spring Boot, Microservices, NoSQL, Containerization and Security
Experience in building and operating applications running on Public cloud environments (AWS, Azure, GCP) including DevSecOps practices, direct experience in GCP is a plus
Must possess experience running high throughput low latency end user-facing microservices",Unknown / Non-Applicable,Automotive Parts & Accessories Stores,Company - Public,Retail & Wholesale
Lead Data Engineer,atlanta,Zodient LLC,"Atlanta, GA",-1,Employer Provided Salary:$65.00 - $70.00 Per Hour,-1,-1,-1,-1,-1,Unknown,Company - Private,"Role- Lead Data Engineer
Location: Atlanta, GA(Day one onsite)
JOB DESCRIPTION
Skills to check and shortlist-
Python application development experience
Lambda, server less,
Aws cloud- development, devops, cloud formation, etc
Api integration, rest api - graph ql,
Kinesis or Kafka type real time data integration experience
No sql databases
Additionally python experience on flask or similar is a bonus
Job Type: Part-time
Salary: $65.00 - $70.00 per hour
Experience level:
10 years
Schedule:
8 hour shift
Work Location: One location",-1,-1,Unknown / Non-Applicable,-1
GCP data engineer,atlanta,"Purple Drive Technologies
4.2","Atlanta, GA",4.2,$107K - $153K (Glassdoor est.),3.9,4.0,4.0,3.7,4.2,1 to 50 Employees,Company - Private,"GCP Data engineer
Onsite- Atlanta GA
Drives world-class design and development of analytical data pipelines.
Provides thought leadership and propose industry standards and implementations.
Adhere to processes to ensure data pulled from various sources meets quality standards, is curated and enhanced for analytical use and there is a ""single source of truth""
Work with counterparts from Tech to build frameworks that integrate data pipelines and machine learning models that facilitate use by data scientists for priority use cases; Enterprise Data and Analytics team focused on ""last mile"" transformations on select data required for use cases
Maintain database structure and standard definitions for business users across Macy's
Work with data architects to build the foundational extract / load / transform process and regularly review the architecture and recommend effectiveness improvements
Collaborate with Technology to future-proof data & analytics software, tools, and code to reduce risk and support pipeline owners
Work with Legal and Privacy teams to adhere to data privacy and security standards
Work with Data Architect to implement the data models, standards, and quality rules
Work with the Data Science team to understand data formatting and sourcing needs to enable them to build out use cases as efficiently as possible.
Keep data separated and secured using masking and encryption.
Explain the requirement to offshore team and create Interface to determine the most efficient and cost-effective approach to meet business requirements.
Daily onsite-offshore coordination
Job Type: Full-time
Benefits:
401(k)
Dental insurance
Flexible schedule
Health insurance
Tuition reimbursement
Vision insurance
Experience level:
10 years
Schedule:
8 hour shift
Weekend availability
Ability to commute/relocate:
Atlanta, GA 30303: Reliably commute or planning to relocate before starting work (Required)
Work Location: One location",-1,-1,Unknown / Non-Applicable,-1
Senior Data Engineer,atlanta,"NCR
3.6","Atlanta, GA",3.6,$112K - $154K (Glassdoor est.),3.2,3.5,3.2,3.2,3.4,10000+ Employees,1884,"About NCR
NCR Corporation (NYSE: NCR) is a leader in transforming, connecting and running technology platforms for self-directed banking, stores and restaurants. NCR is headquartered in Atlanta, Ga., with 38,000 employees globally. NCR is a trademark of NCR Corporation in the United States and other countries.
Data Engineer – GCP Cloud
NCR is searching for a highly innovative, enthusiastic, and results-driven Data Engineer who has built data pipelines and data systems at scale using the GCP architectures. This individual should be from a development background in data engineering and not an infrastructure background. Someone who has a strong familiarity working in an GCP cloud environment to implement enterprise data workloads. Comfortable working with full stack engineers, product managers and product delivery teams.
Responsibilities
Maintain active relationships with Product Owner to understand business requirements, lead requirement gathering meetings and review designs with the product owner
Perform technical design reviews and code reviews
Deep knowledge of Python, Spark best practices and commonly used modules based on extensive work experience and creating self-contained, reusable, and testable modules and components
Responsible for prototyping, developing, and troubleshooting software in the user interface or service layers
Perform peer reviews on source code to ensure reuse, scalability, and the use of best practices
Participate in collaborative technical discussions that focus on software user experience, design, architecture, and development
Perform demonstrations for client stakeholders on project features and sub features, which utilizes the latest Front end and Backend development technologies
Keep up to date with technology and apply new knowledge
Experience with the following software/tools is required
Github, Jenkins, Gitflow, Github Projects
GCP Services:
BigQuery, Cloud Functions, Databricks Apache Spark, Kafka
SQL and NoSQL databases like Atlas (mongoDB) MySQL, Oracle, Postgres, Elasticsearch
Strong programming skills in at least one of the following languages:
Java, Python as well as Unix/Linux shells
Ideal Qualifications
Bachelor’s degree in computer science, software engineering or proven work experience in related field
10+ years’ experience
Experience implementing and achieving PCI compliance in a cloud environment
Solid Python and/or Java programming language experience
Relational and NoSQL database experience is required
Strong complex problem solving and troubleshooting skills
Ability to learn quickly and manage time effectively
Proven written and oral communication skills
Experience in the financial industry a plus
Offers of employment are conditional upon passage of screening criteria applicable to the job.
Full time employee benefits include:
Medical Insurance
Dental Insurance
Life Insurance
Vision Insurance
Short/Long Term Disability
Paid Vacation
401k
EEO Statement
Integrated into our shared values is NCR's commitment to diversity and equal employment opportunity. All qualified applicants will receive consideration for employment without regard to sex, age, race, color, creed, religion, national origin, disability, sexual orientation, gender identity, veteran status, military service, genetic information, or any other characteristic or conduct protected by law. NCR is committed to being a globally inclusive company where all people are treated fairly, recognized for their individuality, promoted based on performance and encouraged to strive to reach their full potential. We believe in understanding and respecting differences among all people. Every individual at NCR has an ongoing responsibility to respect and support a globally diverse environment.

Statement to Third Party Agencies
To ALL recruitment agencies: NCR only accepts resumes from agencies on the NCR preferred supplier list. Please do not forward resumes to our applicant tracking system, NCR employees, or any NCR facility. NCR is not responsible for any fees or charges associated with unsolicited resumes.",$5 to $10 billion (USD),Enterprise Software & Network Solutions,Company - Public,Information Technology
Data Engineer Leader,atlanta,"Equifax
3.6","Atlanta, GA",3.6,$94K - $126K (Glassdoor est.),3.6,3.5,3.2,3.6,3.6,10000+ Employees,1899,"Equifax is where you can power your possible. If you want to achieve your true potential, chart new paths, develop new skills, collaborate with bright minds, and make a meaningful impact, we want to hear from you.
Equifax is seeking a creative, high-energy, Data Engineering Leader with hands-on development skills to work on a variety of high-impact projects. You will have the opportunity to join a team of talented engineers working with leading-edge technology. You will unlock new opportunities for business growth, improve analytical process efficiency, maintain and restructure data pipelines, and coordinate with our Technology teams on accelerated deployment of analytical solutions within our production environments.
What You’ll Do:
Identify optimal path for new analytical product deployment and work with the Technology, Sales, and Marketing organizations on go-to-market execution
Oversee Data and Analytics system architecture, scalability, reliability, and performance
Manage large scale data engineering and analytics projects ensuring milestones are met, risk is mitigated, and delivery occurs within the agreed upon time frames
Oversee the design and implementation of secure data integration processes for both upstream and downstream data pipelines
Build and deploy streaming and batch data pipelines across a hybrid multi-cloud architecture
Build capabilities to run analytics, data visualization, and machine learning algorithms at scale
Build and maintain dimensional databases, data marts, operational data stores, semantic models and ontologies in support of business intelligence and advanced analytics tools in a hybrid multi-cloud architecture
What experience you need
10+ years working in a data engineering ETL, Data Modeling, and Big Data Architecture (at least 5+ years working with distributed systems and 3+ years with cloud)
1 or more years of experience with Big Data technologies such as Spark, Kafka and/or Hadoop or NoSQL such as Cassandra
5+ years managing technical individuals (data engineers and data analysts)
What could set you apart
Experience with Cloud Platforms such as AWS, GCP and Deploying and automating infrastructure/applications using Chef, RPM, Docker, AWS (ECS, ECR), Terraform
You possess excellent written and verbal communication skills with the ability to communicate with team members at various levels, including business leaders.
Knowledge of credit bureau data and FCRA regulated data would be preferred
Ability to communicate with executive leadership
Ability to influence decisions in a complex and matrixed environment
Ability to clearly present technical solutions to a non-technical audience
Solid understanding of big data analytics including machine learning and distributed computing
We offer comprehensive compensation and healthcare packages, 401k matching, paid time off, and organizational growth potential through our online learning platform with guided career tracks.
Are you ready to power your possible? Apply today, and get started on a path toward an exciting new career at Equifax, where you can make a difference!
Equifax is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.",$1 to $5 billion (USD),Research & Development,Company - Public,Management & Consulting
Data Security Engineer - Senior Manager,atlanta,"Boston Consulting Group
4.4","Atlanta, GA",4.4,-1,-1,-1,-1,-1,-1,10000+ Employees,1963,"WHAT YOU'LL DO

The BCG FED Organization is seeking a knowledgeable and talented Data Security Engineer that will be responsible for operating and maintaining the BCG Data Governance program in alignment with NIST 800-171, CMMC and IT Security best practices.

Your duties will include:
Management of the Data Lifecycle for BCG and Client data as data is ingested, stored, processed, transmitted, and purged from the system.
Ownership of the Business Continuity strategy for data
Enhance and maintain the Data Classification strategy in alignment with business and client requirements
Translate compliance and client contractual obligations into a data protection schema.
Collaborate with engineering and cloud teams to lead effective process improvements.
Provide monthly metrics reporting, identify, and manage gaps in data protection policy, and work to resolve.
Document Data Protection process and procedures

YOU'RE GOOD AT

Strong comprehensive problem-solving skills to identify and solve issues quickly
Ability to work well independently as well as part of a virtual, geographically dispersed team bringing a sense of urgency to the tasks at hand
Effectively handle difficult and stressful situations with poise, tact and patience, while demonstrating a sense of urgency
Strong analytical skills, detail-oriented, and quality-minded
Exceptional verbal and written communication and presentation skills

YOU BRING (EXPERIENCE & QUALIFICATIONS)

5-8+ years of experience in information security
3-5+ years of Data Classification technical capabilities and strategies
Encryption and Data Loss Prevention (DLP) experience
Experience with Business Continuity to include backup capabilities
Ability to foresee and identify mitigation strategies for risks
Knowledge of security issues, trends and best practices
Experience with Microsoft Azure and O365
Ability to obtain a Security Clearance

YOU'LL WORK WITH

This individual will collaborate with other BCG information technology teams such as Identity, Information Management, Information Encryption, Hosting, Devices Team - Windows/Mac/Mobile, Security, Voice and Networking
to ensure alignment with BCG’s overall IT architecture plan.",$5 to $10 billion (USD),Business Consulting,Company - Private,Management & Consulting
"Senior Software Engineer, Data Engineering",atlanta,"S&P Global
4.1","Atlanta, GA",4.1,Employer Provided Salary:$68K - $140K,3.8,4.2,3.8,3.8,4.2,10000+ Employees,1860,"The Role: Data Engineer
Location: Team is in Boston, but is available for remote or on-site throughout the US.
GL (for internal use only): 10

Panjiva is a data-driven technology company that uses machine learning to provide powerful search, analysis, and visualization of billions of shipping records from nearly every country in the world. More than 3,000 customers in over 100 countries, ranging from Fortune 500 companies and startups to government agencies and hedge funds, rely on our platform for supply chain intelligence. In global trade, better insight means better decision making and stronger connections between companies and governments across the globe.

Recognizing Panjiva’s cutting-edge technology, S&P Global acquired Panjiva in 2018. This acquisition has grown our resources, dramatically expanded our access to data, and accelerated our growth plans. People are Panjiva’s greatest strength – join our engineering team as we map out a key part of the world economy!
Job Description
As a data engineer on our team, you will play a key role in developing our next-generation data science infrastructure and underlying core technologies. You will work with Panjiva’s world-class data scientists, analysts, and engineers to create products that solve important real-world business problems in a collaborative, fast-paced, and fun environment.

You’ll work closely with our data science team to develop new platforms, infrastructure, and tools that will allow for machine learning applications at production scale over ever-growing datasets.

You’ll design and leverage distributed computing technologies, data schemas, and APIs to construct data science pipelines. In addition, you’ll be expected to participate in augmenting our infrastructure to seamlessly integrate new data sets through constant R&D of the technologies and systems we use.
Join us in building the next generation of products as we continue to deliver valuable and actionable insights to decision-makers in the $15 trillion global trade industry.

Responsibilities
Architect and implement distributed systems that perform complex transformations, processing, and analysis over very large scale datasets
Develop processes to monitor and automate detection of quality regressions in raw data or in the output of Panjiva’s machine learning models
Working with our data scientists to turn large-scale messy, diverse, and often unstructured data into a source of meaningful insights for our customers
Optimizing slow-running database queries and data pipelines
Helping enhance our search engine, capable of running sophisticated user queries quickly and efficiently
Building internal tools and backend services to enable our data scientists and product engineers to improve efficiency
Qualifications
B.S., M.S., or Ph.D. in Computer Science (or a related field) or equivalent work experience
4+ years of experience working with data-at-scale in a production environment
Experience designing and implementing large-scale, distributed systems
Experience in multi-threaded software development (or some form of parallelism)
Significant performance engineering experience (e.g., profiling slow code, understanding complicated query plans, etc.)
Solid understanding of core algorithms and data structures, including the ability to select (and apply) the optimal ones to computationally expensive operations over data-at-scale
Strong understanding of relational databases and proficiency with SQL
Deep knowledge of at least one scripting language (e.g., Python, Ruby, JavaScript)
Deep knowledge of at least one compiled language (e.g., Scala, C++, Java, Go)
Experience developing software on Linux-based operating systems
Experience with distributed version control systems
Nice-to-Haves
Familiarity with relational database internals (especially PostgreSQL)
Proficiency with cloud computing platforms, specifically AWS
Working knowledge of probability & statistics
Contributions to open-source software
Experience building customer-centric products

Compensation/Benefits Information:
S&P Global states that the anticipated base salary range for this position is $68,300 to $140,000 . Base salary ranges may vary by geographic location.
This role is eligible to receive S&P Global benefits. For more information on the benefits we provide to our employees, visit https://www.spgbenefitessentials.com/newhires .

About S&P Global
S&P Global delivers essential intelligence that powers decision making. We provide the world’s leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you’ll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape.

S&P Global Market Intelligence partners with customers to broaden their perspective and operate with confidence by bringing them leading data sources and technologies that embed insight in their daily work.
We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can.

-----------------------------------------------------------

Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment.

If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.

US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law.

----------------------------------------------------------- 20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.1 - Middle Professional Tier I (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)

Job ID: 266145
Posted On: 2023-05-25
Location: Cambridge, Massachusetts, United States",$10+ billion (USD),Research & Development,Company - Public,Management & Consulting
Staff Engineer – Data,atlanta,"Genuine Parts Company
3.5","Atlanta, GA",3.5,$78K - $113K (Glassdoor est.),3.0,3.2,3.0,3.1,3.3,5001 to 10000 Employees,1928,"Company Background:
Genuine Parts Company (“GPC” or the “Company”), founded in 1928 and based in Atlanta, Georgia, is a leading specialty distributor engaged in the distribution of automotive and industrial replacement parts and value-added services. The Company operates a global portfolio of businesses with more than 10,000 locations across the world. GPC has approximately 50,000 global employees. The Company has operations in the United States, Canada, Mexico, Australia, New Zealand, Indonesia, Singapore, France, the U.K., Germany, Poland, the Netherlands, Belgium, Spain and China.

Position Purpose:
Seeking world-class talent to join the world’s leading distributor of automotive and industrial replacement parts and value-added services operating 5,500+ locations and servicing more than 20,000 locations in the U.S and Canada. Specifically, this role will function as the Staff Engineer of a newly formed team of Engineers to build the next generation commerce platforms at GPC. Working with a highly talented team, you'll play a key role to build and run one of the world’s largest automotive and industrial replacement parts operations.

This is an engineering leadership role with responsibility for enabling cloud transformation and execution for GPC’s unified data platform.

This individual must be a technologist & engineer at heart and be comfortable in enabling new technology and being hands on with the execution of the strategy. They must exhibit a deep understanding of modern technology stack and agile delivery models, demonstrated focus on customer experience, and must have a proven track record of modernizing technologies.

Close collaboration and alignment with business teams, application development teams and security will be required. As such, exceptional abilities in building and maintaining strong working relationships and organizational savvy will be required. High level communication and presentation skills are required. Ability to attract, retain, and develop engineering talent will be critical.

Responsibilities:
Lead the development and build out of cloud data management solutions to support the Enterprise Data Platform (data pipelines, metadata, data catalog, reference data, and data quality)
Reviews business context for data solutions to company challenges as well as defining the vision and requirements for the solution, recommending potential options, selecting the most optimal option, and the development of a roadmap for the selected solution.
Initiate both group and one-on-one meetings with senior management in order to gain a clear understanding of business drivers and functional requirements
Collaborate and work closely with other teammates to achieve team goals and outcomes
Defining Data Architecture, standards, industry best practices and communicating across engineering teams to ensure adoption and governance
Assist in setting direction and driving change in data technologies for optimal solutions based on type of workload
Design conceptual/logical data models, data flows and source to target mappings
Maintain data models, lineage, data dictionary, glossary etc. by using enterprise tools to be consistent across all other data domains and products
Lead architecture, design and code reviews with engineering teams
Provides analysis of security protection technologies as necessary
Performance tuning and optimizing data processing/consumption workloads
Coordinate with business and analytics needs to identify future requirements and solutions
Mentor new resources
Daily attend team standups and agile ceremonies
Employ best practices around observability, monitoring, and system resilience
Other duties as assigned

Location:
GPC has two work locations to choose from, Duluth or Atlanta office.
We offer a Flexible Work Policy that permits eligible employees to work remotely

Desired Qualifications & Experiences:
Degree in Computer Science or Engineering fields, or equivalent experience
8 years (10+ preferred) experience in software engineering & technology (5+ years in data architecture design and development)
Proven technical leadership and skills in creating, leading and implementing Data Management architecture for large enterprise scale applications
Experience with Enterprise Data Strategy, Data Modeling, Data Architecture and dealing with structured and semi-structured data at scale
Working knowledge of various types of database management systems and approaches to solve OLTP and OLAP workloads (including but not limited to traditional RDBMS systems, NoSQL, BigData and modern cloud native data warehousing solutions)
Advanced SQL skills
Experience with Data Modeling Tools (Erwin a plus)
Experience with Informatica (Informatica Intelligent Cloud Services a plus)
Experience in designing, building and implementing re-usable utilities
Experience with python scripting
Extensive knowledge around various data integration patterns against databases (inbound and outbound) to solve for real-time, and batch workloads
Familiarity with data visualization tools like PowerBI
Experience in AI/ML, data science and statistical/machine is a plus
Excellent oral and written communication
Analytical and problem-solving skills
Comfortable with ambiguity and time spent outside of comfort zone acquiring new skills
Technically creative and open-minded",Unknown / Non-Applicable,Automotive Parts & Accessories Stores,Company - Public,Retail & Wholesale
Senior Data Engineer (Pre-IPO Startup),atlanta,"Recruiting From Scratch
3.9","Atlanta, GA",3.9,Employer Provided Salary:$120K - $200K,4.0,3.6,3.5,3.9,3.9,1 to 50 Employees,2019,"Who is Recruiting from Scratch:
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
This role will be a senior engineering role at one of our clients that are early stage all the way to IPO / Private companies.
Our Client
Our Client is the global leader in ecommerce technology, helping companies seize the full potential of every transaction moment to grow revenue and acquire new customers at scale. Live Nation, Groupon, Staples, Lands' End, Fanatics, UrbanStems, GoDaddy, Vistaprint and HelloFresh are among the more than 2,500 leading global businesses and advertisers that are using our client's solutions to drive more value through every transaction by offering highly relevant messages to their customers at the moment they are most likely to convert.
With their December 2021 Series E raise of USD$325M, our client's is expanding rapidly and globally – operating in 19 countries across North America, Europe and the Asia-Pacific region with the largest office in NYC and a major R&D hub in Sydney. With annual revenues of more than US$200M and vibrant company culture, Our client has been listed in ‘Great Places to Work’ in the US and Australia. Their award-winning culture is guided by our five core values: Smart with Humility, Own the Outcomes, Force for Good, Conquer New Frontiers, and Enjoy the Ride. These values help us attract, engage, and develop the right talent around the globe and ensure we have the right conditions to do our best work.
The engineering team builds best-in-class ecommerce technology that provides personalized and relevant experiences for customers globally and empowers marketers with sophisticated, AI-driven tooling to better understand consumers. Our bespoke platform handles millions of transactions per day and considers billions of data points which give engineers the opportunity to build technology at scale, collaborate across teams and gain exposure to a wide range of technology. We are expanding rapidly in our major R&D centers in NYC and Sydney. We are passionate about using intelligent systems to improve the transaction moment for retailers everywhere. Come join us and build the future!
Requirements
About the role
We’re working on building a platform for reporting and analytics that is able to handle huge amounts of data in a real-time fashion that would allow us to uncover new insights and help us make decisions.
Our goal is to unlock data and make it available to various users starting from other engineers to end business users and clients. We value pragmatic solutions and simplicity that help us build reliable and fast systems.
Outcomes & responsibilities
Build distributed, high-volume data pipelines and storage that power our reporting and analytics
Work on real-time distributed OLAP custom solutions
Do it with Spark, Kafka, Airflow, and other open-source technologies
Work all over the stack, moving fluidly between programming languages: Scala, Python, and more
You'll help define the processes and infrastructure to transform and make data readily available across the company
Join a tightly knit team solving hard problems the right way
Own meaningful parts of our service, have an impact, grow with the company
Take responsibility for system health, monitoring and alerting, and CI/CD pipelines
Support and mentor other engineers on best practices, architecture, and quality
Capabilities & requirements
You have built and operated data pipelines for real customers in production systems
You are fluent in several programming languages (JVM & otherwise)
You’ve worked with data stores and/or data warehouses, such as AWS Redshift, Snowflake, Clickhouse, or others
You have hands-on experience with BigData frameworks (Hadoop, Hive, Spark, etc.)
You’re able to explain advanced technical concepts in a simple manner and cater to your audience
You enjoy wrangling huge datasets and helping others unlock new insights
You’re concerned about resiliency, high-availability, data quality, and other aspects of a critical system
Benefits
Force for Good. We actively invest in the growth of our people and the strengthening of our communities. Our NYC office is 100% vaccinated to keep our employees and community safe and healthy. We require all rockstars as well as anyone else who will be onsite at the NYC office – clients, contractors, vendors, and suppliers – to show proof of vaccination and their booster shot.
Work with the greatest talent in town. Our recruiting process is tough. We hold a high bar because we have a high-performing, high-velocity culture - we only want the brightest and the best.
Join a community. We believe the best things happen when we come together to solve complex problems and make meaningful connections with each other through interest groups, sports clubs, and social events.
Accelerate your career. Develop through our global training events, ‘Level Up’ investment, online training courses, and our fantastic people leaders. Take your career to speed - Grow your career in our rapidly growing company.
Take a break. When you work hard, we know you also need to rest. We offer generous time off and parental leave policies, as well as mental health and wellness days for all employees. We also offer a paid Sabbatical for employees who have been with us for 3 years or more.
Stay happy and healthy. Enjoy catered lunch 3 times a week and healthy snacks in the office. Plus join the gym on us! In the US, access generous retirement plans like a 4% dollar-for-dollar 401K matching plan and get fully funded premium health insurance for your whole family. And our NYC office is dog-friendly!
Become a shareholder. All employees have stock options. If we succeed, everyone enjoys the upside.
See the world! Along with our global all-staff events in amazing locations (Phuket, Thailand in January 2020, Hawaii in May 2022), we also offer generous relocation packages for those interested in moving to another office. We have cool offices in great cities - New York, Sydney, London, Singapore, Tokyo.
Get the best of both worlds with a hybrid workplace. We currently work 3 days a week in office, allowing you to enjoy the best of both worlds (please note: this is subject to change based on the needs of the business and some support roles still require a full time presence). One week per quarter, you also have the flexibility to work from anywhere.
We believe in equality. They are an Equal Opportunity Employer and recognizes that a diverse workforce is crucial to our success as a business. We would love you to apply for one of our open roles - irrespective of socio-economic status or background, age, gender identity, race, religion, sexual orientation, color, pregnancy, carer/family responsibilities, national and social origin, political opinion, marital, veteran, or disability status.
Salary range: $120,000 - $200,000 / year
Location: Hybrid 3 days, of your choice, a week in office at the intersection of SoHo and TriBeCa within walking distance of the bike path and outdoor fields on the Hudson River. You’ll be tempted to skip the catered lunches to try out all of the delicious local eateries in the area.",$1 to $5 million (USD),Staffing & Subcontracting,Company - Private,Human Resources & Staffing
Senior Data Engineer,atlanta,"Veeam Software
4.1","Alpharetta, GA",4.1,$103K - $141K (Glassdoor est.),3.8,3.9,3.8,3.9,4.1,1001 to 5000 Employees,2006,"Veeam has US government and enterprise customers, and our systems and software may manage sensitive information for various governments. As a result, this position may require you to apply for Secret Security Clearance or above. Applicants selected may be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance may be required. Veeam is a leading provider of backup and recovery software for virtual, physical and cloud environments. Different Veeam departments take care of every phase of the solution life cycle: development and testing, implementation through an extensive partner network, and technical support in multiple languages. Veeam builds products to meet complex backup and data management challenges. We work with VMware vSphere, Microsoft Hyper-V and Nutanix AHV virtualization; Windows, Linux and Unix physical systems; Active Directory, Exchange, SharePoint, SQL, Oracle and SAP HANA servers; Amazon, Azure and Google Cloud public clouds; and many other technologies that form the core of modern IT. Our Corporate Information Systems team oversees the operation of our company’s information systems. These include not only the veeam.com website but also a forum, client portals and internal tools. No product release goes without their support, and all our web services run smoothly as a result of their work. We are now looking for a Senior Data Engineer for DWH Team.
Responsibilities
Job Description
Veeam Software is the leader in data backup, recovery, and ransomware protection with over 400,000 customers world-wide.

We are seeking a Senior Data Engineer to join our internal data team. As a Senior Data Engineer, you will be responsible for designing, implementing, and maintaining our data infrastructure, pipelines, and data processes. You’ll work closely with teams across the enterprise to grow Veeam’s business and drive digital transformation.

Responsibilities
Design, develop, and maintain scalable and efficient data models, infrastructure, pipelines, and ETL/ELT processes.
Collaborate with analysts, data scientists, and business stakeholders to understand their data needs and requirements.
Work closely with architecture and DevOps teams to ensure the reliability and scalability of data systems.
Build and maintain data quality checks to ensure data accuracy and consistency. Document data systems, data flow, and data infrastructure.
Provide feedback to data engineering team and provide technical guidance to other teams.
Requirements
5+ years of professional experience in data engineering
Expert proficiency in SQL and at least one programming language (e.g., Java, Python, Scala).
Experience with cloud-based data platforms (e.g., AWS, Azure, GCP)
Understanding of data modeling and data warehouse, data lake, and cloud architecture
Experience delivering code in a CI/CD framework
Continuous drive to simplify, streamline, and improve operational efficiency
A high-level of curiosity to explore, evaluate, and deploy new methods and technology to improve our data platform and processing
Willing to work with geo-diverse teams in a flexible work environment, with some hours to accommodate international time zones
Must be eligible for a US Security clearance – classified level
Good written and oral English language skills (B1 or higher)
Preferred Qualifications
Ability to secure Secret or above US Government clearance; willingness to take a polygraph exam
Experience with Kotlin/Java/Scala
Experience with AWS
Experience with Postgres and Vertica
Experience with Salesforce data
Experience with data visualization tools, especially Tableau
Clearance: Veeam has US government and enterprise customers, and our systems and software may manage sensitive information for various governments. As a result, this position may require you to apply for Secret Security Clearance or above. Applicants selected may be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance may be required.
#LI-Remote
#LI-JW1
Qualifications
Must be eligible for a US Security clearance - classified level.",$1 to $5 billion (USD),Enterprise Software & Network Solutions,Company - Private,Information Technology
IT Senior Data Engineer,atlanta,"Boston Consulting Group
4.4","Atlanta, GA",4.4,-1,-1,-1,-1,-1,-1,10000+ Employees,1963,"WHAT YOU'LL DO

Understand the business needs through partnership with Marketing Data Hub Product Owner and Chapter Lead to obtain deep knowledge of data requirements for stakeholders.
Independently design, build and launch new data extraction, transformation and loading processes in production, mentoring others around efficient queries.
Support existing processes running in production and implement optimized solutions with limited guidance.
Integrate data from a wide variety of sources, including on premise databases and external data sources with rest APIs and other replication tools.
Participate in architecture design and implementation of high-performance, scalable and optimized data pipelines.
Monitor daily execution, diagnose and log issues, and fix business critical pipelines to ensure SLAs are met with internal stakeholders
Bridge gap between business requirements and ETL logic by troubleshooting data discrepancies and implementing scalable solutions
Propose and implement data model and ETL code improvements to improve pipeline efficiency and data quality
Recognize and adopt best practices in Data engineering: data integrity, test design, analysis, validation, and documentation
Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations

YOU'RE GOOD AT

Designing, developing & tuning medium-high complexity data applications/pipelines on large scale data platform
Strong problem-solving skills and able to analyze data to identify deliverables, gaps, and inconsistencies.
Able to manage conflicting priorities
Excellent written and verbal communication skills and ability to succinctly summarize key findings
Communicating effectively with teams in a matrixed organization with varying technical backgrounds & data expertise
Intellectually curious and continuously striving to learn.
Being a team player, open, pleasure to work with and positive in a group dynamic, ability to work collaboratively in virtual teams and someone who is self-starter and highly proactive.

YOU BRING (EXPERIENCE & QUALIFICATIONS)

Bachelor’s Degree in Computer Science or equivalent
4+ years of relevant experience in Data Engineering stream
Expert in creating API integrated data pipelines using Python for extracting data from different sources.
Advanced knowledge of different AWS technologies like AWS Lambda, AWS Glue, CloudFormation etc.
Working knowledge of CI/CD based deployments using Github and Jenkins
Expertise in SQL, especially within cloud-based data warehouses like Snowflake
Exposure to unstructured datasets and ability to handle XML, JSON file formats
Professional experience in building robust data pipelines using ETL tools (e.g. Alteryx, Talend, SSIS etc.)
Understanding of version controlling tools like Github, SVN etc.
Knowledge of Dbt cloud for orchestrating data models is preferred
Experience of working on complex projects, including strategic and tactical planning and implementation, analysis, design, technology selection and deployment
Experience with Agile and Scrum is preferred

YOU'LL WORK WITH

You will be a member of the Data Hub Squad, a team of passionate individuals whose mission is to ingest, transform, streamline and expose quality data to internal teams and to enable the Marketing function to make data driven decisions. This position will involve daily collaboration with the Chapter Lead, Product Owner, and the rest of the development teams within the Marketing Product Portfolio, as well as stakeholders and vendors throughout Agile design, development, implementation and operations of both infrastructure and business mappings to offer greater visibility and streamlined integrations.
Candidates should be aware that BCG currently maintains a policy requiring all US & Canada based employees to be fully vaccinated against COVID-19. Newly hired employees must be fully vaccinated prior to their employment start date. BCG is an equal opportunity employer and will provide a reasonable accommodation to those unable to be vaccinated for medical or religious reasons where it is not an undue hardship to the company to do so as provided under applicable federal, state, provincial and local law.",$5 to $10 billion (USD),Business Consulting,Company - Private,Management & Consulting
Lead Building Automation and Controls Engineer(Mission Critical/Data Center),atlanta,"WSP
3.7","Atlanta, GA",3.7,$77K - $115K (Glassdoor est.),-1,-1,-1,-1,-1,10000+ Employees,Company - Private,"Lead Building Automation and Controls Engineer(Mission Critical/Data Center)

Who We Are
At WSP, we are driven by inspiring future-ready pioneers to innovate. We’re looking to grow our teams with people who are ready to collaborate in building communities and expanding our skylines. To do this, we hire candidates of all experiences, skillsets, backgrounds and walks of life. We actively foster a work environment and culture where inclusion and diversity is part of our fundamental structure. This is delivered behaviorally, through our policies, trainings, local partnerships with professional diverse organizations, internal networks and most importantly with the support and sponsorship of our leaders who help drive our commitment to an inclusive, diverse, welcoming and equitable work environment. Anything is within our reach and yours as a WSP employee. Come join us and help shape the future!
This Opportunity
kW Mission Critical Engineering, a WSP USA company, is currently initiating a search for a Lead Building Automation and Controls Engineer for our kW office out of Atlanta, GA office (115 Perimeter Center Place, Suite 640 Atlanta GA 30346)

As a Lead Building Automation and Controls Engineer, you will design automation control and monitoring systems serving data centers. Applications include heat rejection systems including industrial air handling units and chilled water plants as well as integration to intelligent HVAC and electrical power monitoring systems (EPMS). Design activities include drawing and specification development for control products, points lists and Sequence of Operations. The ideal candidate will possess experience with HVAC control applications from a controls systems vendor, commissioning agent, or design consultant. Candidates should have strong communication skills, and an interest in liaising with internal and external design, client and construction team members.
Your Impact
Work in a team or independently, planning and executing engineering tasks within projects
Demonstrate significant understanding of the range of services provided by the kW MCE engineering teams & related practices
Independently, under general supervision, supports the team during proposal design, and construction stages of projects
Lead the controls design of complex projects
Work within multi-discipline project teams to develop drawing and specification documents for issuance to architects, contractors and building owners.
Attend client meetings
Lead and manage a team of entry-level and junior engineers
Collaborate and coordinate with internal project discipline team members and external equipment vendors and manufacturers
Communicate complex control and monitoring concepts and decisions to clients and stakeholders
Listen to complex mechanical & electrical engineering requirements and integrate into larger facility controls and monitoring designs
Interact regularly with clients, which includes maintaining current relationships and developing new relationships
Lead meetings with internal and external stakeholders
Work independently to research and recommend fundamental components identified in mechanical designs
Provide oversight of all aspects of controls designs, review systems, drawings prior to issuance
Survey and evaluate existing conditions
Perform construction administration tasks
Mentor and lead junior controls staff
Who You Are
Required Qualifications
Bachelor's degree in Mechanical Engineering or Electrical Engineering with mechanical building systems or controls systems emphasis
7+ years of experience in designing control systems for the high performing, commercial, industrial or mission critical/data center buildings.
Excellent verbal and written communication skills.
Experience with applicable software packages including AutoCAD, Revit
Knowledge of building, mechanical, electrical and energy codes.
Ability to organize and present design information to project staff
Attention to detail, highly organized, self-starter
Ability to travel to project sites
Exercise responsible and ethical decision-making regarding company funds, resources and conduct and adhere to WSP""s Code of Conduct and related policies and procedures
Proven track record of upholding workplace safety and ability to abide by WSP""s health, safety and drug/alcohol and harassment policies
Preferred Qualifications:
Registered Professional Engineer (PE)
Mission Critical/Data Center experience highly preferred
Experience with international projects
#LI-JB3
Additional Requirements
To perform this job successfully, an individual must be able to perform each essential job duty satisfactorily. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform essential job functions.
Additional Details
Travel Required: 80%
Job Status: Regular
Employee Type: Full
Primary Location: ATLANTA - PERIMETER CENTER
All locations: US-GA-Atlanta, US-GA-College Park, US-GA-Covington, US-GA-Kennesaw, US-GA-Marietta, US-GA-Savannah
About WSP
WSP USA is the U.S. operating company of WSP, one of the world's leading engineering and professional services firms. Dedicated to serving local communities, we are engineers, planners, technical experts, strategic advisors and construction management professionals. WSP USA designs lasting solutions in the buildings, transportation, energy, water and environment markets. With more than 15,000 employees in over 300 offices across the U.S., we partner with our clients to help communities prosper. www.wsp.com
WSP provides a flexible and agile workplace model while meeting client needs. Employees are also afforded a comprehensive suite of benefits including medical, dental, vision, disability, life, and retirement savings focused on providing health and financial stability throughout the employee’s career.
At WSP, we want to give our employees the challenges they seek to grow their careers and knowledge base. Your daily contributions to your team will be essential in meeting client objectives, goals and challenges. Are you ready to get started?
WSP USA (and all of its U.S. companies) is an Equal Opportunity Employer Race/Age/Color/Religion/Sex/Sexual Orientation/Gender Identity/National Origin/Disability or Protected Veteran Status.
The selected candidate must be authorized to work in the United States.",-1,-1,$5 to $25 million (USD),-1
Senior Data Engineer,atlanta,"ProIT Inc.
4.9","Atlanta, GA",4.9,Employer Provided Salary:$110K - $121K,4.8,4.6,4.9,4.6,4.6,51 to 200 Employees,Company - Private,"Senior ETL developer– SSIS, and Strong experience on SQL server, Linux/Unix scripting. · At least 7 years’ experience developing enterprise class data pipelines using Informatica PowerCenter, MS SQL Server, Control M. · Good understanding of the Data warehousing concepts, SQL server, Oracle SQL, or any other database SQL expertise. · Understand the business needs that translate them into a scalable, automated solution. · Designing processes that can extract/receive data from various heterogeneous source systems · Design, develop, test, and support new capabilities and ongoing changes within the various application data marts · Experience writing complex SQL queries, SQL Tuning and knowledge of database design and development (SQL and TSQL) · Create a ETL data flow diagrams based on the business requirements and pseudo logic. · Building capabilities to exchange the data with external partners in various formats (XML, CSV, Flat File, JSON) · Perform data cleansing and transforming the data according to business rules · At least 2 years of experience working in Agile - Scrum teams · Developing reusable frameworks for data extraction, loading and cleansing · Strong technical background covering ETL environments with PowerCenter, Shell scripting, python. · Design, develop, test, and support new capabilities and ongoing changes within the various application data marts · Should work with the multiple teams to understand the requirements, Design, Develop and test the interfaces · Should have experience with Unit and Integration Testing process · Strong Data Warehousing skills including Data profiling, Data masking, Auditing in ETL. · Experience extracting data from a variety of sources, and a desire to expand those skills (SQL server, Oracle) · Work with data owners to document data mappings and transformations to support effective downstream analytics and alerts · Update the team on a daily or weekly basis in case of any project blockers and red flags · Provide performance improvement related guidance for scalability and reusability of code and data objects. · Apply specialized knowledge in assembly or integration, cross-discipline functions, knowledge engineering, industry expertise, or legacy evolution · Should have good coordination skills and Data Analysis skills. · Should have experience with Unit and Integration Testing process · Raise software access requests to any database servers, tools and SharePoint portals required for the project.
Job Type: Full-time
Pay: $110,131.31 - $120,857.06 per year
Benefits:
401(k)
Dental insurance
Health insurance
Vision insurance
Schedule:
8 hour shift
Weekend availability
Ability to commute/relocate:
Atlanta, GA 30303: Reliably commute or planning to relocate before starting work (Required)
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: Hybrid remote in Atlanta, GA 30303",-1,-1,Unknown / Non-Applicable,-1
"Senior Software Engineer, Data Engineering",atlanta,"S&P Global
4.1","Atlanta, GA",4.1,Employer Provided Salary:$68K - $140K,3.8,4.2,3.8,3.8,4.2,10000+ Employees,1860,"The Role: Data Engineer
Location: Team is in Boston, but is available for remote or on-site throughout the US.
GL (for internal use only): 10

Panjiva is a data-driven technology company that uses machine learning to provide powerful search, analysis, and visualization of billions of shipping records from nearly every country in the world. More than 3,000 customers in over 100 countries, ranging from Fortune 500 companies and startups to government agencies and hedge funds, rely on our platform for supply chain intelligence. In global trade, better insight means better decision making and stronger connections between companies and governments across the globe.

Recognizing Panjiva’s cutting-edge technology, S&P Global acquired Panjiva in 2018. This acquisition has grown our resources, dramatically expanded our access to data, and accelerated our growth plans. People are Panjiva’s greatest strength – join our engineering team as we map out a key part of the world economy!
Job Description
As a data engineer on our team, you will play a key role in developing our next-generation data science infrastructure and underlying core technologies. You will work with Panjiva’s world-class data scientists, analysts, and engineers to create products that solve important real-world business problems in a collaborative, fast-paced, and fun environment.

You’ll work closely with our data science team to develop new platforms, infrastructure, and tools that will allow for machine learning applications at production scale over ever-growing datasets.

You’ll design and leverage distributed computing technologies, data schemas, and APIs to construct data science pipelines. In addition, you’ll be expected to participate in augmenting our infrastructure to seamlessly integrate new data sets through constant R&D of the technologies and systems we use.
Join us in building the next generation of products as we continue to deliver valuable and actionable insights to decision-makers in the $15 trillion global trade industry.

Responsibilities
Architect and implement distributed systems that perform complex transformations, processing, and analysis over very large scale datasets
Develop processes to monitor and automate detection of quality regressions in raw data or in the output of Panjiva’s machine learning models
Working with our data scientists to turn large-scale messy, diverse, and often unstructured data into a source of meaningful insights for our customers
Optimizing slow-running database queries and data pipelines
Helping enhance our search engine, capable of running sophisticated user queries quickly and efficiently
Building internal tools and backend services to enable our data scientists and product engineers to improve efficiency
Qualifications
B.S., M.S., or Ph.D. in Computer Science (or a related field) or equivalent work experience
4+ years of experience working with data-at-scale in a production environment
Experience designing and implementing large-scale, distributed systems
Experience in multi-threaded software development (or some form of parallelism)
Significant performance engineering experience (e.g., profiling slow code, understanding complicated query plans, etc.)
Solid understanding of core algorithms and data structures, including the ability to select (and apply) the optimal ones to computationally expensive operations over data-at-scale
Strong understanding of relational databases and proficiency with SQL
Deep knowledge of at least one scripting language (e.g., Python, Ruby, JavaScript)
Deep knowledge of at least one compiled language (e.g., Scala, C++, Java, Go)
Experience developing software on Linux-based operating systems
Experience with distributed version control systems
Nice-to-Haves
Familiarity with relational database internals (especially PostgreSQL)
Proficiency with cloud computing platforms, specifically AWS
Working knowledge of probability & statistics
Contributions to open-source software
Experience building customer-centric products

Compensation/Benefits Information:
S&P Global states that the anticipated base salary range for this position is $68,300 to $140,000 . Base salary ranges may vary by geographic location.
This role is eligible to receive S&P Global benefits. For more information on the benefits we provide to our employees, visit https://www.spgbenefitessentials.com/newhires .

About S&P Global
S&P Global delivers essential intelligence that powers decision making. We provide the world’s leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you’ll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape.

S&P Global Market Intelligence partners with customers to broaden their perspective and operate with confidence by bringing them leading data sources and technologies that embed insight in their daily work.
We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can.

-----------------------------------------------------------

Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment.

If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.

US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law.

----------------------------------------------------------- 20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.1 - Middle Professional Tier I (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)

Job ID: 266145
Posted On: 2023-05-25
Location: Cambridge, Massachusetts, United States",$10+ billion (USD),Research & Development,Company - Public,Management & Consulting
Lead Building Automation and Controls Engineer(Mission Critical/Data Center),atlanta,"WSP
3.7","Atlanta, GA",3.7,$77K - $115K (Glassdoor est.),-1,-1,-1,-1,-1,10000+ Employees,Company - Private,"Lead Building Automation and Controls Engineer(Mission Critical/Data Center)

Who We Are
At WSP, we are driven by inspiring future-ready pioneers to innovate. We’re looking to grow our teams with people who are ready to collaborate in building communities and expanding our skylines. To do this, we hire candidates of all experiences, skillsets, backgrounds and walks of life. We actively foster a work environment and culture where inclusion and diversity is part of our fundamental structure. This is delivered behaviorally, through our policies, trainings, local partnerships with professional diverse organizations, internal networks and most importantly with the support and sponsorship of our leaders who help drive our commitment to an inclusive, diverse, welcoming and equitable work environment. Anything is within our reach and yours as a WSP employee. Come join us and help shape the future!
This Opportunity
kW Mission Critical Engineering, a WSP USA company, is currently initiating a search for a Lead Building Automation and Controls Engineer for our kW office out of Atlanta, GA office (115 Perimeter Center Place, Suite 640 Atlanta GA 30346)

As a Lead Building Automation and Controls Engineer, you will design automation control and monitoring systems serving data centers. Applications include heat rejection systems including industrial air handling units and chilled water plants as well as integration to intelligent HVAC and electrical power monitoring systems (EPMS). Design activities include drawing and specification development for control products, points lists and Sequence of Operations. The ideal candidate will possess experience with HVAC control applications from a controls systems vendor, commissioning agent, or design consultant. Candidates should have strong communication skills, and an interest in liaising with internal and external design, client and construction team members.
Your Impact
Work in a team or independently, planning and executing engineering tasks within projects
Demonstrate significant understanding of the range of services provided by the kW MCE engineering teams & related practices
Independently, under general supervision, supports the team during proposal design, and construction stages of projects
Lead the controls design of complex projects
Work within multi-discipline project teams to develop drawing and specification documents for issuance to architects, contractors and building owners.
Attend client meetings
Lead and manage a team of entry-level and junior engineers
Collaborate and coordinate with internal project discipline team members and external equipment vendors and manufacturers
Communicate complex control and monitoring concepts and decisions to clients and stakeholders
Listen to complex mechanical & electrical engineering requirements and integrate into larger facility controls and monitoring designs
Interact regularly with clients, which includes maintaining current relationships and developing new relationships
Lead meetings with internal and external stakeholders
Work independently to research and recommend fundamental components identified in mechanical designs
Provide oversight of all aspects of controls designs, review systems, drawings prior to issuance
Survey and evaluate existing conditions
Perform construction administration tasks
Mentor and lead junior controls staff
Who You Are
Required Qualifications
Bachelor's degree in Mechanical Engineering or Electrical Engineering with mechanical building systems or controls systems emphasis
7+ years of experience in designing control systems for the high performing, commercial, industrial or mission critical/data center buildings.
Excellent verbal and written communication skills.
Experience with applicable software packages including AutoCAD, Revit
Knowledge of building, mechanical, electrical and energy codes.
Ability to organize and present design information to project staff
Attention to detail, highly organized, self-starter
Ability to travel to project sites
Exercise responsible and ethical decision-making regarding company funds, resources and conduct and adhere to WSP""s Code of Conduct and related policies and procedures
Proven track record of upholding workplace safety and ability to abide by WSP""s health, safety and drug/alcohol and harassment policies
Preferred Qualifications:
Registered Professional Engineer (PE)
Mission Critical/Data Center experience highly preferred
Experience with international projects
#LI-JB3
Additional Requirements
To perform this job successfully, an individual must be able to perform each essential job duty satisfactorily. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform essential job functions.
Additional Details
Travel Required: 80%
Job Status: Regular
Employee Type: Full
Primary Location: ATLANTA - PERIMETER CENTER
All locations: US-GA-Atlanta, US-GA-College Park, US-GA-Covington, US-GA-Kennesaw, US-GA-Marietta, US-GA-Savannah
About WSP
WSP USA is the U.S. operating company of WSP, one of the world's leading engineering and professional services firms. Dedicated to serving local communities, we are engineers, planners, technical experts, strategic advisors and construction management professionals. WSP USA designs lasting solutions in the buildings, transportation, energy, water and environment markets. With more than 15,000 employees in over 300 offices across the U.S., we partner with our clients to help communities prosper. www.wsp.com
WSP provides a flexible and agile workplace model while meeting client needs. Employees are also afforded a comprehensive suite of benefits including medical, dental, vision, disability, life, and retirement savings focused on providing health and financial stability throughout the employee’s career.
At WSP, we want to give our employees the challenges they seek to grow their careers and knowledge base. Your daily contributions to your team will be essential in meeting client objectives, goals and challenges. Are you ready to get started?
WSP USA (and all of its U.S. companies) is an Equal Opportunity Employer Race/Age/Color/Religion/Sex/Sexual Orientation/Gender Identity/National Origin/Disability or Protected Veteran Status.
The selected candidate must be authorized to work in the United States.",-1,-1,$5 to $25 million (USD),-1
Principal Analytics Data Engineer,atlanta,"ADP
4.0","Alpharetta, GA",4.0,-1,-1,-1,-1,-1,-1,10000+ Employees,1949,"ADP is hiring a Principal Analytics Data Engineer for our newly formed HR Outsourcing (HRO) Data and Analytics organization. The Principal Analytics Data Engineer will play a key role in growing our newest chapter of analytics engineering professionals while interacting with cross-functional teams to address complex business requirements. We're seeking a value seeking, self-motivated, and analytical profession who act as a player and coach to multiple workstreams at the same time. The role demands the individual to possess technical skills required to perform the job in an effective manner. The right candidate will be a technical expert, should have the passion for data & analytics and works along with the team they manage.

What are we looking for?

An analytics and data engineering professional with a passion and track record for designing analytics and delivery methods to increase accuracy of reporting and advanced analytics in an agile environment to unlock transformational growth. Someone with intellectual curiosity who wakes up excited to work with a team towards excellence and partner with leaders to drive business outcomes and deliver analytical solutions. The ideal candidate is business-minded, customer-centric, team-oriented, self-motivated, a strategic thinker and results-driven.

Like what you see? Apply now!
Learn more about ADP at tech.adp.com/careers
Learn more about Client Services at ADP : https://adp.careers/Client_Services_Videos

A little about ADP: We are a global leader in HR technology, offering the latest AI and machine learning-enhanced payroll, tax, HR, benefits, and much more. We believe our people make all the difference in cultivating an inclusive, down-to-earth culture that welcomes ideas, encourages innovation, and values belonging. ADP has a deep commitment to diversity, equity, and inclusion as a global Best Places to Work, DiversityInc® Top 50 Company, Best CEO and company for women, LGBTQ+, multicultural talent, and more. Learn more about ADP's commitment on our YouTube channel: http://adp.careers/DEI_Videos

WHAT YOU'LL DO:

Behaviors:
Lead workstreams that thrive. As an experienced leader, you want everyone to shine. You are constantly looking for ways to share your knowledge, motivate others, and keep everyone engaged and productive.
Customer focused. You marry data strategy to business strategy. A trusted partner to key stakeholders across business and analytics functions who understands how data can be activated to deliver value. Your teams are responsible for democratizing data for data science and advanced applications.
Clear Communicator . Ability to tell data stories to senior leaders and communicate working plans to the team. Excellent communication skills, both verbal and written; able to communicate effectively with multiple leadership layers and across a broad base of team members. Effective at increasingly complex stakeholder alignment, where priorities often compete, drives transparency on priorities and expected return
Create Results. You're proactive and hands-on when need. When you see a potential issue, you never leave things hanging and unfinished. When you and your team deliver a finished product, it's as polished as you could make it.
Variety of work. There is no typical day. You could be checking in with the CDO one minute, meeting with leadership to review initiatives for the coming quarter later and tomorrow helping your team overcome blockers.
Influence and inspire confidence. You are comfortable presenting to senior leaders, analytics and program management leads, and peers with a compelling voice that you demonstrate through executive presence, leading change, and creating clear executive-level communications on milestone achievements.
Continuous improvement. Document current analytics and automation processes and recommend and implement best practices to improve and optimize.
Challenges. Inevitable challenges will arise, and we'll rely on you to look for a solution.

Responsibilities:
Catalog current analytics and automation processes and recommend best practice methods for improvement and optimization
Partner with Analytics, Data Product, and Business stakeholders to create roadmaps and execute project plans in fast-paced agile development environment
Create use-case specific data tables by joining and engineering critical elements across multiple data domains. Ingests HRO-specific data, ensuring it is well-structured, adheres to data quality rules, and traceablefrom consumption layer back to raw layer.
Partner with the Advanced Analytics and Strategic Operations to streamline data integration, maintain security and access best practices, and create end-to-end data analytics solutions
Mentor more junior team members that will work in matrix pod to support advanced analytics initiative
Research and recommend technologies and processes to support rapid scale and future state growth initiatives
Help your team prioritize Business Needs, Leadership Questions, and Ad Hoc Requests for on-time delivery
Manage workstream leadership reporting, and continuous improvement initiatives
Drive QA and Data Quality efforts to improve development timelines, reduce bugs, and maintain reliable analytics products
Support projects that improve our performance (e.g. Retention & Future of Work): aligning with product strategy and understanding stakeholder requirements
Experienced getting to a v0.5 solution, getting real world feedback, and then iterating to v1.0+ with a continuous improvement mindset
Successful track record of superior service delivery and change management in an enterprise organization

To succeed in this role:
Bachelor's degree in computer science, engineering, business, statistics, or related fields; advanced degree preferred
At least 8-10 years of experience with analytics, engineering and leading implementation, development, improvement and support projects
3+ years in team lead role
Work experience with ETL, Data Modelling and Data Architecture
Preferably working in PEO, Service, or Risk analytics, data engineering, data analytics and visualization, business intelligence, or analytical consulting
Proven ability to guide team to use data, analytics, and business knowledge to solve complex business problems
Experience with designing and maintaining data warehouses and/or data lakes with big data technologies like Hadoop, Spark, or distributed databases like Redshift and Snowflake, and experience with housing, accessing, and transforming data in a variety of relational databases
Experience in building data pipelines and deploying / maintaining them with tools like Git and Jenkins
Knowledge with MLOps infrastructure (e.g., Databricks, MLflow) and containerization and managing production pipelines and microservices (e.g., Docker, Kubernetes)
Experience and skill with data mining methods, data modeling, and working with data warehouses
Pyspark and SQL expertise
Understanding of agile methodologies and what makes teams successful

A college degree is great but not required. What's more important is having the skills to do the job. If you don't have a college degree, other acceptable experiences could include:

Experience noted above, OR

Military experience where skills including teamwork, adaptability, organization, and follow-through will help you build team and client relationships, identify solutions, and achieve success.

Preferred Qualifications
Advanced degree (Masters) in Software engineering, Data engineering, Computer Science, or other data management and data visualization disciplines. MBA.
Hands-on experience on Bigdata Technologies like Apache Spark , Hive, Hadoop
Experience with developing frameworks and utility services including logging/monitoring
Strong technical knowledge of DataBricks
Knowledge of UNIX/Python programming language.
Experience delivering high quality software following continuous delivery and using code quality tools (JIRA,GitHub, Jenkin, Sonar, etc.).
Experience creating large-scale, multi-tiered, distributed applications with Hadoop and ETL tool like Abinitio
Comfortable in Windows and Linux environments.
Comfortable with different data storage solutions such as RDMBS(Oracle), Hive, HBase, Impala etc.
Knowledge on NOSQL Databases like MongoDB, Hbase, Cassandra etc is a plus.
Jira and Confluence preferred
Nice to have data solutions architect experience
Knowledge with dashboarding tools (e.g., Dash, Shiny, Tableau)
Experience with cloud database technologies (e.g., AWS) and developing solutions on cloud computing services and infrastructure in the data and analytics space
Comfortable using PySpark APIs to perform advanced data transformations

YOU'LL LOVE WORKING HERE BECAUSE YOU CAN:
Have courageous team collaboration. Courage comes from how associates are willing to have difficult conversations, speak up, be an owner, and challenge one another's ideas to net out the best solution.
Deliver at epic scale. We deliver real user outcomes using strong judgment and good instincts. We're obsessed with the art of achieving simplicity with a focus on client happiness and productivity.
Be surrounded by curious learners. We align ourselves with other smart people in an environment where we grow and elevate one another to the next level. We encourage our associates to listen, stay agile, and learn from mistakes.
Act like an owner & doer. Mission-driven and committed to leading change, you will be encouraged to take on any challenge and solve complex problems. No tasks are beneath or too great for us. We are hands-on and willing to master our craft.
Give back to others. Always do the right thing for our clients and our community and humbly give back to the community where we live and work. Support our associates in times of need through ADP's Philanthropic Foundation.
Join a company committed to equality and equity. Our goal is to impact lasting change through our actions.

What are you waiting for? Apply today!
Find out why people come to ADP and why they stay: https://youtu.be/ODb8lxBrxrY
(ADA version: https://youtu.be/IQjUCA8SOoA )

#LI-PP1

Explore our COVID-19 page https://tech.adp.com/covid19/ to understand how ADP is approaching safety, travel, the hiring interview process, and more.

Diversity, Equity, Inclusion & Equal Employment Opportunity at ADP: ADP affirms that inequality is detrimental to our associates, our clients, and the communities we serve. Our goal is to impact lasting change through our actions. Together, we unite for equality and equity. ADP is committed to equal employment opportunities regardless of any protected characteristic, including race, color, genetic information, creed, national origin, religion, sex, affectional or sexual orientation, gender identity or expression, lawful alien status, ancestry, age, marital status, or protected veteran status and will not discriminate against anyone on the basis of a disability. We support an inclusive workplace where associates excel based on personal merit, qualifications, experience, ability, and job performance.

Ethics at ADP: ADP has a long, proud history of conducting business with the highest ethical standards and full compliance with all applicable laws. We also expect our people to uphold our values with the highest level of integrity and behave in a manner that fosters an honest and respectful workplace. Click https://jobs.adp.com/life-at-adp/ to learn more about ADP's culture and our full set of values.",$10+ billion (USD),Enterprise Software & Network Solutions,Company - Public,Information Technology
Lead Power Studies Engineer (Mission Critical/Data Center),atlanta,"WSP
3.7","Atlanta, GA",3.7,$71K - $107K (Glassdoor est.),-1,-1,-1,-1,-1,10000+ Employees,Company - Private,"Lead Power Studies Engineer (Mission Critical/Data Center)

Who We Are
At WSP, we are driven by inspiring future-ready pioneers to innovate. We’re looking to grow our teams with people who are ready to collaborate in building communities and expanding our skylines. To do this, we hire candidates of all experiences, skillsets, backgrounds and walks of life. We actively foster a work environment and culture where inclusion and diversity is part of our fundamental structure. This is delivered behaviorally, through our policies, trainings, local partnerships with professional diverse organizations, internal networks and most importantly with the support and sponsorship of our leaders who help drive our commitment to an inclusive, diverse, welcoming and equitable work environment. Anything is within our reach and yours as a WSP employee. Come join us and help shape the future!
This Opportunity
Great people. Great places. Great projects. kW Mission Critical Engineering, a WSP company, is a high-performance, fast-paced consulting engineering firm designing data centers and mission critical environments across the globe. We hire smart, responsive, team players to work in collaborative and mentoring office settings. Our mechanical, electrical, plumbing, fire protection, controls, telecommunications, and security building system designs keep many of the world’s top Fortune 100 financial, technology, enterprise, hyperscale, and colocation companies up and running 24 hours a day, 365 days a year.
We work on innovative, award-winning, large-scale projects. We travel to construction sites to see our designs being built. As part of WSP, we are able to offer our employees increased professional development and career opportunities in addition to kW MCE’s office culture which is consistently recognized as one of the “Best Places to Work.” Join our great people at our great places designing great projects.
kW Mission Critical Engineering, a WSP USA company, is currently initiating a search for a Lead Power Studies Engineer for our Atlanta, GA office. As a Power Studies Engineer with us, you will analyze complex power and other building systems including generator plants, medium voltage distribution, uninterruptible power systems. Selectively coordinate medium voltage relays and low voltage circuit breakers and perform arc flash analysis. Compile data into final report for project leads.
Your Impact
Perform preliminary short circuit calculations to validate equipment ratings during design.
Build power system models which accurately reflect designed and constructed systems.
Perform medium and low-voltage coordination studies to develop optimum protective relay and breaker settings balancing safety and operational reliability.
Evaluate submitted equipment for capability to withstand available fault current at points throughout the distribution system.
Perform arc flash studies in compliance with NFPA and industry standards.
Generate short circuit, coordination, and arc flash study reports, along with arc flash labels.
Perform reliability studies in accordance with IEEE Gold Book standards and industry practices.
Lead junior staff, supervise, train, and mentor.
Coordinate with internal design leads and clients to obtain required information, discuss options, and develop solutions.
Educate clients on the importance of breaker coordination and arc flash.
Perform QA/QC on calculations and studies performed by others.
Refine and maintain standards for power studies and reports across offices.
Assist project management with scheduling, scope development, and proposal development
Who You Are
The ideal candidate has extensive experience in power studies within large scale or mission critical facilities and an interest in production work as well as leading, mentoring and developing a team.
Required Qualifications
Bachelor’s degree in Electrical Engineering
7+ years electrical power studies experience
Technical leadership and strong background in electrical studies
Knowledge of building codes, NFPA 70 & 70E, and IEEE 1584
Significant experience with SKM PowerTools
Big picture mindset, able to see full project mission, not just your discipline
Ability to listen to client needs, engage with design team members, and drive project beyond expectations
Excellent communication skills and the ability to collaborate, lead, and mentor.
Preferred Qualifications:
P.E.
Mission Critical/Data Center experience
Experience with other power studies tools (EasyPower, ETAP, etc)
Protective relaying design experience
Experience with ReliaSoft BlockSim
Additional Requirements
To perform this job successfully, an individual must be able to perform each essential job duty satisfactorily. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform essential job functions.
Additional Details
Travel Required: 20%
Job Status: Regular
Employee Type: Full
Primary Location: ATLANTA - PERIMETER CENTER
All locations: US-GA-Atlanta
About WSP
WSP USA is the U.S. operating company of WSP, one of the world's leading engineering and professional services firms. Dedicated to serving local communities, we are engineers, planners, technical experts, strategic advisors and construction management professionals. WSP USA designs lasting solutions in the buildings, transportation, energy, water and environment markets. With more than 15,000 employees in over 300 offices across the U.S., we partner with our clients to help communities prosper. www.wsp.com
WSP provides a flexible and agile workplace model while meeting client needs. Employees are also afforded a comprehensive suite of benefits including medical, dental, vision, disability, life, and retirement savings focused on providing health and financial stability throughout the employee’s career.
At WSP, we want to give our employees the challenges they seek to grow their careers and knowledge base. Your daily contributions to your team will be essential in meeting client objectives, goals and challenges. Are you ready to get started?
WSP USA (and all of its U.S. companies) is an Equal Opportunity Employer Race/Age/Color/Religion/Sex/Sexual Orientation/Gender Identity/National Origin/Disability or Protected Veteran Status.
The selected candidate must be authorized to work in the United States.",-1,-1,$5 to $25 million (USD),-1
Senior Fullstack Engineer – Product & Benefits Data Hub,atlanta,"Humana
3.9","Atlanta, GA",3.9,-1,-1,-1,-1,-1,-1,10000+ Employees,1961,"The Senior Full Stack Engineer Performs software engineering activities in all layers of the stack, from setting up the database to programming in the back-end and the appearance at the front-end. The Senior Full Stack Engineer work assignments involve moderately complex to complex issues where the analysis of situations or data requires an in-depth evaluation of variable factors.
Responsibilities
The Senior Full Stack Engineer Performs software engineering activities in all layers of the stack, both on-prem and cloud, including hardware and network configs, storage, application development, IAM, etc. The work assignments involve moderately complex to complex issues where the analysis of situations or data requires an in-depth evaluation of variable factors.
Join us and be a part of the unique opportunity to transform Humana into a consumer-focused healthcare leader backed by digital platforms. We’re looking for someone who craves new challenges and solves hard customer problems using the latest in software technology that improve people’s lives. In this role, you will directly work with key client stakeholders to define the business problem and determine solution requirements for our Medicare/Medicaid Product and Benefit Platforms. You will be responsible for ensuring business value and communicating outcomes. You’ll be part of a dynamic agile team to architect, implement, test and continuously deliver new features and products to our customers.

The Senior Full Stack Engineer is involved in all stages of software development, including front-end development, back-end development, database integrations, network and hosting management, user interface, user experience, and back-end server management. Influences department’s strategy. Makes decisions on moderately complex to complex issues regarding technical approach for project components, and work is performed with minimal day-to-day direction with accountability for desired outcomes. Exercises considerable latitude in determining objectives and approaches to assignments.

Required Qualifications
Bachelor's Degree in Computer Science or Information Technology or Related field or in any STEM field
5 or more years of full stack software development experience on 3-tier web applications utilizing Java or .NET technologies and frameworks.
Strong skills in modern Typescript based frameworks and NodeJS.
Expert knowledge in database programming – Relational and No-SQL such as Mongo ATLAS
Proficient in microservices based architecture, REST / Graph APIs
Hands on experience in Docker and Kubernetes
Excellent problem solving skills and attention to detail
Strong verbal and written communication skills
Must be passionate about contributing to an organization focused on continuously improving consumer experiences.

Preferred Qualifications
Master's Degree in the relevant field
Cloud Certification (GCP/AWS)
Experience in Rabbit MQ/Kafka Messaging platforms
Experience in Data streaming utilizing event driven, real-time and batch pub-sub model.
Familiarity with DevOps (Azure/Jenkins/GitHub)

Additional Information
Work-At-Home Requirements
WAH requirements: Must have the ability to provide a high speed DSL or cable modem for a home office. Associates or contractors who live and work from home in the state of California will be provided payment for their internet expense.
A minimum standard speed for optimal performance of 25x10 (25mpbs download x 10mpbs upload) is required.
Satellite and Wireless Internet service is NOT allowed for this role.
A dedicated space lacking ongoing interruptions to protect member PHI / HIPAA information
Scheduled Weekly Hours
40

Not Specified
0",$10+ billion (USD),Health Care Services & Hospitals,Company - Public,Healthcare
"Big Data Engineer - C85793 5.8 Alpharetta, GA (Remote till COVID)",atlanta,CapB InfoteK,"Alpharetta, GA",-1,$69K - $109K (Glassdoor est.),-1,-1,-1,-1,-1,51 to 200 Employees,Company - Private,"We are looking for a Big Data Engineer for our long-term multiyear project out of Alpharetta, GA. (Remote till COVID).

Responsibilities:
5-10 years of hands on experience working with Hadoop and Informatica power center.
Experience in Hadoop ecosystem and experience in applying them to practical problems in Hive, Impala and Spark.
Strong knowledge of working with relational databases like Teradata DB2 Oracle Sql server.
Hands on experience in writing shell scripts on UNIX platform.
Experience in data warehousing ETL tools MPP database systems.
Understanding of Data Models Conceptual Logical and Physical Dimensional Relational Data Model Design.
Analyze functional specifications and assist in designing potential technical solutions Identifies data sources and works with source system team and data analyst to define data extraction methodologies.
Good knowledge in writing complex queries in Teradata DB2 Oracle PL SQL.
Maintain batch processing jobs and respond to critical production issues communicate well with stakeholders on his her proposal recommendations.
Knowledge status risks regarding delivering solution on time.
Strong experience with Data Analysis Data Profiling Root Cause Analysis.
Should able to understand Banking system processes and data flow.
Can work independently lead and mentor the team.",-1,-1,Unknown / Non-Applicable,-1
Sr Site Reliability Engineer – Data Platforms,atlanta,"Genuine Parts Company
3.5","Atlanta, GA",3.5,$83K - $129K (Glassdoor est.),3.0,3.2,3.0,3.1,3.3,5001 to 10000 Employees,1928,"Company Background:
Genuine Parts Company (“GPC” or the “Company”), founded in 1928 and based in Atlanta, Georgia, is a leading specialty distributor engaged in the distribution of automotive and industrial replacement parts and value-added services. The Company operates a global portfolio of businesses with more than 10,000 locations across the world. GPC has approximately 50,000 global employees. The Company has operations in the United States, Canada, Mexico, Australia, New Zealand, Indonesia, Singapore, France, the U.K., Germany, Poland, the Netherlands, Belgium, Spain and China.

Position Purpose:
Seeking world-class talent to join the world’s leading distributor of automotive and industrial replacement parts and value-added services operating 5,500+ locations and servicing more than 20,000 locations in the U.S and Canada. Specifically, this role will function as the engineer to build the next generation commerce platforms for GPC. Working with a highly talented team, you'll play a key role to build and run one of the world’s largest automotive and industrial replacement parts operations.

This is an engineering role with responsibility for enabling cloud transformation and execution for GPC’s unified Data platforms.

This individual must be a technologist & engineer at heart and be comfortable in enabling new technology and being hands on with the execution of the strategy. They must exhibit a deep understanding of modern technology stack and agile delivery models, demonstrated focus on customer experience, and must have a proven track record of modernizing technologies.

Close collaboration and alignment with business teams, application development teams and security will be required. As such, exceptional abilities in building and maintaining strong working relationships and organizational savvy will be required. High level communication and presentation skills are required. Ability to attract, retain, and develop engineering talent will be critical.

Responsibilities:
Data platforms SRE participates and provides feedback in design, development, and implementation of integration processes for Enterprise Data Lake, Data Warehouse and BI Applications
Collaborates with Data Architects, Data Engineers, Business Intelligence Developers, and other teammates to achieve common goals
The Data SRE is responsible for end-to-end service availability and performance of the data platforms
Responsible for meeting defined organizational SLAs, and ongoing tracking and optimizing service availability using established Key Performance Indicators (KPIs)
SRE is responsible for optimizing platform utilization and billing cost containment
Lead incident resolution, Root cause analysis (RCAs), blameless post-mortem, and problem management
Active participant of Disaster Recovery planning and Business continuity planning and drills
Review incident trends, identify recurring issues, build automation to eliminate toil.
Communicate progress and resolution to appropriate stakeholders and leadership
Lead by example, mentor the team, and establish credibility through quality technical execution.
Recommend application changes to improve application performance, reliability, and cost to operate
Review existing processes and recommend changes or institute new processes as necessary, including observability, alerting, operations, engineering, and system tuning, etc.
Generate high-quality documentation detailing the data platform, common patterns, runbooks, SOPs, knowledge base, etc.
Other duties as assigned
Location:
GPC has two work locations to choose from, Duluth or Atlanta office.
We offer a Flexible Work Policy that permits eligible employees to work remotely

Desired Qualifications & Experiences:
Degree in computer science/engineering or equivalent experience
2+ years’ experience (5+ preferred) in SRE or similar roles
2+ years’ experience (5+ preferred) in large-scale RDBMS or Google BigQuery
Experienced in Python, shell scripts, SQL, and PL/SQL scripting
Experienced in Change & Release process, GitHub and CI/CD solutions
Experience in on-prem and public cloud platforms
Experienced in security and Sarbanes-Oxley audits
Experienced in process reviews, continuous improvement, automation, and toil elimination
Experienced in high availability (HA), high transaction volume environments, backup/recovery, and disaster recovery
Strong background in full-lifecycle support across multiple platforms or languages
Ability to interact with tech/non-tech teams in Infrastructure, Network, Development, Business Analysts, and QA teams
Experience in analyzing and recommending solutions for production issues
Familiarity with streaming technologies (STRIIM, Kafka, Pub/Sub) is a plus
Familiarity with Informatica tools (PowerCenter, IICS) is a plus
Familiarity with Business Intelligence tools (Qlik, Power BI) is a plus
Familiarity with Infrastructure as Code (IaC) and Terraform scripting is a plus",Unknown / Non-Applicable,Automotive Parts & Accessories Stores,Company - Public,Retail & Wholesale
